<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[kubernetes 学习笔记]]></title>
    <url>%2F2018%2F07%2F15%2Fk8s-kubernetes-learn-note%2F</url>
    <content type="text"><![CDATA[examplemaster : 172.16.0.105 node_01 : 172.16.0.106node_02 : 172.16.0.107 specification : 规格. Topic 编排 高可用 滚动更新 网络插件 服务发现 监控 数据管理 日志管理 kubernetes 架构kubernetes 由 master 和 node 组成, 节点上运行着若干 kubernetes 服务. Kubernetes 的系统组件都被放到 kube-system 命名空间中, 如 kube-dns 组件, 是在执行 kubeadm init 作为附加组件安装的,为 Cluster 提供 DNS 服务. kubelet 是唯一没有以容器形式运行的 kubernetes 组件, 通过 systemd 服务运行. mastermaster 是 kubernetes 的大脑, 运行的服务有 kube-apiserver, kub-scheduler, kube-controller-manager, etcd, Pod 网络(如 flabbel). kube-apiserver API Server 提供 HTTP/HTTPS RESTful API, 即 Kubernetes API. API Server 是 Kubernetes Cluster 的前端接口, 各种客户端工 以及 kubernetes 其他组件可以通过他管理 cluster 的各种资源. kube-scheduler scheduler 决定 将 Pod 放到那个 Node 上运行. scheduler 在调度时, 会充分考虑 Cluster 的拓扑结构, 当前各节点的负载, 以及应用对高可用, 性能, 数据亲和性的需求. kube-controller-manager Controller Manager 负责管理 Cluster 各种资源, 保证资源处于预期状态. Controller Manager 由多种 controlelr 组成, 不同的 controller 管理不同的资源, 如 replication controller : 管理 Deployment, StatefulSet, DaemonSet 的生命周期 endpoints controller namespace controller : 管理 Namespace 资源 serviceaccounts controller etcd 负责保存 Kubernetes Cluster 的配置信息和各种资源的状态信息, 当数据放生变化时, etcd 会快速的通知 Kubernetes 相关组件. Pod 网络 Pod 之间相互通信, 必须部署 Pod 网络, 如 flannel, calile 等. Node 节点Node 是 Pod 运行的地方, Kubernetes 支持 Docker, rkt 等容器 Runtime. kubelet kubelet 是 Node 的 aget, 当 Scheduler 确定在某个 Node 上运行 Pod 后, 会将 Pod 的具体配置信息(Volume, image等) 发送给该节点的 kubelet, kubelet 会根据这些信息创建和运行 Pod, 并向 master 报告运行状态. kube-proxy service 在逻辑上代表了后端的多个 pod, 外界通过 service 访问 pod. service 接收到的请求 通过 kube-proxy 状态到 pod. Pod 网络 Pod 之间相互通信. kubeadm 安装1. 在 master 操作$ kubeadm init –apiserver-advertise-address 172.16.0.105 –pod-network-cidr=10.244.0.0/16 –apiserver-advertise-address 指明 master 使用 那个 interface 与其他节点 通信 –pod-network-cidr : 制动 pod 网络的范围. k8s 支持多种网络方案, 且不同网络方案对 –pod-network-cidr 有自己的要求, 此处使用 flannel 方案, 必须设置为 CIDR. 返回信息:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071I0715 18:33:03.371488 20968 feature_gate.go:230] feature gates: &amp;&#123;map[]&#125;[init] using Kubernetes version: v1.11.0[preflight] running pre-flight checks [WARNING Service-Docker]: docker service is not enabled, please run &apos;systemctl enable docker.service&apos;I0715 18:33:03.391128 20968 kernel_validator.go:81] Validating kernel versionI0715 18:33:03.391182 20968 kernel_validator.go:96] Validating kernel config [WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 18.03.1-ce. Max validated version: 17.03 [WARNING Hostname]: hostname &quot;izj6c4v865pdzr9a5004a2z&quot; could not be reached [WARNING Hostname]: hostname &quot;izj6c4v865pdzr9a5004a2z&quot; lookup izj6c4v865pdzr9a5004a2z on 100.100.2.138:53: no such host [WARNING Service-Kubelet]: kubelet service is not enabled, please run &apos;systemctl enable kubelet.service&apos;[preflight/images] Pulling images required for setting up a Kubernetes cluster[preflight/images] This might take a minute or two, depending on the speed of your internet connection[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;[preflight] Activating the kubelet service[certificates] Generated ca certificate and key.[certificates] Generated apiserver certificate and key.[certificates] apiserver serving cert is signed for DNS names [izj6c4v865pdzr9a5004a2z kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.16.0.105][certificates] Generated apiserver-kubelet-client certificate and key.[certificates] Generated sa key and public key.[certificates] Generated front-proxy-ca certificate and key.[certificates] Generated front-proxy-client certificate and key.[certificates] Generated etcd/ca certificate and key.[certificates] Generated etcd/server certificate and key.[certificates] etcd/server serving cert is signed for DNS names [izj6c4v865pdzr9a5004a2z localhost] and IPs [127.0.0.1 ::1][certificates] Generated etcd/peer certificate and key.[certificates] etcd/peer serving cert is signed for DNS names [izj6c4v865pdzr9a5004a2z localhost] and IPs [172.16.0.105 127.0.0.1 ::1][certificates] Generated etcd/healthcheck-client certificate and key.[certificates] Generated apiserver-etcd-client certificate and key.[certificates] valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/admin.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/kubelet.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/controller-manager.conf&quot;[kubeconfig] Wrote KubeConfig file to disk: &quot;/etc/kubernetes/scheduler.conf&quot;[controlplane] wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;[controlplane] wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;[controlplane] wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot;[init] this might take a minute or longer if the control plane images have to be pulled[apiclient] All control plane components are healthy after 41.001733 seconds[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace[kubelet] Creating a ConfigMap &quot;kubelet-config-1.11&quot; in namespace kube-system with the configuration for the kubelets in the cluster[markmaster] Marking the node izj6c4v865pdzr9a5004a2z as master by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;[markmaster] Marking the node izj6c4v865pdzr9a5004a2z as master by adding the taints [node-role.kubernetes.io/master:NoSchedule][patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;izj6c4v865pdzr9a5004a2z&quot; as an annotation[bootstraptoken] using token: 41efly.f8cnstm6ao7iz422[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes master has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of machines by running the following on each nodeas root: kubeadm join 172.16.0.105:6443 --token 41efly.f8cnstm6ao7iz422 --discovery-token-ca-cert-hash sha256:eb68f28368883e8c3789da0927d6a70f4ef06526f5a350c5276373dd4bb91cc6 以上 cmd 主要做一下几件事: kubeadm 执行初始化前的检查, 生成 token 和 证书 生成 KubeConfig 文件, kubelet 需要用该文件与 Master 通信 安装 Master 组件, 会从 Google 的 Registry 下载组件的 docker 镜像, 该步骤会花费一些时间, 取决于网络质量. 安装附件组件 kube-proxy 和 kube-dns Kubernetes master 初始化成功 提示如何配置 kubectl 提示如何安装 Pod 网络. 提示如何注册其他节点到 Cluster . 配置 kubectl 1234567## bob 是运行 kubectl 的普通用户.# mkdir /home/bob/.kube# cp -i /etc/kubernetes/admin.conf /home/bob/.kube/config# chown bob.bob /home/bob/.kube/config## 添加自动补全功能, 使用 bob 用户$ echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc 安装 pod 网络 1234567891011## 使用 bob 用户$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.extensions/kube-flannel-ds-amd64 created daemonset.extensions/kube-flannel-ds-arm64 created daemonset.extensions/kube-flannel-ds-arm created daemonset.extensions/kube-flannel-ds-ppc64le created daemonset.extensions/kube-flannel-ds-s390x created 2. node 节点注册到 集群下面的命令由 在 master 上执行 kubeadm 是生成.1$ kubeadm join 172.16.0.105:6443 --token 41efly.f8cnstm6ao7iz422 --discovery-token-ca-cert-hash sha256:eb68f28368883e8c3789da0927d6a70f4ef06526f5a350c5276373dd4bb91cc6 如果没有记录下 token, 可以使用如下命令查看:1$ kubeadm token list 在 master 查看 node 是否注册到 master:12345678910$ kubectl get nodes NAME STATUS ROLES AGE VERSION izj6c4v865pdzr9a5004a2z Ready master 29m v1.11.0 izj6c9a51n762uyn3wfi5qz Ready &lt;none&gt; 1m v1.11.0 izj6cdt5e7ronl6vi6qwkrz Ready &lt;none&gt; 1m v1.11.0一个节点的 ROLE 只是一个 label, 其格式为 `node-role.kubernetes.io/&lt;role&gt;`, 可以手动添加:$ kubectl label nodes 如果 节点处于 NotReady 状态, 则可能是因为, 每个节点需要启动若干组件, 这些组件都在 Pod 中运行, 而这些镜像需要从 Google 下载, 如果尚处于下载中, 则可能处于 NotReady 状态. 1234567## 查看 Pod 状态$ kubelet get pod --all-namespaces$ kubectl get pod --namespace=default -o wide ## 指定 namespace, 并拓展输出信息.## 查看 Pod 的具体状态$ kubectl describe pod POD_NAME --namespace=kube-system 3. kubernetes master 节点 pod 调度出于安全考虑, 默认配置下, Kubernetes 不会讲 Pod 调度到 master, 如果希望将 k8s-master 也当做 Node 使用, 可执行如下命令:$ kubectl taint node k8s-master node-role.kubernetes.io/master- 取消 k8s-master 调度 pod:$ kubectl taint node izj6c4v865pdzr9a5004a2z node-role.kubernetes.io/master=&quot;&quot;:NoSchedule 取消调度, 并不会使 在k8s-master 可调度期间运行在 k8s-master 上的 pod 停止. 停止运行在 master 节点上的 pod 有两种方式: 强制杀掉在 master 上运行的 pod 重新调度. $ kubectl delete pod nginx-deployment-cfg-5799655d4d-xrqhz 在 deployment 缩容时, 取消 taint 的 master 节点上的 pod 优先被停止. kubernetes 运行应用.kubernetes 中对象的命名方式是: 子对象名字 = 父对象名字 + 随机字符串. kubernetes 支持两种创建资源的方式, 使用 kubectl 命令直接创建, 在命令行中通过参数执行资源的属性. 简单, 直观, 快捷, 适合临时测试或者实验. 通过配置文件和 kubectl apply 创建, 配置文件采用 YAML 格式. 配置文件描述了最终的状态, 并可以提供创建资源的模板, 可以重复使用. 可以做版本控制和管理, 适合正式的, 跨环境的, 规模化部署. kubectl apply 不仅能够创建资源, 也能够对资源进行更新, 非常方便. 同时, Kubernetes 还提供了类似的其他命令, 如 kubectl create, kubectl replace, kubectl edit, kubectl patch. Deployment12345## 运行一个 deployment$ kuberctl run nginx-deployment --image=nginx --replicas=2## 查看运行结果$ kubectl get deployment nginx-deployment 查看 deployment 详细信息1234567$ kubectl describe deployment nginx-deployment OldReplicaSets: &lt;none&gt; NewReplicaSet: nginx-deployment-75d95848db (2/2 replicas created) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 3m deployment-controller Scaled up replica set nginx-deployment-75d95848db to 2 如上的 deployment 信息, 可以看到创建了一个 ReplicaSet nginx-deployment-75d95848db , Events 是 Deployment 的日志, 记录了 ReplicaSet 的启动过程. 即 Deployment 是通过 ReplicaSet 来管理 Pod 的. 可以执行 kubectl describe replicaset nginx-deployment-75d95848db 得到印证. 12345678910111213141516171819202122232425262728293031$ kubectl describe replicaset nginx-deployment-75d95848dbName: nginx-deployment-75d95848db... ...Controlled By: Deployment/nginx-deployment... ...Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal SuccessfulCreate 7m replicaset-controller Created pod: nginx-deployment-75d95848db-tdfcs Normal SuccessfulCreate 7m replicaset-controller Created pod: nginx-deployment-75d95848db-58f9t$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-deployment-75d95848db-58f9t 1/1 Running 0 11mnginx-deployment-75d95848db-tdfcs 1/1 Running 0 11m$ kubectl describe pod nginx-deployment-75d95848db-58f9tName: nginx-deployment-75d95848db-58f9tNamespace: defaultNode: izj6c9a51n762uyn3wfi5qz/172.16.0.106... ...Controlled By: ReplicaSet/nginx-deployment-75d95848db... ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 12m default-scheduler Successfully assigned default/nginx-deployment-75d95848db-58f9t to izj6c9a51n762uyn3wfi5qz Normal Pulling 12m kubelet, izj6c9a51n762uyn3wfi5qz pulling image &quot;nginx&quot; Normal Pulled 12m kubelet, izj6c9a51n762uyn3wfi5qz Successfully pulled image &quot;nginx&quot; Normal Created 12m kubelet, izj6c9a51n762uyn3wfi5qz Created container Normal Started 12m kubelet, izj6c9a51n762uyn3wfi5qz Started container deployment , replicaset, pod 关系如下: 12345deployment nginx-deployment | |replicaset ==&gt; nginx-deployment-75d95848db / \ / \pod pod nginx-deployment-75d95848db-58f9t nginx-deployment-75d95848db-tdfcs Deployment 配置文件12345678910111213141516171819202122232425apiVersion: extensions/v1beta1kind: Deploymentmetadata: name: nginx-deployment-cfgspec: replicas: 2 template: metadata: labels: app: web_server spec: containers: - name: nginx image: nginx-- 配置选项说明:apiVersion : 当前配置格式版本kind : 要创建的资源类型, 此处为 Deploymentmetadata : 该类型资源的元数据, name 为 必选项.spec : 该 Deployment 的规格说明.replicas : 指明副本数量, 默认为 1template : 定义 Pod 的模板, 这个配置文件的重要部分.metadata : 定义 Pod 的元数据, 至少需要定义一个 label. label 的 key 和 value 可以任意指定.spec : 描述 Pod 的规格, 此部分定义 Pod 中每一个容器的属性, name 和 image 是 必选项. 使用配置文件创建 deployment 123456789101112131415$ kubectl apply -f deployment/nginx-deployment.yml deployment.extensions/nginx-deployment-cfg created$ kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment-cfg 2 2 2 2 17s$ kubectl get replicaset NAME DESIRED CURRENT READY AGE nginx-deployment-cfg-5799655d4d 2 2 2 51s$ kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE nginx-deployment-cfg-5799655d4d-krxnl 1/1 Running 0 59s 10.244.2.4 izj6cdt5e7ronl6vi6qwkrz nginx-deployment-cfg-5799655d4d-x95hb 1/1 Running 0 59s 10.244.1.4 izj6c9a51n762uyn3wfi5qz 删除 deployment12345$ kubectl delete deployment nginx-deployment-cfg或者$ kubectl delete -f deployment/nginx-deployment.yml 扩缩容编辑 deployment 的配置文件, 修改 replicas 配置项, 就可以实现. 12345678910111213141516171819202122$ kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 2 2 2 2 41m$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE nginx-deployment-cfg-5799655d4d-9qwvx 1/1 Running 0 1m 10.244.2.5 izj6cdt5e7ronl6vi6qwkrz nginx-deployment-cfg-5799655d4d-lw7g6 1/1 Running 0 1m 10.244.1.5 izj6c9a51n762uyn3wfi5qz$ vim deployment/nginx-deployment.yml spec: replicas: 5$ kubectl apply -f deployment/nginx-deployment.yml$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE nginx-deployment-cfg-5799655d4d-2xc42 0/1 ContainerCreating 0 8s &lt;none&gt; izj6c9a51n762uyn3wfi5qz nginx-deployment-cfg-5799655d4d-5jr7d 1/1 Running 0 8s 10.244.1.7 izj6c9a51n762uyn3wfi5qz nginx-deployment-cfg-5799655d4d-92rp6 1/1 Running 0 8s 10.244.2.8 izj6cdt5e7ronl6vi6qwkrz nginx-deployment-cfg-5799655d4d-9qwvx 1/1 Running 0 2m 10.244.2.5 izj6cdt5e7ronl6vi6qwkrz nginx-deployment-cfg-5799655d4d-lw7g6 1/1 Running 0 2m 10.244.1.5 izj6c9a51n762uyn3wfi5qz Failover当集群中的 node 应某种原因故障时, kubernetes 会自动检测到 node 节点不可用, 并将该节点上的 pod 标记为 Unknown 状态, 同时, 在集群中的其他节点上创建 (与故障 node 节点上 pod)数量相同的 pod, 维持配置的副本数量. 当 故障节点恢复后, 故障节点回自动注册回 kubernetes 集群. 同时, kubernetes 会将 状态为 UNknown 的 pod 删除掉, 但是, 已经在运行的 Pod 不会重现调度回 故障节点. 123456789101112131415161718192021222324252627$ kubectl get nodes NAME STATUS ROLES AGE VERSION izj6c4v865pdzr9a5004a2z Ready master 4h v1.11.0 izj6c9a51n762uyn3wfi5qz Ready &lt;none&gt; 3h v1.11.0 izj6cdt5e7ronl6vi6qwkrz NotReady &lt;none&gt; 3h v1.11.0$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE nginx-deployment-cfg-5799655d4d-5jr7d 1/1 Running 0 27m 10.244.1.7 izj6c9a51n762uyn3wfi5qz nginx-deployment-cfg-5799655d4d-6gfnz 1/1 Running 0 14s 10.244.1.10 izj6c9a51n762uyn3wfi5qz nginx-deployment-cfg-5799655d4d-92rp6 1/1 Unknown 0 27m 10.244.2.8 izj6cdt5e7ronl6vi6qwkrz nginx-deployment-cfg-5799655d4d-9qwvx 1/1 Unknown 0 30m 10.244.2.5 izj6cdt5e7ronl6vi6qwkrz nginx-deployment-cfg-5799655d4d-kdk88 1/1 Running 0 14s 10.244.1.9 izj6c9a51n762uyn3wfi5qz nginx-deployment-cfg-5799655d4d-lw7g6 1/1 Running 0 30m 10.244.1.5 izj6c9a51n762uyn3wfi5qz-- 节点恢复后, $ kubectl get nodes NAME STATUS ROLES AGE VERSION izj6c4v865pdzr9a5004a2z Ready master 4h v1.11.0 izj6c9a51n762uyn3wfi5qz Ready &lt;none&gt; 3h v1.11.0 izj6cdt5e7ronl6vi6qwkrz Ready &lt;none&gt; 3h v1.11.0$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE nginx-deployment-cfg-5799655d4d-5jr7d 1/1 Running 0 31m 10.244.1.7 izj6c9a51n762uyn3wfi5qz nginx-deployment-cfg-5799655d4d-6gfnz 1/1 Running 0 4m 10.244.1.10 izj6c9a51n762uyn3wfi5qz nginx-deployment-cfg-5799655d4d-kdk88 1/1 Running 0 4m 10.244.1.9 izj6c9a51n762uyn3wfi5qz nginx-deployment-cfg-5799655d4d-lw7g6 1/1 Running 0 34m 10.244.1.5 izj6c9a51n762uyn3wfi5qz 使用 label 控制 pod 的位置默认情况下, Scheduleler 会将 Pod 调度到所有可用的 Node, 但在有些情况下, 可能希望将 Pod 部署到指定的 Node, 如将有大量磁盘 IO 的 Pod 部署到配置了 SSD 的 Node. Kubernetes 通过 label 来实现这个功能. label 是 键值对, 各种资源都可以设置 label, 灵活的添加各种自定义属性. Kubernetes 也会 维护有自己预定义的 label. 12345678910-- 标记某个节点是配置了 SSD 的节点$ kubectl label node izj6cdt5e7ronl6vi6qwkrz disktype=ssd node/izj6cdt5e7ronl6vi6qwkrz labeled$ kubectl get nodes --show-labels NAME STATUS ROLES AGE VERSION LABELS izj6c4v865pdzr9a5004a2z Ready master 4h v1.11.0 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=izj6c4v865pdzr9a5004a2z,node-role.kubernetes.io/master= izj6c9a51n762uyn3wfi5qz Ready &lt;none&gt; 3h v1.11.0 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=izj6c9a51n762uyn3wfi5qz,shouldrun=here izj6cdt5e7ronl6vi6qwkrz Ready &lt;none&gt; 3h v1.11.0 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,disktype=ssd,kubernetes.io/hostname=izj6cdt5e7ronl6vi6qwkrz 指定将 Pod 部署到 具有某个 label 的 node 上: 通过在 Pod 模板的 spec 里通过 nodeSelector 指定 pod 部署到具有 label disktype=ssd 的 node 上. 如果直接修改了 deployment 的配置文件, 则 apply 配置文件之后, 会立即生效, 之前在其他节点上运行的 pod 会被杀掉, 并调度到指定 label 的节点上. 12345678910111213141516171819202122232425262728293031323334$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE nginx-deployment-cfg-5799655d4d-5jr7d 1/1 Running 0 42m 10.244.1.7 izj6cdt5e7ronl6vi6qwkrz nginx-deployment-cfg-5799655d4d-6gfnz 1/1 Running 0 15m 10.244.1.10 izj6cdt5e7ronl6vi6qwkrz nginx-deployment-cfg-5799655d4d-kdk88 1/1 Running 0 15m 10.244.1.9 izj6c9a51n762uyn3wfi5qz nginx-deployment-cfg-5799655d4d-lw7g6 1/1 Running 0 45m 10.244.1.5 izj6c9a51n762uyn3wfi5qz$ vim nginx-label-deployment.yml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: nginx-deployment-cfg spec: replicas: 4 template: metadata: labels: app: web_server spec: containers: - name: nginx image: nginx nodeSelector: disktype: ssd$ kubectl apply -f nginx-label-deployment.yml deployment.extensions/nginx-deployment-cfg configured$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE nginx-deployment-cfg-f9795f88b-627h8 1/1 Running 0 25s 10.244.2.13 izj6cdt5e7ronl6vi6qwkrz nginx-deployment-cfg-f9795f88b-7xkhj 1/1 Running 0 21s 10.244.2.14 izj6cdt5e7ronl6vi6qwkrz nginx-deployment-cfg-f9795f88b-826xh 1/1 Running 0 30s 10.244.2.12 izj6cdt5e7ronl6vi6qwkrz nginx-deployment-cfg-f9795f88b-z8nhm 1/1 Running 0 30s 10.244.2.11 izj6cdt5e7ronl6vi6qwkrz 删除 node 上的 label, - 即删除. 删除 label 之后, pod 并不会重新部署, 依然在 原节点运行, 除非在 deployment 的配置文件中删除掉 nodeSelector 配置重新部署, kubernetes 才会删除之前的 pod, 重新调度.如果 deployment 配置中的 nodeSelector 配置被删除, 并且 deployment 被重新部署, 则原有 deployment 的所有 pod 都会被杀掉, 并重新调度和运行新 pod 12345678910111213141516171819202122232425262728293031323334$ kubectl label node izj6cdt5e7ronl6vi6qwkrz disktype--- 示例$ kubectl get nodes --show-labels NAME STATUS ROLES AGE VERSION LABELS izj6c4v865pdzr9a5004a2z Ready master 4h v1.11.0 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=izj6c4v865pdzr9a5004a2z,node-role.kubernetes.io/master= izj6c9a51n762uyn3wfi5qz Ready &lt;none&gt; 4h v1.11.0 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=izj6c9a51n762uyn3wfi5qz,shouldrun=here izj6cdt5e7ronl6vi6qwkrz Ready &lt;none&gt; 4h v1.11.0 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,disktype=ssd,kubernetes.io/hostname=izj6cdt5e7ronl6vi6qwkrz$ kubectl label node izj6cdt5e7ronl6vi6qwkrz disktype- node/izj6cdt5e7ronl6vi6qwkrz labeled$ kubectl get nodes --show-labels NAME STATUS ROLES AGE VERSION LABELS izj6c4v865pdzr9a5004a2z Ready master 4h v1.11.0 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=izj6c4v865pdzr9a5004a2z,node-role.kubernetes.io/master= izj6c9a51n762uyn3wfi5qz Ready &lt;none&gt; 4h v1.11.0 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=izj6c9a51n762uyn3wfi5qz,shouldrun=here izj6cdt5e7ronl6vi6qwkrz Ready &lt;none&gt; 4h v1.11.0 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=izj6cdt5e7ronl6vi6qwkrz-- 单纯删除 pod 并不会使得 pod 被调度到其他节点上, 应为 deployment 的配置没变.$ kubectl delete pod nginx-deployment-cfg-f9795f88b-627h8 pod &quot;nginx-deployment-cfg-f9795f88b-627h8&quot; deleted$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE nginx-deployment-cfg-f9795f88b-7xkhj 1/1 Running 0 12m 10.244.2.14 izj6cdt5e7ronl6vi6qwkrz nginx-deployment-cfg-f9795f88b-826xh 1/1 Running 0 12m 10.244.2.12 izj6cdt5e7ronl6vi6qwkrz nginx-deployment-cfg-f9795f88b-8zg2l 0/1 Pending 0 1m &lt;none&gt; &lt;none&gt; nginx-deployment-cfg-f9795f88b-z8nhm 1/1 Running 0 12m 10.244.2.11 izj6cdt5e7ronl6vi6qwkrz$ vim nginx-label-deployment.yml -- 删除 nodeSelector 配置$ kubectl apply -f nginx-label-deployment.yml -- 重新配置 deployment. DaemonSetDaemonSet 在每个 node 上最多只能运行一个副本. 其典型应用场景有: 在集群的每个节点上运行存储 DaemonSet, 如 glusterd 或 ceph. 在每个节点上运行日志收集 DaemonSet, 如 flunentd 或者 logstash. 在每个节点上运行监控 DaemonSet, 如 Prometheus 或者 collectd. 实际上, kubernetes 自己就在用 DaemonSet 运行系统组件, kube-flannel-ds 和 kube-proxy 分别在每个节点上运行 flannel 和 kube-proxy 组件.应为 flannel 和 kube-proxy 属于系统组件, 需要制定 --namespace=kube-system. 1234567891011121314151617181920212223$ kubectl get daemonsets --namespace=kube-system NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE kube-flannel-ds-amd64 3 3 3 3 3 beta.kubernetes.io/arch=amd64 4h kube-flannel-ds-arm 0 0 0 0 0 beta.kubernetes.io/arch=arm 4h kube-flannel-ds-arm64 0 0 0 0 0 beta.kubernetes.io/arch=arm64 4h kube-flannel-ds-ppc64le 0 0 0 0 0 beta.kubernetes.io/arch=ppc64le 4h kube-flannel-ds-s390x 0 0 0 0 0 beta.kubernetes.io/arch=s390x 4h kube-proxy 3 3 3 3 3 beta.kubernetes.io/arch=amd64 4h$ kubectl get pods --namespace=kube-system -o wide NAME READY STATUS RESTARTS AGE IP NODE coredns-78fcdf6894-ctcks 1/1 Running 0 4h 10.244.0.3 izj6c4v865pdzr9a5004a2z coredns-78fcdf6894-dnzrz 1/1 Running 0 4h 10.244.0.2 izj6c4v865pdzr9a5004a2z etcd-izj6c4v865pdzr9a5004a2z 1/1 Running 0 4h 172.16.0.105 izj6c4v865pdzr9a5004a2z kube-apiserver-izj6c4v865pdzr9a5004a2z 1/1 Running 0 4h 172.16.0.105 izj6c4v865pdzr9a5004a2z kube-controller-manager-izj6c4v865pdzr9a5004a2z 1/1 Running 0 4h 172.16.0.105 izj6c4v865pdzr9a5004a2z kube-flannel-ds-amd64-8wf4n 1/1 Running 0 4h 172.16.0.105 izj6c4v865pdzr9a5004a2z kube-flannel-ds-amd64-kzx6v 1/1 Running 1 4h 172.16.0.106 izj6c9a51n762uyn3wfi5qz kube-flannel-ds-amd64-szsr2 1/1 Running 1 4h 172.16.0.107 izj6cdt5e7ronl6vi6qwkrz kube-proxy-d2hsl 1/1 Running 0 4h 172.16.0.106 izj6c9a51n762uyn3wfi5qz kube-proxy-q4jjm 1/1 Running 0 4h 172.16.0.105 izj6c4v865pdzr9a5004a2z kube-proxy-z96c4 1/1 Running 1 4h 172.16.0.107 izj6cdt5e7ronl6vi6qwkrz kube-scheduler-izj6c4v865pdzr9a5004a2z 1/1 Running 0 4h 172.16.0.105 izj6c4v865pdzr9a5004a2z flannel 配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml$ curl https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml apiVersion: extensions/v1beta1 kind: DaemonSet metadata: name: kube-flannel-ds-arm64 namespace: kube-system labels: tier: node app: flannel spec: template: metadata: labels: tier: node app: flannel spec: hostNetwork: true nodeSelector: beta.kubernetes.io/arch: arm64 tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.10.0-arm64 command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.10.0-arm64 command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: &quot;100m&quot; memory: &quot;50Mi&quot; limits: cpu: &quot;100m&quot; memory: &quot;50Mi&quot; securityContext: privileged: true env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg-- 配置参数: DaemonSet 配置文件的语法结构与 Deployment 几乎完全一致, 只是将 kind 设置为 DaemonSet.hostName : 指定 Pod 直接用的是 Node 网络, 相当于 docker run --network=host. 考虑到 flannel 需要为 集群提供网络链接, 这个需求是合理的.containers : 定义了运行 flannel 服务的两个容器. kube-proxy 配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849-- 可以通过 kubectl edit 查看 kube-proxy 配置.$ kubectl edit daemonset kube-proxy --namespace=kube-system apiVersion: extensions/v1beta1 kind: DaemonSet metadata: creationTimestamp: 2018-07-15T10:34:18Z generation: 1 labels: k8s-app: kube-proxy name: kube-proxy namespace: kube-system resourceVersion: &quot;21828&quot; selfLink: /apis/extensions/v1beta1/namespaces/kube-system/daemonsets/kube-proxy uid: a1198958-881a-11e8-8f99-00163e02febc spec: revisionHistoryLimit: 10 selector: matchLabels: k8s-app: kube-proxy template: metadata: creationTimestamp: null labels: k8s-app: kube-proxy spec: containers: - command: - /usr/local/bin/kube-proxy - --config=/var/lib/kube-proxy/config.conf image: k8s.gcr.io/kube-proxy-amd64:v1.11.0 imagePullPolicy: IfNotPresent name: kube-proxy ... ... status: currentNumberScheduled: 3 desiredNumberScheduled: 3 numberAvailable: 3 numberMisscheduled: 0 numberReady: 3 observedGeneration: 1 updatedNumberScheduled: 3-- 配置参数: kind : DaemonSet 指定类型containers : 定义 kube-proxy 容器status : 为当前 DaemonSet 的运行时状态, 为 kubectl edit 独有, 其实 kubernetes 集群中的每个当前运行的资源, 都可以通过 kubectl edit 查看其配置和运行状态. Prometheus Node Exporter DaemonSetPrometheus 是流行的系统监控方案, Node Exporter 是 Prometheus 的 agent, 以 DaemonSet 的形式运行在每个被监控的节点上. 如果直接在 docker 中运行 Node Exporter 容器, 命令为:$ docker run -d -v &quot;/proc:/host/proc&quot; -v &quot;/sys:/host/sys&quot; -v &quot;/:/rootfs&quot; --net=host prom/node-exporter --path.procfs /host/proc --path.sysfs /host/sys --colector.filesystem.ignored-mount-points &quot;^/(sys|proc|dev|host|etc)($|/)&quot; 当使用 DaemonSet 时, 其配置文件 node-exporter.yml 为:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849$ vim node-exporter.yml apiVersion: extensions/v1beta1 kind: DaemonSet metadata: name: node-exporter-daemonset spec: template: metadata: labels: app: prometheus spec: hostNetwork: true containers: - name: node-exporter image: prom/node-exporter imagePullPolicy: IfNotPresent command: - /bin/node_exporter - --path.procfs - /host/proc - --path.sysfs - /host/sys - --collector.filesystem.ignored-mount-points - ^/(sys|proc|dev|host|etc)($|/) volumeMounts: - name: proc mountPath: /host/proc - name: sys mountPath: /host/sys - name: root mountPath: /rootfs volumes: - name: proc hostPath: path: /proc - name: sys hostPath: path: /sys - name: root hostPath: path: /-- 参数配置说明:hostNetwork: true 直接使用 Host 网络command 设置容器启动命令volumeMounts 通过 Volume 将 Host 路径 /proc, /sys 和 / 映射到容器中. 运行 DaemonSet 1234567$ kubectl apply -f node-exporter.yml daemonset.extensions/node-exporter-daemonset created$ kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE node-exporter-daemonset-74dzs 0/1 RunContainerError 0 17s 172.16.0.106 izj6c9a51n762uyn3wfi5qz node-exporter-daemonset-t2ds9 0/1 RunContainerError 0 17s 172.16.0.107 izj6cdt5e7ronl6vi6qwkrz Job容器按照持续运行时间, 可以分为两类: 服务类容器 : 需要持续提供服务, 如 Deployment, ReplicaSet, DaemonSet 都用于管理 服务类容器. 工作类容器 : 一次性任务, 如 批处理, 完成后容器退出, 使用 Job. job 配置1234567891011121314151617181920apiVersion: batch/v1kind: Jobmetadata: name: myjobspce: template: metadata: nema: myjob spec: containers: - name: hello image: busybox command: [&quot;echo&quot;, &quot;hello k8s job&quot;] restartPolicy: Never-- 配置参数说明:betch/v1 当前 Job 的 apiVersionkind: Job 指明当前资源的类型为 JobrestartPolicy 指定什么情况下需要重启容器. 对于 Job 只能设置为 Never 或 OnFailure. 对于其他 controller(如 Deployment) 可以设置为 Always. 启动 job123456789101112$ kubectl apply -f job.yml job.batch/mynewjob created$ kubectl get jobs NAME DESIRED SUCCESSFUL AGE myjob 1 1 2h mynewjob 1 0 26s$ kubectl get pods NAME READY STATUS RESTARTS AGE myjob-dh5hm 0/1 Completed 0 2h mynewjob-72c6v 1/1 Running 0 16s 删除 job12$ kubectl delete job myjob job.batch &quot;myjob&quot; deleted job 并行运行同时运行多个 pod , 提供 job 的执行效率. parallelism: NUM 表示 pod 的并行的数量, 默认为 1. completions: NUM 表示 设置 job 成功完成 pod 的总数, 默认为 1. 12345678910111213141516171819202122232425262728293031323334353637383940414243$ vim job/hello.yml$ cat job/hello.yml apiVersion: batch/v1 kind: Job metadata: name: mynewjob spec: completions: 6 parallelism: 2 template: metadata: name: myjob spec: containers: - name: hello image: busybox command: [&quot;sleep&quot;, &quot;10&quot;] restartPolicy: OnFailure$ kubectl apply -f job/hello.yml job.batch/mynewjob created$ kubectl get jobs NAME DESIRED SUCCESSFUL AGE mynewjob 6 4 37s$ kubectl get pods NAME READY STATUS RESTARTS AGE mynewjob-bz9rn 0/1 Completed 0 26s mynewjob-bzt65 1/1 Running 0 11s mynewjob-c72qc 1/1 Running 0 11s mynewjob-lgbrn 0/1 Completed 0 26s$ kubectl get pods NAME READY STATUS RESTARTS AGE mynewjob-9kqqs 0/1 Completed 0 1m mynewjob-bz9rn 0/1 Completed 0 2m mynewjob-bzt65 0/1 Completed 0 1m mynewjob-c72qc 0/1 Completed 0 1m mynewjob-lfp4p 0/1 Completed 0 1m mynewjob-lgbrn 0/1 Completed 0 2m job 状态 成功 当 DESIRED 和 SUCCESSFUL 都为 1, 表示按预期启动了一个 Pod, 并且已经成功执行. 123$ kubectl get jobs NAME DESIRED SUCCESSFUL AGE myjob 1 1 2h 失败 当 SUCCESSFUL 的 pod 数量为 0 时, 可以看到很多 pod 状态均不正常. 可以通过 kubectl describte pod 查看 pod 的启动日志. 之所以会出现多个 pod 的情况, 是因为 依据 restartPolicy: Never , 失败的容器不会被重启, 但是 Job 的 DESIRED 是 1, 且目前的 SUCCESSFUL 为 0, 不能满足需求, 所以 Job controller 会一致创建新的 Pod, 终止该行为只能删除 job. 12345678910111213141516171819202122$ kubectl get job NAME DESIRED SUCCESSFUL AGE mynewjob 1 0 2m$ kubectl get pods NAME READY STATUS RESTARTS AGE mynewjob-5d6rt 0/1 ContainerCannotRun 0 1m mynewjob-6mfln 0/1 ContainerCannotRun 0 2m mynewjob-6wdnb 0/1 ContainerCannotRun 0 2m mynewjob-jrgtz 0/1 ContainerCannotRun 0 2m mynewjob-rj7qv 0/1 ContainerCannotRun 0 2m$ kubectl describe pod mynewjob-5d6rt ... ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 2m default-scheduler Successfully assigned default/mynewjob-5d6rt to izj6cdt5e7ronl6vi6qwkrz Normal Pulling 2m kubelet, izj6cdt5e7ronl6vi6qwkrz pulling image &quot;busybox&quot; Normal Pulled 2m kubelet, izj6cdt5e7ronl6vi6qwkrz Successfully pulled image &quot;busybox&quot; Normal Created 2m kubelet, izj6cdt5e7ronl6vi6qwkrz Created container Warning Failed 2m kubelet, izj6cdt5e7ronl6vi6qwkrz Error: failed to start container &quot;hello&quot;: Error response from daemon: OCI runtime create failed: container_linux.go:348: starting container process caused &quot;exec: \&quot;no such sleep\&quot;: executable file not found in $PATH&quot;: unknown 也可以修改 job 配置文件中的 restartPolicy: OnFailure, 此时, 当 job 失败时, 不是创建新的 pod 的, 而是在原来的基础上重新启动, 即 RESTARTS 增加. 12345678910$ kubectl apply -f job/hello.yml job.batch/mynewjob created$ kubectl get jobs -o wide NAME DESIRED SUCCESSFUL AGE CONTAINERS IMAGES SELECTOR mynewjob 1 0 8s hello busybox controller-uid=70f9a7f0-88be-11e8-8f99-00163e02febc$ kubectl get pods NAME READY STATUS RESTARTS AGE mynewjob-bsmw4 0/1 CrashLoopBackOff 3 1m CronJob123456789101112131415apiVersion: batch/v2alpha1kind: CronJobmetadata: name: hellospec: schedule: &quot;*/1 * * * *&quot; jobTemplate: spec: template: spec: containers: - name: hello image: busybox command: [&quot;echo&quot;, &quot;hello k8s jobs!&quot;] restartPolicy: OnFailure 启动 cronjob 与查看详情 12345678910111213141516$ kubectl apply -f job/hello_cronjob.yml cronjob.batch/hello created$ kubectl get cronjob NAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE hello */1 * * * * False 0 &lt;none&gt; 9s$ kubectl get pods NAME READY STATUS RESTARTS AGE hello-1531722900-2qsfj 0/1 Completed 0 2m hello-1531722960-dc2q7 0/1 Completed 0 1m hello-1531723020-r8c97 0/1 Completed 0 12s--- 查看运行日志$ kubectl logs hello-1531723020-r8c97 hello k8s jobs! CronJob 是基于 Job 实现的, 如下: 123456789$ kubectl get cronjob NAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE hello */1 * * * * False 1 7s 25m$ kubectl get jobs NAME DESIRED SUCCESSFUL AGE hello-1531724700 1 1 2m hello-1531724760 1 1 1m hello-1531724820 1 1 55s debug:运行 kubectl apply -f job/hello_cronjob.yml 时, 出现如下报错: 12$ kubectl apply -f job/hello_cronjob.yml error: unable to recognize &quot;job/hello_cronjob.yml&quot;: no matches for kind &quot;CronJob&quot; in version &quot;batch/v2alpha1&quot; 其原因是, Kubernetes 默认没有 enable CronJob 功能, 需要在 kube-apiserver 中加入这个功能, 方法如下: 修改 kube-apiserver 的配置文件, kube-apiserver 本身也是一个 pod, 在启动参数上, 加上 --runtime-config=batch/v2alpha1=true 配置, 再次创建 CronJob 即可. 123456789101112131415161718192021222324252627282930313233343536373839$ vim /etc/kubernetes/manifests/kube-apiserver.yaml apiVersion: v1 kind: Pod metadata: annotations: scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot; creationTimestamp: null labels: component: kube-apiserver tier: control-plane name: kube-apiserver namespace: kube-system spec: containers: - command: - kube-apiserver - --runtime-config=batch/v2alpha1=true --&gt; 添加 该行.-- 重启 kube-apiserver 服务$ systemctl restart kubelet -- 确认 kube-apiserver 已经支持 batch/v2alpha1$ kubectl api-versions | grep batch batch/v1 batch/v1beta1 batch/v2alpha1-- 重新运行 CronJob$ kubectl apply -f job/hello_cronjob.yml cronjob.batch/hello created$ kubectl get cronjob NAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE hello */1 * * * * False 0 &lt;none&gt; 9s$ kubectl get cronjob NAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE hello */1 * * * * False 0 36s 4m ReplicaSetStatefulSet通过 Service 访问 Pod我们不应当期望 Kubernetes Pod 是健壮的, 而要假设 Pod 中的容器很可能应为各种原因发生故障而死掉. Deployment 等 Controller 通过动态创建和销毁 Pod 来保证应用整体的健壮性. 换句话说, Pod 是脆弱的, 但 应用是健壮的. Kubernetes Service 从逻辑上代表了一组 Pod, 具体是哪些 Pod 则由 label 来选择. Service 由自己的 IP, 而且这个 IP 是不变的. 客户端只需要访问 Service 的 IP, Kubernetes 则负责建立和维护 Service 与 Pod 的映射关系. 无论后端 Pod 如何变化, 对客户端不会有任何影响, 因为 service 没有变. 123456789101112131415161718192021222324252627282930313233343536373839-- deployment apiVersion: apps/v1beta1 kind: Deployment metadata: name: httpd spec: replicas: 3 template: metadata: labels: run: httpd-label spec: containers: - name: httpd image: httpd ports: - containerPort: 80-- service apiVersion: v1 kind: Service metadata: name: httpd-srv spec: selector: run: httpd ports: - protocol: TCP port: 8080 targetPort: 80-- 配置参数说明:apiVersion: v1 Service 的 apiVersionkind: Service 资源类型selector 指明挑选那些 label 为 `run: httpd` 的 Pod 作为 Service 的后端.将 Service 的 8080 端口映射到 Pod 的 80 端口, 使用 TCP 协议. 启动 service 123456789101112131415161718192021222324252627282930$ kubectl apply -f service.yml service/httpd-srv created$ kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE httpd-srv ClusterIP 10.107.68.152 &lt;none&gt; 8080/TCP 7s kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 20h$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE httpd-569ff4d8c4-6jcp2 1/1 Running 0 17m 10.244.2.60 izj6cdt5e7ronl6vi6qwkrz httpd-569ff4d8c4-8qblv 1/1 Running 0 17m 10.244.1.50 izj6c9a51n762uyn3wfi5qz httpd-569ff4d8c4-mfk52 1/1 Running 0 18m 10.244.2.59 izj6cdt5e7ronl6vi6qwkrz$ kubectl describe service httpd Name: httpd-srv Namespace: default Labels: &lt;none&gt; Annotations: kubectl.kubernetes.io/last-applied-configuration=&#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Service&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;name&quot;:&quot;httpd-srv&quot;,&quot;namespace&quot;:&quot;default&quot;&#125;,&quot;spec&quot;:&#123;&quot;ports&quot;:[&#123;&quot;port&quot;:8080,&quot;protocol&quot;:&quot;TC... Selector: run=httpd-label Type: ClusterIP IP: 10.107.68.152 Port: &lt;unset&gt; 8080/TCP TargetPort: 80/TCP Endpoints: 10.244.1.50:80,10.244.2.59:80,10.244.2.60:80 --&gt; 此处为 3 个 pod 的地址. Session Affinity: None Events: &lt;none&gt;$ curl 10.107.68.152:8080 &lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; Endpoints Endpoints: 10.244.1.50:80,10.244.2.59:80,10.244.2.60:80 指明了 service 与 pod 的对应关系, Pod 的 IP 是在 容器 中配置的, Service 的 Cluster IP 以及 Cluster IP 映射到 Pod IP 都是通过 iptables. Cluster IP 底层实现Cluster IP 是一个 虚拟的 IP, 是由 Kubernetes 节点上的 iptables 规则管理的. 可以通过 iptables-save 打印出 当前 1234567$ iptables-save | grep 10.107.68.152 -A KUBE-SERVICES ! -s 10.244.0.0/16 -d 10.107.68.152/32 -p tcp -m comment --comment &quot;default/httpd-srv: cluster IP&quot; -m tcp --dport 8080 -j KUBE-MARK-MASQ -A KUBE-SERVICES -d 10.107.68.152/32 -p tcp -m comment --comment &quot;default/httpd-srv: cluster IP&quot; -m tcp --dport 8080 -j KUBE-SVC-NUOBVGD4YU5WFXTP-- 以上两条规则的含义是:如果 cluster 内的 pod (源地址来自 10.244.0.0/16) 要访问 httpd-srv, 则允许;其他源地址访问 httpd-srv, 跳转到规则 KUBE-SVC-NUOBVGD4YU5WFXTP. KUBE-SVC-NUOBVGD4YU5WFXTP 规则如下: 123456789$ iptables-save | grep KUBE-SVC-NUOBVGD4YU5WFXTP -A KUBE-SVC-NUOBVGD4YU5WFXTP -m comment --comment &quot;default/httpd-srv:&quot; -m statistic --mode random --probability 0.33332999982 -j KUBE-SEP-TFCNH7ADCCFCQCVZ -A KUBE-SVC-NUOBVGD4YU5WFXTP -m comment --comment &quot;default/httpd-srv:&quot; -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-UUSZIG4YUC7TJE2H -A KUBE-SVC-NUOBVGD4YU5WFXTP -m comment --comment &quot;default/httpd-srv:&quot; -j KUBE-SEP-XPIJMUYGFWX5JR3B-- 以上规则的含义是:1/3 的概率 跳转到 规则 KUBE-SEP-TFCNH7ADCCFCQCVZ1/3 的概率(剩下 2/3 的一般) 跳转到规则 KUBE-SEP-UUSZIG4YUC7TJE2H1/3 的概率跳转到规则 KUBE-SEP-XPIJMUYGFWX5JR3B KUBE-SEP-TFCNH7ADCCFCQCVZ, KUBE-SEP-UUSZIG4YUC7TJE2H, KUBE-SEP-XPIJMUYGFWX5JR3B 规则如下: 1234567891011121314$ iptables-save | grep KUBE-SEP-TFCNH7ADCCFCQCVZ-A KUBE-SEP-TFCNH7ADCCFCQCVZ -s 10.244.1.50/32 -m comment --comment &quot;default/httpd-srv:&quot; -j KUBE-MARK-MASQ-A KUBE-SEP-TFCNH7ADCCFCQCVZ -p tcp -m comment --comment &quot;default/httpd-srv:&quot; -m tcp -j DNAT --to-destination 10.244.1.50:80$ iptables-save | grep KUBE-SEP-UUSZIG4YUC7TJE2H-A KUBE-SEP-UUSZIG4YUC7TJE2H -s 10.244.2.59/32 -m comment --comment &quot;default/httpd-srv:&quot; -j KUBE-MARK-MASQ-A KUBE-SEP-UUSZIG4YUC7TJE2H -p tcp -m comment --comment &quot;default/httpd-srv:&quot; -m tcp -j DNAT --to-destination 10.244.2.59:80$ iptables-save | grep KUBE-SEP-XPIJMUYGFWX5JR3B-A KUBE-SEP-XPIJMUYGFWX5JR3B -s 10.244.2.60/32 -m comment --comment &quot;default/httpd-srv:&quot; -j KUBE-MARK-MASQ-A KUBE-SEP-XPIJMUYGFWX5JR3B -p tcp -m comment --comment &quot;default/httpd-srv:&quot; -m tcp -j DNAT --to-destination 10.244.2.60:80-- 以上规则含义是:将请求分别转发到后端的三个 Pod. 综上, iptables 将访问 service 的流量转发到后端 pod, 而且使用类似 轮训 的负载均衡策略. 需要补充的是, cluster 的每个节点上都配置了相同的 iptables 规则, 这样就确保了整个 Cluster 都能通过 service 的 Cluster IP 访问 service . DNS 访问 Service在 Cluster 中, 除了可以通过 Cluster IP 访问 Service, 还可以通过 DNS 来访问, 使用 kubeadm 部署时, 会默认安装 kube-dns 组件.1$ kubectl get deployment --namespace=kube-system kubeadm 部署时, 会默认安装 kube-dns 组件, kube-dns 是一个 DNS 服务器. 每当有新的 servic 被创建, kube-dns 会添加该 Service 的 DNS 记录. Cluster 中的 Pod 可以通过 &lt;SERVICE)NAME&gt;.&lt;NAMESPACE_NAME&gt;访问 Service. 123456789101112131415$ kubectl run busybox --rm -ti --image=busybox sh/ # wget httpd-srv.default:8080 Connecting to httpd-srv.default:8080 (10.107.68.152:8080) index.html 100% |*************************************| 45 0:00:00 ETA/ # cat index.html &lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;/ # nslookup httpd-srv Server: 10.96.0.10 Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local Name: httpd-srv Address 1: 10.107.68.152 httpd-srv.default.svc.cluster.local DNS 服务器是 kube-dns.kube-system.svc.cluster.local, 这实际上就是 kube-dns 组件, 它本身是部署在 kube-system namespace 中的一个 service. httpd-srv.default.svc.cluster.local 是 httpd-srv 的完整域名, 如果要访问其他 namespace 中的 Service , 就必须带上 namespace 了. 12-- 查看 namespace$ kubectl get namespace 在一个文件中指定, Deployment 和 service, 使用 --- 分割. 12345678910111213141516171819202122232425262728293031apiVersion: apps/v1beta1kind: Deploymentmetadata: name: httpd2 namespace: kube-publicspec: replicas: 2 template: metadata: labels: run: httpd2 spec: containers: - name: httpd2 image: httpd ports: - containerPort: 80---apiVersion: v1kind: Servicemetadata: name: httpd2-srv namespace: kube-publicspec: selector: run: httpd2 ports: - protocol: TCP port: 8080 targetPort: 80 外网访问 Service为了将 service 暴露给 Cluster 外部, Kubernetes 提供了多种类型的 Service, 默认是 ClusterIP. ClusterIP Service 通过 Cluster 内部的 IP 对外提供服务, 只有 Cluster 内的节点和 Pod 可以访问, 这是默认的 Service 类型. NodePort Service 通过 Cluster 节点的 静态端口对外提供服务. Cluster 外部可以通过 : 访问 Service. 使用 NodePort 方式, 需要在 service 的配置文件中指定 type: NodePort, 其中, PORT(S) 是 Service 在节点上监听的端口, Kubernetes 会从 3000 ~ 32767 中分配一个可用的端口, 每个节点都会监听此端口, 并将请求转发给 Service. 如下: 1234567891011121314151617181920212223242526272829$ cat node-port-service.yml apiVersion: v1 kind: Service metadata: name: httpd-svc spec: type: NodePort selector: run: httpd-label ports: - protocol: TCP port: 8080 targetPort: 80$ kubectl apply -f node-port-service.yml$ kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE httpd-svc NodePort 10.96.163.102 &lt;none&gt; 8080:30182/TCP 4h-- 在 三个节点 , 都可以访问 httpd-svc$ curl 172.16.0.105:30182 &lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;$ curl 172.16.0.106:30182 &lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;$ curl 172.16.0.107:30182 &lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; Kubernetes 同样使用 iptables 将 : 映射到 pod. Kubernetes 在每个节点都增加了下面两条 iptables 规则: 12-A KUBE-NODEPORTS -p tcp -m comment --comment &quot;default/httpd-svc:&quot; -m tcp --dport 30182 -j KUBE-MARK-MASQ-A KUBE-NODEPORTS -p tcp -m comment --comment &quot;default/httpd-svc:&quot; -m tcp --dport 30182 -j KUBE-SVC-RL3JAE4GN7VOGDGP KUBE-SVC-RL3JAE4GN7VOGDGP 相关规则如下, 其作用就是 负载均衡到每一个 Pod. 123-A KUBE-SVC-RL3JAE4GN7VOGDGP -m comment --comment &quot;default/httpd-svc:&quot; -m statistic --mode random --probability 0.33332999982 -j KUBE-SEP-HBIHS6NV3RF2B77B-A KUBE-SVC-RL3JAE4GN7VOGDGP -m comment --comment &quot;default/httpd-svc:&quot; -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-HANJX3KI6JYOOOTA-A KUBE-SVC-RL3JAE4GN7VOGDGP -m comment --comment &quot;default/httpd-svc:&quot; -j KUBE-SEP-NKMRAHPRFQ6XNLLG NodePort 默认随机选择, 但是可以通过 nodePort 指定某个特定端口. 最终, Node 和 ClusterIP 在各自端口上接收到的请求都会通过 iptables 转发到 Pod 的 targetPort. 如: 12345ports:- protocol: TCP nodePort: 31111 --&gt; Node 节点上监听的端口, port: 8080 --&gt; ClusterIP 上监听的端口 targetPort: 80 --&gt; Pod 上监听的端口. LoadBalancer Service 使用 cloud provider 特有的 load balancer 对外提供服务, cloud provider 负责将 load balancer 的流量导向 Service. 目前支持的 cloud provider 有 GCP, AWS, Azur 等. Rolling UpdateHealth Check数据管理, 数据持久化Secret &amp;&amp; ConfigMapHelm – Kubernetes 包管理工具网络Dashboard1234567$ kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml secret/kubernetes-dashboard-certs created serviceaccount/kubernetes-dashboard created role.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created deployment.apps/kubernetes-dashboard created service/kubernetes-dashboard created Kubernetes 集群监控Kubernetes 日志管理]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AngularJS高级程序设计读书笔记--查漏补缺篇]]></title>
    <url>%2F2018%2F04%2F12%2FAngularJS%E9%AB%98%E7%BA%A7%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA%E7%AF%87%2F</url>
    <content type="text"><![CDATA[一. AngularJS $http 服务实现跨域请求AngularJS 实现跨域的方式类似于 Ajax, 使用 CORS 机制. AngularJS XMLHttpRequest $http 用于读取远程服务器的数据. 用法如下: 12$http.post(url, data, [config]).success(function()&#123;...&#125;);$http.get(url, [config]).success(function()&#123;...&#125;); 1. $http.jsonp 实现跨域 指定 callback 和 回调函数名, 函数名为 JSON_CALLBACK 时, 会调用 success 回调函数, JSON_CALLBACK 必须全为大写, 指定其他回调函数, 但必须是定义在 windows 下的全局函数. url 中必须加 callback. 2. $http.get 实现跨域 在服务端设置允许在其他域名下访问: 12response.setHeader("Access-Controll-Allow-Origin", "*") // 允许所有域名访问response.setHeader("Access-Control-Allow-Origin", "http://www.123.com") // 允许 www.123.com 访问 AngularJS 端使用 $http.get() 3. $http.post 实现跨域 在服务端设置允许在其他域名下访问, 及响应类型, 响应头设置 123response.setHeader("Access-Control-Allow-Origin", "*");response.setHeader("Access-Control-Allow-Origin", "POST");response.setHeader("Access-Control-Allow-Origin", "x-requested-with, content-type"); AngularJS 端调用 $http.post(), 同时设置头信息. 123$http.post("http://localhost/ajax/getAllRes.pt", &#123;languateColume: "name_eu"&#125;, &#123;"Content-Type": "application/x-www-form-urlencoded"&#125;).success(function(data)&#123; $scope.industries = data;&#125;); 参考文档 AngularJS 实现跨域请求 二. 配置 Basic 认证angular-base64 123456angular .module(&apos;myApp&apos;, [&apos;base64&apos;]) .config(function($httpProvider, $base64) &#123; var auth = $base64.encode(&quot;foo:bar&quot;); $httpProvider.defaults.headers.common[&apos;Authorization&apos;] = &apos;Basic &apos; + auth; &#125;)]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>angularjs</tag>
        <tag>前端框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python state_machine 文档及源码分析]]></title>
    <url>%2F2018%2F03%2F27%2Fpython-state-machine%2F</url>
    <content type="text"><![CDATA[一. 安装$ pip install state_machine 二. 使用方法0. 示例代码from state_machine import acts_as_state_machine, State, Event, before, after @acts_as_state_machine class Person(object): name = &quot;Billy&quot; sleeping = State(initial=True) running = State() cleaning = State() run = Event(from_states=sleeping, to_state=running) cleanup = Event(from_states=running, to_state=cleaning) sleep = Event(from_states=(running, cleaning), to_state=sleeping) @before(&quot;sleep&quot;) def do_one_things(self): print(&quot;{} is sleepy.&quot;.format(self.name)) @before(&quot;sleep&quot;) def do_another_thing(self): print(&quot;{} is REALLY sleepy.&quot;.format(self.name)) @after(&quot;sleep&quot;) def snore(self): print(&quot;Zzzzzzzz&quot;) @after(&quot;sleep&quot;) def big_snore(self): print(&quot;Zzzzzzzz&quot;) person = Person() print(person.current_state) # sleeping print(person.is_sleeping) # True print(person.is_running) # False person.run() # 执行状态转换 print(person.is_running) # True print(person.is_sleeping) # False person.sleep() # 执行状态转换 : Billy is sleepy.\nBilly is REALLY sleepy.\nZzzzzzzz\nZzzzzzzz print(person.current_state) # sleeping 1. 基础使用: State,Event, acts_as_state_machinefrom state_machine import State, Event, acts_as_state_machine 一个状态机类, 需要首先使用 acts_as_state_machine 装饰. 一个状态机类的实例, 会具有 current_state 属性用于判断当前实例的状态. 同时, 会有 is_STATE 属性, 返回布尔值, 用于判断当前实例是否处于某种状态. 一个 State() 类实例, 代表一种状态. State(initial=True) 表示该状态位于初始状态. 一个 Event() 类实例, 代表一种状态转换. from_states 为单个状态或一个状态元组, 是对象在一个状态转换中的起始状态(或之一). to_state 为对象在一个状态装换中的目标状态. 每种Event() 实例, 都是状态机实例的可调用方法, 用于实现状态装换. 2. before/after 装饰器回调from state_machine import after, before after 和 before 是一个接受参数的装饰器, 其参数为一个状态转换(Event)实例, 表示在状态转换之前/后 执行的一个或一组操作. 如果一个 before 钩子函数产生一个异常, 或返回 False, 那么该钩子装饰的状态转换(Event()) 将不会发生, 装饰该状态转换的 after 钩子函数也不会被执行. 3. Exceptionfrom state_machine import InvalidStateTransition 当尝试做一个非法的转换时(即 没有定义对应的状态转换 Event), 一个 InvalidStateTransition 异常会被抛出. 4. ORM 支持state_machine 有对 mongoengine 和 SQLAlchemy 的基础支持. 4.1 mongoengine自定义类只需继承 mongoengine.Document , state_machine 会自动添加一个 StringFiled for state. 必须明确调用 save() 方法, 才能把对象的状态持久化. @acts_as_state_machine class Person(mongoengine.Document): name = mongoengine.StringField(default=&quot;Billy&quot;) sleeping = State(initial=True) running = State() cleaning = State() run = Event(from_states=sleeping, to_state=running) cleanup = Event(from_states=running, to_state=cleaning) sleep = Event(from_states=(running, cleaning), to_state=sleeping) @before(&quot;sleep&quot;) def do_one_things(self): print(&quot;{} is sleepy.&quot;.format(self.name)) @before(&quot;sleep&quot;) def do_another_thing(self): print(&quot;{} is REALLY sleepy.&quot;.format(self.name)) @after(&quot;sleep&quot;) def snore(self): print(&quot;Zzzzzzzz&quot;) @after(&quot;sleep&quot;) def big_snore(self): print(&quot;Zzzzzzzzzzzzzzzzzz&quot;) person = Person() person.save() eq_(person.current_state, Person.sleeping) assert person.is_sleeping assert not person.is_sleeping person.run() assert person.is_running person.sleep() assert person.is_sleeping person.run() person.save() person2 = Person.objects(id=person.id).first() assert person2.is_running 4.2 SQLAlchemyAll you need to do is have sqlalchemy manage your object. from sqlalchemy.ext.declarative import declarative_base Base = declarative_base() @acts_as_state_machine class Puppy(Base): pass 示例代码 from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import sessionmaker Base = declarative_base() @acts_as_state_machine class Penguin(Base): __tablename__ = &apos;penguins&apos; id = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True) name = sqlalchemy.Column(sqlalchemy.String) sleeping = State(initial=True) running = State() cleaning = State() run = Event(from_states=sleeping, to_state=running) cleanup = Event(from_states=running, to_state=cleaning) sleep = Event(from_states=(running, cleaning), to_state=sleeping) Base.metadata.create_all(engine) Session = sessionmaker(bind=engine) session = Session() # Note: No state transition occurs between the initial state and when it&apos;s saved to the database. penguin = Penguin(name=&apos;Tux&apos;) eq_(penguin.current_state, Penguin.sleeping) assert penguin.is_sleeping session.add(penguin) session.commit() penguin2 = session.query(Penguin).filter_by(id=penguin.id)[0] assert penguin2.is_sleeping 三. state_machine 源码解析0. acts_as_state_machine使用状态机的第一步是, 使用 acts_as_state_machine 装饰器, 装饰状态机类. def acts_as_state_machine(original_class): # get_adaptor 是一个适配器, # 其后是 BaseAdaptor, NullAdaptor(默认), MongoAdaptor, SqlAlchemyAdaptor adaptor = get_adaptor(original_class) global _temp_callback_cache modified_class = adaptor.modifed_class(original_class, _temp_callback_cache) _temp_callback_cache = None return modified_class get_adaptor 是一个适配器调用函数, 其后分别是使用适配器设计模式实现的几个类. BaseAdaptor : 基类. NullAdaptor : 默认适配器实现. MongoAdaptor : 适用与 Mongodb 的适配器. SqlAlchemyAdaptor : 适用于 SQLAlchemy 的适配器. 各适配器的方法的 modified_class() 方法, 返回重载过的类(使用 inspect.getmembers() 解析), 添加 current_state 和 aasm_state 属性(两者相等)和 is_STATE 属性, 用于返回当前状态和判断是否处于某种状态. # is_STATE 属性的实现 : 通过为 State 实例添加 property 来实现. # state_machine/orm/base.py BaseAdaptor.process_states() is_method_string = &quot;is_&quot; + member # member 是一个 State 实例 def is_method_builder(member): def f(self): return self.aasm_state == str(member) return property(f) # 添加 is_STATE 属性. is_method_dict[is_method_string] = is_method_builder(member) 1. Event &amp;&amp; StateEvent 和 State 只是普通的继承自 object 的类, State 实现了一个 __eq__ 和 __ne__ 方法, 添加了一个 initial=False 的参数, 用于定位初始State. # state_machine/orm/base.py BaseAdaptor.process_states() : L14 # 其中的 value 是一个 State 类的实例 # 最终 BaseAdaptor.process_states 返回该 initial_state. if isinstance(value, State): if value.initial: if initial_state is not None: raise ValueError(&quot;multiple initial states!&quot;) initial_state = value # BaseAdaptor.modifed_class() # 其中, extra_class_members() 需要各 Adapter 自实现. state_method_dict, initial_state = self.process_states(original_class) class_dict.update(self.extra_class_members(initial_state)) # NullAdaptor class NullAdaptor(BaseAdaptor): def extra_class_members(self, initial_state): return {&quot;aasm_state&quot;: initial_state.name} # SqlAlchemyAdaptor class SqlAlchemyAdaptor(BaseAdaptor): def extra_class_members(self, initial_state): return {&apos;aasm_state&apos;: sqlalchemy.Column(sqlalchemy.String)} # MongoAdaptor class MongoAdaptor(BaseAdaptor): def extra_class_members(self, initial_state): return {&apos;aasm_state&apos;: mongoengine.StringField(default=initial_state.name)} Event 实时实现了 __init__() 方法, 添加了 from_states 属性, 是一个数组. 添加了 to_state 是一个 State 类实例. 2. after &amp; before用于为状态机类添加 {&#39;before&#39;: {STATE: []}, &#39;after&#39;: {STATE: []}} 属性. 用于在之前后之后添加钩子函数.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>PyPi</tag>
        <tag>状态机</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--pdb 代码调试技巧]]></title>
    <url>%2F2018%2F03%2F27%2FPyStdLib-pdb%2F</url>
    <content type="text"><![CDATA[设置断点方式 命令行方式 $ python -m pdb myscript.py 代码方式 在 代码中希望调试的部分, 插入如下代码 import pdb; pdb.set_trace(); pdb 常用命令 命令 含义 break 或 b 设置断点 设置断点 continue 或 c 继续执行程序 list 或 l 查看当前行的代码段 step 或 s 进入 函数 return 或 r 执行代码直到从函数返回 exit 或 q 终止并退出 next 或 n 执行下一行 pp VAR 格式化打印变量的值 p VAR 打印变量的值 help 显示帮助 key = value 变量赋值 !key = value 变量重新赋值 pdb 一个明显的缺陷就是对于多线程, 远程调试等支持的不够好, 同时没有直观的界面显示. ipdbpdb 调试会话非常简单, 并没有提供 tab 补全或 代码高亮等功能, ipdb 可以提供基于 ipython 的扩展包, 实现上诉功能. # 安装 $ pip install ipdb # 使用 $ python -m ipdb my_script.py &gt;&gt; from ipdb import set_trace; set_trace()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
        <tag>代码调试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-设计模式]]></title>
    <url>%2F2018%2F03%2F20%2Fpython-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[零. 设计模式设计模式是可复用的且有点语言相关的解决方案. 根据 Design Patterns: elements of Reusable Object-Oriented Software 对设计模式的分类, 有如下几种: 创建型模式(creational patterns) : 用于生成具有特定行为的对象. 结构性模式(structural patterns) : 有助于为特定用例构建代码 行为模式(behavioral patterns) : 有助于分配责任和封装行为. 一. 创建型模式创建型模式处理对象创建相关问题, 目标是当直接创建对象不方便时, 提供更好的方式. 1. 工厂模式Python 的类和类型是内置工厂, 可以创建新对象, 并利用元类与类和对象生产进行交互. 在工厂模式中, 客户端(调用者)可以请求一个对象, 而无需知道这个对象使用哪个类生成. 工厂背后的思想是简化对象的创建. 与客户端(调用者)自己基于类实例化直接创建对象相比, 基于一个中心化函数来实现, 更易于追踪创建了那些对象. 通过创建对象的代码和使用对象的代码解耦, 工厂能够降低应用维护的复杂度. 工厂有两种形式: 工厂方法: 一个方法(函数)对于不同的输入参数返回不同的对象. 抽象工厂: 是一组用于创建一系列相关事物对象的工厂方法. (1) 工厂方法在工厂方法模式中, 传入一个参数, 执行单个函数, 但不要求知道任何关于对象如何实现以及对象来自哪里的细节. 如 Django 框架中使用工厂方法模式创建表单字段. Django 的 forms 模块支持不同种类字段(charField, EmailField)的创建和订制(max_length, required). 使用场景: 应用创建对象的代码分布在多个不同的地方, 而不是仅在一个函数/方法中, 并且无法跟踪这些对象. 工厂方法集中地在一个地方创建对象, 使对象跟踪变得更容易. 创建多个工厂方法也完全没有问题, 实践中常常对相似的对象创建进行逻辑分组, 每个工厂方法负责一个分组. 将对象的创建和使用解耦. 创建对象时, 并没有与某个特定类耦合/绑定到一起, 而只是通过调用某个函数来提供关于我们想要什么的部分信息. 这意味修改这个函数比较容易, 不需要同时修改使用这个函数的代码. 应用案例与应用性能及内存使用相关. 工厂方法可以在必要时创建新的对象, 从而提高性能和内存使用率. 示例代码: import xml.etree.ElementTree as etree import json ## JSONConnector 和 XMLConnector 类有相同的接口. class JSONConnector: &quot;&quot;&quot; 解析 json 格式文件的类&quot;&quot;&quot; def __init__(self, filepath): self.data = dict() with open(filepath, mode=&apos;r&apos;, encoding=&apos;utf-8&apos;) as f: self.data = json.load(f) @property def parsed_data(self): return self.data class XMLConnector: &quot;&quot;&quot; 解析 XML 格式文件的类&quot;&quot;&quot; def __init__(self, filepath): self.tree = etree.parse(filepath) @property def parsed_data(self): return self.tree def connection_factory(filepath): &quot;&quot;&quot; 一个工厂方法, 基于输入文件路径的扩展名返回一个 JSONConnector 或 XMLConnector 的实例. &quot;&quot;&quot; if filepath.endswith(&apos;json&apos;): connector = JSONConnector elif filepath.endswith(&apos;xml&apos;): connector = XMLConnector else: raise ValueError(&apos;Cannot connect to {}&apos;.format(filepath)) return connector(filepath) def connect_to(filepath): &quot;&quot;&quot; 对 connection_factory 方法进行包装, 并添加异常处理 &quot;&quot;&quot; factory = None try: factory = connection_factory(filepath) except ValueError as ve: print(ve) return factory def main(): &quot;&quot;&quot; 使用工厂方法设计模式 &quot;&quot;&quot; # 确认异常处理是否有效. sqlite_factory = connect_to(&apos;data/person.sq3&apos;) print() # 使用 工厂方法 处理 XML 文件 xml_factory = connect_to(&apos;data/person.xml&apos;) xml_data = xml_factory.parsed_data liars = xml_data.findall(&quot;.//{}[{}=&apos;{}&apos;]&quot;.format(&apos;person&apos;, &apos;lastName&apos;, &apos;Liar&apos;)) print(&apos;found: {} persons&apos;.format(len(liars))) for liar in liars: print(&apos;first name: {}&apos;.format(liar.find(&apos;firstName&apos;).text)) print(&apos;last name: {}&apos;.format(liar.find(&apos;lastName&apos;).text)) [print(&apos;phone number ({})&apos;.format(p.attrib[&apos;type&apos;]), p.text) for p in liar.find(&apos;phoneNumbers&apos;)] print() # 使用工厂方法 处理 JSON 文件. json_factory = connect_to(&apos;data/donut.json&apos;) json_data = json_factory.parsed_data print(&apos;found: {} donuts&apos;.format(len(json_data))) for donut in json_data: print(&apos;name: {}&apos;.format(donut[&apos;name&apos;])) print(&apos;price: ${}&apos;.format(donut[&apos;ppu&apos;])) [print(&apos;topping: {} {}&apos;.format(t[&apos;id&apos;], t[&apos;type&apos;])) for t in donut[&apos;topping&apos;]] if __name__ == &apos;__main__&apos;: main() (2) 抽象工厂抽象工厂设计模式是抽象方法的一种泛化, 具体来说, 一个抽象工厂是(逻辑上的) 一组工厂方法, 其中的每个工厂方法负责产生不同种类的对象. 因此, 他能提供相同的好处: 让对象的创建更容易追踪; 将对象创建与使用解耦; 提供优化内存占用和应用性能的潜力. 通常一开始使用工厂方法, 因为他更简单. 如果后来发现应用需要许多工厂方法, 那么僵创建一系列对象的过程合并在一起更合理, 从而最终引入抽象工厂. 抽象工厂的一个优点, 在使用工厂方法时, 从用户角度通常是看不到的, 那就是抽象工厂能够通过改变激活的工厂方法动态的(运行时)改变应用行为. django_factory 是一个用于在测试中创建 Django 模型的抽象工厂实现, 可用来为支持测试专有属性的模型创建实例. 这能让测试代码的可读性更高, 且避免共享不必要的代码. 示例代码: 以下代码演示了一个根据用户输入年龄, 来区分运行不同游戏(青蛙吃虫子 和 巫师打怪兽). class Frog: def __init__(self, name): self.name = name def __str__(self): return self.name def interact_with(self, obstacle): print(&apos;{} the Frog encounters {} and {}!&apos;.format(self, obstacle, obstacle.action())) class Bug: def __str__(self): return &apos;a bug&apos; def action(self): return &apos;eats it&apos; class FrogWorld: &quot;&quot;&quot; 一个抽象工厂, 主要职责就是创建游戏的主人公和障碍物. 区分创建方法并使其名字通用, 和可以实现动态修改当前激活的工厂, 而无需进行代码变更&quot;&quot;&quot; def __init__(self, name): print(self) self.player_name = name def __str__(self): return &apos;\n\n\t------ Frog World ———&apos; def make_character(self): return Frog(self.player_name) def make_obstacle(self): return Bug() class Wizard: def __init__(self, name): self.name = name def __str__(self): return self.name def interact_with(self, obstacle): print(&apos;{} the Wizard battles against {} and {}!&apos;.format(self, obstacle, obstacle.action())) class Ork: def __str__(self): return &apos;an evil ork&apos; def action(self): return &apos;kills it&apos; class WizardWorld: &quot;&quot;&quot; 抽象工厂, 同 FrogWorld. &quot;&quot;&quot; def __init__(self, name): print(self) self.player_name = name def __str__(self): return &apos;\n\n\t------ Wizard World ———&apos; def make_character(self): return Wizard(self.player_name) def make_obstacle(self): return Ork() class GameEnvironment: &quot;&quot;&quot; 游戏的主入口, 接收 factory 作为输入. &quot;&quot;&quot; def __init__(self, factory): self.hero = factory.make_character() self.obstacle = factory.make_obstacle() def play(self): self.hero.interact_with(self.obstacle) def validate_age(name): &quot;&quot;&quot;验证年龄的有效性&quot;&quot;&quot; try: age = input(&apos;Welcome {}. How old are you? &apos;.format(name)) age = int(age) except ValueError as err: print(&quot;Age {} is invalid, please try \ again…&quot;.format(age)) return (False, age) return (True, age) def main(): &quot;&quot;&quot; 根据用户输入的年龄, 区分运行不同的游戏&quot;&quot;&quot; name = input(&quot;Hello. What&apos;s your name? &quot;) valid_input = False while not valid_input: valid_input, age = validate_age(name) game = FrogWorld if age &lt; 18 else WizardWorld environment = GameEnvironment(game(name)) environment.play() if __name__ == &apos;__main__&apos;: main() 2. 建造者模式可用于细粒度控制复杂对象的创建过程. 我们想要创建一个由多个部分构成的对象, 而且他的构成需要一步接一步的完成, 只有当各个部分都创建好, 这个对象才完整. 此时, 需要使用 建造者模式. 建造者模式将一个复杂对象构建过程预期表现分离, 这样, 同一个构造过程可用于创建多个不同的表现. 该模式有两个参与者: 建造者 和 指挥者. 建造者: 负责创建复杂对象的各个组成部分. 指挥者: 使用一个建造者实例控制建造过程. django-widgy 是一个 Django 的第三方树编辑器扩展, 可用作内容管理系统. 它包含一个网页构建器, 用来创建具有不同布局的 HTML 页面. django-query-builder 是另一个基于建造者模式的 Django 第三方扩展, 该扩展可用于动态的创建 SQL 查询. 使用他, 我们能够控制一个查询的方方面面, 并能创建不同种类的查询, 从简单的到复杂的都可以. 示例代码: from enum import Enum import time PizzaProgress = Enum(&apos;PizzaProgress&apos;, &apos;queued preparation baking ready&apos;) PizzaDough = Enum(&apos;PizzaDough&apos;, &apos;thin thick&apos;) PizzaSauce = Enum(&apos;PizzaSauce&apos;, &apos;tomato creme_fraiche&apos;) PizzaTopping = Enum(&apos;PizzaTopping&apos;, &apos;mozzarella double_mozzarella bacon ham mushrooms red_onion oregano&apos;) STEP_DELAY = 3 # 考虑是示例，单位为秒 class Pizza: &quot;&quot;&quot; 最终产品类, 不支持直接实例化. &quot;&quot;&quot; def __init__(self, name): self.name = name self.dough = None self.sauce = None self.topping = [] def __str__(self): return self.name def prepare_dough(self, dough): self.dough = dough print(&apos;preparing the {} dough of your {}...&apos;.format(self.dough.name, self)) time.sleep(STEP_DELAY) print(&apos;done with the {} dough&apos;.format(self.dough.name)) class MargaritaBuilder: &quot;&quot;&quot; 建造者, 创建 Pizza 示例, 并包含遵从 Pizza 制作流程方法. &quot;&quot;&quot; def __init__(self): self.pizza = Pizza(&apos;margarita&apos;) self.progress = PizzaProgress.queued self.baking_time = 5 # 考虑是示例，单位为秒 def prepare_dough(self): self.progress = PizzaProgress.preparation self.pizza.prepare_dough(PizzaDough.thin) def add_sauce(self): print(&apos;adding the tomato sauce to your margarita...&apos;) self.pizza.sauce = PizzaSauce.tomato time.sleep(STEP_DELAY) print(&apos;done with the tomato sauce&apos;) def add_topping(self): print(&apos;adding the topping (double mozzarella, oregano) to your margarita&apos;) self.pizza.topping.append([i for i in (PizzaTopping.double_mozzarella, PizzaTopping.oregano)]) time.sleep(STEP_DELAY) print(&apos;done with the topping (double mozzarrella, oregano)&apos;) def bake(self): self.progress = PizzaProgress.baking print(&apos;baking your margarita for {} seconds&apos;.format(self.baking_time)) time.sleep(self.baking_time) self.progress = PizzaProgress.ready print(&apos;your margarita is ready&apos;) class CreamyBaconBuilder: &quot;&quot;&quot; 建造者, 创建 Pizza 示例, 并包含遵从 Pizza 制作流程方法. &quot;&quot;&quot; def __init__(self): self.pizza = Pizza(&apos;creamy bacon&apos;) self.progress = PizzaProgress.queued self.baking_time = 7 # 考虑是示例，单位为秒 def prepare_dough(self): self.progress = PizzaProgress.preparation self.pizza.prepare_dough(PizzaDough.thick) def add_sauce(self): print(&apos;adding the crème fraîche sauce to your creamy bacon&apos;) self.pizza.sauce = PizzaSauce.creme_fraiche time.sleep(STEP_DELAY) print(&apos;done with the crème fraîche sauce&apos;) def add_topping(self): print(&apos;adding the topping (mozzarella, bacon, ham, mushrooms, red onion, oregano) to your creamy bacon&apos;) self.pizza.topping.append([t for t in (PizzaTopping.mozzarella, PizzaTopping.bacon, PizzaTopping.ham, PizzaTopping.mushrooms, PizzaTopping.red_onion, PizzaTopping.oregano)]) time.sleep(STEP_DELAY) print(&apos;done with the topping (mozzarella, bacon, ham, mushrooms, red onion, oregano)&apos;) def bake(self): self.progress = PizzaProgress.baking print(&apos;baking your creamy bacon for {} seconds&apos;.format(self.baking_time)) time.sleep(self.baking_time) self.progress = PizzaProgress.ready print(&apos;your creamy bacon is ready&apos;) class Waiter: &quot;&quot;&quot;指挥者, 接受一个建造者作为参数, 并以正确的顺序执行 Pizza 的所有准备步骤. 选择恰当的建造者, 无需修改指挥者代码, 即可实现制作不同的 Pizza.&quot;&quot;&quot; def __init__(self): self.builder = None def construct_pizza(self, builder): self.builder = builder [step() for step in (builder.prepare_dough, builder.add_sauce, builder.add_topping, builder.bake)] @property def pizza(self): return self.builder.pizza def validate_style(builders): &quot;&quot;&quot; 输入有效性检查.&quot;&quot;&quot; try: pizza_style = input(&apos;What pizza would you like, [m]argarita or [c]reamy bacon? &apos;) builder = builders[pizza_style]() valid_input = True except KeyError as err: print(&apos;Sorry, only margarita (key m) and creamy bacon (key c) are available&apos;) return (False, None) return (True, builder) def main(): &quot;&quot;&quot; 实例化一个建造者, 然后指挥者使用建造者创建 Pizza,完成交付给用户. &quot;&quot;&quot; builders = dict(m=MargaritaBuilder, c=CreamyBaconBuilder) valid_input = False while not valid_input: valid_input, builder = validate_style(builders) print() waiter = Waiter() waiter.construct_pizza(builder) pizza = waiter.pizza print() print(&apos;Enjoy your {}!&apos;.format(pizza)) if __name__ == &apos;__main__&apos;: main() 2.2 流利的建造者: 链式调用建造者方法, 一个建造者的变体.流利的建造者 是一种建造者模式的变体, 该变体会链式地调用建造者方法, 通过将建造者本身定义为内部类并从其每个设置器方法返回自身来实现. builder() 方法返回最终的对象. class Pizza: def __init__(self, builder): self.garlic = builder.garlic self.extra_cheese = builder.extra_cheese def __str__(self): garlic = &apos;yes&apos; if self.garlic else &apos;no&apos; cheese = &apos;yes&apos; if self.extra_cheese else &apos;no&apos; info = (&apos;Garlic: {}&apos;.format(garlic), &apos;Extra cheese: {}&apos;.format(cheese)) return &apos;\n&apos;.join(info) class PizzaBuilder: def __init__(self): self.extra_cheese = False self.garlic = False def add_garlic(self): self.garlic = True return self def add_extra_cheese(self): self.extra_cheese = True return self def build(self): return Pizza(self) # 注意此处的实例化. if __name__ == &apos;__main__&apos;: pizza = Pizza.PizzaBuilder().add_garlic().add_extra_cheese().build() print(pizza) 3. 原型模式用于克隆对象. 原型设计模式(Prototype design pattern) 用于创建对象的克隆, 其最简单的形式就是一个 clone() 函数, 结构一个对象作为输入参数, 返回输入对象的一个副本. 在 Python 可以用 copy.deepcopy() 函数来完成. 很多 Python 应用都使用了原型模式, 但几乎都不称之为原型模式, 因为对象克隆是编程语言的一个内置特性. 引用与副本引用可以理解为执行对象的一个指针. 副本可以进一步分为深副本与浅副本. 深副本即原始对象的所有数据都被简单的复制到克隆对象中, 没有例外. 浅副本则依赖引用. 可以引入数据共享和写时复制一类的技术来优化性能和内存使用. 如果可用资源有限或性能至关重要, 那么使用浅副本可能更佳. Python 中的浅副本(copy.copy())及深副本(copy.deepcopy()): 浅副本(copy.copy()) : 浅副本构造一个新的复合对象后, (会尽可能的)将在原始对象中找到的对象的引用插入新对象中. 深副本(copy.deepcopy()) : 深副本构造一个新的复合对象后, 会递归的将在原始对象中找到的对象的副本插入新对象中. 代码实例: import copy from collections import OrderedDict class Book: def __init__(self, name, authors, price, **rest): &apos;&apos;&apos;rest的例子有：出版商，长度，标签，出版日期&apos;&apos;&apos; self.name = name self.authors = authors self.price = price # 单位为美元 self.__dict__.update(rest) def __str__(self): mylist = [] # OrderedDict : 保证元素有序. ordered = OrderedDict(sorted(self.__dict__.items())) for i in ordered.keys(): mylist.append(&apos;{}: {}&apos;.format(i, ordered[i])) if i == &apos;price&apos;: mylist.append(&apos;$&apos;) mylist.append(&apos;\n&apos;) return &apos;&apos;.join(mylist) class Prototype: &quot;&quot;&quot; 实现了原型设计模式. 其核心为 clone() 方法. &quot;&quot;&quot; def __init__(self): self.objects = dict() def register(self, identifier, obj): &quot;&quot;&quot; 用于在一个字典中, 追踪被克隆的对象 &quot;&quot;&quot; self.objects[identifier] = obj def unregister(self, identifier): &quot;&quot;&quot; 用于在一个字典中, 追踪被克隆的对象 &quot;&quot;&quot; del self.objects[identifier] def clone(self, identifier, **attr): &quot;&quot;&quot; attr 可以仅传递那些在克隆了一个对象时真正需要变更的属性变量. &quot;&quot;&quot; found = self.objects.get(identifier) if not found: raise ValueError(&apos;Incorrect object identifier: {}&apos;.format(identifier)) obj = copy.deepcopy(found) obj.__dict__.update(attr) return obj def main(): &quot;&quot;&quot; 克隆书籍的多个版本 &quot;&quot;&quot; b1 = Book(&apos;The C Programming Language&apos;, (&apos;Brian W. Kernighan&apos;, &apos;Dennis M.Ritchie&apos;), price=118, publisher=&apos;Prentice Hall&apos;, length=228, publication_date=&apos;1978-02-22&apos;, tags=(&apos;C&apos;, &apos;programming&apos;, &apos;algorithms&apos;, &apos;data structures&apos;)) prototype = Prototype() cid = &apos;k&amp;r-first&apos; prototype.register(cid, b1) b2 = prototype.clone(cid, name=&apos;The C Programming Language(ANSI)&apos;, price=48.99, length=274, publication_date=&apos;1988-04-01&apos;, edition=2) for i in (b1, b2): print(i) print(&apos;ID b1 : {} != ID b2 : {}&apos;.format(id(b1), id(b2))) if __name__ == &apos;__main__&apos;: main() 4. 单例模式单例(Singletom)模式限制 类的实例化, 只能实例化一个对象. 通常有以下集中实现方法: 单例不应该有几个层级的继承, 标记为单例的类已经是特定的. 重写 __new__() 方法 这种实现方法比较危险, 因为 重写 __new__() 方法后, 在子类的继承中, 将会出现难以调试的 bug : 类实例的创建顺序, 将影响类本身. class Singleton: _instance = None def __new__(cls, *args, **kwargs): if cls._instance is None: cls._instance = super().__new__(cls, *args, **kwargs) return cls._instance ins_a = Singleton() ins_b = Singleton() print(id(ins_a) == id(ins_b)) # True print(ins_a == ins_b) # True # 类的创建顺序将影响类实例本身: class ConcreteClass(Singleton): pass print(Singleton()) # &lt;__main__.Singleton object at 0x055B4570&gt; print(ConcreteClass()) # &lt;__main__.Singleton object at 0x055B4570&gt; print(ConcreteClass()) # &lt;__main__.ConcreteClass object at 0x05504570&gt; print(Singleton()) # &lt;__main__.Singleton object at 0x05504530&gt; 通过元类实现, 通过重写 __call__() 方法, 可以影响自定义类的创建. 可以创建一个可重用的单实例, 可以安全子类化, 并且与实例创建顺序无关. class Singleton: _instances = {} def __call__(cls, *args, **kwargs): if cls not in cls._instances: cls._instances[cls] = super().__call__(*args, **kwargs) return cls._instances[cls] class ConcreteClass(Singleton): pass class ConcreteSubClass(ConcreteClass): pass print(Singleton()) # &lt;__main__.Singleton object at 0x051C4570&gt; print(ConcreteClass()) # &lt;__main__.ConcreteClass object at 0x051C4570&gt; print(ConcreteSubClass()) # &lt;__main__.ConcreteSubClass object at 0x051C4570&gt; 使用装饰器实现 def singleton(cls, *args, **kw): instances = {} def _singleton(): if cls not in instances: instances[cls] = cls(*args, **kw) return instances[cls] return _singleton @singleton class MyClass4(object): &quot;&quot;&quot; 单例类本身根本不知道自己是单例的,因为他本身(自己的代码)并不是单例的 &quot;&quot;&quot; a = 1 def __init__(self, x=0): self.x = x one = MyClass4() two = MyClass4() two.a = 3 print one.a #3 print id(one) #29660784 print id(two) #29660784 print one == two #True print one is two #True one.x = 1 print one.x #1 print two.x #1 二. 结构型模式结构型设计模式处理一个系统中不同实体之间的关系, 关注的是提供一种简单的对象组合方式来创造新功能.结构型模式在大型应用中非常重要, 他决定代码的组织方式, 并告诉开发人员如何与应用程序的每个部分进行交互. 1. 适配器模式适配器模式(Adapter pattern)是一种结构型设计模式, 帮助我们实现两个不兼容接口之间的兼容. 例如, 我们可以编写一个额外的代码层, 该代码层实现新老两个接口之间能够通信的所有修改. 这个代码层即为适配器. 这种模式在无法修改新老接口源码的情况下, 尤其有用. Grok 是一个 Python 框架, 运行在 Zope3 之上, 专注于敏捷开发. Grok 框架使用适配器, 让已有对象无需变更就能符合指定 API 的标准. 开放/封闭原则是面向对象设计的基本原则之一, 声明一个软件实体应该对扩展是开放的, 对修改则是封闭的.本质上, 这意味着我们应该无需修改一个软件实体的源代码就能扩展其行为. 适配器模式遵从开放/封闭原则. 示例代码一, 使用更新字典方式实现: class Synthesizer: def __init__(self, name): self.name = name def __str__(self): return &apos;the {} synthesizer&apos;.format(self.name) def play(self): return &apos;is playing an electronic song&apos; class Human: def __init__(self, name): self.name = name def __str__(self): return &apos;{} the human&apos;.format(self.name) def speak(self): return &apos;says hello&apos; class Computer: def __init__(self, name): self.name = name def __str__(self): return &apos;the {} computer&apos;.format(self.name) def execute(self): return &apos;executes a program&apos; class Adapter: &quot;&quot;&quot; 适配器类, 将一些带不同接口的对象适配到一个统一接口中. &quot;&quot;&quot; def __init__(self, obj, adapted_methods): &quot;&quot;&quot; obj 为需要适配的对象, adapted_methods 是一个字典, 键值对中的键是客户端要调用的方法(execute), 值是应该被调用的方法.&quot;&quot;&quot; self.obj = obj self.__dict__.update(adapted_methods) def __str__(self): return str(self.obj) def main(): &quot;&quot;&quot; 使用适配器模式. &quot;&quot;&quot; objects = [Computer(&apos;Asus&apos;)] synth = Synthesizer(&apos;moog&apos;) objects.append(Adapter(synth, dict(execute=synth.play))) human = Human(&apos;Bob&apos;) objects.append(Adapter(human, dict(execute=human.speak))) for i in objects: print(&apos;{} {}&apos;.format(str(i), i.execute())) if __name__ == &quot;__main__&quot;: main() 示例代码二, 使用子类(继承)方式实现: 抽象基类(Abstract Base Classes, ABC)抽象基类是 Python 支持构建轻量级替代接口的核心. ABC 是一个不需要提供具体实现的类, 而是定义了可用于检查类型兼容性的蓝图类. 抽象基类用于两个目的: 检查实现完整性 检查隐式接口兼容性 使用特殊的 ABCMeta 元类 和 abstractmethod()装饰器 可以创建新的抽象基类. from abc import ABCMeta, abstractmethod class Pushable(metaclass=ABCMeta): @abstractmethod def push(self, x): &quot;&quot;&quot; 推入任意参数 &quot;&quot;&quot; pass @classmethod def __subclasshook__(cls, C): &quot;&quot;&quot; 该方法可以实现将自己的逻辑注入到已确定对象是否是给定类的实例的过程中. 这样, 隐式实现接口的实例也会被视为接口的实例. &quot;&quot;&quot; if cls is Pushable: if any(&quot;push&quot; in B.__dict__ for B in C.__mro__): return True return NotImplemented class DummyPushable(Pushable): &quot;&quot;&quot; 是 Pushable 的子类 &quot;&quot;&quot; def push(self, x): return True class IncompletePushable(Pushable): &quot;&quot;&quot; 该类在实例化时, 将会出错, 因为没有实现 push() 方法. &quot;&quot;&quot; pass class SomethingWithPush: &quot;&quot;&quot; 不是 Pushable 的子类 &quot;&quot;&quot; def push(self, x): pass isinstance(DummyPushable(), Pushable) # Pushable 没实现 __subclasshook__ 方法时, 返回 False # 实现后, 返回 True print(isinstance(SomethingWithPush(), Pushable)) collections.abc 模块提供了许多预定义的 抽象基类(ABC), 这些基类可以验证许多基本的 Python 类型的接口兼容性. 结合 isinstance() 函数使用它们比基于 Python 类型的比较更好. Container : 对象支持 in 运算符, 并实现 __contains__() 方法. Iterable : 对象支持迭代, 并实现 __iter__() Callable : 对象可以像一个函数一样被调用, 并实现了 __call__() 方法. Hashable : 对象是可哈希的(可以包含在集合中, 作为字典的键), 并实现 __hash__() 方法. Sized : 对象具有大小(可以是函数 len() 的主体), 并实现 __len__() 方法. 2. 修饰器模式给一个对象添加额外的功能, 有以下几种不同的方法: 直接将功能添加到对象所属的类. 使用组合 使用继承. 修饰器 修饰器(Decorator)模式能够以透明的方式不影响其他对象, 动态地将功能添加到一个对象中. 在 Python 中, 可以使用内置的修饰器特性. 一个 Python 修饰器就是对 Python 语法的一个特定改变, 用于扩展一个类, 方法 或 函数的行为, 而无需使用继承. 从实现的角度来说, Python 修饰器是一个可调用对象(函数, 方法, 类), 接受一个函数对象作为输入, 并返回另一个函数对象. 这意味着可以将任何具有这些属性的可调用对象当做一个修饰器. 修饰器模式和 Python 修饰器不是一对一的等价关系. Python 修饰器能做的实际上比修饰器模式多得多, 其中之一就是实现修饰器模式. Django 框架大量的使用修饰器, 例如视图修饰器 可以限制某些 HTTP 请求对视图的访问, 控制特定视图上的缓存行为, 按单个视图控制压缩, 基于特定 HTTP 请求头控制缓存. 使用场景: 实现横切关注点一般来说, 应用中有些部件时通用的, 可应用于其他部件, 这样的部件可以被看做横切关注点. 以下是横切关注点的例子: 数据校验 事务处理(类似数据库事务) 缓存 日志 监控 调试 业务规划 压缩 加密 代码示例: memoization 装饰器, 所有递归函数都能因 memoization 而提速. import functools def memoize(fn): known = dict() @functools.wraps(fn) def memoizer(*args): if args not in known: known[args] = fn(*args) return known[args] return memoizer @memoize def nsum(n): &apos;&apos;&apos;返回前n个数字的和&apos;&apos;&apos; assert(n &gt;= 0), &apos;n must be &gt;= 0&apos; return 0 if n == 0 else n + nsum(n-1) @memoize def fibonacci(n): &apos;&apos;&apos;返回斐波那契数列的第n个数&apos;&apos;&apos; assert(n &gt;= 0), &apos;n must be &gt;= 0&apos; return n if n in (0, 1) else fibonacci(n-1) + fibonacci(n-2) if __name__ == &apos;__main__&apos;: from timeit import Timer measure = [{&apos;exec&apos;: &apos;fibonacci(100)&apos;, &apos;import&apos;: &apos;fibonacci&apos;, &apos;func&apos;: fibonacci}, {&apos;exec&apos;: &apos;nsum(200)&apos;, &apos;import&apos;: &apos;nsum&apos;, &apos;func&apos;: nsum}] for m in measure: t = Timer(&apos;{}&apos;.format(m[&apos;exec&apos;]), &apos;from __main__ import \ {}&apos;.format(m[&apos;import&apos;])) print(&apos;name: {}, doc: {}, executing: {}, time: \ {}&apos;.format(m[&apos;func&apos;].__name__, m[&apos;func&apos;].__doc__, m[&apos;exec&apos;], t.timeit())) 代码示例: 可接受参数的装饰器, 实现运行时决定是否执行装饰器. def memoize(use=True): def wrap(fn): known = dict() @functools.wraps(fn) def memoizer(*args): if not use: return fn(*args) if args not in known: known[args] = fn(*args) return known[args] return memoizer return wrap @memoize(use=True) def fibonacci(n): &apos;&apos;&apos;返回斐波那契数列的第n个数&apos;&apos;&apos; assert(n &gt;= 0), &apos;n must be &gt;= 0&apos; return n if n in (0, 1) else fibonacci(n-1) + fibonacci(n-2) 3. 外观模式外观设计模式有助于隐藏系统的内部复杂性, 并通过一个简化的接口向客户端暴露必要的部分. 本质上, 外观(Facade)是在已有复杂系统之上实现的一个抽象层. 例如, 现实生活中, 公司的客服部门在顾客和公司内部业务部门之间充当一个外观的角色. 外观模式有点: 为一个复杂系统提供单个简单的入口点. 引入外观之后, 客户端代码通过简单地调用一个方法/函数就能使用一个系统. 系统内部的改变不会影响客户端使用, 客户端无需关心这个改变, 也不受这个改变影响. 当系统包含多层时, 为每一层引入一个外观入口点, 并让所有层级通过他们的外观相互通信. 可以提高层级之间的松耦合性, 尽可能保持层级独立. 示例代码: from enum import Enum from abc import ABCMeta, abstractmethod # Enum 类型描述一个服务进程的不同状态. State = Enum(&apos;State&apos;, &apos;new running sleeping restart zombie&apos;) class User: pass class Process: pass class File: pass class Server(metaclass=ABCMeta): &quot;&quot;&quot; 使用 abc 模块来禁止对 Server 接口直接进行初始化, 并强制子类实现 boot() 和 kill() 方法. &quot;&quot;&quot; @abstractmethod def __init__(self): &quot;&quot;&quot; abstractmethod 装饰的方法, 子类都必须实现该方法. &quot;&quot;&quot; pass def __str__(self): return self.name @abstractmethod def boot(self): pass @abstractmethod def kill(self, restart=True): pass class FileServer(Server): def __init__(self): &apos;&apos;&apos;初始化文件服务进程要求的操作&apos;&apos;&apos; self.name = &apos;FileServer&apos; self.state = State.new def boot(self): print(&apos;booting the {}&apos;.format(self)) &apos;&apos;&apos;启动文件服务进程要求的操作&apos;&apos;&apos; self.state = State.running def kill(self, restart=True): print(&apos;Killing {}&apos;.format(self)) &apos;&apos;&apos;杀死文件服务进程要求的操作&apos;&apos;&apos; self.state = State.restart if restart else State.zombie def create_file(self, user, name, permissions): &apos;&apos;&apos;自定义方法, 检查访问权限的有效性、用户权限，等等&apos;&apos;&apos; print(&quot;trying to create the file &apos;{}&apos; for user &apos;{}&apos; with permissions {}&quot;.format(name, user, permissions)) class ProcessServer(Server): def __init__(self): &apos;&apos;&apos;初始化进程服务进程要求的操作&apos;&apos;&apos; self.name = &apos;ProcessServer&apos; self.state = State.new def boot(self): print(&apos;booting the {}&apos;.format(self)) &apos;&apos;&apos;启动进程服务进程要求的操作&apos;&apos;&apos; self.state = State.running def kill(self, restart=True): print(&apos;Killing {}&apos;.format(self)) &apos;&apos;&apos;杀死进程服务进程要求的操作&apos;&apos;&apos; self.state = State.restart if restart else State.zombie def create_process(self, user, name): &apos;&apos;&apos;自定义方法, 检查用户权限、生成PID，等等&apos;&apos;&apos; print(&quot;trying to create the process &apos;{}&apos; for user &apos;{}&apos;&quot;.format(name, user)) class WindowServer: pass class NetworkServer: pass class OperatingSystem: &apos;&apos;&apos;外观&apos;&apos;&apos; def __init__(self): &quot;&quot;&quot; 创建所有需要的 服务进程实例 &quot;&quot;&quot; self.fs = FileServer() self.ps = ProcessServer() def start(self): &quot;&quot;&quot; 系统入口点, 供 客户端代码使用. &quot;&quot;&quot; [i.boot() for i in (self.fs, self.ps)] def create_file(self, user, name, permissions): return self.fs.create_file(user, name, permissions) def create_process(self, user, name): return self.ps.create_process(user, name) def main(): os = OperatingSystem() os.start() # 客户端可以调用方法创建文件和进程, 但它们是模拟的. os.create_file(&apos;foo&apos;, &apos;hello&apos;, &apos;-rw-r-r&apos;) os.create_process(&apos;bar&apos;, &apos;ls /tmp&apos;) if __name__ == &apos;__main__&apos;: main() 4. 享元模式享元设计模式通过相似对象引入数据共享来最小化内存使用, 提升性能. 一个享元(Flyweight)就是一个包含状态独立的不可变(又称固有的)数据的共享对象. 依赖状态的可变(又称非固有的)数据不应是享元的一部分, 因为每个对象的这种信息都不同, 无法共享. 如果享元需要非固有的数据, 应该有客户端代码显式的提供. 享元模式是一个用于优化的设计模式. 旨在优化性能和内存使用. 所有嵌入式系统和性能关键的应用 都能从中受益. 重点在 将不可变(可共享)的属性和可变的属性区分开 享元模式有效的几个前提条件: 应用需要使用大量的对象; 对象太多, 存储/渲染他们的代价太大.一旦移除对象中的可变状态, 多组不同的对象可被相对更少的共享状态所替代. 对象 ID 对于 应用不重要. 对象共享会造成 ID 比较的失败, 所以不能依赖对象 ID . memoization 与 享元模式之间的区别 memoization 是一种优化技术, 使用一个缓存来避免重复计算那些在更早的执行步骤中已经计算好的结果. memoization 并不只能应用于某种特定的编程方式, 如 OOP. 也可以用于方法和简单的函数. 享元是一种特定于面向对象编程优化的设计模式, 关注的共享对象数据. 在 Python 中, 享元可以以多种方式实现. 示例代码: 使用元类实现 import random from enum import Enum TreeType = Enum(&apos;TreeType&apos;, &apos;apple_tree cherry_tree peach_tree&apos;) class Tree: # pool 类属性, 是一个对象池, 类的所有实例共享该变量. pool = dict() def __new__(cls, tree_type): &quot;&quot;&quot; __new__() 在 __init__() 之前调用. 把 Tree 编程一个元类, 元类支持自引用. 这意味着 cls 引用的是 Tree 类. 当客户端要创建 Tree 的一个实例时, 会以 tree_type 参数传递数的种类. 树的种类用于检查是否创建过相同的树, 如果是, 则返回之前创建的对象, 否则将新的树种类添加到池中, 并返回相应的新对象. &quot;&quot;&quot; obj = cls.pool.get(tree_type, None) if not obj: obj = object.__new__(cls) cls.pool[tree_type] = obj obj.tree_type = tree_type return obj def render(self, age, x, y): &quot;&quot;&quot; 用于渲染一颗树. 享元不知道的所有可变信息都由客户端代码显式传递.&quot;&quot;&quot; print(&apos;render a tree of type {} and age {} at ({}, {})&apos;.format(self.tree_type, age, x, y)) def main(): &quot;&quot;&quot;如何使用 享元模式. &quot;&quot;&quot; rnd = random.Random() age_min, age_max = 1, 30 # 单位为年 min_point, max_point = 0, 100 tree_counter = 0 for _ in range(10): t1 = Tree(TreeType.apple_tree) t1.render(rnd.randint(age_min, age_max), rnd.randint(min_point, max_point), rnd.randint(min_point, max_point)) tree_counter += 1 for _ in range(3): t2 = Tree(TreeType.cherry_tree) t2.render(rnd.randint(age_min, age_max), rnd.randint(min_point, max_point), rnd.randint(min_point, max_point)) tree_counter += 1 for _ in range(5): t3 = Tree(TreeType.peach_tree) t3.render(rnd.randint(age_min, age_max), rnd.randint(min_point, max_point), rnd.randint(min_point, max_point)) tree_counter += 1 print(&apos;trees rendered: {}&apos;.format(tree_counter)) print(&apos;trees actually created: {}&apos;.format(len(Tree.pool))) t4 = Tree(TreeType.cherry_tree) t5 = Tree(TreeType.cherry_tree) t6 = Tree(TreeType.apple_tree) # 享元模式不能依赖对象的 ID. print(&apos;{} == {}? {}&apos;.format(id(t4), id(t5), id(t4) == id(t5))) print(&apos;{} == {}? {}&apos;.format(id(t5), id(t6), id(t5) == id(t6))) if __name__ == &apos;__main__&apos;: main() 5. 模型-视图-控制器模式关注点分离(Separation of Concerns, SoC)原则是软件工程相关的设计原则之一. SoC 原则背后的思想是讲一个应用切分成不同的部分, 每个部分解决一个单独的关注点. 分层设计中的层次(数据访问层, 业务逻辑层, 表示层), 即是关注点的例子. 使用 SoC 原则能简化软件应用的开发和维护. 模型-视图-控制器(Model-View-Controller, MVC)模式是应用到面向对象编程的 SoC 原则. MVC 被认为是一种架构模式, 而不是一种设计模式. 架构模式和设计模式之间的区别在于前者比后者的范畴更广. 模型是核心的部分, 代表着应用的信息本源, 包含和管理(业务)逻辑, 数据和状态以及应用的规则. 视图是模型的可视化表现, 它只展示数据, 并不处理数据. 控制器是模型和视图至今的链接/粘附. 模型和视图之间的所有通信都通过控制器进行. MVC 是一个非常通用且大有用处的设计模式. 实际上, 所有流行的 Web 框架(Django, Rails, Yii) 和应用框架(iPhone SDK, Android 和 QT) 都使用了 MVC 或者其变种. 如 模式-视图-适配器(Model-View-Adapter, MVA), 模型-视图-演示者(Model-View-Presenter, MVP)等. 从头开始实现 MVC 时, 请确保创建的模型很智能, 控制器很瘦, 视图很傻瓜. 智能模型 包含所有的校验/业务规则/逻辑 处理应用的状态 访问应用数据(数据库, 云或其他) 不依赖 UI 瘦控制器 在用户与视图交互时, 更新模型 在模型改变时, 更新视图 如果需要, 在数据传递给模型/视图之前进行处理 不展示数据 不直接访问应用数据 不包含校验/业务规则/逻辑 傻瓜视图 展示数据 允许用户与其交互 仅做最小的数据处理, 通常有一种模板语言提供处理能力 不存储任何数据 不直接访问应用数据 不包含校验/业务规则/逻辑 示例代码 quotes = (&apos;A man is not complete until he is married. Then he is finished.&apos;, &apos;As I said before, I never repeat myself.&apos;, &apos;Behind a successful man is an exhausted woman.&apos;, &apos;Black holes really suck...&apos;, &apos;Facts are stubborn things.&apos;) class QuoteModel: &quot;&quot;&quot; 模型&quot;&quot;&quot; def get_quote(self, n): try: value = quotes[n] except IndexError as err: value = &apos;Not found!&apos; return value class QuoteTerminalView: &quot;&quot;&quot; 视图 &quot;&quot;&quot; def show(self, quote): print(&apos;And the quote is: &quot;{}&quot;&apos;.format(quote)) def error(self, msg): print(&apos;Error: {}&apos;.format(msg)) def select_quote(self): return input(&apos;Which quote number would you like to see?&apos;) class QuoteTerminalController: &quot;&quot;&quot; 控制器, 负责协调 &quot;&quot;&quot; def __init__(self): self.model = QuoteModel() self.view = QuoteTerminalView() def run(self): valid_input = False while not valid_input: n = self.view.select_quote() try: n = int(n) except ValueError as err: self.view.error(&quot;Incorrect index &apos;{}&apos;&quot;.format(n)) else: valid_input = True quote = self.model.get_quote(n) self.view.show(quote) def main(): &quot;&quot;&quot;初始化并触发控制器.&quot;&quot;&quot; controller = QuoteTerminalController() while True: controller.run() if __name__ == &apos;__main__&apos;: main() 6. 代理模式代理设计模式(Proxy design pattern)使用代理对象在访问实际对象之前执行重要操作. 有 4 中不同的代理类型: 远程代理: 实际存在不同地址空间的对象在本地的代理者. 对象关系映射(Object-Relational Mapping, ORM) API 也是一个如何使用远程代理的例子. 提供类 OOP 的关系型数据库访问. 即 ORM 是关系型数据库的代理, 数据库可以部署在任何地方. 虚拟代理: 用于懒初始化, 讲一个大计算量对象的创建延迟到真正需要的时候进行. 示例代码: class LazyProperty: def __init__(self, method): self.method = method self.method_name = method.__name__ print(&apos;function overriden: {}&apos;.format(self.method)) print(&quot;function&apos;s name: {}&quot;.format(self.method_name)) def __get__(self, obj, cls): &quot;&quot;&quot;使用值来替代方法. 这意味着 特性是惰性加载的, 而且仅可以设置一次. &quot;&quot;&quot; if not obj: return None value = self.method(obj) print(&apos;value {}&apos;.format(value)) setattr(obj, self.method_name, value) return value class Test: def __init__(self): self.x = &apos;foo&apos; self.y = &apos;bar&apos; self._resource = None # 希望懒加载的变量 @LazyProperty def resource(self): print(&apos;initializing self._resource which is: {}&apos;.format(self._resource)) self._resource = tuple(range(5)) # 代价大的 return self._resource def main(): t = Test() print(t.x) print(t.y) # 做更多的事情。。。 print(t.resource) print(t.resource) if __name__ == &apos;__main__&apos;: main() 在 OOP 中有两种基本的, 不同类型的懒初始化(懒加载): 在实例级 : 这意味着会一个对象的特性进行懒初始化, 但该特性有一个对象作用域. 同一个类的每个实例(对象)都有自己的(不同的)特性副本. 在类级或模块级 : 在这种情况下, 我们不希望每个实例都有一个不同的 特性副本, 而是所有实例共享同一个特性, 而特性是懒初始化的. 保护/防护代理: 控制对敏感对象的访问. 示例代码: class SensitiveInfo: def __init__(self): self.users = [&apos;nick&apos;, &apos;tom&apos;, &apos;ben&apos;, &apos;mike&apos;] def read(self): print(&apos;There are {} users: {}&apos;.format(len(self.users), &apos; &apos;.join(self.users))) def add(self, user): self.users.append(user) print(&apos;Added user {}&apos;.format(user)) class Info: &apos;&apos;&apos;SensitiveInfo的保护代理&apos;&apos;&apos; def __init__(self): self.protected = SensitiveInfo() self.secret = &apos;0xdeadbeef&apos; def read(self): self.protected.read() def add(self, user): sec = input(&apos;what is the secret? &apos;) self.protected.add(user) if sec == self.secret else print(&quot;That&apos;s wrong!&quot;) def main(): info = Info() while True: print(&apos;1. read list |==| 2. add user |==| 3. quit&apos;) key = input(&apos;choose option: &apos;) if key == &apos;1&apos;: info.read() elif key == &apos;2&apos;: name = input(&apos;choose username: &apos;) info.add(name) elif key == &apos;3&apos;: exit() else: print(&apos;unknown option: {}&apos;.format(key)) if __name__ == &apos;__main__&apos;: main() 智能(引用)代理: 在对象被访问时执行额外的动作.包括引用计数和线程安全检查. Python 的 weakref 模块包含一个 proxy() 方法, 该方法接受一个输入对象并将一个智能代理返回给该对象. 弱引用是为对象添加引用计数支持的一种推荐方法. 三. 行为型模式行为型模式通过结构化他们的交互过程来简化类之间的交互. 1. 责任链模式责任链(Chain of Responsibility) 模式用于让多个对象来处理单个请求时, 或用于预先不知道应该由那个对象(来自某个对象链)来处理某个特定请求. 这一模式的价值在于解耦, 客户端与所有处理程序(一个处理程序与其他处理程序之间也是如此)之间不再是多对多的关系, 客户端仅需知道如何与链的起始节点(标头)进行通信. 责任链设计模式有如下原则: 存在一个对象链(链表, 树或任何其他便捷的数据结构) 一开始将请求发送给链中的第一个对象 对象决定其是否要处理该请求 对象将请求装发给下一个对象. 重复该过程, 直到到达链尾. 客户端仅知道 对象链中的第一个对象, 而非拥有对所有处理元素的引用; 并且每个元素仅知道其直接的下一个邻居, 而不知道所有其他处理元素. 即对象链通常为一个单项关系. 在基于事件的编程中, 多个对象需要对同一个请求进行处理. 即单个事件可被多个事件监听者捕获. 示例代码: 实现一个简单的事件系统, 使用动态分发来处理请求. class Event: &quot;&quot;&quot; 描述一个事件 &quot;&quot;&quot; def __init__(self, name): self.name = name def __str__(self): return self.name class Widget: &quot;&quot;&quot; 核心类.&quot;&quot;&quot; def __init__(self, parent=None): self.parent = parent # parent 聚合关系表明每个控件都有一个到父对象的引用. def handle(self, event): &quot;&quot;&quot; 动态分发, 事件作为参数传递给方法. 通过 hasattr() 和 getattr() 决定一个特定请求的处理方法 &quot;&quot;&quot; handler = &apos;handle_{}&apos;.format(event) if hasattr(self, handler): method = getattr(self, handler) method(event) elif self.parent: # 使用父子关系作为回退机制. self.parent.handle(event) elif hasattr(self, &apos;handle_default&apos;): # 父子对象中, 父对象必须要有 handle_default 方法. self.handle_default(event) class MainWindow(Widget): def handle_close(self, event): print(&apos;MainWindow: {}&apos;.format(event)) def handle_default(self, event): print(&apos;MainWindow Default: {}&apos;.format(event)) class SendDialog(Widget): def handle_paint(self, event): print(&apos;SendDialog: {}&apos;.format(event)) class MsgText(Widget): def handle_down(self, event): print(&apos;MsgText: {}&apos;.format(event)) def main(): mw = MainWindow() sd = SendDialog(mw) # 注意传入的参数, 父子关系 msg = MsgText(sd) # 注意传入的参数, 父子关系 for e in (&apos;down&apos;, &apos;paint&apos;, &apos;unhandled&apos;, &apos;close&apos;): evt = Event(e) print(&apos;\nSending event -{}- to MainWindow&apos;.format(evt)) mw.handle(evt) print(&apos;Sending event -{}- to SendDialog&apos;.format(evt)) sd.handle(evt) print(&apos;Sending event -{}- to MsgText&apos;.format(evt)) msg.handle(evt) if __name__ == &apos;__main__&apos;: main() 2. 命令模式命令模式(Command pattern)可以将一个操作(撤销, 重做, 复制, 粘贴等) 封装成一个对象. 这意味着, 创建一个类, 包含实现该操作所需要的所有逻辑和方法. 优势: 无需直接执行一个命令. 调用命令的对象与指导如何执行命令的对象解耦. 调用者无需知道命令的任何实现细节. 如果有意义, 可以把多个命令组织起来, 并按顺序执行. 例如在, 实现一个多层撤销命令时, 这是很有用的. 使用场景: GUI 按钮和菜单项 : 如 PyQT 使用命令模式实现按钮和菜单项上的动作. 其他操作 : 命令模式可用于实现任何操作, 如撤销, 剪切, 赋值, 粘贴, 重做和文本大写. 事务性行为和日志记录 : 事务性行为和日志记录对于为变更记录一份持久化日志是非常重要的. 宏 : 宏只一个动作序列, 可在任意时间按要求进行录制和执行. 示例代码: 文件新建, 写入, 读取, 删除操作 import os verbose = True # 一个全局标记, 被激活时向用户反馈执行的操作. class RenameFile: def __init__(self, path_src, path_dest): self.src, self.dest = path_src, path_dest def execute(self): &quot;&quot;&quot; 执行操作. &quot;&quot;&quot; if verbose: print(&quot;[renaming &apos;{}&apos; to &apos;{}&apos;]&quot;.format(self.src, self.dest)) os.rename(self.src, self.dest) def undo(self): &quot;&quot;&quot; 撤销操作. &quot;&quot;&quot; if verbose: print(&quot;[renaming &apos;{}&apos; back to &apos;{}&apos;]&quot;.format(self.dest, self.src)) os.rename(self.dest, self.src) class CreateFile: def __init__(self, path, txt=&apos;hello world\n&apos;): self.path, self.txt = path, txt def execute(self): if verbose: print(&quot;[creating file &apos;{}&apos;]&quot;.format(self.path)) with open(self.path, mode=&apos;w&apos;, encoding=&apos;utf-8&apos;) as out_file: out_file.write(self.txt) def undo(self): delete_file(self.path) class ReadFile: def __init__(self, path): self.path = path def execute(self): if verbose: print(&quot;[reading file &apos;{}&apos;]&quot;.format(self.path)) with open(self.path, mode=&apos;r&apos;, encoding=&apos;utf-8&apos;) as in_file: print(in_file.read(), end=&apos;&apos;) def delete_file(path): if verbose: print(&quot;deleting file &apos;{}&apos;&quot;.format(path)) os.remove(path) def main(): orig_name, new_name = &apos;file1&apos;, &apos;file2&apos; commands = [] for cmd in CreateFile(orig_name), ReadFile(orig_name), RenameFile(orig_name, new_name): commands.append(cmd) [c.execute() for c in commands] answer = input(&apos;reverse the executed commands? [y/n] &apos;) if answer not in &apos;yY&apos;: print(&quot;the result is {}&quot;.format(new_name)) exit() for c in reversed(commands): try: c.undo() except AttributeError as e: pass if __name__ == &apos;__main__&apos;: main() 3. 解释器模式解释器模式可用于创建一种专注于某个特定领域的, 具有有限表达能力的计算机语言. 这种语言被称为领域特定语言(Domain Specific Language, DSL). 解释器模式背后的主要思想是让非初级用户或领域专家使用一门简单的语言来表达想法. DSL 分为 内部DSL 和 外部 DSL : 内部 DSL : 构建在一种宿主编程语言之上. 如 使用 Python 解决线性方程组的一种语言. 优势: 无需担心创建, 编译及解析语法, 因为这已经被宿主语言解决掉了. 劣势: 首先于宿主语言的特性. 外部 DSL : 不依赖于某种宿主语言. DSL 的创建者可以决定语言的方方面(语法, 句法等). 但也需要为其创建一个解析器和编译器. 解释器模式仅与内部 DSL 相关. 解释器根本不处理语言解析, 它假设我们已经有某种便利形式的解析好的数据, 可以是抽象语法数(Abstract Syntax Tree, AST) 或任何好友的数据结构, 如 yaml 之于 ansible. 另外, 解释器模式应仅用于实现简单的语言, 其目标是为专家提供恰当的编程抽象, 使其生产力更高, 并且这些专家通常不是程序员. 此外, DSL 的性能通常不是一个重要的关注点, 重点是提供一种语言, 隐藏宿主语言的独特性, 并提供更简洁易读的语法. 实现一种 内部 DSL 有多重方式, 可以使用正则表达式, 字符串处理, 操作符重载的组合以及元编程, 或其他第三方的库或工具. 示例代码: from pyparsing import Word, OneOrMore, Optional, Group, Suppress, alphanums # pyparsing 对空格, tab 或 意料之外的输出都是敏感的. class Gate: def __init__(self): self.is_open = False def __str__(self): return &apos;open&apos; if self.is_open else &apos;closed&apos; def open(self): print(&apos;opening the gate&apos;) self.is_open = True def close(self): print(&apos;closing the gate&apos;) self.is_open = False class Garage: def __init__(self): self.is_open = False def __str__(self): return &apos;open&apos; if self.is_open else &apos;closed&apos; def open(self): print(&apos;opening the garage&apos;) self.is_open = True def close(self): print(&apos;closing the garage&apos;) self.is_open = False class Aircondition: def __init__(self): self.is_on = False def __str__(self): return &apos;on&apos; if self.is_on else &apos;off&apos; def turn_on(self): print(&apos;turning on the aircondition&apos;) self.is_on = True def turn_off(self): print(&apos;turning off the aircondition&apos;) self.is_on = False class Heating: def __init__(self): self.is_on = False def __str__(self): return &apos;on&apos; if self.is_on else &apos;off&apos; def turn_on(self): print(&apos;turning on the heating&apos;) self.is_on = True def turn_off(self): print(&apos;turning off the heating&apos;) self.is_on = False class Boiler: def __init__(self): self.temperature = 83 # in celsius def __str__(self): return &apos;boiler temperature: {}&apos;.format(self.temperature) def increase_temperature(self, amount): print(&quot;increasing the boiler&apos;s temperature by {} degrees&quot;.format(amount)) self.temperature += amount def decrease_temperature(self, amount): print(&quot;decreasing the boiler&apos;s temperature by {} degrees&quot;.format(amount)) self.temperature -= amount class Fridge: def __init__(self): self.temperature = 2 # 单位为摄氏度 def __str__(self): return &apos;fridge temperature: {}&apos;.format(self.temperature) def increase_temperature(self, amount): print(&quot;increasing the fridge&apos;s temperature by {} degrees&quot;.format(amount)) self.temperature += amount def decrease_temperature(self, amount): print(&quot;decreasing the fridge&apos;s temperature by {} degrees&quot;.format(amount)) self.temperature -= amount def main(): # 定义语法. word = Word(alphanums) command = Group(OneOrMore(word)) token = Suppress(&quot;-&gt;&quot;) device = Group(OneOrMore(word)) argument = Group(OneOrMore(word)) event = command + token + device + Optional(token + argument) gate = Gate() garage = Garage() airco = Aircondition() heating = Heating() boiler = Boiler() fridge = Fridge() tests = (&apos;open -&gt; gate&apos;, &apos;close -&gt; garage&apos;, &apos;turn on -&gt; aircondition&apos;, &apos;turn off -&gt; heating&apos;, &apos;increase -&gt; boiler temperature -&gt; 5 degrees&apos;, &apos;decrease -&gt; fridge temperature -&gt; 2 degrees&apos;) open_actions = {&apos;gate&apos;: gate.open, &apos;garage&apos;: garage.open, &apos;aircondition&apos;: airco.turn_on, &apos;heating&apos;: heating.turn_on, &apos;boiler temperature&apos;: boiler.increase_temperature, &apos;fridge temperature&apos;: fridge.increase_temperature} close_actions = {&apos;gate&apos;: gate.close, &apos;garage&apos;: garage.close, &apos;aircondition&apos;: airco.turn_off, &apos;heating&apos;: heating.turn_off, &apos;boiler temperature&apos;: boiler.decrease_temperature, &apos;fridge temperature&apos;: fridge.decrease_temperature} &quot;&quot;&quot; 执行 print(event.parseString(&quot;increase -&gt; boiler temperature -&gt; 3 degrees&quot;)) 结果为 : [[&quot;increase&quot;], [&quot;boiler&quot;, &quot;temperature&quot;], [&quot;3&quot;, &quot;degrees&quot;]] &quot;&quot;&quot; for t in tests: if len(event.parseString(t)) == 2: # 没有参数 cmd, dev = event.parseString(t) cmd_str, dev_str = &apos; &apos;.join(cmd), &apos; &apos;.join(dev) if &apos;open&apos; in cmd_str or &apos;turn on&apos; in cmd_str: open_actions[dev_str]() elif &apos;close&apos; in cmd_str or &apos;turn off&apos; in cmd_str: close_actions[dev_str]() elif len(event.parseString(t)) == 3: # 有参数 cmd, dev, arg = event.parseString(t) cmd_str, dev_str, arg_str = &apos; &apos;.join(cmd), &apos; &apos;.join(dev), &apos; &apos;.join(arg) num_arg = 0 try: num_arg = int(arg_str.split()[0]) # 抽取数值部分 except ValueError as err: print(&quot;expected number but got: &apos;{}&apos;&quot;.format(arg_str[0])) if &apos;increase&apos; in cmd_str and num_arg &gt; 0: open_actions[dev_str](num_arg) elif &apos;decrease&apos; in cmd_str and num_arg &gt; 0: close_actions[dev_str](num_arg) if __name__ == &apos;__main__&apos;: main() 4. 观察者模式观察者模式用于在两个或多个对象之间创建一个发布-订阅通信类型. 观察者模式描述单个对象(发布者, 又称为主持者或者可观察者)与一个或多个对象(订阅者, 又称为观察者)之间的发布-订阅关系. 观察者模式背后的思想等同于 MVC 和 关注点分离原则 背后的思想, 即降低分布者与订阅者之间的耦合度, 从而易于在运行时添加/删除订阅者. 此外, 发布者不关心它的订阅者是谁, 它只是将通知发送给所有订阅者. 观察者的数量以及谁是观察者可能会有所不同, 也可以在运行时动态改变. 拍卖会类似于观察者模式, 每个拍卖出价人都有一些拍牌, 在他们想出价时就可以举起来. 不论出价人在何时举起一块拍牌, 拍卖师都会像主持者那样更新报价, 并将新的价格广播给所有出价人(订阅者). django-observer 是一个第三方 Django 包, 可用于注册回调函数, 之后在某些 Django 模型字段发生变化时执行. 它支持许多不同类型的模型字段(CharField, IntegerField 等). RabbitMQ 可用于为应用添加异步消息支持, 支持多种消息协议(如 HTTP, AMQP), 可在 Python 应用中用于实现 发布-订阅 模式, 也就是观察者设计模式. Blinker 为python对象提供快速并且简单的对象到对象以及广播的信号传递. 事件驱动系统是使用观察者模式的典型实现. 在这种系统中, 监听者被用于监听特定事件. 监听者正在监听的事件被创建出来时, 就会触发他们. 其关键点是单个事件(发布者)可以关联多个监听者(观察者). 代码示例: class Publisher: &quot;&quot;&quot; 发布者, 基类&quot;&quot;&quot; def __init__(self): self.observers = [] # 观察者保存列表 def add(self, observer): &quot;&quot;&quot; 添加观察者 &quot;&quot;&quot; if observer not in self.observers: self.observers.append(observer) else: print(&apos;Failed to add: {}&apos;.format(observer)) def remove(self, observer): &quot;&quot;&quot; 删除观察者 &quot;&quot;&quot; try: self.observers.remove(observer) except ValueError: print(&apos;Failed to remove: {}&apos;.format(observer)) def notify(self): &quot;&quot;&quot; 通知所有观察者 &quot;&quot;&quot; [o.notify(self) for o in self.observers] class DefaultFormatter(Publisher): &quot;&quot;&quot; 默认格式化程序.&quot;&quot;&quot; def __init__(self, name): Publisher.__init__(self) self.name = name self._data = 0 def __str__(self): &quot;&quot;&quot; 默认格式化 &quot;&quot;&quot; return &quot;{}: &apos;{}&apos; has data = {}&quot;.format(type(self).__name__, self.name, self._data) @property def data(self): return self._data @data.setter def data(self, new_value): # 核心, try: self._data = int(new_value) except ValueError as e: print(&apos;Error: {}&apos;.format(e)) else: self.notify() class HexFormatter: &quot;&quot;&quot; 观察者 &quot;&quot;&quot; def notify(self, publisher): print(&quot;{}: &apos;{}&apos; has now hex data = {}&quot;.format(type(self).__name__, publisher.name, hex(publisher.data))) class BinaryFormatter: &quot;&quot;&quot; 观察者 &quot;&quot;&quot; def notify(self, publisher): print(&quot;{}: &apos;{}&apos; has now bin data = {}&quot;.format(type(self).__name__, publisher.name, bin(publisher.data))) def main(): df = DefaultFormatter(&apos;test1&apos;) print(df) print(&quot;-&quot; * 30) hf = HexFormatter() df.add(hf) df.data = 3 print(df) print(&quot;-&quot; * 30) bf = BinaryFormatter() df.add(bf) df.data = 21 print(df) print(&quot;-&quot; * 30) df.remove(hf) df.data = 40 print(df) print(&quot;-&quot; * 30) df.remove(hf) # 多次删除 df.add(bf) # 多次添加 df.data = &apos;hello&apos; # 数据类型错误 print(df) print(&quot;-&quot; * 30) df.data = 15.8 print(df) if __name__ == &apos;__main__&apos;: main() 6. 状态模式面向对象编程着力于在对象交互时改变他们的状态. 状态设计模式可用于实现一个核心的计算机科学概念: 状态机. 有限状态机(通常名为状态机)是一个非常方便的状态装换建模(并在必要时以数学方式形式化)工具. 状态设计模式就是应用到一个 特定软件工程问题的状态机. 状态设计模式解决的是一定上下文中无限数量状态的完全封装, 从而实现更好的可维护性和灵活性. 状态设计模式, 通常使用一个父 State 类和许多派生 ConcreteState 类 来实现, 父类包含所有状态共同的功能, 每个派生类则仅包含特定状态要求的功能. 如下代码所示: &quot;&quot;&quot; Implementation of the state pattern This example has a very simple radio. It has an AM/FM toggle switch, and a scan button to scan to the next station. &quot;&quot;&quot; class State(object): &quot;&quot;&quot;Base state. This is to share functionality&quot;&quot;&quot; def scan(self): &quot;&quot;&quot;Scan the dial to the next station&quot;&quot;&quot; self.pos += 1 if self.pos == len(self.stations): self.pos = 0 print &quot;Scanning… Station is&quot;, self.stations[self.pos], self.name class AmState(State): def __init__(self, radio): self.radio = radio self.stations = [&quot;1250&quot;, &quot;1380&quot;, &quot;1510&quot;] self.pos = 0 self.name = &quot;AM&quot; def toggle_amfm(self): print &quot;Switching to FM&quot; self.radio.state = self.radio.fmstate class FmState(State): def __init__(self, radio): self.radio = radio self.stations = [&quot;81.3&quot;, &quot;89.1&quot;, &quot;103.9&quot;] self.pos = 0 self.name = &quot;FM&quot; def toggle_amfm(self): print &quot;Switching to AM&quot; self.radio.state = self.radio.amstate class Radio(object): &quot;&quot;&quot;A radio. It has a scan button, and an AM/FM toggle switch.&quot;&quot;&quot; def __init__(self): &quot;&quot;&quot;We have an AM state and an FM state&quot;&quot;&quot; self.amstate = AmState(self) self.fmstate = FmState(self) self.state = self.amstate def toggle_amfm(self): self.state.toggle_amfm() def scan(self): self.state.scan() # Test our radio out radio = Radio() actions = [radio.scan] * 2 + [radio.toggle_amfm] + [radio.scan] * 2 actions = actions * 2 for action in actions: action() 状态机是一个抽象机器, 有两个关键部分,状态和转换. 状态 : 指系统的当前(激活)状态. 一个状态机在一个特定时间只能有一个激活状态. 转换 : 指从一个状态切换到另一个状态, 因某个事件或条件的触发而开始. 通常, 在一次转换发生之前或之后会执行一个或一组工作. 状态机可以用图来表现(称为状态图), 其中每个状态都是一个节点, 每个转换都是两个节点之间的边. django-fsm 用途 Django 框架中简化状态机的实现和使用.state_machine 模块也可以方便的创建状态机. 代码示例: 使用 state_machine 实现的状态机. from state_machine import State, Event, acts_as_state_machine, after, before, InvalidStateTransition @acts_as_state_machine # 装饰器. class Process: # 定义状态机的状态. created = State(initial=True) # initial 指定状态及的初始状态. waiting = State() running = State() terminated = State() blocked = State() swapped_out_waiting = State() swapped_out_blocked = State() # 定义状态转换, 一个状态转换就是一个 Event. # from_states 为单个状态或一个状态元组, 是对象的起始状态(或之一). # to_state 为对象的目标状态. wait = Event(from_states=(created, running, blocked, swapped_out_waiting), to_state=waiting) run = Event(from_states=waiting, to_state=running) terminate = Event(from_states=running, to_state=terminated) block = Event(from_states=(running, swapped_out_blocked), to_state=blocked) swap_wait = Event(from_states=waiting, to_state=swapped_out_waiting) swap_block = Event(from_states=blocked, to_state=swapped_out_blocked) def __init__(self, name): &quot;&quot;&quot; 进程元信息&quot;&quot;&quot; self.name = name ## before 和 after 装饰器, 用于在状态转换之前或之后执行工作. @after(&apos;wait&apos;) def wait_info(self): print(&apos;{} entered waiting mode&apos;.format(self.name)) @after(&apos;run&apos;) def run_info(self): print(&apos;{} is running&apos;.format(self.name)) @before(&apos;terminate&apos;) def terminate_info(self): print(&apos;{} terminated&apos;.format(self.name)) @after(&apos;block&apos;) def block_info(self): print(&apos;{} is blocked&apos;.format(self.name)) @after(&apos;swap_wait&apos;) def swap_wait_info(self): print(&apos;{} is swapped out and waiting&apos;.format(self.name)) @after(&apos;swap_block&apos;) def swap_block_info(self): print(&apos;{} is swapped out and blocked&apos;.format(self.name)) def transition(process, event, event_name): &quot;&quot;&quot; 状态转换函数, process 是一个 Process 类实例 event 是一个 Event 类实例 event_name 是事件名称, 此处需手动输入, 用于在出错时, 输出事件名称. &quot;&quot;&quot; try: event() except InvalidStateTransition as err: print(&apos;Error: transition of {} from {} to {} failed&apos;.format(process.name, process.current_state, event_name)) def state_info(process): &quot;&quot;&quot;展示进程当前状态的一些基本信息. process 是一个 Process 类实例. &quot;&quot;&quot; print(&apos;state of {}: {}&apos;.format(process.name, process.current_state)) def main(): # 字符串常量, 作为 event_name 参数值传递. RUNNING = &apos;running&apos; WAITING = &apos;waiting&apos; BLOCKED = &apos;blocked&apos; TERMINATED = &apos;terminated&apos; pn = Process(&quot;processn&quot;) print(dir(pn)) print(pn.current_state) print(pn.aasm_state) print(&quot;-&quot; * 30) p1, p2 = Process(&apos;process1&apos;), Process(&apos;process2&apos;) [state_info(p) for p in (p1, p2)] print() transition(p1, p1.wait, WAITING) transition(p2, p2.terminate, TERMINATED) [state_info(p) for p in (p1, p2)] print() transition(p1, p1.run, RUNNING) transition(p2, p2.wait, WAITING) [state_info(p) for p in (p1, p2)] print() transition(p2, p2.run, RUNNING) [state_info(p) for p in (p1, p2)] print() [transition(p, p.block, BLOCKED) for p in (p1, p2)] [state_info(p) for p in (p1, p2)] print() [transition(p, p.terminate, TERMINATED) for p in (p1, p2)] [state_info(p) for p in (p1, p2)] if __name__ == &apos;__main__&apos;: main() 7. 策略模式使用策略模式实现在(在许多候选算法中)动态地选择算法. 策略模式(Strategy pattern)鼓励使用多种算法来解决一个问题, 他能在运行时透明的切换算法(客户端代码对变化无感知). 策略模式是一种非常通用的设计模式, 无论何时希望动态, 透明的应用不同的算法, 策略模式都是可行之路. 此处的不同算法指: 目的相同但实现方案不同的一类算法. 这意味着算法结果应该是完全一致的, 但每种实现都有不同的性能和代码复杂性. 使用场景: 创建各种不同的资源过滤器, 如排序问题, 身份验证, 日志记录, 数据压缩和加密. 创建不同的样式表现, 为了实现可移植性或动态的改变数据的表现. 模拟, 如模拟机器人, 机器人行为中的所有不同之处都可以使用不同的策略来建模. Python 中的 sorted() 和 list.sort() 函数是策略模式的例子, 两个函数都接受一个命名参数key, 这个参数本质上是实现了一个排序策略的函数的名称. 示例代码: import time SLOW = 3 # 单位为秒 LIMIT = 5 # 字符数 WARNING = &apos;too bad, you picked the slow algorithm :(&apos; def pairs(seq): &quot;&quot;&quot; 返回所有相邻字符对的一个序列.&quot;&quot;&quot; n = len(seq) for i in range(n): yield seq[i], seq[(i + 1) % n] def allUniqueSort(s): if len(s) &gt; LIMIT: print(WARNING) time.sleep(SLOW) srtStr = sorted(s) for (c1, c2) in pairs(srtStr): if c1 == c2: return False return True def allUniqueSet(s): if len(s) &lt; LIMIT: print(WARNING) time.sleep(SLOW) return True if len(set(s)) == len(s) else False def allUnique(s, strategy): return strategy(s) def autoStrate(s): if len(s) &gt; LIMIT: return allUniqueSet(s) else return allUniqueSort(s) def main(): &quot;&quot;&quot; 通常代码使用的策略不应该由用户来选择, 策略模式的要点是可以透明的选择使用不同的算法, 即程序自动选择最快的算法, 如 autoStrate() . &quot;&quot;&quot; while True: word = None while not word: word = input(&apos;Insert word (type quit to exit)&gt; &apos;) if word == &apos;quit&apos;: print(&apos;bye&apos;) return strategy_picked = None strategies = {&apos;1&apos;: allUniqueSet, &apos;2&apos;: allUniqueSort} while strategy_picked not in strategies.keys(): strategy_picked = input(&apos;Choose strategy: [1] Use a set, [2] Sort and pair&gt; &apos;) try: strategy = strategies[strategy_picked] print(&apos;allUnique({}): {}&apos;.format(word, allUnique(word, strategy))) except KeyError as err: print(&apos;Incorrect option: {}&apos;.format(strategy_picked)) if __name__ == &apos;__main__&apos;: main() 8. 模板模式模板模式通过定义抽象步骤来帮助设计一个通用算法, 这些抽象步骤有子类来实现. 这种模式使用里氏替换原则, 即: 如果 S 是 T 的子类型, 则程序中类型 T 的对象可以用类型 S 的对象替换, 而无需改变该程序的任何期望属性. 换句话说, 抽象类可以通过在具体类中实现的步骤来定义算法如何工作. 抽象类还可以该出算法的基本或部分实现, 并允许开发人员覆写其部分. 模板模式用于抽取一个算法的通用部分, 从而提高代码复用. 模板设计模式(Template Design Pattern) 关注的是消除代码冗余, 其思想是应该无需改变算法结构就能重新定义一个算法的某些部分. 当发现结构相近的(多个)算法中有重复代码, 则可以把算法的不变(通用)部分留在一个模板方法/函数中, 把易变(不同)的部分移到动作/钩子方法/函数中. Python 的 cmd 模块使用了模板模式, 该模块用于构建面向行的命令解释器. 具体而言, cmd.Cmd.cmdloop() 实现了一个算法, 持续的读取输入命令并将命令分发到动作方法. 每次循环之前, 之后做的事情以及命令解释部分使用时相同的, 这即使算法中的不变部分; 变化的是实际的动作方法(易变的部分). 示例代码 from cowpy import cow def dots_style(msg): msg = msg.capitalize() msg = &apos;.&apos; * 10 + msg + &apos;.&apos; * 10 return msg def admire_style(msg): msg = msg.upper() return &apos;!&apos;.join(msg) def cow_style(msg): &quot;&quot;&quot; 使用 cowpy 模块生成随机 ASCII 码艺术字符.&quot;&quot;&quot; msg = cow.milk_random_cow(msg) return msg def generate_banner(msg, style=dots_style): print(&apos;-- start of banner --&apos;) print(style(msg)) print(&apos;-- end of banner --\n\n&apos;) def main(): msg = &apos;happy coding&apos; [generate_banner(msg, style) for style in (dots_style, admire_style, cow_style)] if __name__ == &apos;__main__&apos;: main()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 扩展之--flask-pagedown]]></title>
    <url>%2F2018%2F03%2F19%2FflaskExt--flask-pagedown%2F</url>
    <content type="text"><![CDATA[支持 Markdown 语法, 并添加 富文本文章的预览功能. 使用到的包列表: PageDown : 使用 JavaScript 实现的客户端 Markdown 到 HTML 的转换程序. Flask-PageDown : 为 Flask 包装的 PageDown, 把 PageDown 集成到 Flask-WTF 表单中. Markdown : 使用 Python 实现的服务端 Markdown 到 HTML 的转换程序. Bleanch : 使用 Python 实现的 HTML 清理器. 一. 安装 :$ pip install flask-pagedown markdown bleach 二. 初始化 Flask-PageDown :与在 Flask 中初始化其他扩展一样. from flask_pagedown import PageDown # ... pagedown = PageDown() # ... def create_app(config_name): # ... pagedown.init_app(app) # ... 三. 使用(渲染) Flask-PageDown :Flask-PageDown 扩展定义了一个 PageDownField 类, 该类与 WTForms 的 TextAreaField 接口一致. from flask_pagedown.fields import PageDownField class PostForm(Form): body = PageDownField(&quot;Post:&quot;, validators=[required()]) submit = SubmitField(&quot;Submit&quot;) 四. Markdown 预览 :Markdown 预览使用 PageDown 库生成, 因此需要在 Jinja 模板中修改. Flask-PageDown 简化了这一过程, 提供了一个红模板, 从 CDN 中加载所需文件. {% block scripts %} {{ super() }} {{ pagedown.include_pagedown() }} {% endblock %} 五. 在服务器上处理富文本出于安全考虑, 表单在提交后, POST 请求只会发送纯 Markdown 文本给服务端, 页面中显示的 HTML 预览会被丢掉. 被提交的 POST 数据, 在服务端使用 Markdown 将其转换为 HTML, 得到HTML 之后, 在使用 Bleach 进行清理, 确保其中只包含几个允许使用的 HTML 标签. 转换步骤 : markdown() 函数将 Markdown 文本转换成 HTML; clean() 函数将 HTML 与允许使用的 HTML 标签列表对比, 清除所有不在白名单中的标签. linkify() , 由 Bleach 提供, 把纯文本的 URL 转换成适当的 链接. 因为 Markdown 规范没有为自动生成 链接 提供官方支持, PageDown 以扩展的方式实现了该功能. 示例代码 : from markdown import markdown import bleach class Post(db.Model): # ... body = db.Colume(db.Text) body_html = db.Column(db.Text) # ... @staticmethod def on_changed_method(target, value, oldvalue, initiator): allowed_tags = [&quot;a&quot;, &quot;abbr&quot;, &quot;acronym&quot;, &quot;b&quot;, &quot;blockquote&quot;, &quot;code&quot;, &quot;em&quot;, &quot;i&quot;, &quot;li&quot;, &quot;ol&quot;, &quot;pre&quot;, &quot;strong&quot;, &quot;ul&quot;, &quot;h1&quot;, &quot;h2&quot;,&quot;h3&quot;,&quot;h4&quot;,&quot;p&quot;] target.body_html = bleach.linkify(bleach.clean(markdown(value, output_format=&quot;html&quot;), tags=allowed_tags, strip=True)) db.event.listen(Post.body, &quot;set&quot;, Post.on_changeed_body) # on_changed_body 函数注册在 body 字段上, 是 SQLIAlchemy &quot;set&quot; 事件的监听程序, 这意味着只要这个类实例的 body 字段设了新值, 函数就会自动被调用. on_changed_body 函数把 body 字段中的文本渲染成 HTML 格式, 结果保存在 body_html 中, 自动高效的完成 Markdown 文本到 HTML 的转换.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Flask 扩展</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 扩展之--flask-login]]></title>
    <url>%2F2018%2F03%2F19%2FflaskExt--flask-login%2F</url>
    <content type="text"><![CDATA[一. 使用 Werkzeug 实现密码散列.generate_password_hash(password, method=pbkdf2:sha1, salt_length=8)将原始密码作为输入, 以字符串形式输出密码散列值, 输出的值可保存在用户数据库中. method 和 salt_length 的默认值就能满足大多数需求. check_password_hash(hash, password)这个函数的参数是从数据库中取回的密码散列值和用户输入的密码. 返回值为 True, 表明密码正确. 示例代码 : from werkzeug.security import generate_password_hash, check_password_hash class User(db.Model): # ... password_hash = db.Column(db.String(128)) @property def password(self): # 设置属性不可读. raise AttributeError(&quot;Password is not a readable attribute.&quot;) @password.setter def password(self, password): # 写入密码 self.password_hash = generate_password_hash(password) def verify_password(self, password): # 认证密码 return check_password_hash(self.password_hash, password) 二. 使用 Flask-Login 认证用户.用户登录程序后, 他们的认证状态要被记录下来, 这样浏览不同的页面时, 才能记住这个状态. Flask-Login 是专门用来管理用户认证系统中的认证状态, 并且不依赖特定的认证机制. 1. 安装$ pip install flask-loging 2. 初始化from flask_login import LoginManager login_manager = LoginManager(app) login_manager.session_protection = &apos;strong&apos; login_manager.login_view = &apos;auth.login&apos; session_protection : 属性可以设为 None, ‘basic’, ‘strong’ , 已提供不同的安全等级防止用户篡改会话. strong : Flask-Login 会记录客户端IP地址和浏览器的用户代理信息, 如果发现异常就登出用户. login_view : 设置登录页面的端点. 3. 使用方法1) 模型实现方法一 : 实现4个模型方法使用 Flask-Login 扩展, 程序的 模型必须实现几个方法 : Flask-Login 要求实现的用户方法 方法 说明 is_authenticated() 如果用户一登录, 返回 True, 否则返回 False is_active() 如果允许用户登录, 返回 True, 否则返回 False. 如果要禁用账户, 可以返回 False is_anonymous() 对普通用户必须返回 False get_id() 必须返回用户的唯一标识符, 使用 Unicode 编码字符串 这四个方法可以在模型类中作为方法直接实现. 方法二 : UserMixin 类Flask-Login 提供了一个 UserMixin 类, 其中包含以上方法的默认实现, 且能满足大多数需求. 示例代码 : from flask_login import UserMixin class User(UserMixin, db.Model): pass 回调函数 : 使用指定的标识符加载用户. 定义在用户模型中.加载用户的回调函数, 接受已 Unicode 字符串形式表示的用户标识符. 如果能找到用户, 这个函数必须返回用户对象, 否则返回 None. 示例代码 : from . import login_manager @login_manager.user_loader def load_user(user_id): return User.query.get(int(user_id)) 2) 保护路由 : login_required 装饰器为了保护路由只让认证用户访问, Flask-Login 提供了一个 login_required 装饰器. 示例代码 : from flask_login import login_required @app.route(&apos;/secret&apos;) @login_required def secret(): return &quot;Only authenticated users are allowed!&quot; 3) 模板调用Flask-Login 变量提供 current_user 变量, 且在视图函数和模板中自动可用, 该变量的值是当前登录的用户, 如果用户尚未登录, 则是一个匿名用户代理对象. 示例代码 : # 视图函数中调用 from flask-login import current_user @auth.route(&quot;/confirm/&lt;token&gt;&quot;) @login_required def confirm(token): if current_user.confirmed: return redirect(url_for(&quot;main.index&quot;)) if current_user.confirm(token): flash(&quot;You have confirmed you account. Thanks!&quot;) else: flash(&quot;You confirmation link is invalid or has expired.&quot;) return redirect(url_for(&quot;main.index&quot;)) # 模板中调用 &lt;ul class=&quot;nav navbar-nav navbar-right&quot;&gt; {% if current_user.is_authenticated %} Sign Out {% else %} Sign In {% endif %} &lt;/ul&gt; 4) 登入用户: login_user(user, BOOLEAN)Flask-Login 提供 login_user() 函数, 在用户会话中把用户标记为已登录. login_user() 函数的参数是要登录的用户, 以及可选的 “记住我” 布尔值, “记住我” 也可在表单中实现. 如果布尔值为 True, 那么 关闭浏览器后用户会话就会过期, 下次访问时要重新登录; 如果为 False, 那么会在用户浏览器中写入一个长期有效的 cookie, 使用这个 cookie 可以复现用户会话. 示例代码 : from flask import render_template, redirect, request, url_for, flash from flask_login import login_user from . import auth from ..models import User from .forms import LoginForm @auth.route(&quot;/login&quot;, methods=[&quot;GET&quot;, &quot;POST&quot;]) def login(): form = LoginForm() if form.validate_on_submit(): user = User.query.filter_by(email=form.email.data).first() if user is not None and user.verify_password(form.password.data): login_user(user, form.remember_me) return redirect(request.args.get(&apos;next&apos;) or url_for(&apos;main.index&apos;)) flash(&quot;Invalid Username or Password&quot;) return render_template(&apos;auth/login.html&apos;, form=form) 用户访问未授权的 URL 时, 会显示登录表单. Flask-Login 会把原地址保存在查询的 next 参数中, 这个参数可从 request.args 字典读取. 如果查询字符串没有 next 参数, 则重定向到首页. 5) 登出用户: logout_user()Flask-Login 提供 logout_user() 函数, 删除并重设用户会话. 示例代码 : from flask_login import logout_user, login_required @auth.route(&quot;/logout&quot;) @login_required def logout(): logout_user() flash(&quot;You have been logged out.&quot;) return redirect(url_for(&quot;main.index&quot;)) 三. 使用 itsdangerours 生成确认令牌对于某些特定类型的程序, 有必要确认注册时用户提供的信息是否正确. 常见要求是能通过提供的调子邮件地址与用户取得联系. In [1]: from itsdangerous import TimedJSONWebSignatureSerializer as Serializer In [2]: s = Serializer(app.config[&apos;SECRET_KEY&apos;],expires_in=3600) In [3]: token = s.dumps({&apos;confirm&apos;:23}) In [4]: token Out[4]: &apos;eyJhbGciOiJIUzI1NiIsImV4cCI6MTQ4OTgyMDY4MiwiaWF0IjoxNDg5ODE3MDgyfQ.eyJjb25maXJtIjoyM30.Fg9uyyOMtJ7Mk_LhycSaJgI5tIkkK1tbfswTxZ7qaEk&apos; In [5]: data=s.loads(token) In [6]: data Out[6]: {&apos;confirm&apos;: 23} itsdangerous 提供多种生成令牌的方法. 其中 TimedJSONWebSignatureSerializer 类生成具有过期时间的 JSON web 签名(JSON Web Signatures, JWS). 这个类的构造函数接受的参数是一个密钥, 在 Flask 程序中可使用 SECRET_KEY 设置. dumps() 方法为指定的数据生成一个加密签名, 然后在对数据和签名进行序列化, 生成令牌字符串. expires_in 参数设置令牌的过期时间, 单位为 秒. loads() 用于解码令牌. 其唯一的参数是令牌字符串. 这个方法会检查签名和过期时间, 如果通过, 返回原始数据. 如果令牌不正确或过期, 抛出异常.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Flask 扩展</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 扩展之--flask-mail]]></title>
    <url>%2F2018%2F03%2F19%2FflaskExt--flask-mail%2F</url>
    <content type="text"><![CDATA[Flask-Mail 封装了 python 标准库 smtplib 包, 以便于更好的与 Flask 集成. 一. 安装$ pip install flask-mail 二. 配置 及 初始化Flask-Mail SMTP 服务器配置列表 配置 默认值 说明 MAIL_SERVER localhost 电子邮件服务器的主机名或 IP 地址 MAIL_PORT 25 电子邮件服务器的端口 MAIL_USE_TLS False 启用传输层安全（Transport Layer Security，TLS）协议 MAIL_USE_SSL False 启用安全套接层（Secure Sockets Layer，SSL）协议 MAIL_USERNAME None 邮件账户的用户名 MAIL_PASSWORD None 邮件账户的密码 配置示例 import os # ... app.config[&quot;MAIL_SERVER&quot;] = &apos;smtp.googlemail.com&apos; app.config[&quot;MAIL_PORT&quot;] = 587 app.config[&quot;MAIL_USE_TLS&quot;] = True app.config[&quot;MAIL_USERNAME&quot;] = os.environ.get(&quot;MAIL_USERNAME&quot;) app.config[&quot;MAIL_PASSWORD&quot;] = os.environ.get(&quot;MAIL_PASSWORD&quot;) ------------------------------------------------------------ 定义环境变量 : Linux : $ export MAIL_USERNAME=&lt;MY_USERNAME&gt; $ export MAIL_PASSWORD=&lt;MY_PASSWD&gt; Windows : $ set MAIL_USERNAME=&lt;MY_USERNAME&gt; $ set MAIL_PASSWORD=&lt;MY_PASSWD&gt; 初始化 from flask_mail import Mail mail = Mail(app) 三. 在程序中集成发送电子邮件功能可以使用 jinja2 模板渲染邮件正文 from flask_migrate import Migrate, MigrateCommand app.config[&quot;FLASK_MAIL_SUBJECT_PREFIX&quot;] = &apos;[MyFlask]&apos; # 邮件中主题前缀. app.config[&quot;FLASK_MAIL_SENDER&quot;] = &apos;FLASK Admin &lt;admin@example.com&gt;&apos; # 发件人地址 def send_email(to, subject, template, **kwargs): &quot;&quot;&quot;收件人地址, 主题, 邮件末班, 关键字参数列表(模板中定义的模板参数)&quot;&quot;&quot; msg = Message(app.config[&quot;FLASK_MAIL_SUBJECT_PREFIX&quot;] + subject, sender=app.config[&quot;FLASK_MAIL_SENDER&quot;], recipients=[to]) msg.body = render_template(template + &apos;.txt&apos;, **kwargs) # 纯文本正文 msg.html = render_template(template + &apos;.html&apos;, **kwargs) # 富文本正文 mail.send(msg) 四. 异步发送电子邮件.from threading import Thread def send_async_email(app, msg): with app.app_context(): # 激活程序上下文. mail.send(msg) def send_email(to, subject, template, **kwargs): &quot;&quot;&quot;收件人地址, 主题, 邮件末班, 关键字参数列表(模板中定义的模板参数)&quot;&quot;&quot; msg = Message(app.config[&quot;FLASK_MAIL_SUBJECT_PREFIX&quot;] + subject, sender=app.config[&quot;FLASK_MAIL_SENDER&quot;], recipients=[to]) msg.body = render_template(template + &apos;.txt&apos;, **kwargs) msg.html = render_template(template + &apos;.html&apos;, **kwargs) thr = Thread(target=send_async_email, args=[app, msg]) return thr 当程序要发送大量邮件时, 使用专门发送电子邮件的作业要比给每封邮件都新建一个线程更合适, 如使用 Celery 等任务队列]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Flask 扩展</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 扩展之--flask-moment]]></title>
    <url>%2F2018%2F03%2F19%2FflaskExt--flask-moment%2F</url>
    <content type="text"><![CDATA[一. 安装$ pip install flask-moment 二. 初始化from flask_moment import Moment moment = Moment(app) 三. 解决依赖moment.js示例代码 : 在基模板的 scripts 块中引入该库. {% block scripts %} {{ super() }} {{ moment.include_moment() }} {% endblock %} jquery.jsFlask-Moment依赖于 jquery.js, 需在文档中导入这个 js 库. 四. 在模板中使用 Flask-Moment示例代码 : # 从视图函数中, 向模板传入时间变量. from datetime import datetime @app.route(&apos;/&apos;) def index(): return render_template(&quot;index.html&quot;, current_time=datetime.utctime()) # 在模板中渲染 &lt;p&gt;The local date and time is {{ moment(current_time).format('LLL') }}.&lt;/p&gt; &lt;p&gt;That was {{ moment(current_time).from Now(refresh=True) }}&lt;/p&gt; 五. 其他方法 :文档: http://momentjs.com/docs/#/displaying format()根据客户端电脑中的时区和区域设置渲染日期和时间。参数决定了渲染的方式，’L’ 到 ‘LLLL’ 分别对应不同的复杂度。format() 函数还可接受自定义的格式说明符。 formNow()渲染相对时间戳. calendar()valueOf()unix()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Flask 扩展</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 扩展之--flask-script]]></title>
    <url>%2F2018%2F03%2F19%2FflaskExt--flask-script%2F</url>
    <content type="text"><![CDATA[一. 使用 Flask-Script 支持命令行选项1. 安装$ pip install flask-script 2. 配置from flask_script import Manager manager = Manager(app) # ... if __name__ == &quot;__main__&quot;: manager.run() 3. 使用$ python hello.py usage: myflask.py [-h] {shell,runserver} ... positional arguments: {shell,runserver} shell Runs a Python shell inside Flask application context. runserver Runs the Flask development server i.e. app.run() optional arguments: -h, --help show this help message and exit $ python hello.py shell --help $ python hello.py runserver --help $ python hello.py runserver --host 0.0.0.0 二. 添加自定义命令方法一 : manager.add_command()使用 Flask-Script 的 shell 命令自动导入特定的对象 : 为 shell 注册一个 make_context 回调函数. 1234567from flask_script import Shelldef make_shell_conntext(): """ make_shell_context() 注册了程序, 数据库实例, 以及模型.""" return dict(app=app, db=db, User=User, Role=Role)manager.add_command("shell". Shell(make_context=make_shell_context)) # 添加命令. 方法二 : 继承 Command 的子类1234567891011from flask_script import Commandclass Hello(Command): "prints hello world" def run(self): print "hello world"manager.add_command('hello', Hello()) # 或 manager.run(&#123;'hello' : Hello()&#125;)$ python manage.py hello 为命令行, 添加参数 : 添加 option_list 类属性 或者 添加 get_options() 类方法.1234567891011121314151617181920212223from flask_script import Command, Manager, Optionclass Hello1(Command): """ 添加 option_list 类属性 """ option_list = ( Option('--name', '-n', dest='name'), ) def run(self, name): print "hello %s" % nameclass Hello2(Command): """ 添加 get_options() 类方法 """ def __init__(self, default_name='Joe'): self.default_name=default_name def get_options(self): return [ Option('-n', '--name', dest='name', default=self.default_name), ] def run(self, name): print "hello", name 方法三 : manager.command 装饰器manager.command 让自定义命令变得简单. 装饰函数名就是命令名, 安徽省农户的文档字符串会显示在帮助命令中. 1234567891011121314@manager.commanddef test(): """Run the unit tests.""" import unittest tests = unittest.TestLoader().discover('tests') unittest.TextTestRunner(verbosity=2).run(tests)$ python manage.py test@manager.commanddef hello(): print "Hello world"$ python manage.py hello 为命令行, 添加参数支持. 123456@manager.commanddef hello(name): print "hello", name$ python manage.py hello Joehello Joe 方法四 : manager.option 装饰器, 本身即支持参数.123456789101112131415161718@manager.option('-e', '--email', dest='email', help="Plz input a user's email address !")def mfareset(email): """ Doc String here. """ user = User.query.filter_by(email=email).first() if user is not None: user.otp_secret = None db.session.add(user) db.session.commit() print "the MFA of '%s' have been reset, Plz relogin, and scan the QR code." % email else: print "User is not exist: %s ." % email$ python manage.py mfareset -h # 查看帮助信息. 帮助信息同时会显示 doc_string, 作为辅助帮助信息输出.$ python manage.py mfareset -e test@example.com$ python manage.py mfareset --email=test@example.com 三. Sub-ManagerA Sub-Manager is an instance of Manager added as a command to anothor Manager. 创建 Sub-Manager :12345678910111213141516171819def sub_opts(app, **kwargs): passuser_manager = Manager(sub_opts, usage="User management.") # usage 将出现在 --help 的说明中.@user_manager.commanddef hello(): print "hello user!"@user_manager.option("-n", "--name", dest="name", help="add new user")def add(name): print "Add user : %s" % namemanager = Manager(self.app)manager.add_command("user", user_manager)# shell$ python manage.py user hello$ python manage.py user add --name='tom' If you attach options to the user_manager, the sub_opts procedire will reveive their values. Your application is passed in app for convenience. If sub_opts returns a value other than None, this value will replace the app value that’s passed on. This way, you can implement a sub-manager which replaces the whole app. One use case is to create a separate administrative application for improved security: 123456789101112def gen_admin(app, **kwargs): from myweb.admin import MyAdminApp ## easiest but possibly incomplete way to copy your settings. return MyAdminApp(config=app.config, **kwargs)sub_manager = Manager(gen_admin)manager = Manager(MyApp)manager.add_command("admin", sub_manager)# shell$ python manage.py admin SUB_CMD A sub-manager does not get default commands added to itself(by default). flaks-migrate.MigrateCommand 示例参考:123456789101112131415161718192021# lib/python2.7/site-packages/flask_migrate/__init__.pyfrom alembic import commandMigrateCommand = Manager(usage = 'Perform database migrations')@MigrateCommand.option('-d', '--directory', dest = 'directory', default = None, help = "migration script directory (dedef init(directory = None): "Generates a new migration" if directory is None: directory = current_app.extensions['migrate'].directory config = Config() config.set_main_option('script_location', directory) config.config_file_name = os.path.join(directory, 'alembic.ini') command.init(config, directory, 'flask')# myapp/manage.pyfrom flask_migrate import Migrate, MigrateCommandmanager.add_command('db', MigrateCommand)# shell$ python manage.py db init]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Flask 扩展</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fask 扩展之--flask-sqlalchemy]]></title>
    <url>%2F2018%2F03%2F19%2FflaskExt--flask-sqlalchemy%2F</url>
    <content type="text"><![CDATA[一. 安装$ pip install flask-sqlalchemy 二. 配置配置选项列表 : 选项 说明 SQLALCHEMY_DATABASE_URI 用于连接的数据库 URI 。例如:sqlite:////tmp/test.db 或 mysql://username:password@server/db SQLALCHEMY_BINDS 一个映射 binds 到连接 URI 的字典。更多 binds 的信息见 用 Binds 操作多个数据库 。 SQLALCHEMY_ECHO 如果设置为 Ture ， SQLAlchemy 会记录所有 发给 stderr 的语句，这对调试有用。 SQLALCHEMY_RECORD_QUERIES 可以用于显式地禁用或启用查询记录。查询记录 在调试或测试模式自动启用。更多信息见 get_debug_queries() 。 SQLALCHEMY_NATIVE_UNICODE | 可以用于显式禁用原生 unicode 支持。当使用 不合适的指定无编码的数据库默认值时，这对于 一些数据库适配器是必须的（比如 Ubuntu 上某些版本的 PostgreSQL ）。|| SQLALCHEMY_POOL_SIZE | 数据库连接池的大小。默认是引擎默认值（通常 是 5 ） || SQLALCHEMY_POOL_TIMEOUT | 设定连接池的连接超时时间。默认是 10 。 || SQLALCHEMY_POOL_RECYCLE | 多少秒后自动回收连接。这对 MySQL 是必要的， 它默认移除闲置多于 8 小时的连接。注意如果 使用了 MySQL ， Flask-SQLALchemy 自动设定这个值为 2 小时。| app.config[&quot;SQLALCHEMY_DATABASE_URI&quot;] = DATABASE_URI app.config[&quot;SQLALCHEMY_COMMIT_ON_TEARDOWN&quot;] = True/False # 每次请求结束后都会自动提交数据库中的变动. app.config[&quot;&quot;] = app.config[&quot;&quot;] = app.config[&quot;&quot;] = app.config[&quot;&quot;] = DATABASE_URI : mysql : mysql://username:password@hostname/database pgsql : postgresql://username:password@hostname/database sqlite(linux) : sqlite:////absolute/path/to/database sqlite(windows) : sqlite:///c:/absolute/path/to/database 三. 初始化示例from flask import Flask from flask_sqlalchemy import SQLAlchemy base_dir = os.path.abspath(os.path.dirname(__file__)) app = Flask(__name__) app.config[&quot;SQLALCHEMY_DATABASE_URI&quot;] = &apos;sqlite:///&apos; + os.path.join(base_dir, &apos;data.sqlite&apos;) app.config[&quot;SQLALCHEMY_COMMIT_ON_TEARDOWN&quot;] = True db = SQLAlchemy(app) 四. 定义模型模型 表示程序使用的持久化实体. 在 ORM 中, 模型一般是一个 Python 类, 类中的属性对应数据库中的表. Flaks-SQLAlchemy 创建的数据库实例为模型提供了一个基类以及一些列辅助类和辅助函数, 可用于定义模型的结构. db.Model # 创建模型, db.Column # 创建模型属性. 模型属性类型 : 类型名 Python类型 说明 Integer int 普通整数，一般是 32 位 SmallInteger int 取值范围小的整数，一般是 16 位 Big Integer int 或 long 不限制精度的整数 Float float 浮点数 Numeric decimal.Decimal 定点数 String str 变长字符串 Text str 变长字符串，对较长或不限长度的字符串做了优化 Unicode unicode 变长 Unicode 字符串 Unicode Text unicode 变长 Unicode 字符串，对较长或不限长度的字符串做了优化 Boolean bool 布尔值 Date datetime.date 日期 Time datetime.time 时间 DateTime datetime.datetime 日期和时间 Interval datetime.timedelta 时间间隔 Enum str 一组字符串 PickleType 任何 Python 对象 自动使用 Pickle 序列化 LargeBinary str 二进制文件 常用 SQLAlchemy 列选项 选项名 说明 primary_key 如果设为 True，这列就是表的主键 unique 如果设为 True，这列不允许出现重复的值 index 如果设为 True，为这列创建索引，提升查询效率 nullable 如果设为 True，这列允许使用空值；如果设为 False，这列不允许使用空值 default 为这列定义默认值 Flask-SQLAlchemy 要求每个模型都要定义主键, 这一列通常命名为 id . 示例 : class Role(db.Model): __tablename__ = &quot;roles&quot; id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String(64), unique=True) def __repr__(self): &quot;&quot;&quot;非必须, 用于在调试或测试时, 返回一个具有可读性的字符串表示模型.&quot;&quot;&quot; return &apos;&lt;Role %r&gt;&apos; % self.name class User(db.Model): __tablename__ = &apos;users&apos; id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(64), unique=True, index=True) def __repr__(self): &quot;&quot;&quot;非必须, 用于在调试或测试时, 返回一个具有可读性的字符串表示模型.&quot;&quot;&quot; return &apos;&lt;Role %r&gt;&apos; % self.username 五. 关系关系型数据库使用关系把不同表中的行联系起来. 常用 SQLAlchemy 关系选项 : 选项名 说明 backref 在关系的另一个模型中添加反向引用 primaryjoin 明确指定两个模型之间使用的联结条件。只在模棱两可的关系中需要指定. lazy 指定如何加载相关记录。可选值如下 : select（首次访问时按需加载） immediate（源对象加载后就加载） joined（加载记录，但使用联结） subquery（立即加载，但使用子查询） noload（永不加载） dynamic（不加载记录，但提供加载记录的查询） uselist 如果设为 Fales，不使用列表，而使用标量值 order_by 指定关系中记录的排序方式 secondary 指定多对多关系中关系表的名字 secondaryjoin SQLAlchemy 无法自行决定时，指定多对多关系中的二级联结条件 1) 一对多原理 : 在 “多” 这一侧加入一个外键, 指定 “一” 这一侧联结的记录. 示例代码 : 一个角色可属于多个用户, 而每个用户只能有一个角色. class Role(db.Model): # ... users = db.relationship(&apos;User&apos;, backref=&apos;role&apos;) class User(db.Model): # ... role_id = db.Column(db.Integer, db.ForeignKey(&apos;roles.id&apos;)) # 外键关系. ############### db.ForeignKey(&apos;roles.id&apos;) : 外键关系, Role.users = db.relationship(&apos;User&apos;, backref=&apos;role&apos;) : 代表 外键关系的 面向对象视角. 对于一个 Role 类的实例, 其 users 属性将返回与角色相关联的用户组成的列表. db.relationship() 第一个参数表示这个关系的另一端是哪个模型. backref 参数, 向 User 模型添加了一个 role 数据属性, 从而定义反向关系. 这一属性可替代 role_id 访问 Role 模型, 此时获取的是模型对象, 而不是外键的值. 2) 多对多最复杂的关系类型, 需要用到第三章表, 即 关联表 , 这样多对多关系可以分解成原表和关联表之间的两个一对多关系. 查询多对多关系分两步 : 遍历两个关系来获取查询结果. 代码示例: registrations = db.Table(&quot;registrations&quot;, db.Column(&quot;student_id&quot;, db.Integer, db.ForeignKey(&quot;students.id&quot;)), db.Column(&quot;class_id&quot;, db.Integer, db.ForeignKey(&quot;classes.id&quot;)) ) class Student(db.Model): __tablename__ = &quot;students&quot; id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String) classes = db.relationship(&quot;Class&quot;, secondary=registrations, backref=db.backref(&quot;students&quot;, lazy=&quot;dynamic&quot;), lazy=&quot;dynamic&quot;) class Class(db.Model): __tablename__ = &quot;classes&quot; id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String) 多对多关系仍然使用定义一对多关系的 db.relationship() 方法进行定义, 但在多对多关系中, 必须把 secondary 参数设为 关联表. 多对多关系可以在任何一个类中定义, backref 参数会处理好关系的另一侧. 关联表就是一个简单的表, 不是模型, SQLAlchemy 会自动接管这个表. classes 关系使用列表语义, 这样处理多对多关系比较简单. Class 模型的 students 关系有 参数 db.backref() 定义. 这个关系还指定了 lazy 参数, 所以, 关系两侧返回的查询都可接受额外的过滤器. 自引用关系自引用关系可以理解为 多对多关系的特殊形式 : 多对多关系的两边由两个实体变为 一个实体. 高级多对多关系使用多对多关系时, 往往需要存储所联两个实体之间的额外信息. 这种信息只能存储在关联表中. 对用户之间的关注来说, 可以存储用户关注另一个用户的日期, 这样就能按照时间顺序列出所有关注者. 为了能在关系中处理自定义的数据, 必须提升关联表的地位, 使其变成程序可访问的模型. 关注关联表模型实现: class Follow(db.Model): __tablename__ = &quot;follows&quot; follower_id = db.Column(db.Integer, db.ForeignKey(&quot;users.id&quot;), primary_key=True) followed_id = db.Column(db.Integer, db.ForeignKey(&quot;users.id&quot;), primary_key=True) timestamp = db.Column(db.DateTime, default=datetime.utcnow) # SQLAlchemy 不能直接使用这个关联表, 因为如果这个做程序就无法访问其中的自定义字段. 相反的, 要把这个多对多关系的左右两侧拆分成两个基本的一对多关系, 而且要定义成标准的关系. 使用两个一对多关系实现的多对多关系: 1234567891011121314151617class User(UserMixin, db.Model): # ... followd = db.relationship(&quot;Follow&quot;, foreign_keys=[Follow.follower_id], backref=db.backref(&quot;follower&quot;, lazy=&quot;joined&quot;), lazy=&quot;dynamic&quot;, cascade=&quot;all, delete-orphan&quot;) followrs = db.relationship(&quot;Follow&quot;, foreign_keys=[Follow.followed_id], backref=db.backref(&quot;followed&quot;, lazy=&quot;joined&quot;), lazy=&quot;dynamic&quot;, cascade=&quot;all, delete-orphan&quot;)# 这段代码中, followed 和 follower 关系都定义为 单独的 一对多关系. # 注意: 为了消除外键歧义, 定义关系是必须使用可选参数 foreign_keys 指定的外键. 而且 db.backref() 参数并不是指定这两个关系之间的引用关系, 而是回引 Follow 模型. 回引中的 lazy=&quot;joined&quot; , 该模式可以实现立即从连接查询中加载相关对象.# 这两个关系中, user 一侧设定的 lazy 参数作用不一样. lazy 参数都在 &quot;一&quot; 这一侧设定, 返回的结果是 &quot;多&quot; 这一侧中的记录. dynamic 参数, 返回的是查询对象.# cascade 参数配置在父对象上执行的操作相关对象的影响. 比如, 层叠对象可设定为: 将用户添加到数据库会话后, 要自定把所有关系的对象都添加到会话中. 删除对象时, 默认的层叠行为是把对象联结的所有相关对象的外键设为空值. 但在关联表中, 删除记录后正确的行为是把执行该记录的实体也删除, 因为这样才能有效销毁联结. 这就是 层叠选项值 delete-orphan 的作用. 设为 all, delete-orphan 的意思是启动所有默认层叠选项, 并且还要删除孤儿记录. 3) 一对一可以看做特殊的 一对多 关系. 但调用 db.relationship() 时 要把 uselist 设置 False, 把 多变为 一 . 4) 多对一将 一对多 关系,反过来即可, 也是 一对多关系. 六. 数据库操作1) 创建数据库及数据表创建数据库 db.create_all() 示例 : $ python myflask.py shell &gt; from myflask import db &gt; db.create_all() 如果使用 sqlite , 会在 SQLALCHEMY_DATABASE_URI 指定的目录下 多一个文件, 文件名为该配置中的文件名. 如果数据库表已经存在于数据库中, 那么 db.create_all() 不会创建或更新这个表. 更新数据库方法一 :先删除, 在创建 –&gt; 原有数据库中的数据, 都会消失. &gt; db.drop_all() &gt; db.create_all() 方法二 :数据库迁移框架 : 可以跟自动数据库模式的变化, 然后增量式的把变化应用到数据库中. SQLAlchemy 的主力开发人员编写了一个 迁移框架 Alembic, 除了直接使用 Alembic wait, Flask 程序还可使用 Flask-Migrate 扩展, 该扩展对 Alembic 做了轻量级包装, 并集成到 Flask-Script 中, 所有操作都通过 Flaks-Script 命令完成. ① 安装 Flask-Migrate $ pip install flask-migrate ② 配置 from flask_migrate import Migrate, MigrateCommand # ... migrate = Migrate(app, db) manager.add_command(&apos;db&apos;, MigrateCommand) ③ 数据库迁移 a. 使用 init 自命令创建迁移仓库. $ python myflask.py db init # 该命令会创建 migrations 文件夹, 所有迁移脚本都存在其中. b. 创建数据路迁移脚本. $ python myflask.py db revision # 手动创建 Alemic 迁移 创建的迁移只是一个骨架, upgrade() 和 downgrade() 函数都是空的. 开发者需要使用 Alembic 提供的 Operations 对象指令实现具体操作. $ python myflask.py db migrate -m COMMONT # 自动创建迁移. 自动创建的迁移会根据模型定义和数据库当前的状态之间的差异生成 upgrade() 和 downgrade() 函数的内容. ** 自动创建的迁移不一定总是正确的, 有可能漏掉一些细节, 自动生成迁移脚本后一定要进行检查. c. 更新数据库 $ python myflask.py db upgrade # 将迁移应用到数据库中. 2) 插入行模型的构造函数, 接收的参数是使用关键字参数指定的模型属性初始值. 注意, role 属性也可使用, 虽然他不是真正的数据库列, 但却是一对多关系的高级表示. 这些新建对象的 id 属性并没有明确设定, 因为主键是由 Flask-SQLAlchemy 管理的. 现在这些对象只存在于 Python 解释器中, 尚未写入数据库.1234567891011121314151617181920212223242526&gt;&gt; from myflask import db, User, Role&gt;&gt; db.create_all()&gt;&gt; admin_role = Role(name=&quot;Admin&quot;)&gt;&gt; mod_role = Role(name=&quot;Moderator&quot;)&gt;&gt; user_role = Role(name=&quot;User&quot;)&gt;&gt; user_john = User(username=&quot;john&quot;, role=admin_role)&gt;&gt; user_susan = User(username=&quot;susan&quot;, role=mod_role)&gt;&gt; user_david = User(username=&quot;david&quot;, role=user_role)&gt;&gt; admin_role.name&apos;Admin&apos;&gt;&gt; admin_role.idNone---------&gt;&gt; db.session.add_all([admin_role, mod_role, user_role, user_john, user_susan, user_david]) # 把对象添加到会话中.&gt;&gt; db.session.commit() # 把对象写入数据库, 使用 commit() 提交会话. 3) 修改行&gt;&gt; admin_role = &quot;Administrator&quot; &gt;&gt; db.session.add(admin_role) &gt;&gt; db.session.commit() 4) 删除行&gt;&gt; db.session.delete(mod_role) &gt;&gt; db.session.commit() 5) 查询行Flask-SQLAlchemy 为每个模型类都提供了 query 对象. 获取表中的所有记录 &gt;&gt; Role.query.all() [&lt;Role u&apos;Admin&apos;&gt;, &lt;Role u&apos;Moderator&apos;&gt;, &lt;Role u&apos;User&apos;&gt;] &gt;&gt; User.query.all() [&lt;Role u&apos;john&apos;&gt;, &lt;Role u&apos;susan&apos;&gt;, &lt;Role u&apos;david&apos;&gt;] 查询过滤器 filter_by() 等过滤器在 query 对象上调用, 返回一个更精确的 query 对象. 多个过滤器可以一起调用, 直到获取到所需的结果. &gt;&gt; User.query.filter_by(role=user_role).all() # 以列表形式,返回所有结果, &gt;&gt; User.query.filter_by(role=user_role).first() # 返回结果中的第一个. filter() 对查询结果过滤，比”filter_by()”方法更强大，参数是布尔表达式 # WHERE age&lt;20 users = User.query.filter(User.age&lt;20) # WHERE name LIKE &apos;J%&apos; AND age&lt;20 users = User.query.filter(User.name.startswith(&apos;J&apos;), User.age&lt;20) 查询过滤器 : 过滤器 说明 filter() 把过滤器添加到原查询上, 返回一个新查询 filter_by() 把等值过滤器添加到原查询上, 返回一个新查询 limit() 使用是zing的值限制原查询返回的结果数量, 返回一个新查询 offset() 偏移原查询返回的结果, 返回一个新查询 order_by() 根据指定条件对原查询结果进行排序, 返回一个新查询 group_by() 根据指定条件对原查询结果进行分组, 返回一个新查询 查询执行函数 : 方法 说明 all() 以列表形式返回查询的所有结果 first() 返回查询的第一个结果，如果没有结果，则返回 None first_or_404() | 返回查询的第一个结果，如果没有结果，则终止请求，返回 404 错误响应 | || get() | 返回指定主键对应的行，如果没有对应的行，则返回 None |get_or_404() | 返回指定主键对应的行，如果没找到指定的主键，则终止请求，返回 404 | |错误响应| count() | 返回查询结果的数量 || paginate() | 返回一个 Paginate 对象，它包含指定范围内的结果 | 6) 会话管理, 事务管理单个提交 &gt;&gt; db.session.add(ONE) &gt;&gt; db.session.commit() 多个提交 &gt;&gt; db.session.add_all([LIST_OF_MEMBER]) &gt;&gt; db.session.commit() 删除会话 &gt;&gt; db.session.delete(mod_role) &gt;&gt; db.session.commit() 事务回滚 : 添加到数据库会话中的所有对象都会还原到他们在数据库时的状态. &gt;&gt; db.session.rollback() 七. 视图函数中操作数据库12345678910111213141516@app.route(&apos;/&apos;, methods=[&apos;GET&apos;, &apos;POST&apos;])def index(): form = NameForm() if form.validate_on_submit(): user = User.query.filter_by(username=form.name.data).first() if user is None: user = User(username=form.name.data) db.session.add(user) session[&quot;known&quot;] = False else: session[&quot;known&quot;] = True session[&quot;name&quot;] = form.name.data form.name.data = &quot;&quot; # why empty it ? return redirect(url_for(&quot;index&quot;)) return render_template(&quot;index.html&quot;, current_time=datetime.utcnow(), form=form, name=session.get(&quot;name&quot;), known=session.get(&quot;known&quot;)) 八. 分页对象 Pagination1. paginate() 方法paginate() 方法的返回值是一个 Pagination 类对象, 该类在 Flask-SQLAlchemy 中定义, 用于在模板中生成分页链接. paginate(页数[,per_page=20, error_out=True]) 页数 : 唯一必须指定的参数, per_page : 指定每页现实的记录数量, 默认 20. error_out : True 如果请求的页数超出了返回, 返回 404 错误; False 页数超出范围时返回一个,空列表. 示例代码:12345678@main.route(&quot;/&quot;, methods=[&quot;GET&quot;, &quot;POST&quot;])def index(): # ... page = request.args.get(&apos;page&apos;, 1, type=int) # 渲染的页数, 默认第一页, type=int 保证参数无法转换成整数时, 返回默认值. pagination = Post.query.order_by(Post.timestamp.desc()).paginate(page, per_page=current_app.config[&quot;FLASKY_POSTS_PER_PAGE&quot;], error_out=False) posts = pagination.items return render_template(&apos;index.html&apos;, form=form, posts=posts,pagination=pagination) 2. 分页对象的属性及方法:Flask_SQLAlchemy 分页对象的属性: 属性 说明 items 当前分页中的记录 query 分页的源查询 page 当前页数 prev_num 上一页的页数 next_num 下一页的页数 has_next 如果有下一页, 返回 True has_prev 如果有上一页, 返回 True pages 查询得到的总页数 per_page 每页显示的记录数量 total 查询返回的记录总数 在分页对象可调用的方法: 方法 说明 iter_pages(left_edge=2,left_current=2,right_current=5,right_edge=2) 一个迭代器, 返回一个在分页导航中显示的页数列表. 这个列表的最左边显示 left_edge 页, 当前页的左边显式 left_current 页, 当前页的右边显示 right_currnt 页, 最右边显示 right_edge 页. 如 在一个 100 页的列表中, 当前页为 50 页, 使用默认配置, 该方法返回以下页数 : 1, 2, None, 48,49,50,51,52,53,54,55, None, 99 ,100. None 表示页数之间的间隔. prev() 上一页的分页对象 next() 下一页的分页对象 3. 在模板中与 BootStrap 结合使用示例使用 Flaks-SQLAlchemy 的分页对象与 Bootstrap 中的分页 CSS, 可以轻松的构造出一个 分页导航. 分页模板宏 _macros.html : 创建一个 Bootstrap 分页元素, 即一个有特殊样式的无序列表. 1234567891011121314151617181920212223242526272829&#123;% macro pagination_widget(pagination,endpoint) %&#125;&lt;ul class=&quot;pagination&quot;&gt; &lt;li &#123;% if not pagination.has_prev %&#125; class=&quot;disabled&quot; &#123;% endif %&#125;&gt; &lt;a href=&quot;&#123;% if pagination.has_prev %&#125;&#123;&#123;url_for(endpoint, page=paginatin.page - 1, **kwargs)&#125;&#125;&#123;% else %&#125;#&#123;% endif %&#125;&quot;&gt; &amp;laquo; &lt;/a&gt; &lt;/li&gt; &#123;% for p in pagination,.iter_pages() %&#125; &#123;% if p %&#125; &#123;% if p == pagination.page %&#125; &lt;li class=&quot;active&quot;&gt; &lt;a href=&quot;&#123;&#123; url_for(endpoint, page=p, **kwargs) &#125;&#125;&quot;&gt;&#123;&#123;p&#125;&#125;&lt;/a&gt; &lt;/li&gt; &#123;% else %&#125; &lt;li&gt; &lt;a href=&quot;&#123;&#123; url_for(endpoint, page = p, **kwargs) &#125;&#125;&quot;&gt;&#123;&#123;p&#125;&#125;&lt;/a&gt; &lt;/li&gt; &#123;% endif %&#125; &#123;% else %&#125; &lt;li class=&quot;disabled&quot;&gt;&lt;a href=&quot;#&quot;&gt;&amp;hellip;&lt;/a&gt; &lt;/li&gt; &#123;% endif %&#125; &#123;% endfor %&#125; &lt;li &#123;% if not pagination.has_next %&#125; class=&quot;disabled&quot; &#123;% endif%&#125;&gt; &lt;a href=&quot;&#123;% if paginatin.has_next %&#125;&#123;&#123; url_for(endpoint, page=pagination.page+1, **kwargs) &#125;&#125;&#123;% else %&#125;#&#123;% endif %&#125;&quot;&gt; &amp;raquo; &lt;/a&gt; &lt;/li&gt;&lt;/ul&gt;&#123;% endmacro %&#125; 导入使用分页导航123456&#123;% extends &quot;base.html&quot; %&#125;&#123;% import &quot;_macros.html&quot; as macros %&#125;...&lt;div class=&quot;pagination&quot;&gt; &#123;&#123; macro.pagination_widget(pagination, &quot;.index&quot;)&#125;&#125;&lt;/div&gt; 九. 监听事件1. set 事件示例代码 :1234567891011121314151617181920from markdown import markdownimport bleachclass Post(db.Model): # ... body = db.Colume(db.Text) body_html = db.Column(db.Text) # ... @staticmethod def on_changeed_body(target, value, oldvalue, initiator): allowed_tags = [&quot;a&quot;, &quot;abbr&quot;, &quot;acronym&quot;, &quot;b&quot;, &quot;blockquote&quot;, &quot;code&quot;, &quot;em&quot;, &quot;i&quot;, &quot;li&quot;, &quot;ol&quot;, &quot;pre&quot;, &quot;strong&quot;, &quot;ul&quot;, &quot;h1&quot;, &quot;h2&quot;,&quot;h3&quot;,&quot;h4&quot;,&quot;p&quot;] target.body_html = bleach.linkify(bleach.clean(markdown(value, output_format=&quot;html&quot;), tags=allowed_tags, strip=True))db.event.listen(Post.body, &quot;set&quot;, Post.on_changeed_body) # on_changed_body 函数注册在 body 字段上, 是 SQLIAlchemy &quot;set&quot; 事件的监听程序, # 这意味着只要这个类实例的 body 字段设了新值, 函数就会自动被调用. # on_changed_body 函数把 body 字段中的文本渲染成 HTML 格式, # 结果保存在 body_html 中, 自动高效的完成 Markdown 文本到 HTML 的转换. 十. 记录慢查询.十一. Binds 操作多个数据库十二. 其他1. ORM 在查询时做初始化操作当 SQLIAlchemy ORM 从数据库查询数据时, 默认不调用__init__ 方法, 其底层实现了 Python 类的 __new__() 方法, 直接实现 对象实例化, 而不是通过 __init__ 来实例化对象. 如果需要在查询时, 依旧希望实现一些初始化操作, 可以使用 orm.reconstructor() 装饰器或 实现 InstanceEvents.load() 监听事件.1234567891011121314151617181920212223# orm.reconstructorfrom sqlalchemy import ormclass MyMappedClass(object): def __init__(self, data): self.data = data # we need stuff on all instances, but not in the database. self.stuff = [] @orm.reconstructor def init_on_load(self): self.stuff = []# InstanceEvents.load()from sqlalchemy import event## standard decorator style@event.listens_for(SomeClass, &apos;load&apos;)def receive_load(target, context): &quot;listen for the &apos;load&apos; event&quot; # ... (event handling logic) ... 如果只是希望在从数据库查询生成的对象中包含某些属性, 也可以使用 property 实现:1234567891011class AwsRegions(db.Model): name=db.Column(db.String(64)) ... @property def zabbix_api(self): return ZabbixObj(zabbix_url) @zabbix_api.setter def zabbix_api(self): raise ValueError(&quot;zabbix can not be setted!&quot;)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Flask 扩展</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--logging]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-logging%2F</url>
    <content type="text"><![CDATA[线程安全的日志记录模块. 一. 使用示例import logging logging.basicConfig(filename=&quot;app.log&quot;, format=&quot;%(asctime)s - %(name)s - %(levelname)s -%(module)s: %(message)s&quot;, datefmt=&quot;%Y-%m-%d %H:%M:%S %p&quot;, level=10) # level=ERROR, INFO, WARN # 记录日志 : 只有【当前写等级】大于【日志等级】时，日志文件才被记录。 logging.debug(&quot;debug&quot;) logging.info(&quot;info&quot;) logging.warning(&quot;warning&quot;) logging.error(&quot;error&quot;) logging.critical(&quot;critical&quot;) logging.log(LEVEL, msg) logging.log(10, &apos;info&apos;) 二. 日志等级CRITICAL = 50 FATAL = CRITICAL ERROR = 40 WARNING = 30 WARN = WARNING INFO = 20 DEBUG = 10 NOTSET = 0 三. 日志格式变量]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--random]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-random%2F</url>
    <content type="text"></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--unittest]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-unittest%2F</url>
    <content type="text"><![CDATA[一. unittest 单元测试编写单元测试示例代码 : import unittest from flask import current_app from app import create_app, db class BaseTestCase(unittest.TestCase): def setUp(self): self.app = create_app(&apos;testing&apos;) self.app_context = self.app.app_context() self.app_context.push() db.create_all() def tearDown(self): db.session.remove() db.drop_all() self.app_context.pop() def test_app_exists(self): self.assertFalse(current_app is None) def test_app_is_testing(self): self.assertTrue(current_app.config[&apos;TESTING&apos;]) 单元测试方法汇总 :setUp() 和 tearDown() 方法分别在各测试前后运行. 以 test_ 开头的函数都作为测试执行. self.asserTrue(EXPRESSION) self.asserFalse(EXPRESSION) self.asserRaise(ERROR_TYPE) 调用单元测试在 manage.py 中添加自定义命令 , 用于测试.: @manager.command def test(): &quot;&quot;&quot;Run the unit tests.&quot;&quot;&quot; import unittest tests = unittest.TestLoader().discover(&apos;tests&apos;) unittest.TextTestRunner(verbosity=2).run(tests) 装饰函数名就是命令名, 函数的文档字符串会显示在帮助信息中. tests() 函数的定义体重调用了 unittest 包提供的测试运行函数.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--configparser]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-configparser%2F</url>
    <content type="text"><![CDATA[configparser 用于处理 ini 格式的配置文件, 其本质上是利用 open 来操作文件. 示例文件 :[zhangsan] name = zhangsan age = 12 job = worker [lisi] name = lisi age = 32 job = manager 文件中不需要引号, 所有内容都是字符串. 并且在程序中返回的也是 字符串. 使用时, 需要根据需要进行类型转换. 用法:import configparser conf = configparser.ConfigParser() conf.read(&apos;test.ini&apos;, encoding=&apos;utf-8&apos;) # 读取文件 conf.write(open(&apos;test.ini&apos;, &apos;w&apos;)) # 写入文件 conf.sections() : 获取所有节点, 返回 所有键组成的列表. conf.has_section(SEC_NAME) # 判断是否具有某个节点, 返回布尔值. conf.add_section(NEW_SEC) # 添加节点, conf.remove_section(SEC_NAME) # 删除节点. conf.items() : 获取指定节点下所有的键值对, 返回元组组成的列表. conf.options(section) : 获取指定节点下所有的键, 返回 所有键组成的列表. conf.get(&quot;SEC_NAME&quot;, &quot;KEY&quot;) # 获取指定 键 的 值. 返回为 字符串形式. conf.getint(&quot;SEC_NAME&quot;, &quot;KEY&quot;) # 返回 int 形式 conf.getfloat(&quot;SEC_NAME&quot;, &quot;KEY&quot;) # 返回 float 形式 conf.getboolean(&quot;SEC_NAME&quot;, &quot;KEY&quot;) # 返回 boolean 形式 conf.has_option(SEC_NAME, KEY) # 判断某个 section 下是否有 某个 item . conf.remove_option(SEC_NAME, KEY) # 删除某个 section 下的 item conf.set(SECTION, KEY, VALUE) # 在某个 section 下 修改/新增 item.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--requests]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-requests%2F</url>
    <content type="text"><![CDATA[一. 安装$ pip install requests requests 并不是python 标准库, 但为了汇总方便, 将其放置于此. 二. 用法requests.get() : GET 请求payload = {&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: &apos;value2&apos;} ret = requests.get(&apos;http://www.example.com&apos;, params=payload) ret.url # 访问的 url ret.text # 访问结果 ret.content ret.cookis ret.headers ret.json ret.status_code ret.ok requests.post() : POST 请求import requests import json url = &apos;http://httpbin.org/post&apos; payload = {&apos;some&apos;: &apos;data&apos;} headers = {&apos;content-type&apos;: &apos;application/json&apos;} ret = requests.post(url, data=json.dumps(payload), headers=headers) print(ret.text) print(ret.cookies) 其他方法 : requests.get(url, params=None, **kwargs) requests.post(url, data=None, json=None, **kwargs) requests.put(url, data=None, **kwargs) requests.head(url, **kwargs) requests.delete(url, **kwargs) requests.patch(url, data=None, **kwargs) requests.options(url, **kwargs) # 以上方法都是在 此方法的基础上构建的 requests.request(method, url, **kwargs) 三. 文档摘抄1. 功能特性Requests 支持 Python 2.6—2.7以及3.3—3.7，而且能在 PyPy 下完美运行。 Keep-Alive &amp; 连接池 国际化域名和 URL 带持久 Cookie 的会话 浏览器式的 SSL 认证 自动内容解码 基本/摘要式的身份认证 优雅的 key/value Cookie 自动解压 Unicode 响应体 HTTP(S) 代理支持 文件分块上传 流下载 连接超时 分块请求 支持 .netrc 2. 使用文档请求与响应对象: 任何使用进行了类似requests.get() 调用, 都会做两件事: 构建一个 Request 对象, 该对象将被发送到某个服务器请求或查询一些资源. 一旦 requests 得到一个从服务器返回的响应就会产生一个 Response 对象, 该响应对象包含服务器返回的所有信息, 也包含原来创建的 Request 对象. 123&gt;&gt;&gt; r = requests.get(&apos;http://en.wikipedia.org/wiki/Monty_Python&apos;)&gt;&gt;&gt; r.headers # 响应首部信息&gt;&gt;&gt; r.request.headers # 请求首部信息 2.1 发送请求123456&gt;&gt;&gt; r = requests.get(&apos;https://api.github.com/events&apos;)&gt;&gt;&gt; r = requests.post(&apos;http://httpbin.org/post&apos;, data = &#123;&apos;key&apos;:&apos;value&apos;&#125;)&gt;&gt;&gt; r = requests.put(&apos;http://httpbin.org/put&apos;, data = &#123;&apos;key&apos;:&apos;value&apos;&#125;)&gt;&gt;&gt; r = requests.delete(&apos;http://httpbin.org/delete&apos;)&gt;&gt;&gt; r = requests.head(&apos;http://httpbin.org/get&apos;)&gt;&gt;&gt; r = requests.options(&apos;http://httpbin.org/get&apos;) 2.1.1 传递 URL 参数使用 URL 的查询字符串传递数据. Requests 使用 params 关键词参数, 以一个字典来提供查询字符串. 字典里值为 None 的键都不会被添加到 URL 的查询字符串里. 原始请求URL : httpbin.org/get?key=val 1234&gt;&gt;&gt; payload = &#123;&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: [&apos;value2&apos;, &apos;value3&apos;]&#125;&gt;&gt;&gt; r = requests.get(&quot;http://httpbin.org/get&quot;, params=payload)&gt;&gt;&gt; print r.url http://httpbin.org/get 2.1.2 定制请求头定制 HTTP 请求首部, 只需传递一个 dict 给 headers 参数即可. 定制 header 的优先级低于某些特定的信息源: 如果在 .netrc 中设置了用户认证信息, 使用 headers= 设置的授权就不会生效. 而如果设置 auth= 参数, .netrc 的设置就无效了. 如果被重定向到了别的主机, 授权 header 就会被删除. 代理授权 header 会被 URL 中提供的代理身份覆盖掉. 在可以判断内容长度的情况下, header 的 Content-Length 会被改写. 进一步讲, Request 不会基于定制 header 的具体情况改变自己的行为. 只不过在最后的请求中, 所有的 header 信息都会被传递进去. 所有的 header 字典的值, 必须是 string, bytestring 或者 unicode. 不建议 unicode. 123&gt;&gt;&gt; url = &quot;http://httpbin.org/get&quot;&gt;&gt;&gt; headers = &#123;&quot;user-agent&quot;: &quot;my-app/1.0.1&quot;&#125;&gt;&gt;&gt; r = requests.get(url, headers=headers) 2.1.3 复杂的 POST 请求, 表单发送表单数据, 只需简单传递一个 dict 给 data 参数. 数据字典在发送请求时会自动编码为表单形式. 123456789101112&gt;&gt;&gt; payload = &#123;&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: &apos;value2&apos;&#125;&gt;&gt;&gt; r = requests.post(&quot;http://httpbin.org/post&quot;, data=payload)&gt;&gt;&gt; print(r.text) &#123; ... &quot;form&quot;: &#123; &quot;key2&quot;: &quot;value2&quot;, &quot;key1&quot;: &quot;value1&quot; &#125;, ... &#125; 还可以为 data 参数传入一个元组列表, 在表单中多个元素使用同一 key 的时候, 这种方式尤其有效. 12345678910111213&gt;&gt;&gt; payload = ((&apos;key1&apos;, &apos;value1&apos;), (&apos;key1&apos;, &apos;value2&apos;))&gt;&gt;&gt; r = requests.post(&apos;http://httpbin.org/post&apos;, data=payload)&gt;&gt;&gt; print(r.text) &#123; ... &quot;form&quot;: &#123; &quot;key1&quot;: [ &quot;value1&quot;, &quot;value2&quot; ] &#125;, ... &#125; 有些时候, 发送的数据并非编码为表单形式的, 如果传递一个 string 而不是一个 dict, 那么, 数值会被直接发布出去. 发送 json 编码的数据: 123456789## POST/PATCH 编码为 JSON 的数据&gt;&gt;&gt; import json&gt;&gt;&gt; url = &quot;https://api.github.com/some/endpoint&quot;&gt;&gt;&gt; payload = &#123;&quot;some&quot;: &quot;data&quot;&#125;&gt;&gt;&gt; r = requests.post(url, data=json.dumps(payload))## 使用 json 参数直接传递 json 数据, 内容会被自动编码&gt;&gt;&gt; r = requests.post(url, json=payload) 2.1.4 POST 一个 多部分编码的文件( Multipart-Encoded )的文件上传 multipart-encoded 编码文件123456789101112&gt;&gt;&gt; url = &quot;http://httpbin.org/post&quot;&gt;&gt;&gt; files = &#123;&quot;file&quot;: open(&quot;report.xml&quot;, &quot;rb&quot;)&#125;&gt;&gt;&gt; r = requests.post(url, files=files)&gt;&gt;&gt; r.text &#123; ... &quot;files&quot;: &#123; &quot;file&quot;: &quot;&lt;censored...binary...data&gt;&quot; &#125;, ... &#125; 显式设置文件名, 文件类型和请求头: 123456789101112&gt;&gt;&gt; url = &quot;http://httpbin.org/post&quot;&gt;&gt;&gt; files = &#123;&apos;file&apos;: (&apos;report.xls&apos;, open(&apos;report.xls&apos;, &apos;rb&apos;), &apos;application/vnd.ms-excel&apos;, &#123;&apos;Expires&apos;: &apos;0&apos;&#125;)&#125;&gt;&gt;&gt; r = requests.post(url, files=files)&gt;&gt;&gt; r.text &#123; ... &quot;files&quot;: &#123; &quot;file&quot;: &quot;&lt;censored...binary...data&gt;&quot; &#125;, ... &#125; 发送作为文件来接受的字符串: 123456789101112&gt;&gt;&gt; url = &apos;http://httpbin.org/post&apos;&gt;&gt;&gt; files = &#123;&apos;file&apos;: (&apos;report.csv&apos;, &apos;some,data,to,send\nanother,row,to,send\n&apos;)&#125;&gt;&gt;&gt; r = requests.post(url, files=files)&gt;&gt;&gt; r.text &#123; ... &quot;files&quot;: &#123; &quot;file&quot;: &quot;some,data,to,send\\nanother,row,to,send\\n&quot; &#125;, ... &#125; 当发送一个非常大的文件作为 multipart/form-data 请求时, 可以将请求做成数据流. 默认下, requests 不支持, 但有个第三方包 requests-toolbelt 支持, 可以阅读其文档了解其使用方法. 强烈建议使用 二进制模式 打开文件. 这是 Requests 会视图提供 Content-Length 首部, 当使用 二进制模式 打开文件时, 该值会被设置为 文件的字节数; 如果使用文本模式打开, 可能会发生错误. 2.2 响应2.2.1 响应内容2.2.1.1 文本 响应内容与响应编码Requests 会自动解码来自服务器的内容, 大多数 unicode 字符集都能被正确的解码. 请求发出之后, Requests 会基于 HTTP 首部对响应的编码做出有根据的预测, 并且在使用 r.text 时, 使用其推测的文本编码. 可以使用 r.encoding 来查看/修改响应内容使用的编码. 在改变 编码 之后, 再次访问 r.text, Requests 会使用新的编码. 1234567&gt;&gt;&gt; r = requests.get(&quot;http://httpbin.org/get&quot;)&gt;&gt;&gt; r.text u&apos;&#123;&quot;args&quot;:&#123;&#125;,&quot;headers&quot;:&#123;&quot;Accept&quot;:&quot;*/*&quot;,&quot;Accept-Encoding&quot;:&quot;gzip, deflate&quot;,&quot;Connection&quot;:&quot;close&quot;,&quot;Host&quot;:&quot;httpbin.org&quot;,&quot;User-Agent&quot;:&quot;python-requests/2.18.4&quot;&#125;,&quot;origin&quot;:&quot;61.171.67.218&quot;,&quot;url&quot;:&quot;http://httpbin.org/get&quot;&#125;\n&apos;&gt;&gt;&gt; r.encoding &quot;utf-8&quot;&gt;&gt;&gt; r.encoding = &quot;ISO-8859-1&quot; # 修改编码方式. 2.2.1.2 二进制 响应内容Requests 能以 字节 的方式访问请求响应体, 使用 r.content. 同时, Requests 会自动解码 gzip 和 deflate 传输编码的响应数据. 12345# 以请求返回的二进制数据创建一张图片.&gt;&gt;&gt; from PIL import Image&gt;&gt;&gt; from io import BytesIO&gt;&gt;&gt; i = Image.open(BytesIO(r.content)) 2.2.1.3 json 响应内容Requests 内置 JSON 解码器, 用于处理 JSON 数据. 如果 JSON 解码失败, r.json() 会抛出一个异常. 需要注意的是, r.json() 调用成功 并不意味着响应的成功. 有的服务器会在失败的响应中包含一个 JSON 对象, 如 HTTP 500 的错误细节. 如果需要检查请求是否成功, 请使用 r.raise_for_status() 或者检查 r.status_code . 12345678910&gt;&gt;&gt; r = requests.get(&quot;http://httpbin.org/get&quot;)&gt;&gt;&gt; r.json() &#123;u&apos;args&apos;: &#123;&#125;, u&apos;headers&apos;: &#123;u&apos;Accept&apos;: u&apos;*/*&apos;, u&apos;Accept-Encoding&apos;: u&apos;gzip, deflate&apos;, u&apos;Connection&apos;: u&apos;close&apos;, u&apos;Host&apos;: u&apos;httpbin.org&apos;, u&apos;User-Agent&apos;: u&apos;python-requests/2.18.4&apos;&#125;, u&apos;origin&apos;: u&apos;61.171.67.218&apos;, u&apos;url&apos;: u&apos;http://httpbin.org/get&apos;&#125; 2.2.1.4 原始 响应内容有些情况下, 需要获取来自服务器的原始套接字响应, 可以访问 r.raw. 需要确保在初始请求中设置 stream=True. 12345&gt;&gt;&gt; r = requests.get(&apos;https://api.github.com/events&apos;, stream=True)&gt;&gt;&gt; r.raw &lt;requests.packages.urllib3.response.HTTPResponse object at 0x101194810&gt;&gt;&gt;&gt; r.raw.read(10) &apos;\x1f\x8b\x08\x00\x00\x00\x00\x00\x00\x03&apos; 一般情况下, 使用下面的模式, 将文本流保存到文件. 使用 Response.iter_content 将会隐藏处理大量 在直接使用 Response.raw 时需要处理的细节 ( Using Reponse.iter_content will handle a lot of waht you would otherwise have to handle when using Response.raw directly). 当使用 流 下载时, 这是优先推荐的获取内容方式. 123with open(filename, &quot;wb&quot;) as fd: for chunk in r.iter_content(chunk_size): # 此处 chunk_size 根据实际大小调整. fd.write(chunk) 2.2.2 响应状态码检测响应状态码123&gt;&gt;&gt; r = requests.get(&quot;http://httpbin.org/get&quot;)&gt;&gt;&gt; r.status_code 200 Requests 内置一个状态码查询对象1&gt;&gt;&gt; r.status_code == requests.codes.ok 请求错误或失败时, 可以通过 Response.raise_for_status() 来抛出异常. 当请求的返回码为 200 时, r.raise_for_status() 返回 None.123456&gt;&gt;&gt; bad_r = requests.get(&quot;http://httpbin.org/status/404&quot;)&gt;&gt;&gt; bad_r.status_code 404&gt;&gt;&gt; bad_r.raise_for_status() ... ... HTTPError: 404 Client Error: NOT FOUND for url: http://httpbin.org/status/404 2.2.3 响应首部Requests 使用字典形式展示服务器响应首部.且, HTTP 首部是大小写不敏感的. 服务器可以多次接受同一个 header, 每次都是用不同的值, 但是 Requests 会将他们合并, 这样他们就可用同一个映射来表示. 1234567891011&gt;&gt;&gt; r.headers &#123;&apos;Content-Length&apos;: &apos;352&apos;, &apos;Via&apos;: &apos;1.1 vegur&apos;, &apos;Server&apos;: &apos;gunicorn/19.8.1&apos;, &apos;Connection&apos;: &apos;keep-alive&apos;, &apos;Access-Control-Allow-Credentials&apos;: &apos;true&apos;, &apos;Date&apos;: &apos;Thu, 17 May 2018 15:11:48 GMT&apos;, &apos;Access-Control-Allow-Origin&apos;: &apos;*&apos;, &apos;Content-Type&apos;: &apos;application/json&apos;&#125;&gt;&gt;&gt; r.headers[&quot;Content-Type&quot;] &apos;application/json&apos;&gt;&gt;&gt; r.headers[&quot;Content-type&quot;] &apos;application/json&apos;&gt;&gt;&gt; r.headers[&quot;content-type&quot;] &apos;application/json&apos; 2.3 Cookie查看 cookie12345&gt;&gt;&gt; url = &apos;http://example.com/some/cookie/setting/url&apos;&gt;&gt;&gt; r = requests.get(url)&gt;&gt;&gt; r.cookies[&apos;example_cookie_name&apos;] &apos;example_cookie_value&apos; 发送 cookies, 可以使用 cookies 参数123456&gt;&gt;&gt; url = &apos;http://httpbin.org/cookies&apos;&gt;&gt;&gt; cookies = dict(cookies_are=&apos;working&apos;)&gt;&gt;&gt; r = requests.get(url, cookies=cookies)&gt;&gt;&gt; r.text &apos;&#123;&quot;cookies&quot;: &#123;&quot;cookies_are&quot;: &quot;working&quot;&#125;&#125;&apos; Cookie 返回的对象为 RequestsCookieJar, 他的行为和字典类似, 但接口更为完整, 适合跨域名使用. 还可以吧 CookieJar 传到 Requests 中. 1234567&gt;&gt;&gt; jar = requests.cookies.RequestsCookieJar()&gt;&gt;&gt; jar.set(&apos;tasty_cookie&apos;, &apos;yum&apos;, domain=&apos;httpbin.org&apos;, path=&apos;/cookies&apos;)&gt;&gt;&gt; jar.set(&apos;gross_cookie&apos;, &apos;blech&apos;, domain=&apos;httpbin.org&apos;, path=&apos;/elsewhere&apos;)&gt;&gt;&gt; url = &apos;http://httpbin.org/cookies&apos;&gt;&gt;&gt; r = requests.get(url, cookies=jar)&gt;&gt;&gt; r.text &apos;&#123;&quot;cookies&quot;: &#123;&quot;tasty_cookie&quot;: &quot;yum&quot;&#125;&#125;&apos; 2.4 重定向与请求历史默认情况下, 除了 HEAD, Requests 会自动处理所有重定向. 可以使用响应对象的 r.history 方法来追踪重定向. Response.history 是一个 Response 对象的列表, 为了完成请求而创建这小对象, 这个对象列表, 按照从最老到最新的请求进行排序. 123456789101112&gt;&gt;&gt; r = requests.get(&quot;http://httpbin.org/absolute-redirect/6&quot;)&gt;&gt;&gt; r.status_code 200&gt;&gt;&gt; r.history [&lt;Response [302]&gt;, &lt;Response [302]&gt;, &lt;Response [302]&gt;, &lt;Response [302]&gt;, &lt;Response [302]&gt;, &lt;Response [302]&gt;] 如果使用 GET, OPTIONS, POST, PUT, PATCH, DELETE 方法, 可以通过 allow_redirects 参数禁用重定向处理. 12345&gt;&gt;&gt; r = requests.get(&apos;http://github.com&apos;, allow_redirects=False)&gt;&gt;&gt; r.status_code 301&gt;&gt;&gt; r.history [] 如果使用 HEAD, 可以启动 重定向12345&gt;&gt;&gt; r = requests.head(&apos;http://github.com&apos;, allow_redirects=True)&gt;&gt;&gt; r.url &apos;https://github.com/&apos;&gt;&gt;&gt; r.history [&lt;Response [301]&gt;] 2.5 超时使用 timeout 参数设定在 一定时间之后 Requests 停止等待响应. 如果没有设置 timeout, Requests 将永不超时. timeout 进队连接过程有效, 与响应体的下载无关. timout 并不是整个下载响应的时间限制, 而是如果服务器在 timeout 时间内没有应答, 将会引发一个异常. 更精确的说, 是在 timeout 秒内没有从基础套接字上接受到任何字节的数据时.1234&gt;&gt;&gt; requests.get(&quot;http://github.com&quot;, timeout=0.001) Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; requests.exceptions.Timeout: HTTPConnectionPool(host=&apos;github.com&apos;, port=80): Request timed out. (timeout=0.001) 2.6 错误与异常所有 Requests 抛出的异常, 继承自 requests.exceptions.RequestException. ConnectionError : 遇到网络连接问题, 如 DNS 查询失败, 拒绝连接. HTTPError : 如果 HTTP 请求返回了不成功的状态码, Response.raise_for_status() 抛出 HTTPError 异常. Timeout : 请求超时. TooManyRedirects : 请求超过了设定的最大重定向次数. 2.7 会话对象会话对象能够跨请求保持某些参数, 他会在同一个 Session 实例发出的所有请求之间保持 cookie, 期间使用 urllib3 的 connection pooling 功能. 如果想同一主机发送多个请求, 底层的 TCP 连接会被重用, 从而带来显著的性能提升. 会话对象具有主要的 Requests API 的所有方法. 会话可用来跨请求保持 cookie123456789&gt;&gt;&gt; s = requests.Session()&gt;&gt;&gt; s.get(&quot;http://httpbin.org/cookies/set/sessioncookie/123321&quot;) &lt;Response [200]&gt;&gt;&gt;&gt; r = s.get(&quot;http://httpbin.org/cookies&quot;)&gt;&gt;&gt; r.text u&apos;&#123;&quot;cookies&quot;:&#123;&quot;sessioncookie&quot;:&quot;123321&quot;&#125;&#125;\n&apos; 会话可用来为请求方法提供缺省数据, 这是通过为会话对象的属性好提供数据来实现的. 任何传递给请求方法的字典都会与以设置会话层数据合并. 方法层的参数覆盖会话的参数. 123456&gt;&gt;&gt; s = requests.Session()&gt;&gt;&gt; s.auth = (&apos;user&apos;, &apos;pass&apos;)&gt;&gt;&gt; s.headers.update(&#123;&apos;x-test&apos;: &apos;true&apos;&#125;) # both &apos;x-test&apos; and &apos;x-test2&apos; are sent&gt;&gt;&gt; s.get(&apos;http://httpbin.org/headers&apos;, headers=&#123;&apos;x-test2&apos;: &apos;true&apos;&#125;) 注意: 即使使用了会话, 方法级别的参数也不会被跨请求保持. 下面示例中, 只会使用第一个请求发送的 cookie , 而非第二个. 如果手动为会话添加 cookie, 就需要使用 Cookie utility 函数 来操纵 Session.cookies 123456789&gt;&gt;&gt; s = requests.Session()&gt;&gt;&gt; r = s.get(&apos;http://httpbin.org/cookies&apos;, cookies=&#123;&apos;from-my&apos;: &apos;browser&apos;&#125;)&gt;&gt;&gt; print(r.text) &apos;&#123;&quot;cookies&quot;: &#123;&quot;from-my&quot;: &quot;browser&quot;&#125;&#125;&apos;&gt;&gt;&gt; r = s.get(&apos;http://httpbin.org/cookies&apos;)&gt;&gt;&gt; print(r.text) &apos;&#123;&quot;cookies&quot;: &#123;&#125;&#125;&apos; 会话可用作上下文管理器, 这样可以确保 with 区块退出后会话能被关闭, 即使发生了异常.12with requests.Session() as s: s.get(&apos;http://httpbin.org/cookies/set/sessioncookie/123456789&apos;) 如果想要省略字典参数中一些会话层的键, 只需简单的在方法层参数中将这个键的值设置为 None 即可, 该键会被自动省略掉. 包含在一个会话中的所有数据都可以直接使用, 会话 API 文档.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--time]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-time%2F</url>
    <content type="text"></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--datetime]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-datetime%2F</url>
    <content type="text"></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--multiprocessing]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-multiprocessing%2F</url>
    <content type="text"><![CDATA[multiprocessing 与 threading.Thread 类似 multiprocessing.Process 创建进程, 该进程可以运行用 python 编写的函数.multiprocessing.Process.start() multiprocessing.Process.run() multiprocessing.Process.join() Process.PID 保存有 PID, 如果进程还没有 start() , 则 PID 为 None. 注意 在 UNIX 平台上, 当某一个进程终止之后, 该进程需要被其父进程调用 wait , 否则进程就成为 僵尸进程. 所以, 需要对每个 Process 对象调用 join() 方法(等同于 wait), 对于多线程来说, 由于只有一个进程, 所以不存在次必要性. multiprocessing 提供了 threading 中没有的 IPC (比如 Queue,Pipe), 效率上更高. 应有限考虑 Pipe 和 Queue, 避免使用 Lock/Event/Semaphore/Condition 等同步方式(应为他们占据的不是用户进程的资源). 多进程应该避免共享资源. 在多线程中, 我们可以比较容易的共享资源, 比如使用全局变量或传递参数. 在多进程情况下, 由于每个进程有自己独立的内存空间, 以上方法并不合适. 此时我们可以通过共享内存和 Manager 的方法来共享资源. 但这样做提高了程序的复杂度, 并因为同步的需要而降低了程序的效率. ######示例代码 #!/usr/local/bin/env python # import os import threading import multiprocessing def worker(sign,lock): lock.acquire() print(sign,os.getpid()) lock.release() print(&quot;main:&quot;,os.getpid()) # multi-thread record=[] lock = threading.Lock() for i in range(5): thread = threading.Thread(target=worker,args=(&apos;thread&apos;,lock)) thread.start() record.append(thread) for thread in record: thread.join() # multi-process record = [] lock = multiprocessing.Lock() for i in range(5): process = multiprocessing.Process(target=worker,args=(&apos;process&apos;,lock)) process.start() record.append(process) for process in record: process.join() 输出 : 所有 Thread 的 PID 都与主程序相同, 而每个 Process都有一个不同的 PID. (&apos;main:&apos;, 105748) (&apos;thread&apos;, 105748) (&apos;thread&apos;, 105748) (&apos;thread&apos;, 105748) (&apos;thread&apos;, 105748) (&apos;thread&apos;, 105748) (&apos;process&apos;, 105754) (&apos;process&apos;, 105756) (&apos;process&apos;, 105758) (&apos;process&apos;, 105755) (&apos;process&apos;, 105757) ##multiprocessing.Lock ##multiprocessing.Event ##multiprocessing.Semaphore ##multiprocessing.Condition ##multiprocessing.Pipe() multiprocessing.Pipe() # 默认创建双向管道, 该对象返回一个包含两个元素的表, 每个元素代表 Pipe 的一端(Connection对象). 可以在一端调用 send() 方法, 另一端调用 recv() 方法, 实现通信. multiprocessing.Pipe(duplex=False) # 创建单向管道 multiprocessing.Pipe().send() multiprocessing.Pipe().recv() ######示例代码: #!/usr/local/bin/env python # import multiprocessing as mul def proc1(pipe): pipe.send(&apos;hello&apos;) print(&apos;proc1 rec:&apos;,pipe.recv()) def proc2(pipe): print(&apos;proc2 rec:&apos;,pipe.recv()) pipe.send(&apos;hello, too&apos;) # Build a pipe pipe = mul.Pipe() # Pass an end of the pipe to process 1 p1 = mul.Process(target=proc1, args=(pipe[0],)) # Pass the other end of the pipe to process 2 p2 = mul.Process(target=proc2, args=(pipe[1],)) p1.start() p2.start() p1.join() p2.join() 输出: (&apos;proc2 rec:&apos;, &apos;hello&apos;) (&apos;proc1 rec:&apos;, &apos;hello ,too!&apos;) ##multiprocessing.Queue 是先进先出的结构. Queue 允许多个进程放入, 多个进程从队列取出对象. mutiprocessing.Queue(maxsize) 创建队列, maxsize 表示队列中可以存放对象的最大数量. mutiprocessing.Queue(maxsize).put() mutiprocessing.Queue(maxsize).get() ######示例代码 #!/usr/local/bin/env python # import os import multiprocessing import time # input worker def inputQ(queue): info = str(os.getpid()) + &apos;(put):&apos; + str(time.time()) queue.put(info) # output worker def outputQ(queue,lock): info = queue.get() lock.acquire() print (str(os.getpid()) + &apos;(get):&apos; + info) lock.release() # Main record1 = [] # store input processes record2 = [] # store output processes lock = multiprocessing.Lock() # To prevent messy print queue = multiprocessing.Queue(3) # input processes for i in range(10): process = multiprocessing.Process(target=inputQ,args=(queue,)) process.start() record1.append(process) # output processes for i in range(10): process = multiprocessing.Process(target=outputQ,args=(queue,lock)) process.start() record2.append(process) for p in record1: p.join() queue.close() # No more object will come, close the queue for p in record2: p.join() 输出: 105880(get):105865(put):1488439837.07 105883(get):105866(put):1488439837.07 105879(get):105867(put):1488439837.08 105884(get):105870(put):1488439837.08 105877(get):105873(put):1488439837.08 105885(get):105871(put):1488439837.08 105886(get):105874(put):1488439837.09 105878(get):105872(put):1488439837.08 105881(get):105868(put):1488439837.08 105887(get):105876(put):1488439837.09 ##multiprocessing.Pool(num) # num 表示创建的进程数. multiprocessing.Pool(num) # 创建进程池, multiprocessing.Pool(num).map() # 与 map() 函数类似. multiprocessing.Pool(num).apply_async(func,args) # 从进程池中取出一个进程执行 func, args 为 func 的参数. 他将返回一个 AsyncResult 的对象, 可以对该对象调用 get() 方法, 获取结果. multiprocessing.Pool(num).apply_async(func,args).get() multiprocessing.Pool(num).close() # 进程池不再创建新的进程 multiprocessing.Pool(num).join() # wait 进程池的全部进程, 必须对 Pool 先调用 close() 方法, 才能 join. ######示例代码: import multiprocessing as mul def f(x): return x**2 pool = mul.Pool(5) rel = pool.map(f,[1,2,3,4,5,6,7,8,9,10]) print(rel) 输出: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] ##共享内存 multiprocessing.Value(key,value) # 双精度数数字 multiprocessing.Array(key,value_list) # 数组 代码示例import multiprocessing def f(n, a): n.value = 3.14 a[0] = 5 num = multiprocessing.Value(&apos;d&apos;, 0.0) arr = multiprocessing.Array(&apos;i&apos;, range(10)) p = multiprocessing.Process(target=f, args=(num, arr)) p.start() p.join() print num.value print arr[:] 输出: 3.14 [5, 1, 2, 3, 4, 5, 6, 7, 8, 9] Managers = multiprocessing.Manager() s.address s.dict s.list s.register s.Value s.Array s.Event s.Lock s.RLock s.BoundedSemaphore s.get_server s.Namespace s.Semaphore s.Condition s.join s.Pool s.shutdown s.connect s.JoinableQueue s.Queue s.start 代码示例import multiprocessing def f(x, arr, l): x.value = 3.14 arr[0] = 5 l.append(&apos;Hello&apos;) server = multiprocessing.Manager() x = server.Value(&apos;d&apos;, 0.0) arr = server.Array(&apos;i&apos;, range(10)) l = server.list() proc = multiprocessing.Process(target=f, args=(x, arr, l)) proc.start() proc.join() print(x.value) print(arr) print(l) 输出结果: 3.14 array(&apos;i&apos;, [5, 1, 2, 3, 4, 5, 6, 7, 8, 9]) [&apos;Hello&apos;]]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--shutil]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-shutil%2F</url>
    <content type="text"><![CDATA[shutilshutil.move(src,dst)shutil.move(&apos;/tmp/20170223/new&apos;,&apos;/tmp/20170223/test&apos;) # 移动文件, 重命名等 shutil.copytree(src, dst, symlinks=False, ignore=None)shutil.copytree(&apos;/tmp/20170223/&apos;,&apos;/tmp/20170223-2/&apos;) # 递归复制 shutil.copytree(&apos;folder1&apos;, &apos;folder2&apos;, ignore=shutil.ignore_patterns(&apos;*.pyc&apos;, &apos;tmp*&apos;)) shutil.rmtree(path, ignore_errors=False, onerror=None)shutil.rmtree(&apos;/tmp/20170223-2/&apos;) # 递归删除目录树 shutil.get_archive_formats()shutil.get_archive_formats() # 返回支持的 压缩格式列表, 如 [(name,desc),(&apos;tar&apos;,&apos;uncompressed tar file&apos;)], shutil.make_archive(base_name, format, root_dir=None, base_dir=None, verbose=0, dry_run=0, owner=None, group=None, logger=None)shutil.make_archive(&apos;/tmp/20170223/new2&apos;,&apos;zip&apos;,root_dir=&apos;/tmp/20170223/&apos;) # 创建压缩文件, base_name : 压缩包的文件名, 也可以使压缩包的路径. format : 压缩种类 root_dir : 要压缩的文件夹路径, 默认当前目录 owner : 用户, 默认当前用户 group : 组, 默然当前组 shutil.copy(src, dst)shutil.copy(&apos;/tmp/20170223/new&apos;,&apos;/tmp/20170223/new2&apos;) # 复制文件及权限, Copy data and mode bits shutil.copyfileobj(fsrc, fdst, length=16384)shutil.copyfileobj(open(&apos;old.xml&apos;,&apos;r&apos;), open(&apos;new.xml&apos;, &apos;w&apos;)) # 将文件内容拷贝到另一个文件, copy data from file-like object fsrc to file-like object fdst shutil.copyfile(src, dst)shutil.copyfile(&apos;f1.log&apos;, &apos;f2.log&apos;) # 拷贝文件, Copy data from src to dst shutil.copymode(src, dst)shutil.copymode(&apos;f1.log&apos;, &apos;f2.log&apos;) # 仅拷贝权限,内容,用户,组不变, Copy mode bits from src to dst shutil.copystat(src, dst)shutil.copystat(&apos;f1.log&apos;, &apos;f2.log&apos;) # 仅拷贝状态信息, Copy all stat info (mode bits, atime, mtime, flags) from src to dst shutil.copy2(src, dst)shutil.copy2(&apos;f1.log&apos;, &apos;f2.log&apos;) # 拷贝文件和状态信息, Copy data and all stat info]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--subprocess]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-subprocess%2F</url>
    <content type="text"><![CDATA[subprocess主要功能室执行外部的命令和程序 一个进程可 fork 一个子进程, 并让这个子进程 exec 另外一个程序. 在 python 中, 可以通过标准库中的 subprocess 包来 fork 一个子进程, 并运行一个外部的程序. subprocess 创建子进程的函数, 这些函数分别用不同的方式创建进程. 使用 subprocess 包中的函数创建子进程时, 要注意 : 在创建子进程之后, 父进程是否暂停, 并等待子进程运行, 函数返回什么 当 returncode 不为 0 时, 父进程如何处理. 管理标准流(standard stream)和管道(pipe)的工具, 从而在进程间使用文本通信. subprocess.call(*popenargs, **kwargs)父进程等待子进程完成, 返回退出信息(returncocde, 相当于 exit code) subprocess.call(&quot;ls -l&quot;, shell=True) # 返回值为 命令执行结果返回码 subprocess.call([&quot;ls&quot;,&quot;-l&quot;]) subprocess.check_call(*popenargs, **kwargs)父进程等待子进程完成, 返回 0 , 检查退出信息, 如果 returncode 不为 0, 则抛出 subprocess.CalledProcessError 错误. subprocess.check_call([&apos;ls&apos;,&apos;-l&apos;]) # 返回值为 命令执行结果返回码 subprocess.check_output(*popenargs, **kwargs)父进程等待子进程完成, 返回子进程向标准输出的输出结果. 检查退出信息, 如果 returncode 不为 0, 则抛出错误 subprocess.CalledProcessError , 该对象包含有 returncode 属性和 output 属性, output 属性为标准输出的输出结果. subprocess.check_output([&apos;ls&apos;,&apos;-l&apos;]) # 返回值为 命令执行结果. 如果使用了shell=True这个参数。这个时候，我们使用一整个字符串，而不是一个表来运行子进程。Python将先运行一个shell，再用这个shell来解释这整个字符串。shell命令中有一些是shell的内建命令，这些命令必须通过shell运行，$cd。shell=True允许我们运行这样一些命令。当使用 shell 的内建命令时, 需要执行的命令及其参数必须为 一个整字符串, 并且加上 shell=True 参数. subprocess.Popen()上面三个函数(subprocess.call(), subprocess.check_all(), subprocess.check_output() )都是基于 Popen() 的封装. 该类生成的对象来代表子进程. class Popen(args, bufsize=0, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=False, shell=False, cwd=None, env=None, universal_newlines=False, startupinfo=None, creationflags=0) args should be a string, or a sequence of program arguments. The program to execute is normally the first item in the args sequence or string, but can be explicitly set by using the executable argument. On UNIX, with shell=False (default): In this case, the Popen class uses os.execvp() to execute the child program. args should normally be a sequence. A string will be treated as a sequence with the string as the only item (the program to execute). On UNIX, with shell=True: If args is a string, it specifies the command string to execute through the shell. If args is a sequence, the first item specifies the command string, and any additional items will be treated as additional shell arguments. On Windows: the Popen class uses CreateProcess() to execute the child program, which operates on strings. If args is a sequence, it will be converted to a string using the list2cmdline method. Please note that not all MS Windows applications interpret the command line the same way: The list2cmdline is designed for applications using the same rules as the MS C runtime. bufsize, if given, has the same meaning as the corresponding argument to the built-in open() function: 0 means unbuffered, 1 means line buffered, any other positive value means use a buffer of (approximately) that size. A negative bufsize means to use the system default, which usually means fully buffered. The default value for bufsize is 0 (unbuffered). stdin, stdout and stderr specify the executed programs&apos; standard input, standard output and standard error file handles, respectively. Valid values are PIPE, an existing file descriptor (a positive integer), an existing file object, and None. PIPE indicates that a new pipe to the child should be created. With None, no redirection will occur; the child&apos;s file handles will be inherited from the parent. Additionally, stderr can be STDOUT, which indicates that the stderr data from the applications should be captured into the same file handle as for stdout. If preexec_fn is set to a callable object, this object will be called in the child process just before the child is executed. If close_fds is true, all file descriptors except 0, 1 and 2 will be closed before the child process is executed. if shell is true, the specified command will be executed through the shell. If cwd is not None, the current directory will be changed to cwd before the child is executed. If env is not None, it defines the environment variables for the new process. If universal_newlines is true, the file objects stdout and stderr are opened as a text files, but lines may be terminated by any of &apos;\n&apos;, the Unix end-of-line convention, &apos;\r&apos;, the Macintosh convention or &apos;\r\n&apos;, the Windows convention. All of these external representations are seen as &apos;\n&apos; by the Python program. Note: This feature is only available if Python is built with universal newline support (the default). Also, the newlines attribute of the file objects stdout, stdin and stderr are not updated by the communicate() method. The startupinfo and creationflags, if given, will be passed to the underlying CreateProcess() function. They can specify things such as appearance of the main window and priority for the new process. (Windows only) Instances of the Popen class have the following methods: child.poll() # 检查进程状态 Check if child process has terminated. Returns returncode attribute. child.wati() wait for child process to terminate. Return returncode attribute.,\ child.commuticate(input=None) # 阻塞父进程, 直到子进程完成. Interact with process : Send data to stdin. Read data from stdout and stderr, until end-of-file is reached. Wait for process ti terminate. The optional input argument shout be a string to be sent to the child process, or None, if no data should be sent to the child . communicate() returns a tuple (stdout, stderr). Note: The data read is buffered in memory, so do not use this method if the data size is large or unlimited. child.kill() # 终止进程 child.send_signal() # 向子进程发送信号 child.terminate() # 终止子进程. attributes stdin If the stdin argument is PIPE, this attribute is a file object that provides input to the child process. Otherwise, it is None. stdout If the stdout argument is PIPE, this attribute is a file object that provides output from the child process. Otherwise, it is None. stderr If the stderr argument is PIPE, this attribute is file object that provides error output from the child process. Otherwise, it is None. pid The process ID of the child process. returncode The child return code. A None value indicates that the process hasn&apos;t terminated yet. A negative value -N indicates that the child was terminated by signal N (UNIX only). 子进程的文本流控制 : subprocess.PIPEsubprocess.PIPE 实际上为文本流提供了一个缓冲区. 子进程的标准输入, 标准输出, 标准错误: child.stdin child.stdout child.stderr 我们可以在 Popen() 建立子进程的时候改变标准输入, 标准输出, 标准错误, 并利用 subprocess.PIPE 将多个子进程的输入和输出链接在一起, 构成管道(pipe) : import subprocess child1 = subprocess.Popen([&quot;ls&quot;,&quot;-l&quot;], stdout=subprocess.PIPE) child2 = subprocess.Popen([&quot;wc&quot;], stdin=child1.stdout,stdout=subprocess.PIPE) out = child2.communicate() print(out) child.communicate() 是 Popen 对象的一个方法, 该方法阻塞父进程, 直到子进程完成. 使用 communicate() 方法来使用 PIPE 给子进程输入 : import subprocess child = subprocess.Popen([&apos;cat&apos;], stdin=subprocess.PIPE) child.communicate(&quot;hahahah&quot;) # 我们启动子进程之后, cat 会等待输入, 知道 communicate() 输入 &quot;hahahah&quot; 参考]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--pickle]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-pickle%2F</url>
    <content type="text"><![CDATA[pickle &amp; cPicklepickle 和 cPickle 除了导入名称不一样之外, 使用方法, 均一样.pickle 导入 import picklecPickle 导入 import cPickle as pickle cPickle 比 pickle 快很多 pickle.dumps(OBJ) –&gt; 序列化对象import cPickle as pickle b = {&quot;name&quot;:&quot;tom&quot;, &quot;age&quot;:12,&quot;job&quot;:&quot;dev&quot;} s=pickle.dumps(b) pickle.dump(OBJ,f) –&gt; 序列化对象, 并存储到文件import cPickle as pickle b = {&quot;name&quot;:&quot;tom&quot;, &quot;age&quot;:12,&quot;job&quot;:&quot;dev&quot;} with open(&quot;a.pkl&quot;, &apos;f&apos;) as f: s=pickle.dump(b,f) pickle.load(f) –&gt; 从文件加载被序列化的 对象.import cPickle as pickle with open(&quot;a.pkl&quot;,&apos;r&apos;) as f: b = pickle.load(f) type(b)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--re]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-re%2F</url>
    <content type="text"><![CDATA[re 正则表达式语法import re m = re.search(&apos;[0-9]&apos;,&apos;abc4def67&apos;) # 匹配字符及匹配范围 print m.group(0) # 返回匹配结果 re.search()m = re.search(pattern, string, re.IGNORECASE) # 搜索整个字符串，直到发现符合的子字符串。不区分大小写. re.match()m = re.match(pattern, string) # 从头开始检查字符串是否符合正则表达式。必须从字符串的第一个字符开始就相符。 s = re.match(&quot;0ab&quot;,&apos;0abasdasda&apos;) # 有匹配 s = re.match(&quot;[0-9]ab&quot;,&apos;0abasdasda&apos;) # 有匹配 s = re.match(&quot;ab&quot;,&apos;0abasdasda&apos;) # 没有匹配 re.sub()str = re.sub(pattern, replacement, string) # 在string中利用正则变换pattern进行搜索，对于搜索到的字符串，用另一字符串replacement替换。返回替换后的字符串 re.findall()re.findall() # 根据正则表达式搜索字符串，将所有符合的子字符串放在一给表(list)中返回 s = &apos;0a1b2c3d4e5f6&apos; l=re.findall(&apos;[0-9]&apos;,s) print l re.split()re.split() # 根据正则表达式分割字符串， 将分割后的所有子字符串放在一个表(list)中返回 s = &apos;0a1b2c3d4e5f6&apos; l = re.split(&apos;[0-9]&apos;,s) # 返回列表,去除数字之后的. print l re.compile() 编译后的正则, 更快import re regexes = [re.compile(p, re.IGNORECASE) for p in [&quot;this&quot;, &quot;that&quot;]] text = &apos;Does this text match the pattern?&apos; for regex in regexes: print regex.pattern # this \n that if regex.search(text): print &quot;OK&quot; # OK print regex.search(text).group() # this else: print &quot;Problem&quot;]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--signal]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-signal%2F</url>
    <content type="text"><![CDATA[signal 的核心是, 设置信号处理函数. 预定义信号signal.SIG_DFL signal.SIGBUS signal.SIGFPE signal.SIGIO signal.SIGPOLL signal.SIGRTMAX signal.SIGSYS signal.SIGTTIN signal.SIGUSR2 signal.SIGXFSZ signal.SIG_IGN signal.SIGCHLD signal.SIGHUP signal.SIGIOT signal.SIGPROF signal.SIGRTMIN signal.SIGTERM signal.SIGTTOU signal.SIGVTALRM signal.SIGABRT signal.SIGCLD signal.SIGILL signal.SIGKILL signal.SIGPWR signal.SIGSEGV signal.SIGTRAP signal.SIGURG signal.SIGWINCH signal.SIGALRM signal.SIGCONT signal.SIGINT signal.SIGPIPE signal.SIGQUIT signal.SIGSTOP signal.SIGTSTP signal.SIGUSR1 signal.SIGXCPU signal.signal(signalnum, handler)为指定的信号, 设置自定义的处理函数. import signal # Define signal handler function def myHandler(signum, frame): print(&apos;I received: &apos;, signum) # register signal.SIGTSTP&apos;s handler signal.signal(signal.SIGTSTP, myHandler) signal.pause() print(&apos;End of Signal Demo&apos;) # 效果 : 当执行该脚本时, 脚本自身阻塞; 当向脚本发送 SIGTSTP 信号时, 脚本执行 myHandler 函数, 并继续执行之后的 print 语句. signal.pause()当运行到此处时, 进程暂停并等待信号. 代码如上示例. signal.alarm(SECONDS)被用于在一定时间之后, 向进程自身发送 SIGALRM 信号. import signal # Define signal handler function def myHandler(signum, frame): print(&quot;Now, it&apos;s the time&quot;) exit() # register signal.SIGALRM&apos;s handler signal.signal(signal.SIGALRM, myHandler) signal.alarm(5) while True: print(&apos;not yet&apos;) # 效果 : 脚本无条件循环 打印语句, 在执行 5 秒之后, signal.alarm() 向自身发送 SIGALRM 信号, 执行 myHandler 函数.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--threading]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-threading%2F</url>
    <content type="text"><![CDATA[threading : 提高对网络端口的读写效率.threading.Thread.start() 执行线程操作 threading.Thread.run() 执行线程操作 threading.Thread.join() 调用该方法的线程将等待, 直到该 Thread 对象完成, 再回复运行. 这与进程间调用 wait() 函数类似. 下面对象用于处理多线程同步, 对象一旦被建立,可以被多个线程共享, 并根据情况阻塞某些进程. threading.Lock 互斥锁, mutex, threading.Lock.acquire() threading.Lock.release() threading.Condition condition variable, 建立该对象时, 包含一个 Lock 对象, 因为 condition variable 总是和 mutex 一起使用. 可以对 condition 对象调用acquire() 和 release() 方法, 以控制潜在的Lock 对象. threading.Condition.acquire() threading.Condition.release() threading.Condition.wait() 相当于 cond_wait() threading.Condition.notify_all() 相当于 cond_broadcase() threading.Condition.notify() 与 notify_all() 功能类似, 但置唤醒一个等待的线程, 而不是全部. threading.Semaphore 计数锁,(Semaphore)传统上是一种进程间同步工具. 创建对象的时候,可以传递一个整数作为计数上限(sema= threading.Semaphore(5)). 与 Lock 类似, 也有 Lock 的两个方法. threading.Semaphore.acquire() threading.Semaphore.release() threading.Event 与 threading.Condition 类似, 相当于没有潜在 Lock 保护的 condition variable. 对象有 True 和 False 两个状态 . 可以多个线程使用 wait() 等待, 直到某个线程调用该对象的 set() 方法, 将对象设置为 True. 线程可以调用对象的 clear() 方法来重置对象为 False 状态. threading.Event.wait() 等待 threading.Event.set() 将对象设置为 True 状态. threading.Event.clear() 将对象重置为 False 状态. 线程 threading.Thread.start() + 过程式编程示例#!/usr/local/bin/env python # import threading import time import os def doChore(): time.sleep(1) def booth(tid): global i global lock while True: lock.acquire() if i != 0: i = i - 1 print(tid,&apos;: now left :&apos;,i) doChore() else: print(&quot;Thread_id&quot;,tid,&quot; no more tickets.&quot;) os._exit(0) lock.release() doChore() i = 100 lock = threading.Lock() for k in range(10): new_thread = threading.Thread(target=booth,args=(k,)) new_thread.start() 线程 threading.Thread.run() + 面向对象 示例#!/usr/local/bin/env python # import threading import time import os def doChore(): time.sleep(1) class BoothThread(threading.Thread): def __init__(self,tid,monitor): self.tid = tid self.monitor = monitor threading.Thread.__init__(self) def run(self): while True: monitor[&quot;lock&quot;].acquire() if monitor[&apos;tick&apos;] != 0: monitor[&apos;tick&apos;] = monitor[&apos;tick&apos;] - 1 print(self.tid,&apos;now left:&apos;,monitor[&apos;tick&apos;]) doChore() else: print(&apos;Thread_id&apos;, self.tid,&quot;No more ticket.&quot;) os._exit(0) monitor[&apos;lock&apos;].release() doChore() monitor = {&apos;tick&apos;:100, &apos;lock&apos;:threading.Lock()} for k in range(10): new_thread = BoothThread(k,monitor) new_thread.start()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--os]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-os%2F</url>
    <content type="text"><![CDATA[osos.getcwd()os.getcwd() # 获取当前工作目录 os.listdir(path)os.listdir(&apos;/tmp&apos;) # 列出指定目录下的文件和目录 os.mkdir(path [, mode=0777])os.mkdir(&apos;/tmp/newtest&apos;) # 创建新目录 os.mkdir(&apos;/tmp/ntest/test/test&apos;) # 无法递归创建. os.rmdir(path)os.rmdir(&apos;/tmp/newtest&apos;) # 删除**空**目录 os.remove(path)os.remove(&apos;/tmp/newtest/readne.md&apos;) # 删除指定*文件* ,而非目录 os.rename(src,dst)os.rename(&quot;/tmp/newtest/readme.txt&quot;, &apos;/tmp/newtest/readme.md&apos;) # 给文件重命名 os.chmod(path,mod)os.chmod(&apos;/tmp/newtest/readme.md&apos;, 0700) # 修改文件的权限, mod 为 4 位数字. os.chown(path,uid,gid)os.chown(&apos;/tmp/20170223/new&apos;,502,502) # 修改文件的属主和属组 os.stat(path)os.stat(&apos;/tmp/20170223/new&apos;) # 查看文件的附加信息, 相当于 `$ls -l` # 返回结果 : # posix.stat_result(st_mode=33261, st_ino=141209, st_dev=64768, st_nlink=1, st_uid=502, st_gid=502, st_size=0, st_atime=1487818970, st_mtime=1487818970, st_ctime=1487819520) os.stat(&apos;/tmp/20170223/new&apos;).uid os.stat(&apos;/tmp/20170223/new&apos;).gid os.stat(&apos;/tmp/20170223/new&apos;).mode os.stat(&apos;/tmp/20170223/new&apos;).ino os.stat(&apos;/tmp/20170223/new&apos;).dev os.stat(&apos;/tmp/20170223/new&apos;).nlink os.stat(&apos;/tmp/20170223/new&apos;).size os.stat(&apos;/tmp/20170223/new&apos;).ctime os.stat(&apos;/tmp/20170223/new&apos;).mtime os.stat(&apos;/tmp/20170223/new&apos;).atime os.symlink(src,dst)os.symlink(&apos;/tmp/20170223/new&apos;,&apos;/tmp/new&apos;) # 为文件 dst 创建软连接, src 为软连接文件的路径. os.pathimport os.path path = &apos;/var/run/supervisord/supervisor.sock&apos; os.path.basename()os.path.basename(path) # 返回路径中的文件名 os.path.dirname()os.path.dirname(path) # 返回路径中的目录 os.path.split()print os.path.split(path) # 将路径分割为文件名和路径两部分,放在一个元组中返回, (&apos;/var/run/supervisord&apos;, &apos;supervisor.sock&apos;) path=&apos;/var/run/supervisord&apos; # 为目录 print os.path.split(path) # (&apos;/var/run&apos;, &apos;supervisord&apos;) os.path.join()os.path.join(&apos;/&apos;, &apos;home&apos;, &apos;tom&apos;, &apos;scripts&apos;, &apos;init.sh&apos;) # &apos;/home/tom/scripts/init.sh&apos; os.path.join(&apos;home&apos;, &apos;tom&apos;, &apos;scripts&apos;, &apos;init.sh&apos;) # &apos;home/tom/scripts/init.sh&apos; os.path.commonprefix()path = &apos;/home/tom/scripts/init.sh&apos; path2 = &apos;/home/tom/scripts/status.sh&apos; path3 = &apos;home/tom/scripts/init.sh&apos; os.path.commonprefix([path,path2]) # &apos;/home/tom/scripts/&apos; os.path.commonprefix([path,path3]) # &apos;&apos; os.path.normpath()去除路径中的冗余 path = &apos;/home/tom/../.&apos; os.path.normpath(path) # &apos;/home&apos; os.path.exists(path)判断路径是否存在, 返回 布尔值 os.path.getsize()返回文件大小, 单位字节 os.path.getatime()返回文件上一次的读取时间, unix 时间戳 os.path.getmtime()返回文件上一次的修改时间, unix 时间戳 os.path.isfile()路径存在, 且是文件 os.path.isdir()路径存在, 且是目录 获取进程相关信息os.uname() # 操作系统先关信息 os.umask() # umask 权限码 os.get*() uid,euid,resuid,gid,egid,resgid : 权限相关, resuid 返回 saved UID. pid,pgid,ppod,sid : 进程相关 os.put*() edid,egid : 更改 euid,egid uid, gid : 改变进程的 uid,gid. 只用 super user 才有权限.( $sudo python ) pgid,sid : 改变进程所在的进程组和会话. os.getenviron() : 获得进程的环境变量 os.setenviron() : 更改进程的环境变量]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--glob]]></title>
    <url>%2F2018%2F03%2F19%2FPyStdLib-glob%2F</url>
    <content type="text"><![CDATA[globglob.glob()import glob l = glob.glob(&quot;/root/*&quot;) # 返回列表 print l # 输出如下 [&apos;/root/databases&apos;, &apos;/root/install.log&apos;, &apos;/root/anaconda-ks.cfg&apos;, &apos;/root/install&apos;, &apos;/root/install.log.syslog&apos;, &apos;/root/requirements.txt&apos;, &apos;/root/test&apos;]]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 mysqldump 备份数据]]></title>
    <url>%2F2018%2F03%2F19%2Fmysql-mysqldump-%E5%A4%87%E4%BB%BD%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[mysqldump 备份备份数据库 my_database $ mysqldump -uUSER -pPASSWD my_database &gt; my_database.sql 备份数据库 my_database 中的 my_table 表 $ mysqldump -uUSER -pPASSWD my_database my_table.sql &gt; my_table.sql 备份数据库 my_database 中的 my_table 表中 id 大于 120 的数据, where 用法 $ mysqldump -uUSER -pPASSWD my_database my_table.sql --where &quot;id &gt; 120&quot;&gt; my_table.sql 备份数据库 my_database 表结构 $ mysqldump -uUSER -pPASSWD -d my_database &gt; my_database.sql 备份数据库 my_database 中 my_table 表(多个表)的表结构 $ mysqldump -uUSER -pPASSWD -d my_database my_table1 my_table2 &gt; my_table.sql 备份多个数据库 my_database1, my_database2 $ mysqldump -uUSER -pPASSWD --databases my_database1 my_database2 &gt; my_database.sql 备份所有数据库 $ mysqldump -uUSER -pPASSWD --all-databases &gt; my_database.sql 备份后压缩保存, 及还原压缩保存的数据 $ mysqldump -uUSER -pPASSWD --all-databases | gzip &gt; backupfile.sql.gz $ gunzip -c abc.sql.gz |mysql -uroot -proot abc # 还原压缩的数据到数据库 在两个 mysql server 之间复制数据 $ mysqldump --opt db_name | mysql --host=remote_host -C db_name mysqldump 帮助 --add-locks : 在每个表导出之前增加 LOCK TABLES 并且之后 UNLOCK TABLE , 为了使得更快的插入到 Mysql --add-drop-table : 在每个 Create 语句之前增加一个 drop table. 参考]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysqldump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 特殊用户权限 suid sgid sticky]]></title>
    <url>%2F2018%2F03%2F19%2FLinux-%E7%89%B9%E6%AE%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90-suid-sgid-sticky%2F</url>
    <content type="text"><![CDATA[每个进程会维护有如下6个ID: 真实身份 : real UID, readl GID --&gt; 登录 shell 使用的身份 有效身份 : effective UID, effective GID --&gt; 当进程真正去操作文件是所检查的身份, 存储身份 : saved UID, saved GID --&gt; 当将一个程序文件执行为进程的时候, 该程序文件本身的属主和属组可以被存储为存储身份, 在随后进程运行的过程中, 进程就可以选择将 真实身份或存储身份 复制到有效身份, 以拥有真实身份或存储身份的权限. 但并不是所有的程序文件在执行的过程中都会设置存储身份的, 需要这么做的程序文件会在其 9 位权限的执行位的 x 改为 s, 这时, 这一位叫做 set UID bit 或 set GID bit. $ chmod 4799 file ** 必须要在有 x 位的基础上, 才能设置 s 位. 这里的chmod后面不再只是三位的数字。最前面一位用于处理set-UID bit/set-GID bit，它可以被设置成为4/2/1以及或者上面数字的和。4表示为set UID bit, 2表示为set GID bit，1表示为sticky bit . 当 进程 fork 的时候, 真实身份和有效身份都会复制给子进程. 大部分情况下, 真实身份和有效身份都相同. setuid, setgid,sticky setuid : 在一个程序或命令上添加setuid以后（u+s）,这样属主有了s权限，意味着任何用户在执行此程序时,其进程的属主不再是发起者本人,而是这个程序的属主。最典型的一个例子就是passwd这个命令； 普通用户运执行passwd命令来修改自己的密码，其实最终更改的是/etc/passwd这个文件。 $ll /etc/passwd -rw-r--r-- 1 root root 2597 11月 12 15:36 /etc/passwd 但是 /etc/passwd 文件只有 root 才有权限更改, 再看下 passwd 命令的权限: ll /usr/bin/passwd -rwsr-xr-x 1 root root 54256 3月 29 2016 /usr/bin/passwd* passwd 命名运行时, 进程的属主是程序的属主, 即 root, 这样普通用户就有了修改自己账号密码的权限了. 设置 setuid 方法 : $ chmod u(+|-)s /path/to/file $ chmod 4644 /path/to/file setgid : 数组有 s 权限, 即 执行此程序时, 次进程的属组不是运行程序的用户, 而是此程序文件的属组. 如果 setgid 赋值给 文件, 则运行次文件的其他用户具有该文件的属组特权; 如果 setgid 赋值为 目录, 则任何用户在该目录下创建的文件,该文件属组都和目录的属组一直. $ chmod g+s /tmp/test sticky 在有权限的情况下,可以添加和修改其他用户的文件，就是不能删除其他用户的文件，自己可以删除自己创建的文件。 $ chmod o(+|-)t /path/somefile 三个权限用 八进制表示 : suid : 4 sgid : 2 sticky : 1]]></content>
      <categories>
        <category>计算机原理与操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>权限管理</tag>
        <tag>用户管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二进制运算]]></title>
    <url>%2F2018%2F03%2F19%2F%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[一. 二进制运算电子计算机运算: 算术运算 : 逻辑运算 : 所有的逻辑运算都是按位进行的，位与位之间没有任何联系. 二进制运算规则一览表 二. 二进制算术运算 : 加,减,乘,除,1. 加法 : 逢二进一. 2. 减法 : 借一有二 3. 乘法 : 可参照十进制乘法. 4. 除法 : 参照十进制除法. 三. 二进制逻辑运算 : 与,或,非,异或1. 或, 逻辑加运算符号 : + 或 V 运算法则 : 两个相“或”的逻辑变量中，只要有一个为1，“或”运算的结果就为1。 仅当两个变量都为0时，或运算的结果才为0。 示例: 0＋0＝0或0∨0＝0 0＋1＝1或0∨1＝1 1＋0＝1或1∨0＝1 1＋1＝1或1∨1＝1 2. 与, 逻辑乘运算符号 : × 或 · 或 ∧ 运算法则 : 两个相“与”的逻辑变量中，只要有一个为0，“与”运算的结果就为0。 仅当两个变量都为1时，“与”运算的结果才为1。 示例: 0×1＝0或0·1＝0或0∧1＝0 1×0＝0或1·0＝0或1∧0＝0 1×1＝1或1·1＝1或1∧1＝1 3. 非, 逻辑否定运算符号 : 在变量的上方加一横线表示“非”。 运算法则 : 将原逻辑变量的状态求反. 4. 异或运算符号 : 或 运算法则 : 两个相“异或”的逻辑运算变量取值相同时，“异或”的结果为0。 取值相异时，“异或”的结果为1]]></content>
      <categories>
        <category>计算机原理与操作系统</category>
      </categories>
      <tags>
        <tag>数制</tag>
        <tag>二进制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机数的表示]]></title>
    <url>%2F2018%2F03%2F19%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%95%B0%E7%9A%84%E8%A1%A8%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[计算机要处理的数 无符号数 有符号数 : 机器数 原码 反码 补码 无符号数无符号数通常表示一个数的绝对值, 即数的各位都用来表示数值的大小. 一个字节(8位)二进制数只能表示 0~255 范围内的数, 要表示大于 255 的数,必须采用多字节表示, 它的长度可以为任意倍字节长. 数据格式 有符号数有符号数, 即用来表示一个任意位长的整数或负数. 一般用一个数的最高位来表示符号位, 其余位为数值位: 0 : 表示 正号 1 : 表示 负号 原码原码表示数的方法很简单，只需要在真值的基础上，将符号位用数码“0”和“1”表示即可. 反码正数的反码与原码相同，而负数的反码则是在原码的基础上，符号位不变（仍为1），其余数位按位求反，即0→1，1→0。 补码如果是正数，补码同原码也同反码，如果是负数，则在反码的基础上最末位加1。 注：补码中0只有一种表示，无正负之分， 补码特性: [[X]补]补＝[X]原 补码运算两个用补码表示的带符号数进行加减运算时，特点是把符号位上表示正负的“1”和“0”也看成数，与数值部分一同进行运算，所得的结果也为补码形式，即结果的符号位为“0”，表示正数，结果的符号位为“1”表示负数。 两个带符号的数X和Y进行相加时，是将两个数分别转换为补码的形式，然后进行补码加运算，所得的结果为和的补码形式。即： [X＋Y]补＝[X]补＋[Y]补 两个带符号的数X和Y进行相减时, 求[X－Y]补，可以用[X]补和[－Y]补相加来实现。这里关键在于求[－Y]补。如果已知[Y]补，那么对[Y]补的每一位（包括符号位）都按位求反，然后再在末位加1，结果即为[－Y]补。（证明从略）。一般称[－Y]补为对[Y]补的“变补”，即[[Y]补]变补＝[－Y]补；已知[Y]补求[－Y]补的过程叫变补。 [X－Y]补＝[X＋(－Y)]补＝[X]补＋[－Y]补 减数（补码）变补与被减数（补码）相加]]></content>
      <categories>
        <category>计算机原理与操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 文件系统]]></title>
    <url>%2F2018%2F03%2F19%2Flinux-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[一. 存储设备分区文件系统的最终目的是把大量数据有组织的放入持久性(persistant)的存储设备中, 如硬盘和磁盘. 这些设备的存储能力具有持久性, 不会应为断电而消失; 存储量大, 但读取速度慢. 最开始的区域是 MBR, 用于Linux 开机启动.剩余的空间可能分成数个分区(partition), 每个分区有一个相关的分区表(partition table), 记录相关的分区信息. 这个分区表存储在分区之外. 分区表说明了对应分区的起始位置和分区大小. 分区的第一个部分是启动区(boot block), 主要为计算机开机服务. Linux 开机之后, 会首先载入 MBR, 随后 MBR 从某个硬盘的启动区加载程序.该程序负责进一步的操作系统的加载和启动. 为了方便管理, 即使某个分区中没有安装操作系统, Linux 也会在该分区预留启动分区. 启动区之后的是 超级区(super block) : 它存储有文件系统的相关信息, 包括文件系统的类型, inode 的数目, 数据块的数目. 随后是多个 inode, 他们是实现文件存储的关键. 在 Linux 系统中, 一个文件可以分成几个数据块存储. 每个文件对应一个 inode. 这个 inode 包含多个指针, 指向该文件各个数据块. 当操作系统需要读取文件时, 只需要对应 inode 的 地图, 收集起分散的数据块就可以获取到文件. 真正存储数据的是数据块 (data blocks) 二. inode文件是文件系统对数据的分割单元. 文件系统用目录来组织文件, 赋予文件上下分级的结构. 在硬盘上实现这一分级结构的关键, 是使用 inode 来虚拟普通文件和目录文件对象. 文件元数据用来记录文件的大小,属组,属主,修改日期等相关信息, 元数据并不包含在文件的数据中, 而是由操作系统维护的. 元数据包含在 inode 当中. 每个 inode 有一个唯一的整数彪悍(inode number) 表示. 在保存元数据, inode 是文件从抽象到具体的关键. 每个inode能够存储的数据块指针总数是固定的。如果一个文件需要的数据块超过这一总数，inode需要额外的空间来存储多出来的指针。 目录文件也有inode 当我们读取一个文件时，实际上是在目录中找到了这个文件的inode编号，然后根据inode的指针，把数据块组合起来，放入内存供进一步的处理。当我们写入一个文件时，是分配一个空白inode给该文件，将其inode编号记入该文件所属的目录，然后选取空白的数据块，让inode的指针指像这些数据块，并放入内存中的数据。 三. 文件描述符与文件共享在 Linux 的进程中, 当我们打开一个文件时, 返回的是一个文件描述符. 这个描述符是一个数组的下标, 对应数组元素为一个指针. 有趣的是, 这个指针并没有直接指向文件的 inode, 而是指向一个文件表格(因为不仅需要记录inode , 还需要记录文件的读写状态, 读写位置等信息), 在通过该表格, 执行加载到内存中的目标文件的 inode. 每个文件表格中记录了文件打开的状态(status flags), 比如只读,写入等, 还记录了每个文件的当前读写位置(offset). 当有两个进程同事打开同一个文件时, 可以有两个文件表格, 每个文件表格对应的打开状态和当前位置不同, 从而支持一些文件共享的操作, 比如同时读取. 要注意的是进程fork 之后的情况, 子进程将只复制文件描述符的数组, 和父进程共享内核维护的文件表格和 inode, 此时要特别小心程序的编写. [参考] http://www.cnblogs.com/vamei/p/3506566.html]]></content>
      <categories>
        <category>计算机原理与操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-数据类型.md]]></title>
    <url>%2F2018%2F03%2F19%2Fpython-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[一. intn1 + n2 --&gt; n1.__add__(n2) int.bit_length() # 返回二进制长度, 最少. # 定义 int n = 123 n = int(3) n = int.__init__(123) -5 ~ 257 内存优化数字. int 范围 : 与计算机类型有关 32bit : 64bit : 二. strstr.center(width, fillchar=None) : 居中, 总长度, 填充字符. str.zfill(width) : 返回指定长度的额字符串, 原字符串右对齐, 前面填充 0 str.count(sub,start=None,end=None) : 子序列个数. str.decode(encoding=None, error=None) : 解码 str.encode(encoding=None, error=None) : 编码, 针对 unicode str.endswith(suffix, start=None, end=None) : 是否已 suffix 结尾. str.startswith(prefix, start=None, end=None) : str.expandtabs(tabsize=None) : 将 tab 转换为 空格, 默认一个 tab 转换为 8 个空格. str.find(sub, start=None, end=None) : 寻找子字符串的位置. 返回字符串索引, 没有找到返回 -1 str.rfind(sub, start=None, end=None) str.index(sub, start=None, end=None) : 寻找子字符串的位置. 返回字符串索引, 没有找到返回 报错. str.rindex(sub, start=None, end=None) str.format(*args, **kwargs) 字符串格式化, 动态参数 str.isalnum() str.isalpha() str.isdigit() str.islower() str.isspace() str.istitle() str.isupper() str.join() str.ljust(width, fillchar=None) : 内容左对齐，右侧填充 str.rjust(width, fillchar=None) : str.lower() str.upper() str.title() str.capitalize() str.swapcase() : 大写变小写，小写变大写 str.translate(table, deletechars=None) : 转换，需要先做一个对应表，最后一个表示删除字符集合 str.lstrip() : 移除左侧空白 str.rstrip() : 移除右侧空白 str.strip() : 移除两侧空白 str.partition(sep) : 分割，前，中，后三部分 str.rpartition(sep) : 从右侧索引开始 str.replace(old, new, count=None) str.split(sep=None, maxsplit=None) : 字符串切割, 结果为 list str.rsplit(sep=None, maxsplit=None) : 字符串切割, 结果为 list str.splitlines(keepends=False) : 字符串切割, 以换行符为依据, 结果为 list 三. listl.sort(cmp=None, key=None, reverse=False) : 同时包含数字,字母,中文等的列表, 无法排序, 会报错. l.reverse() : 倒序 l.remove(value) l.pop(index=None) : 默认删除末尾元素 # 删除指定索引, del l[INDEX] l.extend(iterable) : 扩展列表 l1 = [1,2,3] l2 = [4,5,6] l1.extend(l2) l.append(p_object) : 添加元素 l1 = [1,2,3] l1.append(4) l.insert(index, p_obj) l.count(value) : 统计出现的次数. l.index(value, start=None, stop=None) 四. tuplet.count(index) t.index(value, start=None, stop=None) 五. dictd.clear() : 清理所有的元素 d.copy() : 浅拷贝 d.get(k, d=None) : 依据 key 获取值. d.has_key(k) : 判断元素是否存在 d.pop(k, d=None) : 获取并在字典中移除 d.popitem() : 随机删除元素 d.setdefault(k,d=None) : 如果 key 不存在, 则创建, 存在则返回原有的值. d.update(E=None, **f) : d.items() : 所有元素的列表形式 d.iteritems() : 可迭代 items d.iterkeys() : 可迭代 keys d.itervalues() : 可迭代 values d.keys() : keys, 列表 d.values() : value , 列表 d.viewitems() d.viewkeys() d.viewvalues() dict.fromkeys(key_list,default_value) # 从字典 d 中遍历 寻找key_list对应的 key, 返回 key和 default_value 组成的字典. 用于创建字典, 是一个类方法. a = dict(a=123,b=234) 六. dict七. set1. 创建 sets = set() s = set(list) # list 为可迭代对象的即可 s = {1,23,4} 2. 内建方法1) 一般方法:s.add() # 为集合添加元素 s.clear() # 清空集合 a.isdisjoint(b) # 判断有无交集, 有交集返回 False a.issubset(b) # 是否是子集 a.issuperset(b) # 是否是父集 s.discard(a) # 移除指定元素, 元素不存在不报错 s.remove(a) # 移除指定元素, 元素不存在报错. s.pop() # 随机移除元素, 并返回 被删除的元素. s.update(b) # b 可以为 set, 也可以为 list 2) 差集:a.difference(b) # 返回 a 与 b 的差集 a.difference_update(b) # 用 a 与 b 的 差集更新 a 3) 交集:a.intersection(b) # 返回 a 与 b 的交集, a.intersection_update(b) # 用 a 与 b 的交集跟新 a 4) 补集:a.union(b) a.union_update(b) 5) 对称交集:a.symmetric_difference(b) # 返回 a 存在, b 不存在 和 a 不存在 ,b 存在的 元素组成的 set a.symmetric_difference_update(b) # a 和 b 的交叉补集 更新 a. 八. 序列通用方法# s为一个序列 len(s) 返回： 序列中包含元素的个数 min(s) 返回： 序列中最小的元素 max(s) 返回： 序列中最大的元素 all(s) 返回： True, 如果所有元素都为True的话 any(s) 返回： True, 如果任一元素为True的话 s.count(x) 返回： x在s中出现的次数 s.index(x) 返回： x在s中第一次出现的下标 range(1,10) : 指定范围生成数字列表. xrange(1,10) : 指定范围生成数字列表. 可迭代. 九. enumrate() : 可迭代对象添加序号l = range(6) for k,v in enumerate(l): print k,v 十. 标准库 collections : 容器数据类型1. collections.namedtuple是一个函数,用来创建自定义的 tuple 对象, 并且规定 tuple 的元素个数,并可以用 属性 而不是 索引 来引用 tuple 的某个元素. In [1]: from collections import namedtuple In [2]: Point = namedtuple(&apos;Point&apos;,[&apos;x&apos;,&apos;y&apos;]) In [3]: p = Point(1,2) In [4]: p.x Out[4]: 1 In [5]: p.y Out[5]: 2 In [6]: isinstance(p,Point) Out[6]: True In [7]: isinstance(p,tuple) Out[7]: True ** 可以方便的定义一种数据类型, 具备 tuple 元素的不变性, 又可以根据属性来引用. 示例 : 用坐标和半径表示一个圆 Circle = namedtuple(&apos;Circle&apos;, [&apos;x&apos;,&apos;y&apos;,&apos;z&apos;]) 定义 : 各种namedtuple 都由其自己的类表示, 使用namedtuple() 工厂函数来创建. 参数就是新类名和一个包含元素名的字符串. import collections Person = collections.namedtuple(&quot;Person&quot;, &quot;name age gender&quot;) bob = Person(name=&quot;bob&quot;, age=12, gender=&quot;Male&quot;) # 匹配定义使用的元素名字符串, 正好匹配, 不多不少. print bob[0] print bob.name,bob.age,bob.gender print bob._fields # 打印所有预定义字段. 除了使用标准元组的位置索引外, 还可以使用点记法(obj.attr)按名字访问 namedtuple 的字段. 元素名字符串不可与 Python 关键字冲突, 不可重复. &gt;&gt; engineer = collections.namedtuple(&quot;engineer&quot;, &quot;name age job&quot;, rename=True) &gt;&gt; print engineer._field # (&apos;name&apos;, &apos;age&apos;, &apos;job&apos;) &gt;&gt; with_class = collections.namedtuple(&quot;Person&quot;,&quot;name class age gender&quot;,rename=True) &gt;&gt; with_class._fields # (&apos;name&apos;, &apos;_1&apos;, &apos;age&apos;, &apos;gender&apos;) &gt;&gt; two_ages = collections.namedtuple(&quot;Person&quot;,&quot;name age gender age&quot;,rename=True) &gt;&gt; two_ages._fields # (&apos;name&apos;, &apos;age&apos;, &apos;gender&apos;, &apos;_3&apos;) ** 重命名的字段的新名字取决于他在 tuple 中的索引, 所以名为 class 的字段会变成 _1, 重复的age字段则变成 _3. 2. collections.deque : 双端队列支持从任意一端增加和删除元素. 更为常用的两种结构, 即栈和队列, 就是双端队列的退化形式, 其输入和输出限制在一端. 为了高效实现插入和删除操作的双向列表, 使用于队列和栈. In [8]: from collections import deque In [9]: q = deque([&apos;a&apos;,&apos;b&apos;,&apos;c&apos;]) In [10]: q.append(&apos;x&apos;) In [12]: q Out[12]: deque([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;x&apos;]) In [16]: q.appendleft(&apos;x&apos;) In [17]: q Out[17]: deque([&apos;x&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;x&apos;]) deque.append() deque.appendleft() deque.pop() deque.popleft() deque 是一种序列容器, 因此同样支持 list 的一些操作. d = collections.deque(&quot;abcdefg&quot;) print d print len(d) print d[0] print d[-1] d.remove(&apos;c&apos;) 填充 : 可以从任意一端填充, 在 Python 中成为 “左端” 和 “右端” d1 = collections.deque() d.extend() d1.extend(&quot;abcdefg&quot;) print d1 # deque([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;f&apos;, &apos;g&apos;]) d.append() d1.append(&quot;h&quot;) print d1 # deque([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;f&apos;, &apos;g&apos;, &apos;h&apos;]) d.extendleft() : 迭代处理其输入, 对各个元素完成与 appendleft() 同样的处理, 其结果是 deque 将包含逆序的输入序列. d1.extendleft(range(5)) d.appendleft() d1.appendleft(&quot;10&quot;) d.pop() : 从右端删除一个元素 d.popleft() : 从左端删除一个元素 ** 由于双端队列是线程安全的, 所以甚至可以在不同线程中同时从两端利用队列内容. d.rotate() : 旋转, 类似拨号盘. d.rotate(NUM) : 向右旋转, 即从队列右端取元素, 移动到左端 d.rotate(-NUM) : 向左旋转, 即从队列左端取元素, 移动到右端 d2 = collections.deque(range(10)) print d2 # deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) de.rotate(2) # deque([8, 9, 0, 1, 2, 3, 4, 5, 6, 7]) de.rotate(-2) # deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 3. collections.defaultdict使用 dict 使, 当 key 不存在时,返回一个默认值. In [20]: from collections import defaultdict In [21]: dd=defaultdict(lambda: &apos;xyz&apos;) In [22]: dd[&apos;name&apos;]=&apos;bob&apos; In [23]: dd[&apos;age&apos;] = 12 In [24]: dd Out[24]: defaultdict(&lt;function __main__.&lt;lambda&gt;&gt;, {&apos;age&apos;: 12, &apos;name&apos;: &apos;bob&apos;}) In [25]: dd[&apos;name&apos;] Out[25]: &apos;bob&apos; In [26]: dd[&apos;gaga&apos;] Out[26]: &apos;xyz&apos; ** 默认值是调用函数返回的, 而函数在创建 defaultdict 对象时传入. ** 除了在 key 不存在时返回默认值, defaultdict 的其他行为跟 dict 是完全一样的. 标准字典 : dict.setdefault() # 来获取一个值, 如果这个值不存在则建立一个默认值. defaultdict 初始化时,容器会让调用者提前指定默认值. import collections def default_factory(): return &quot;default value&quot; d = collections.defaultdict(defaultdict, foo=&quot;bar&quot;) print d[&quot;foo&quot;] # &quot;bar&quot; print d[&quot;aaa&quot;] # &quot;default value&quot; print d[&quot;bar&quot;] # &quot;default value&quot; ** 只要所有键都是相同的默认值并无不妥, 就可以使用这个方法. ** 如果默认值是一种用于聚集或者累加值的类型, 如 list,set 甚至是 int, 该方法尤其有用. 4. collections.OrderdDict使得 dict 保持有序. &gt;&gt;&gt; from collections import OrderedDict &gt;&gt;&gt; d = dict([(&apos;a&apos;, 1), (&apos;b&apos;, 2), (&apos;c&apos;, 3)]) &gt;&gt;&gt; d # dict的Key是无序的 {&apos;a&apos;: 1, &apos;c&apos;: 3, &apos;b&apos;: 2} &gt;&gt;&gt; od = OrderedDict([(&apos;a&apos;, 1), (&apos;b&apos;, 2), (&apos;c&apos;, 3)]) &gt;&gt;&gt; od # OrderedDict的Key是有序的 OrderedDict([(&apos;a&apos;, 1), (&apos;b&apos;, 2), (&apos;c&apos;, 3)]) ** OrderedDict 是按照插入的顺序排列,而不是 key 本身排序. ** OrderedDict 可以实现一个 FIFO 的 dict, 当容量超出限制时, 先删除最早添加的 key. from collections import OrderedDict class LastUpgradeOrderedDict(OrderedDict): def __init__(self, capacity): super(LastUpgradeOrderedDict, self).__init__() self._capacity = capacity def __setitem__(self,key,value): containsKey = 1 if key in self else 0 if len(self) - containsKey &gt;= self._capacity: last = self.popitem(last=False) print &apos;remove: &apos;, last if containKey: del self[key] print &apos;set:&apos;,(key,value) else: print &apos;add&apos;,(key,value) OrderedDict.__setitem__(self,key,value) 标准字典并不跟踪插入顺序, 迭代处理时会根据键在散列表中存储的顺序来生成值. 在 OrderedDict 中则相反, 他会记住元素插入的顺序, 并在创建迭代器时使用这个顺序. 标准字典在检查相等性时, 会查看其内容; OrderedDict 还会考虑元素增加的顺序. od = collections.OrderedDict() od[&quot;a&quot;] = &quot;A&quot; od[&quot;b&quot;] = &quot;B&quot; od[&quot;c&quot;] = &quot;C&quot; od[&quot;d&quot;] = &quot;D&quot; for k,v in od.items(): print k,v 5. collections.Counter一个简单的计数器, 例如, 统计字符出现的个数. 可以跟踪相同的值增加了多少次. In [35]: from collections import Counter In [36]: c = Counter() In [37]: for ch in &apos;programing&apos;: ...: c[ch] = c[ch] + 1 ...: In [38]: c Out[38]: Counter({&apos;a&apos;: 1, &apos;g&apos;: 2, &apos;i&apos;: 1, &apos;m&apos;: 1, &apos;n&apos;: 1, &apos;o&apos;: 1, &apos;p&apos;: 1, &apos;r&apos;: 2}) 初始化 : 三种初始化方法 print collections.Counter([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;]) # 元素序列 print collections.Counter({&quot;a&quot;: 2, &quot;b&quot;: 3, &quot;c&quot;: 1}) # 一个包含键和计数的字典 print collections.Counter(a=2, b=3, c=1) # 使用关键字参数,将字符串映射到计数. 不提供任何参数, 构造一个空的 Counter, 然后通过 update() 方法填充. import collections c = collections.Counter() c.update(&quot;abcdaab&quot;) print c # Counter({&apos;a&apos;: 3, &apos;b&apos;: 2, &apos;c&apos;: 1, &apos;d&apos;: 1}) c.update({&quot;a&quot;:1,&quot;d&quot;:5}) print c # Counter({&apos;a&apos;: 4, &apos;b&apos;: 2, &apos;c&apos;: 1, &apos;d&apos;: 6}) 计数值将根据新数据增加, 替换数据不会改变计数. ####访问计数 : 使用字典API 获取 c = collections.Counter(&quot;abcdaab&quot;) for letter in &apos;abcde&apos;: print c[letter] # 打印字符出现的次数. ** 未出现的字符, 不会产生 KeyError, 其计数为 0. elements() : 返回一个迭代器, 将生成 Counter 知道的所有元素. c = collections.Counter(&quot;extremely&quot;) c[&quot;z&quot;] = 0 print list(c.elements()) # [&apos;e&apos;, &apos;e&apos;, &apos;e&apos;, &apos;m&apos;, &apos;l&apos;, &apos;r&apos;, &apos;t&apos;, &apos;y&apos;, &apos;x&apos;] 不能保证元素的顺序不变, 计数小于或者等于0的元素, 不包含在内. most_common() : 生成一个序列, 其中包含 n 个最常遇到的输入值及其相应计数. 没有参数时, 返回一个列表, 按词频排序 print c.most_common() [(&apos;e&apos;, 3), (&apos;m&apos;, 1), (&apos;l&apos;, 1), (&apos;r&apos;, 1), (&apos;t&apos;, 1), (&apos;y&apos;, 1), (&apos;x&apos;, 1)] 带参数时, 返回前 3 个词频较大的元素. 当参数大于序列的长度时, 返回所有. print c.most_common(3) [(&apos;e&apos;, 3), (&apos;m&apos;, 1), (&apos;l&apos;, 1)] 算数操作,集合操作 c1 = Counter([&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;a&quot;,&quot;b&quot;,&quot;b&quot;]) c2 = Counter(&apos;alphabet&apos;) print c1 Counter({&apos;a&apos;: 2, &apos;b&apos;: 3, &apos;c&apos;: 1}) print c2 Counter({&apos;a&apos;: 2, &apos;b&apos;: 1, &apos;e&apos;: 1, &apos;h&apos;: 1, &apos;l&apos;: 1, &apos;p&apos;: 1, &apos;t&apos;: 1}) print c1 + c2 Counter({&apos;a&apos;: 4, &apos;b&apos;: 4, &apos;c&apos;: 1, &apos;e&apos;: 1, &apos;h&apos;: 1, &apos;l&apos;: 1, &apos;p&apos;: 1, &apos;t&apos;: 1}) print c1 - c2 Counter({&apos;b&apos;: 2, &apos;c&apos;: 1}) print c1 &amp; c2 Counter({&apos;a&apos;: 2, &apos;b&apos;: 1}) print c1 | c2 Counter({&apos;a&apos;: 2, &apos;b&apos;: 3, &apos;c&apos;: 1, &apos;e&apos;: 1, &apos;h&apos;: 1, &apos;l&apos;: 1, &apos;p&apos;: 1, &apos;t&apos;: 1}) 每次通过一个操作生成一个新的 Counter 时, 计数为 0 或负数的元素都会被删除.]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[博客文档写作规范]]></title>
    <url>%2F2018%2F03%2F19%2F%E5%8D%9A%E5%AE%A2%E6%96%87%E6%A1%A3%E5%86%99%E4%BD%9C%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[一. 文档写作所有写作均使用 markdown 语法, 个人文档总结地址 二. 在 markdown 基础上, 添加层次级别, 方便阅读 为给博客文章添加层次, 增加易读性, 使用如下层级表示方法, 其中, 无标号, 不建议使用 部分, 能不用则不用, 必要时考虑文章拆分. | 级别 | 文字表示 | markdown 级别 | | — | — | — | | 一级 | 不要用, 留给文章标题 | # | | 二级 | 一, 二, 三, 四, 五 …, | ## | | 三级 | (一), (二), (三), (四), (五) …, | ### | | 四级 | 1, 2, 3, 4, 5, 代替有序列表 | #### | | 五级 | 1.1, 1.2 1.3, 1.4 ,1.5 … | ##### | | 六级 | 1.1.1, 1.1.2, 1.1.3 … | ###### | | 列表(七级) | 无序列表 | - | 不要在文章中使用有序列表, 需要使用时, 使用 #### 1. 代替 只能使用无序列表表示序列, 关闭 nexT 提供的侧边栏的自动索引, 手动提供标题和索引. 各个等级之间必须连续出现, 不能跨越, 否则 hexo 显示或有问题. 三. 博客模板模板使用 Hexo, 基于 github page, 使用 nexT.Mist 主题, 文档地址: Hexo-nexT-博客建设指南. 另, hexo 在解析 markdown 文档时, 可能会在解析 `{{ }}`, `{% %}` 时 发生错误, 建议在两个符号之间添加空格替代之. {% raw %} {{ --> { { }} --> } } {% --> { % %} --> % } {% endraw %} 五. cnblog 使用 JS 在文档右侧显示目录 已弃用(一) 申请 js 权限(二) 上传文件里面的 js 和 css 文件 https://github.com/ctxsdhy/cnblogs-example/tree/master/1-%E5%8D%9A%E5%AE%A2%E5%9B%AD%E6%96%87%E7%AB%A0%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E5%AF%BC%E8%88%AA%E7%9B%AE%E5%BD%95 (三) 修改页面设置 (四) 参考链接#### 参考链接: [title](http://www.example.com/p/1234.html) [title](http://www.example.com/p/1234.html)]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 函数与数组]]></title>
    <url>%2F2018%2F03%2F19%2Flinux-shell-%E5%87%BD%E6%95%B0%E4%B8%8E%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[一. 数组bash Shell只支持一维数组，数组从0开始标号，以array[x]表示数组元素，那么，array[0]就表示array数组的第1个元素、array[1]表示array数组的第2个元素、array[x]表示array数组的第x+1个元素bash Shell取得数组值（即引用一个数组元素）的命令格式是： ${array[x]} #引用array数组标号为x的值 ** $符号后面的 {大括号} 必不可少 示例: city=(Nanjing Beijing Melbourne NewYork) city=(Nanjing [10]=Atlanta Massachusetts Marseilles) # 下标前面的有效 如 ${city[0]}, ${city[10]}; 后面的无效,无法调用. city=([2]=Nanjing [10]=Atlanta [1]=Massachusetts [5]=Marseilles) # 指定下标. array[@]和array[\*]都表示了array数组的所有元素 value_0=(net.ipv4.ip_forward net.ipv4.conf.all.send_redirects net.ipv4.conf.default.send_redirects net.ipv4.conf.all.accept_source_route net.ipv4.conf.default.accept_source_route net.ipv4.conf.all.accept_redirects net.ipv4.conf.default.accept_redirects net.ipv4.conf.all.secure_redirects net.ipv4.conf.default.secure_redirects net.ipv6.conf.all.accept_ra net.ipv6.conf.default.accept_ra net.ipv6.conf.all.accept_redirects net.ipv6.conf.default.accept_redirects) value_1=(net.ipv4.conf.all.log_martians net.ipv4.conf.default.log_martians net.ipv4.icmp_echo_ignore_broadcasts net.ipv4.icmp_ignore_bogus_error_responses net.ipv4.conf.all.rp_filter net.ipv4.conf.default.rp_filter net.ipv4.tcp_syncookies) for i in ${value_0[*]};do sysctl -w $i=0 grep $i /etc/sysctl.conf &amp;&gt;/dev/null if [ $? -ne 0 ];then echo &quot;$i = 0&quot; &gt;&gt; /etc/sysctl.conf else sed -i &quot;s/$i = \*/$i = 0/&quot; &gt;&gt; /etc/sysctl.conf fi done for i in ${value_1[@]};do sysctl -w $i=1 grep $i /etc/sysctl.conf &amp;&gt;/dev/null if [ $? -ne 0 ];then echo &quot;$i = 0&quot; &gt;&gt; /etc/sysctl.conf else sed -i &quot;s/$i = \*/$i = 0/&quot; &gt;&gt; /etc/sysctl.conf fi done read -a array可以将读到的值存储到array数组 二. 函数function addlvm(){ local devname=$1 local lvmname=$2 local sname=$3 local mountdir=$4 pvcreate /dev/$devname vgcreate $lvmname /dev/$devname lvcreate -l 100%VG -n $sname $lvmname sleep 10 if [ &quot;$lvmname&quot; = &quot;LVMSWAP&quot; ]; then mkswap /dev/$lvmname/$sname [ $? -ne 0 ] &amp;&amp; { echo &quot;create swap -$lvmname-$sname- error&quot;; exit; } echo &quot;/dev/$lvmname/$sname swap swap defaults 0 0&quot; &gt;&gt; /etc/fstab else mkfs.ext4 /dev/$lvmname/$sname [ $? -ne 0 ] &amp;&amp; { echo &quot;mkefs -$lvmname-$sname- error&quot;; exit; } echo &quot;/dev/$lvmname/$sname $mountdir ext4 defaults 0 0&quot; &gt;&gt; /etc/fstab fi }]]></content>
      <categories>
        <category>计算机原理与操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[csvn 安装记录]]></title>
    <url>%2F2018%2F03%2F19%2Fcsvn-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[1. 安装步骤如下# 确保 java 已安装 $ java -version $ echo $JAVA_HOME # 解压二进制包 $ tar xf CollabNetSubversionEdge-5.2.0_linux-x86_64.tar.gz -C /usr/local # Install the application so that it will start antomatically when the server restarts. This command generally requires root/sudo to execute. # 安装 csvn, 使用 csvn 提供的安装工具. $ cd csvn $ sudo -E bin/csvn install # this will write JAVA_HOME and username to the file data/conf/csvn.conf . you can change it bu setting the JAVA_HOME and RUN_AS_USER variables in the file. 四. start the server. be sure that you are logged in as your own userid and not running as root.# 启动 csvn 服务, 确保使用 非root 用户启动. $ bin/csvn start $ bin/csvn console # start the server and output the initial startup msg to the console. # you must login to the web-based management consoel and configure the Apache server before it can be run for the first time. URL : http://localhost:3343/csvn SSL : https://localhost:4434/csvn # you can force the user to use it. user: admin pass: admin # 启动 csvn 的 apache 子服务 # Configure the Apache Subversion server to start automatically when the system boots. $ cd csvn $ sudo bin/csvn-httpd install **you should config the Apache Server on the web-UI before this step.** 2. 更新.csvn 用于内置的自动发现更新及自动更新机制, 用户必须使用该机制更新 csvn 程序, 切忌自主下载和安装更新新版本 csvn 程序 csvn 更新机制, 需要重启 csvn 服务器, 无需手动重启, csvn 将自动重启. 3. 其他资源1) doc :http://help.collab.net/ 2) download_page :https://www.collab.net/downloads/subversion#tab-1 # you have to register first. 3) auto start$ chkconfig csvn on $ chkconfig svnserve on 4) command line help$bin/csvn --help Usage: bin/csvn [ console | start | stop | restart | condrestart | status | install | remove | dump ] Commands: console Launch in the current console. start Start in the background as a daemon process. stop Stop if running as a daemon or in another console. restart Stop if running and then start. condrestart Restart only if already running. status Query the current status. install Install to start automatically when system boots. remove Uninstall. dump Request a Java thread dump if running.]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>svn</tag>
        <tag>csvn</tag>
        <tag>代码管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fdisk 非交互式创建分区]]></title>
    <url>%2F2018%2F03%2F19%2Flinux-fdisk-%E9%9D%9E%E4%BA%A4%E4%BA%92%E5%BC%8F%E5%88%9B%E5%BB%BA%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[一. key 非交互式创建分区, 与 交互式创建分区区别不大. 使用 fdisk 的默认选项, 使用空行即可, 不用回车. 创建 主分区 和 扩展分区时, 需要注意 分区号 二. 创建主分区fdisk /dev/xvdk &lt;&lt;EOF n p 1 # 注意分区号 p w EOF 三. 创建扩展分区# make Extended Partition, use all space. fdisk /dev/xvdk &lt;&lt;EOF n e 4 # 注意分区号 p w EOF 四. 创建逻辑分区# make 5G logical Partition for /tmp fdisk /dev/xvdk &lt;&lt;EOF n l +3G p w EOF]]></content>
      <categories>
        <category>计算机原理与操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>磁盘管理</tag>
        <tag>fdisk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables 汇总]]></title>
    <url>%2F2018%2F03%2F19%2Flinux-iptables-%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[一. 背景知识1. 相关网络背景知识(1) Linux 主机内部路由Linux 在 内核中维护由一个路由表, 报文进入本机后, 由该路由表判断目标地址; 报文离开本机之前, 判断经由那个接口发出. (2) TCP 报文格式erg : 紧急指针是否有效. ack : 确认号是否有效. psh : 不再缓冲中停留, 直接发往内核. rst : reset, 重置. syn : 同步, 请求建立连接. fin : 结束, 请求关闭连接. (3) TCP 协议的三次握手和四次断开(4) TCP 的有限状态机2. iptables 简介iptables 是 Linux 主机上的防火墙软件, 由两部分构成: iptables : 命令行工具, 用于编写 规则, 并可以实现规则的语法检查. netfilter : 网络过滤器, 内核中工作为 TCP/IP 协议栈上的框架. 3. netfilter 的四表五链(0) 表与链每个钩子函数上可以防止 n 条规则, 数据包在每条规则上依次匹配, 对应于每个钩子上的多条规则成为一个 链(CHAIN); 每个功能(表)有多个链, 所以成为 表 (1) 四表 filter : 包过滤 input --&gt; forward --&gt; output NAT : 地址转换 prerouting --&gt; output --&gt; postrouting mangle : 修改报文首部中的某些信息; prerouting --&gt; input --&gt; forward --&gt; output --&gt; postrouting raw : 关闭 nat 表上启动的链接追踪功能. prerouting --&gt; output (2) 五链(5 个 hooks functions) prerouting : 进入本机后, 路由功能发生之前 input : 到达本机内部 output : 由本机发出 forward : 由本机转发 postrouting : 路由功能发生之后, 即将离开本机之前. (3) 报文流向经由的位置 到本机内部 prerouting --&gt; input 由本机发出 output --&gt; postrouting 由本机转发 prerouting --&gt; forward --&gt; postrouting (4) 链上规则的检查次序匹配的内部机制 : 检查 IP 首部, 检查 TCP,UDP,ICMP 首部; 同时, 基于扩展机制, 可以进行额外的检查, 例如做链接追踪等. 每个 链 上的规则检查为依次检查; 当某个链上的某个规则被匹配之后, 则执行该规则的 target, 该链上的其他规则不再执行; 钩子函数(表)的优先级 在每个钩子(链)上, 规则是按不同的功能(表), 分别存放的. 每个数据包到来之后, 按表的优先级, 依次检查每一个链, 完成之后, 转到下一个链. 优先级 : raw &gt; mangle &gt; nat &gt; filter (5) 规则编写最佳实践写作规则的最佳实践: 同类规则 : 匹配范围小的放在最前面; 同类规则, 如果能合并, 则尽量合并; 不同类规则 : 匹配范围几率较大的放前面; 应该为每个链, 设置默认规则; 二. iptables 规则编写1. 添加规则时的考量点 要实现的功能 –&gt; 判断添加到哪个表上; 报文流向及经由路径 –&gt; 判断添加到哪个链上; 2. 规则和链的计数器 pkts: 由规则或链匹配到的报文的个数； bytes：由规则或链匹配到的所有报文大小之和； 3. 规则的编写.如果同时指定多个匹配条件, 则默认多个条件需要同时被满足. iptables [-t TABLE] SUBCOMMAND CHAIN CRETERIA -j TARGET -t TABLE: 默认为filter, 共有filter, nat, mangle, raw四个可用； SUBCOMMAND： 链： -F：flush，清空指定表的指定链上所有规则；省略链名时，清空表中的所有链； -N：new, 新建一个用户自定义的链；自定义链只能作为默认链上的跳转对象，即在默认链通过引用来生效自定义链； -X：drop，删除用户自定义的空链；非空自定义链和内置链无法删除； -Z：zero，将规则的计数器置0； -P：policy，设置链的默认处理机制；当所有都无法匹配或有匹配有无法做出有效处理机制时，默认策略即生效； filter表的可用策略：ACCEPT, DROP, REJECT -E：rename，重命名自定义链； 注意：被引用中的链，无法删除和改名 规则： -A：append，在链尾追加一条规则； -I：insert，在指定位置插入一条规则； -D：delete，删除指定的规则；rule or rulenum -R：replace，替换指定的规则； $ iptable -t filter -R INPUT 1 -s 172.16.100.2 -d 172.16.100.11 -p tcp -i eth0 -j ACCEPT 查看： -L：list，列出指定链上的所有规则； -n: numeric，以数字格式显示地址和端口号，即不反解； -v: verbose，详细格式，显示规则的详细信息，包括规则计数器等； -vv: -vvv: --line-numbers: 显示规则编号； -x: exactly，显示计数器的精确值； pkts bytes target prot opt in out source destination pkts: 被本规则所匹配到的包个数； bytes：被本规则所匹配到的所包的大小之和； target: 处理目标 （目标可以为用户自定义的链） prot: 协议 {tcp, udp, icmp} opt: 可选项 in: 数据包流入接口 out: 数据包流出接口 source: 源地址 destination: 目标地址； CHAIN : 指定要添加规则的链; 可以是自定义链. 注意：报文不可能经由自定义链(不再内核中)，只有在被内置链上的引用才能生效（即做为自定义目标） CRETERIA : 指定匹配条件. 1. 通用匹配 -s, --src, --source IP|Network：检查报文中的源IP地址； -d, --dst, --destination：检查报文中的目标IP地址/网段 -p, --protocol：检查报文中的协议，即ip首部中的protocols所标识的协议；tcp、udp或icmp三者之一； -i, --in-interface：数据报文的流入接口；通常只用于PREROUTING, INPUT, FORWARD链上的规则； -o, --out-interface：检查报文的流出接口；通常只用于FORWARD, OUTPUT, POSTROUTING链上的规则； 2. 扩展匹配: 使用 iptables 的模块实现扩展检查机制. (1) 隐式扩展 : ** 如果在通用匹配上使用 -p 选项指明了协议的话，则使用-m选项指明对其协议的扩展就变得可有可无了； 1) tcp: -m tcp --dport PORT[-PORT] # 必须是连续的端口 --sport --tcp-flags LIST1 LIST2 LIST1: 要检查的标志位； LIST2：在LIST1中出现过的，且必须为1标记位；而余下的则必须为0; 例如：--tcp-flags syn,ack,fin,rst syn # 表示 三次握手的第一次. 等同 --syn --syn：用于匹配tcp会话三次握手的第一次；新建连接. $ iptable -A INPUT 1 -s 172.16.100.2 -d 172.16.100.11 -p tcp [-m tcp] --dport 80 -j REJECT # -m tcp 可省略, 因为 -p tcp 指明了协议. 2) udp: -m udp --sport --dport 3) icmp: -m icmp --icmp[-type] # ICMP TYPE CODE 表 8: echo request, ping 请求 0：echo reply, ping 响应 # 允许自己 ping 别人. 本机地址 为 172.16.100.11 . $ iptables -A OUTPUT -s 172.16.100.11 -p icmp --icmp-type 8 -j ACCEPT $ iptables -A INPUT -d 172.16.100.11 -p icmp --icmp-type 0 -j ACCEPT (2) 显式扩展: 必须指明使用的扩展机制. 0) 通用语法格式: -m 模块名称 每个模块会引入新的匹配机制； 查看可用模块: 小写字母，以.so结尾； 大写通常指 处理方式. 1) multiport扩展：以离散定义多端口匹配；最多指定15个端口； 专用选项： --source-ports, --sports PORT[,PORT,...] --destination-ports, --dports PORT[,PORT,...] --ports PORT[,PORT,...] # 源和目标端口. 例子： $ iptables -I INPUT 1 -d 172.16.100.11 -p tcp -m multiport --dports 22,80,443 -j ACCEPT $ iptables -I OUTPUT 1 -s 172.16.100.11 -p tcp -m multiport --sports 22,80,443 -j ACCEPT 2) iprange扩展：指定连续的ip地址范围；在匹配非整个网络地址时使用； 专用选项： [!] --src-range IP[-IP] # 也支持单个 ip [!] --dst-range IP[-IP] # 也支持单个 ip 示例： $ iptables -A INPUT -d 172.16.100.11 -p tcp --dport 23 -m iprange --src-range 172.16.100.1-172.16.100.100 -j ACCEPT $ iptables -A OUTPUT -s 172.16.100.11 -p tcp --sport 23 -m iprange --dst-range 172.16.100.1-172.16.100.100 -j ACCEPT 3) string扩展：对应用层首部和数据进行检查. 检查报文中出现的字符串，与给定的字符串作匹配； 字符串匹配检查算法：实现高效匹配. 两者相近. kmp : bm : 专用选项： --algo {kmp|bm} --string &quot;STRING&quot; --hex-string &quot;HEX_STRING&quot;：HEX_STRING为编码成16进制格式的字串； 示例： $ iptables -I OUTPUT 1 -s 172.16.100.11 -p tcp --sport 80 -m string --string &quot;sex&quot; --algo kmp -j REJECT 4) time扩展：基于时间区间做访问控制 专用选项： --datestart YYYY[-MM][-DD][hh[:mm[:ss]]] --dattestop YYYY[-MM][-DD][hh[:mm[:ss]]] --timestart --timestop --weekdays DAY1[,DAY2,...] 示例： $ iptables -R INPUT 1 -d 172.16.100.11 -p tcp --dport 80 -m time --timestart 08:30 --timestop 18:30 --weekdays Mon,Tue,Thu,Fri -j REJECT 5) connlimit扩展：基于连接数作限制；对每个IP能够发起的并发连接数作限制； 专用选项： --connlimit-above [n] # 包含 n . $ iptables -I INPUT 2 -d 172.16.100.11 -p tcp --dport 22 -m connlimit --connlimit-above 5 -j REJECT 6) limit扩展：基于令牌桶算法实现的.基于发包速率作限制； 专用选项：令牌桶算法 --limit n[/second|/min|/hour|/day] --limit-burst n # 突发速率时, 最大速率. $ iptables -R INPUT 3 -d 172.16.100.11 -p icmp --icmp-type 8 -m limit --limit 10/minute --limit-burst 5 -j ACCEPT ** limit 仅按一定速率匹配数据, 若限制, 先放过一定速率的数据, 然后阻断. $ iptables -A FORWARD -p icmp -s 172.16.11.0/24 -m limit --limit 10/s -j ACCEPT $ iptables -A FORWARD -p icmp -s 172.16.11.0/24 -j DROP 7) state扩展：启用连接追踪模板记录连接，并根据连接匹配连接状态的扩展； 启用连接追踪功能之前：简单包过滤防火墙； 启用连接追踪功能：带状态检测的包过滤防火墙； # 反弹式木马: 木马可以探测主机开放的端口, 并使用该端口作为客户端,想外发送请求, 从而出入的连接成为 ESTABLISHED 状态. 专用选项： --state STATE $ iptables -I INPUT 1 -d 172.16.100.11 -p tcp -m multiport --dport 22,80 -m state --state NEW,ESTABLISHED -j ACCEPT $ iptables -I OUTPUT 1 -d 172.16.100.11 -m state --state ESTABLISHED -j ACCEPT 调整连接追踪功能所能容纳的连接的最大数目： $cat /proc/sys/net/nf_conntrack_max $ lsmod | grep nf_conntrack # 查看是否打开连接追踪功能. $ modprobe -r nf_conntrack $ modprobe -r nf_conntrack_ipv4 当前追踪的所有连接： /proc/net/nf_conntrack 不同协议或连接类型追踪时的时长属性： /proc/sys/net/netfilter/ 如何放行被动模式下的ftp服务： (1) 装载模块： # modprobe nf_conntrack_ftp (2) 放行请求报文 放行入站请求端口为21的请求报文； 放行所有状态为ESTABLISHED和RELATED状态的入站报文； (3) 放行出站响应报文 放行所有状态为ESTABLISHED的出站报文； 8) recent 扩展 : 利用iptables的recent模块来抵御DOS攻击. 示例: iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --set --name SSH # SSH 只是个名字, 用于日志记录 /var/log/messages . iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 300 --hitcount 3 --name SSH -j LOG --log-prefix &quot;SSH Attack: &quot; iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 300 --hitcount 3 --name SSH -j DROP 1.利用connlimit模块将单IP的并发设置为3；会误杀使用NAT上网的用户，可以根据实际情况增大该值； 2.利用recent和state模块限制单IP在300s内只能与本机建立2个新连接。被限制五分钟后即可恢复访问。 下面对最后两句做一个说明： 1.第二句是记录访问tcp 22端口的新连接，记录名称为SSH --set 记录数据包的来源IP，如果IP已经存在将更新已经存在的条目 2.第三句是指SSH记录中的IP，300s内发起超过3次连接则拒绝此IP的连接。 --update 是指每次建立连接都更新列表； --seconds必须与--rcheck或者--update同时使用 --hitcount必须与--rcheck或者--update同时使用 3.iptables的记录：/proc/net/xt_recent/SSH # 防止被探测 SSH 密码 $ iptables -A INPUT -p tcp --dport 22 -m state --state NEW -m recent --set --name SSH --rsource -m recent --name SSH --update --seconds 10 --hitcount 4 --rsource -j DROP TARGET： -j: jump，跳转目标 内置目标： ACCEPT : 接受 DROP : 丢弃 REJECT : 拒绝 SNAT DNAT MASQUERADE LOG：日志 REDIRECT：端口重定向； RETURN: 返回至调用者； MARK：防火墙标记, 用于 mangle 表中. 见 LVS. 4. NAT : Network Address Translation(1) 分类:NAT : 工作于 3 和 4 层. 并非是用户空间运行的进程完成转换功能，靠的是内核中地址转换规则； 仅从请求报文判断，地址转换： 源地址转换：SNAT SNAT: CIP –&gt; SIP: CIP –&gt; SNAT(PIP) –&gt; SIP CIP: 本地客户端地址 目标地址转换：DNAT DNAT：RemoteIP –&gt; PIP: RemoteIP –&gt; DNAT(SIP) –&gt; SIP RemoteIP：远程客户端地址； 端口转换：PNAT 通常在 DNAT 中实现. (2) SNAT：主要用于实现让内网客户端访问外部主机时使用；注意： 要定义在POSTROUTING链；也可以在OUTPUT上使用(较少)； 需要打开网络间转发: echo 1 &gt; /proc/sys/net /ipv4/ip_forward 定义方法： $ iptables -t nat -A POSTROUTING -s 内网网络或主机地址 -j SNAT --to-source NAT服务器上的某外网地址 另一个TARGET： MASQUERADE：地址伪装； 能自行判断该转为哪个源地址； iptables -t nat -A POSTROUTING -s 内网网络或主机地址 -j MASQUERADE 示例: $ iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -j SNAT --to-source 172.16.100.11 # 172.16.100.11 为本机的一个接口. (3) DNAT：主要用于发布内部服务器，让内网中的服务器在外网中可以被访问到；注意： 要定义在PREROUTING链； 定义方法： $ iptables -t nat -A PREROUTING -d NAT服务器的某外网地址 -p 某协议 --dport 某端口 -j DNAT --to-destination 内网某服务器地址[:PORT] 示例: $ iptables -t nat -A PREROUTING -d 172.16.100.11 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.7 (4) FULLNAT: 全地址转换, 见 LVS.在请求报文到时：既修改源地址，又修改目标地址; 响应报文也是. 5. 规则的保存与重载.保存: service iptables save # 保存到 /etc/sysconfig/iptables 文件； iptables-save &gt; /PATH/TO/SOMEFILE # 自定义保存文件 重载: service iptables reload # 使用默认保存文件 iptables-restore &lt; /PATH/FROM/SOMEFILE # 使用自定义保存文件. 三. 其他相关1. REDIRECT 与 DNAT 的区别?$ iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j REDIRECT --to 3128 $ iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j DNAT --to-destination 172.16.11.1:3128 $ iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 3389 -j DNAT --to-destination 172.16.11.250 结论 REDIRECT 是 DNAT 的一个特例. DNAT的功能更强大. 2. MASQUEREAD 与 SNAT 的区别?$ iptables -t nat -s 172.16.11.0/24 -o eth0 -j MASQUERADE $ iptables -t nat -s 172.l6.11.0/24 -o eth0 -j SNAT --to 123.123.123.123 $ iptables -t nat -s 172.l6.11.0/24 -o eth0 -j SNAT --to 123.123.123.1-123.123.123.10 结论: MASQUERADE 自动根据路由选择出口; SNAT 适用于固定 IP 的环境, 负责小; 例外, 可实现地址面积映射. 3. -j 与 -g 的区别$ iptables -N TESTA $ iptables -N TESTB $ iptables -A FORWARD -s 172.16.11.1 -j TESTA $ iptables -A FORWARD -s 172.16.11.2 -j TESTB $ iptables -A TESTA -j MARK --set-mark 1 $ iptables -A TESTB -j MARK --set-mark 2 $ iptables -A FORWARD -m mark --mark 1 -j DROP $ iptables -A FORWARD -m mark --mark 2 -j DROP 结论 -j(jump) 相当于调用, 自定链结束后返回 -g(goto) 一去不复返. 4. raw 表的用途$ iptables -t raw -A PREROUTING -i eth0 -s 172.16.11.250 -j DROP 结论 raw 表工作于最前端, 在 conntrack 之前 可以明确对某些数据不进行链接追踪; raw 可以提前 DROP 数据, 有效降低负载. 5. 如何防止被 tracert ?tracert == TTL 试探 $ iptables -A INPUT -m ttl --ttl-eq 1 -j DROP $ iptables -A INPUT -m ttl --ttl-lt 4 -j DROP $ iptables -A FORWARD -m ttl --ttl-lt 6 -j DROP]]></content>
      <categories>
        <category>计算机原理与操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>iptables</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-并发编程]]></title>
    <url>%2F2018%2F03%2F16%2Fpython-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[参考地址 参考地址 参考地址 Python 2 时代, 高性能的网络编程主要是使用 Twisted, Tornado, Gevent 这三个库. 但是他们的异步代码相互之间不兼容越不能移植. asyncio 在 python 3.4 中被引入到标准库. Python 3.5 添加了 async 和 await 两个关键字 , 替换 asyncio.coroutine 和 yield from. 自此, 协程成为新的语法, 而不再是一种生成器类型了. 事件循环与写成的引入, 可以极大提高高负载下程序的 IO 性能. 除此之外, 还增加了 async with(异步山下文管理) 和 asyncfor(异步迭代器)语法. 在续不发言的 Python 3.6 里面终于可以使用 异步生成器了 asyncioasyncio 使用单线程, 单个进程的方式进行切换 通常程序等待读或者写数据时, 就是切换上下文的时机. 同步机制Semaphore (信号量)Lock (锁)Condition (条件)Event (事件)Queue (队列) LifoQueue PriorityQueue Task事件循环###]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python-内置函数]]></title>
    <url>%2F2018%2F03%2F16%2Fpython-%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[循环设计与循环对象range() enumerate() zip() iter() 函数对象map() filter() reduce() 序列操作all([True, 1, &quot;hello!&quot;]) # 是否所有的元素都相当于True值 any([&quot;&quot;, 0, False, [], None]) # 是否有任意一个元素相当于True值 sorted([1,5,3]) # 返回正序的序列，也就是[1,3,5] reversed([1,5,3]) # 返回反序的序列，也就是[3,5,1] 类, 对象, 属性# define class class Me(object): def test(self): print &quot;Hello!&quot; def new_test(): print &quot;New Hello!&quot; me = Me() ----------------------- hasattr(me, &quot;test&quot;) # 检查me对象是否有test属性 getattr(me, &quot;test&quot;) # 返回test属性 setattr(me, &quot;test&quot;, new_test) # 将test属性设置为new_test delattr(me, &quot;test&quot;) # 删除test属性 isinstance(me, Me) # me对象是否为Me类生成的对象 (一个instance) issubclass(Me, object) # Me类是否为object类的子类 globals() # 返回全局命名空间, 比如全局变量名, 全局函数名 locals() # 返回局部命名空间. 编译,执行repr(me) # 返回对象的字符串表达 compile(&quot;print(&apos;Hello&apos;)&quot;,&apos;test.py&apos;,&apos;exec&apos;) # 编译字符串成为code对象 eval(&quot;1 + 1&quot;) # 解释字符串表达式。参数也可以是compile()返回的code对象 exec(&quot;print(&apos;Hello&apos;)&quot;) # 解释并执行字符串，print(&apos;Hello&apos;)。参数也可以是compile()返回的code对象]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C 语言笔记]]></title>
    <url>%2F2018%2F03%2F16%2FC%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[C语言 之 概述与入门 C语言 之 变量和运算符 C语言 之 控制结构 C语言 之 函数 C语言 之 测试与调试技术 C语言 之 指针和数组 C语言 之 递归 C语言 之 C语言中的 C语言 之 数据结构 概述及入门1. 计算机语言程序就是一组计算机能识别和执行的指令. 每一条指令使计算机指定行特定的操作. 计算机的本质是程序的机器. 程序和指令是计算机系统中最基本的概念. 计算机语言的发展阶段 机器语言 0 和 1 一条计算机指令的长度为 16, 即以 16 个二进制数(0或1) 组成一条指令. 符号语言(汇编语言或符号汇编语言) 符号语言由英文字母和数字组成, 一般一条符号语言的指令对应转换为一条机器指令. 人们通过汇编程序将符号语言指令转换为机器指令. 不同型号的计算机的机器语言和汇编语言是互不通用的. 机器语言和汇编语言是完全依赖于具体机器特性的, 是面向机器的语言. 符号语言 –汇编–&gt; 机器指令 高级语言 源程序(高级语言程序) – 编译 –&gt; 目标程序(机器指令的程序) 高级语言更接近于人们习惯使用的自然语言和数学语言. 且不依赖于具体机器. 高级语言的一个语言往往对应多条机器指令. 高级语言的发展阶段: 非结构化语言 编程风格比较随意, 只要符合语法规则即可, 没有严格的规范要求, 程序中的流程可以随意跳转. 结构化语言 程序必须具有良好特性的基本结构(顺序,分支,循环)构成, 程序中的流程不能随意跳转, 程序总是自上而下执行各个基本结构. 面向对象语言 处理规模较大问题. 2. C 语言的发展及其特点37 个关键字, 9 种控制语句, 34 种运算符 : C语言把括号, 赋值和强制类型转换等都作为运算符处理. 数据类型: 整型, 浮点型, 字符型, 数组, 指针, 结构体, 共用体. C 99 又扩充了 复数浮点类型, 超长整型, 布尔类型. 指针类型能用来实现各种复杂的数据结构, 如链表, 树, 栈等. C 语言允许直接访问物理地址, 能进行位(bit)操作, 能实现汇编语言的大部分功能, 可以直接对硬件进行操作. 3. C 语言程序结构3.1 一个程序由一个或多个源程序文件组成一个源文件包含如下三个部分. 预处理指令 C 编译系统在对源程序进行”翻译”之前, 先由一个预处理器(也成为预处理程序, 预编译器)对预处理指令进行预处理. 对于 #include &lt;stdio.h&gt; 来说, 就是将stdio.h头文件的内容读出来, 放在 #include 行处, 取代 #include &lt;stdio.h&gt;. 由预处理得到的结果与程序其他部分一起, 组成一个完整的, 可以用来编译的最后的源程序, 然后由编译程序对该源程序进行编译, 得到目标程序. #include 有两种格式: #include &lt;stdin.h&gt; : 表示从存放 C 编译系统的子目录中去找索要包含的文件, 称为标准方式 $include &quot;stdin.h&quot; : 在编译时, 先在用户的当前目录寻找, 如果未找到, 则按标准方式查找. 如果头文件不在当前目录中, 可以使用#include &quot;/path/to/stdin.h&quot; 格式. 全局声明: 即在函数外进行的数据声明. 在函数外声明的变量称为全局变量, 在整个源文件内有效. 在函数内声明的变量称为局部变量, 在整个函数内有效. 函数定义 每个函数用于完成一个特定的功能, 在调用这些函数时, 会完成函数中指定的功能. 3.2 函数是 C 语言的主要组成部分C 程序的几乎全部工作都由各个函数分别完成, 函数是 C 程序的基本单位. 一个 C 程序由一个或多个函数组成, 其中必须包含一个且只能有一个 main 函数. 一个源程序文件就是一个程序模块. 在进行编译时, 是以源程序文件为对象进行的, 在分别对各个源程序文件进行编译并得到相应的目标程序后,再将这些目标程序连接成一个统一的二进制程序. 在程序中被调用的函数有 3 类: 系统提供的库函数 用户编写函数 编译系统提供的专门的函数. 不同编译系统所提供的库函数个数和功能不完全相同. 函数组成部分: 函数首部 函数第一行, 包括 函数名, 函数类型, 函数参数(形式参数)名, 参数类型, 函数属性. int max (int x, int y) 函数类型 函数名 函数参数类型 函数参数名 一个函数名后面必须跟一对圆括号, 括号内写参数名及其类型. 如果函数没有参数, 可以在括号内写 void 或者 直接使用空括号. int main(void) int main() 函数体 函数首部花括号内的部分. 如果在一个函数中包括有多层花括号, 则最外层的一对花括号是函数体的范围. 函数体一般包括如下两部分: 声明部分 局部变量声明 调用函数声明 执行部分 由若干个语句组成, 指定在函数中所进行的操作. 在某些情况下, 可以 没有声明部分, 甚至可以既没有声明部分, 也没有执行部分. // 如下为一个 空函数, 什么也不做, 但这是合法的. void dump() {} 3.3 程序总是从 main 函数开始执行, 而无论 main 函数在整个函数中的位置如何.3.4 在每个数据声明和语句的最后必须有一个分号.3.5 C 语言本身并不提供输入输出语句.输入输出操作有库函数 scanf 和 printf 等函数来完成. 由于输入输出操作涉及具体的计算机设备, 把输入和输出操作用库函数操作实现, 可使得 C 语言本身短小精悍, 编译程序简单, 且程序具有可移植性. 3.6 程序应当包含注释, 以增强程序的可读性.4. C 语言程序示例示例1 : 打印语句#include &lt;stdio.h&gt; // 编译预处理指令 int main() // 定义主函数 { // 函数开始标志 printf(&quot;This is a C program.\n&quot;); // 输出信息 return 0; // 函数执行完毕时, 返回函数值 0 } // 函数结束标志 每一个 C语言程序都必须有一个 main 函数, 函数体有花括号{}括起来. main 是函数的名字, 表示主函数, main 前面的 int 表示此函数的类型是 int 类型, 在执行主函数后会得到一个值(即函数值), 此值纪委整型. 程序中, return 9; 的作用是: 当main函数执行结束前将整数 0 作为函数值, 返回到调用函数处. 每个语句都由一个最后都有一个分号;, 表示语句结束. 在使用函数库中的输入输出函数时, 编译系统要求程序提供有关此函数的信息(如对函数的声明和宏定义,全局量的定义等), 即#include &lt;stdio.h&gt;, 文件后缀.h 表示头文件(header file), 应为这些文件放在文件模块的开头. 注释: 注释可以用汉语或英语表示. // : 单行注释, /* ... ... */ : 多行注释. 在程序进行预编译处理时, 将每个注释替换为一个空格, 因此在编译时注释部分不产生目标代码, 注释对运行不起作用. 示例2 : 函数调用程序第 5 行, 是对被调用函数(max)的声明, 因为 max 函数的定义在 main 函数之后, 在对程序进行编译时, 编译系统无法得知 max 为何物, 因而无法把它作为函数调用处理. 函数声明 即告诉编译系统 max 是什么, 及 max 的相关信息. #include &lt;stdio.h&gt; // 主函数 int main() { int max(int x, int y); int a, b, c; scanf(&quot;%d, %d&quot;, &amp;a, &amp;b); c=max(a, b); printf(&quot;max=%d\n&quot;, c); return 0; } // 求两个整数中较大者的 max 函数. int max(int x, int y) { int z; if(x&gt;y) z=x; else z=y; return(z); } scanf(A, B) 是 C 标准库中的输入函数的名字,用于接受用户输入. A 参数指定输入格式, B 参数指定输入的数据赋给那个变量. &amp; 是地址符, &amp;a 表示 变量 a 的地址. 5. 运行 C 程序的步骤及方法源程序 —[预编译/正式编译]—&gt; 目标程序 —[连接]—&gt; 库函数/其他目标程序 —&gt; 可执行二进制程序 $ gcc test.c -o test $ ./test 6. 程序 = 数据结构 + 算法数据结构 : 对数据的描述, 在程序中用到了那些数据, 这些数据的类型和数据的组织形式. 算法 : 对操作的描述, 即要求计算机进行操作的步骤. 广义的说, 为解决一个问题而采取的方法和步骤就是算法. 计算机算法分为两类: 数值运算算法 目的是求数值解. 数值运算算法, 往往有现成的模型, 可以运用数值分析方法. 非数值运算算法 包括非常广, 常见的是用于事务管理领域. 目前, 计算机在非数值运算方面的应用远远超过 数值运算算法的运用. 非数值运算算法种类繁多, 要求各异, 只有一些典型的非数值运算算法(如排序算法, 查找搜索算法等). 实际上, 一个过程化的程序除了数据结构和算法之外, 还应当采用结构化的程序设计方法进行程序设计, 并且用一种计算机语言表示. 7. 结构化程序设计方法采用以下方法来保证得到结构化的程序: 自顶向下 逐步细化 模块化设计 结构化编码 变量,运算符,表达式和语句1 数据 1.1 常量在程序运行过程中, 其值不能改变的量称为常量. 整型常量如 1000, 123, 0 , -123 等. 实型常量 十进制小数形式 : 由数字和小数点组成. 指数形式: 以 e 或 E 表示以 10 为底的指数. e 或 E 之前必须有数字, 且 e 或 E 之后必须为整数. 字符常量 普通字符 用单撇号括起来的一个字符. 如 ‘z’, ‘A’, ‘3’, ‘?’ 等. 单撇号只是界限符, 字符常量只能是一个字符, 不包括单撇号. 字符常量存储在计算机存储单元中时, 并不是存储字符本身, 而是一起代码(一般为 ASCII)存储的. 转义字符 以字符 \ 开头的字符序列. | 转义字符 | 字符值 | 输出结果 | | — | — | — | | \&#39; | 一个单撇号 | 具有此八进制码的字符 | | \&quot; | 一个双撇号 | 输出此字符 | | \? | 一个问号 | 输出此字符 | | \\ | 一个反斜线 | 输出此字符 | | \a | 警告(alert) | 产生声音或视觉信号 | | \b | 退格(backspace) | 将当前位置后退一个字符 | | \f | 换页(form feed) | 将当前位置移到下一页的开头 | | \n | 换行 | 将当前位置移到下一行的开头 | | \r | 回车(carriage return) | 将当前位置移到本行的开头 | | \t | 水平制表符 | 将当前位置移到下一个 tab 位置 | | \v | 垂直制表符 | 将当前位置移到下一个垂直指标对齐点 | | \o 或 \oo 或 \ooo, 其中 o 代表一个八进制数字 | 与该八进制码对应的 ASCII 字符 | 与该八进制码对应的字符, 如 \101 代表字母 A. | | \xh[h...] 其中 h 代表一个十六进制数字 | 与该十六进制码对应的 ASCII 字符 | 与该十六进制码对应的字符, 如 \x41 代表字母 A | 字符串常量用双撇号把若干个字符括起来, 字符串常量是双撇号中的全部字符(但不包括双撇号本身). 单撇号只能包含一个字符, 双撇号可以包含一个字符串. 符号常量用#define指令, 指定用一个符号名称代表一个常量, 在源代码预编译后, 符号常量被全部替换为字面常量. 如下示例: #define PI 3.1416 // 注意行末没有分号 要注意区别符号常量和变量: 符号常量不占内存, 只是一个临时符号, 在预编译后这个符号就不存在了, 故不能对符号常量赋予新值. 为与变量名相区别, 习惯上符号常量用大写表示, 如 PI, PRICE 等. 1.2 变量变量代表一个有名字的, 具有特定属性的一个存储单元. 他用来存放数据, 也就是存放变量的值. 在程序运行期间, 变量的值是可以改变的. 变量必须先定义, 后使用. 在定义时指定变量的名字和类型, 一个变量应该有一个名字, 以便被引用. 区分变量名与变量值: - 变量名: 变量名实际上是一个名字代表的一个存储地址. 在对程序编译连接时, 由编译系统给每一个变量名分配对应的内存地址. 从变量中取值, 实际上时通过变量名找到相应的内存地址, 从该存储单元中读取数据. - 变量值: 变量的实际值. 1.3. 常变量C 99 允许使用常变量, 如: const int a = 3; // 表示 a 被定义为一个整型变量, 其指定值为 3, 且在变量存在期间, 其值不能改变. 常变量与常量的异同: 常变量具有常量的基本属性: 有类型, 占存储单元, 只是不允许改变其值. 常变量是有名字的不变量; 有名字方便在程序中调用. 常量是没有名字的不变量. 常变量与符号变量的异同: - 符号常量: 定义符号常量用 &apos;#define&apos; 指令, 他是预编译指定, 他只是用符号常量代表一个字符串, 在预编译时仅是进行字符替换, 在预编译后, 符号常量就不存在了, 对符号常量的名字是不分配存储单元的. - 常变量: 常变量占用存储单元, 有变量值, 只是改值不改变而已. - 从使用的角度, 常变量具有符号变量的有点, 而且使用方便. 有了常变量之后, 可以不必多用符号常量. 1.4. 标识符在计算机高级语言中, 用来对变量, 符号常量名, 函数, 数组, 类型等命名的有效字符序列统称为标识符. 标识符就是一个对象的名字. // 标识符举例 变量名 : p1, p2, p3 符号常量名 : PI, PRICE 函数名 : printf, scanf C 语言规定标识符只能有字母, 数字, 下划线 3 种字符组成, 且第一个字符必须为字母或下划线. 标识符是大小写敏感的. 2 数据类型 C 语言要求在定义所有的变量时都要指定变量的类型. 常量也是区分类型的. 数据类型产生的原因: 数学是一门研究抽象的学科, 数和数的运算都是抽象的. 而在计算机中, 数据是存放在存储单元中的, 他是具体存在. 而且, 存储单元是以优先的字节构成的, 每一个存储单元中存放数据的范围是有限的, 不可能存放无穷大的数, 也不能存放无限循环小数. 用计算机进行的计算不是抽象的计算, 而是用工程的方法实现的计算, 在许多情况下, 只能得到近似的结果. 所谓类型, 就是对数据分配存储单元的安排, 包括存储单元的长度(占用多少字节)以及数据的存储形式. 不同的类型分配不同的长度和存储形式. 2.1 基本类型整型类型 基本整型 编译系统分配给 int 型数据 2 个或 4 个字节(由具体的C编译系统自定决定). 存储方式: 用整数的补码形式存放. 正数: 一个正数的补码是此数的二进制形式. 复数: 先将此数的绝对值写成二进制形式, 然后对其后面所有各二进制按位取反, 再加1. 在存放整数的存储单元中, 最左面一位是用来表示符号的, 如果该位为 0 , 表示数值为正; 如果该位为 1 , 表示数值为负. 短整型 类型名为 short int 或 short. 一个短整型变量的值得范围是 -32768 ~ 32767 长整型 类型名为 long int 或 long. 编译系统分配给 长整型 4 个字节. 双长整型 类型名为 long long int 或 long long. 一般分配 8 个字节. 有符号整数与无符号整数 为充分利用变量的值得范围, 可以将变量定义为无符号类型. 在类型符号前面加上修饰符unsigned 表示指定该变量是无符号整数类型. 在类型符号前面加上修饰符signed 表示该变量是有符号类型. 此类型为默认类型, 即当一个正数既没有指定为 signed 也没有指定为 unsigned, 则默认为 有符号类型. 因此, 以上四种数据类型可以扩展为 8 种数据类型: | 名称 | 类型符号 | | --- | --- | | 有符号基本类型 | [signed] int | | 无符号基本类型 | unsigned int | | 有符号短整型 | [signed] short [int] | | 无符号短整型 | unsigned short [int] | | 有符号长整型 | [signed] long [int] | | 无符号长整型 | unsigned long [int] | | 有符号双长整型 | [signed] long long [int] | | 无符号双长整型 | unsigned long long [int] | **注意**: 1. 只有整型(包括字符型)数据可以加 signed 或 unsigned 修饰符, 实型数据不能加. 2. 对无符号整型数据用`%u` 格式输出, 表示无符号十进制数. 3. 将一个变量定义为无符号整形后, 不应向他赋予一个负值, 否则会得到一个错误的结果. 字符型 由于字符是按其代码(整数)形式存储的, 因此 C 99 把字符型数据作为整数类型的一种. 各种字符集(包含 ASCII) 的基本集都包含 127 个字符. 在 C 中, 指定用一个字节存储一个字符, 此时字节的第一位置为 0 . 字符变量使用 char 定义, 实质上是一个字节的整型变量. 可以把 0~127 之间的整数赋值给一个字符变量. char c=&apos;?&apos; // c 是字符变量, printf(&quot;%d %c\n&quot;, c, c) // 输出字符变量的值时, 可以十进制整数形式输出, 也可以字符形式输出. // 输出: 63 ? 字符型数据的存储空间和值范围: | 类型 | 字节数 | 取值范围 | | — | — | — | | signed char | 1 | -128~127 | | unsigned char | 1 | 0~255 | 如果把一个负整数赋给有符号字符型变量时合法的, 但他不代表一个字符, 而作为一个字节整型变量存储负整数. 如果在定义变量时即不加 signed 也不加 unsigned, C 标准并未规定如何处理, 由各个编译系统自己决定, 可用如下方法做测试: char c=255; printf(&quot;%d\n&quot;, c) 布尔型 浮点类型浮点型数据用来表示具有小数点的实数. 在 C 语言中, 实数是以指数形式存放在存储单元中的. 规范化的指数形式: 把小数部分中小数点前的数字为 0, 小数点后第一位不为 0 的表示形式. 一个实数只有一个规范化的指数形式, 在程序以指数形式输出时, 必然以规范化的指数形式输出. 单精度浮点型(float) 编译系统为每一个 float 型变量分配 4 个字节, 数值以规范化的二进制指数形式存放在存储单元中. 在存储时, 系统将实型数据分成小数部分和指数部分两部分, 以二进制形式分别存放. 由于用二进制形式表示一个实数以及存储单元的长度是有限的, 因此不可能得到完全精确的值, 只能存储成优先的精确度: 小数部分占的位(bit)数越多, 数的有效数字越多, 精度也就越高; 指数部分占的位(bit)数越多, 表示的数值的范围就越大. float 可以得到 6 位有效数字. 双精度浮点型(double) 用 8 个字节存储一个 double 型数据, 可以得到 15 位有效数字. 在 C 语言中进行浮点数的算术运算时, 将 float 型数据都自动转换为 double 型, 然后进行运算. 长双精度浮点型(long double) 不同的编译系统对 long double 型的处理方法不同, Turbo C 分配 16 字节, Visual C++ 6.0 分配 8 字节. 2.2 枚举类型2.3 空类型2.4 派生类型指针类型数组类型结构体类型共用体类型函数类型3 运算符C 语言的运算符范围很宽, 把除了控制语句和输入输出意外的几乎所有操作都作为运算符处理. 3.1 算术运算符基本的算术运算符 自增自减运算符作用是使变量的值加 1 或 减 1. ++i, --i : 在使用之前, 先使 i 的值加(减)1.i++, i-- : 在使用之后, 使 i 的值加(减)1. 自增运算符(++) 和 自减运算符(–) 只能用于变量, 不能用于常量或表达式. 自增(减)运算符常用与循环语句中, 使循环变量自动加 1; 也用于指针变量, 使指针指向下一个地址. 混合运算如果一个运算符的两侧的数据类型不同, 则先自动进行类型转换, 使二者具有同一种类型, 然后进行运算.因此, 整型,实型, 字符型数据间可以进行混合运算. 规律如下: +,-,*,/ 运算的两个数中有一个数为 float 或 double 型, 结果是 double 型, 因为系统将所有 float 型数据都先转换为 double 型, 然后进行运算. 如果 int 型与 float 或 double 型数据进行运算, 先把 int 型 和 float 型数据转换为 double 型, 然后进行运算, 结果是 double 型. 字符型数据与整型数据进行运算, 就是把字符的 ASCII 代码与整型数据进行运算. 如果字符型数据与实型数据进行运算, 则将字符的 ASCII 代码转换为 double 型数据, 然后进行运算. 以上转换, 由编译系统自动完成, 用户无需干预. 强制类型转换.可以利用强制类型转换运算符将一个表达式转换成所需类型.其格式为: (类型名)(表达式) 在强制类型转换时, 得到一个所需类型的中间数据, 而原来的变量的类型保持不变. (int)(x+y) // 将 x+y 的结果转换为 int 类型 (int)x+y // 将 x 转换为 int 类型, 然后与 y 做加法. 复合的赋值运算符在赋值符=之前加上其他运算符, 可以构成复合的运算符.凡是二元运算符, 都可以与赋值符一起组合成复合赋值符. a+=b // 如果 b 为一个表达式, 则相当于他有括号 a=a+b x*=y+8 &lt;--&gt; x=x*(y+8) 赋值过程中的强制类型转换如果赋值运算符两侧的类型不一致, 但都是算术类型时, 在赋值时要进行类型转换. 类型转换由系统自动完成, 规则如下: 赋值给谁, 以谁为准. 将浮点型数据赋值给 整型变量时, 先对浮点数取整, 然后赋值给整型变量; 将整型数据赋值给 浮点型数据时, 数值不变, 但以浮点数形式存储到变量中. 将一个 double 型数据赋值给 float 型数据, 先将双精度转换为单精度, 存储到 float 变量的 4 个字节中. 要注意 双精度数值的大小不能超过 float 型变量的数值范围. 字符型数据赋给整型变量时, 将字符的 ASCII 代码赋给整型变量. 将一个占字节多的整型数据赋给一个占字节少的整型变量或字符变量时, 只将其低字节原封不同的赋值给变量, 即发生截断. 3.2 关系运算符(&gt;,&lt;,==,&gt;=,&lt;=,!=)关系运算符与优先级: 运算符 含义 优先级 &lt; 小于 优先级高 &lt;= 小于等于 优先级高 &gt; 大于 优先级高 &gt;= 大于等于 优先级高 == 等于 优先级低 != 不等于 优先级低 注意: 前四种(&lt;,&lt;=,&gt;,&gt;=)关系运算符的优先级别相同, 后两种(==,!=)也相同. 前四种优先级高于后两种.. 关系运算符的优先级低于算术运算符. 关系运算符的优先级高于赋值运算符. 示例: c &gt; a + b --&gt; c &gt; (a+b) a &gt; b == c --&gt; (a&gt;b)==c a==b&lt;c --&gt; a==(b&lt;c) a=b&gt;c --&gt; a=(b&gt;c) 3.3 逻辑运算符(!, &amp;&amp;, ||)逻辑运算符与优先级 运算符 含义 举例 说明 &amp;&amp; 逻辑与 a &amp;&amp; b 如果 a 和 b 都为真, 则结果为真; 否则为假 ` ` 逻辑或 `a b` 如果 a 和 b 至少有一个为真, 则结果为真; 否则为假 ! 逻辑非 !a 如果 a 为假, 则 !a 为真; 反之, 为假. 优先级: !(非) &gt; 算术运算符 &gt; 关系运算符 &gt; &amp;&amp; 和 || &gt; 赋值运算符 C 语言编译系统在表示逻辑运算结果时, 以数值 1 表示 真, 数值 0 代表 假; 但在判断一个量是否为真时, 以 0 为假, 非0 为真. 实际上, 逻辑运算符两侧的运算对象不但可以是 0 和 1, 或者 0 或 非0 的整数, 也可以是字符型, 浮点型, 枚举型或指针型的纯量型数据. 系统最终以 0 或 非0 来判断他们属于 真或假. 逻辑表达式在判断时, 执行短路逻辑. (m=a&gt;b) &amp;&amp; (n=c&gt;d) 当 a&gt;b 为假时, m=0, 则此时 &amp;&amp; 表达式必定为假, 则 (n=c&gt;d) 将不会执行, 即 n 的值保持不变. 3.4 位运算符(&lt;&lt;,&gt;&gt;,~,|,^,&amp;)3.6 赋值运算符(=, 及其扩展运算符)3.7 条件运算符(?:) –&gt; C 中唯一的 三目运算符条件表达式的一般形式: 表达式_1 ? 表达式_2 : 表达式_3; // 如果 表达式_1 为真, 则执行 表达式_2, 否则执行 表达式_3. 示例: max=(a&gt;b) ? a:b; // 求 a,b 的最大值. // 输入一个字母, 判断是否为大写字母, 如果是, 将其转换为小写字母, 如果不是, 不转换. #include &lt;stdio.h&gt; int main() { char ch; scanf(&quot;%c&quot;, &amp;ch); ch=(ch&gt;=&apos;A&apos; &amp;&amp; ch&lt;=&apos;Z&apos;) ? (ch + 32) : ch; printf(&quot;%c\n&quot;, ch); return 0; } 3.8 逗号运算符(,)3.9 指针运算符(*, &amp;)3.10 求字节数运算符(sizeof)3.11 强制类型转换运算符((TYPE))3.12 成员运算符(.,-,&gt;)3.13 下标运算符([])4. C 语句和表达式 4.1 控制语句条件 if() ... else ... switch 循环 for() ... while() ... do ... while () continue break returngoto4.2 函数调用语句由一个函数调用 + 一个分号组成. printf(&quot;Just for test.&quot;); 4.3 表达式语句由一个表达式 + 一个分号组成. a=3 // 表达式 a=3; // 表达式语句 i++; // 表达式语句 x+y; // 表达式语句, 只是没有赋值, 没有实际意义 其实函数调用语句, 也是一种表达式语句, 因为函数调用也是表达式的一种. 赋值语句输入输出语句putchar(输出字符)输出单个字符: putchar(c) // c 可以是字符常量, 整型常量, 字符变量或整型变量(在ASCII代码范围内) 示例: putchar(c) // 输出变量 c putchar(&apos;\101&apos;) // 输出字符 A putchar(&apos;\&apos;&apos;) // 输出单撇号 putchar(&apos;\o15&apos;) // 八进制15, 输出回车 getchar(输入字符)向计算机输入一个字符: getchar() // 没有参数, 只能接受一个字符. printf(格式输出) printf 函数的一般格式为: printf(格式控制, 输出列表) 格式控制 = 格式声明 + 普通字符串 格式声明 = &quot;%&quot; + 格式字符 输出列表是程序需要输出的一些数据, 可以是变量, 常量 或 表达式. 格式控制和输出列表实质上是 printf 函数的参数. 示例: printf(&quot;%5d\n%5d\n&quot;, 12, -345); 12 // 12 前面 3 个空格 -345 // -345 前面 1 个空格 printf(&quot;%ld&quot;) // 表示 long 型数据 printf(&quot;%lld&quot;) // 表示 long long 型数据 printf(&quot;%5c&quot;, &quot;a&quot;) a // a 前面 4 个空格 printf(&quot;%5c&quot;, 121) // 会自动执行 ASCII 转换. printf(&quot;%s&quot;, &quot;China&quot;) // 输出字符串 printf(&quot;%f&quot;) // 输出实数 printf(&quot;%m.nf&quot;) // m 数据宽度, n 小数位数. printf(&quot;%-m.nf&quot;) // 数据输出左对齐 printf(&quot;%e&quot;) // 指数格式输出 printf(&quot;%E&quot;) // 指数格式输出 printf(&quot;%o&quot;) // 输出八进制格式 printf(&quot;%x&quot;) // 输出十六进制格式 printf(&quot;%%&quot;) // 输出百分号(%) scanf(格式输入) 一般格式: scanf(格式控制, 地址表列) 地址表列是由若干个地址组成的表列, 可以是变量的地址, 或字符串的首地址. 注意问题: scanf 函数中的地址表列, 应当是变量地址, 而不是变量名. scanf(“%f%f%f”, a, b, c) // 错误 scanf(“%f%f%f”, &amp;a, &amp;b, &amp;c) // 正确 如果在格式控制字符串中, 除了格式声明之外, 还有其他字符, 则在输入数据时, 在对应的位置上应输入与这些字符相同的字符. scanf(“a=%f, b=%f”, &amp;a, &amp;b) // 应当输入 “a=1, b=3” 在使用 %c 格式声明输入字符时, 空格字符和转义字符中的字符都作为有效字符输入. 在输入数值数据时, 如输入空格, 回车, Tab 键, 或遇非法字符(不属于数值的字符), 认为该数据结束. puts(输出字符串)gets(输入字符串)4.4 空语句空语句什么也不做, 主要用来作为流程的转向点(流程从程序其他地方转到此语句处), 也可以作为循环语句中的循环体(循环体是空语句, 表示循环体什么也不做). ; // 空语句 4.5 复合语句用{}把一些语句和声明括起来称为复合语句(又称语句块). 复合语句常用在 if 语句或循环中. 可以在复合语句中包含声明部分, 声明部分可以放在复合语句中的任何位置, 但习惯上把它放在语句块开头的位置. 复合语句中最后一个语句中最后的分号不能省略. { float pi=3.14159, r=2.5m, area; area = pi * r * r; printf(&quot;area=%f&quot;, area); } 函数控制结构1. 顺序语句自上而下依次执行. 2. 选择2.1 if 选择if 语句的一般形式: // 一般形式 if(表达式) 语句_1 [ else 语句_2 ] // 常见形式 if(表达式) 语句_1 if(表达式) 语句_1 else 语句_2 if(表达式_1) 语句_1 else if(表达式_2) 语句_2 else if(表达式_3) 语句_3 ... else 语句_n 注意: if语句中的表达式可以为关系表达式, 逻辑表达式, 甚至是数值表达式. 语句_1, 语句_2 … 是 if 语句的内嵌语句, 每个内嵌语句末尾都应当有分号结尾. 语句_1, 语句_2 … 可以是单个语句, 也可以是复合语句, 复合语句应当用花括号括起来. 实例代码: #include &lt;stdio.h&gt; // 输入三个数字, 按从小到大输出. int main() { float a,b,c,t; scanf(&quot;%f,%f,%f&quot;, &amp;a, &amp;b, &amp;c); if(a&gt;b) { t=a; a=b; b=t; } if(a&gt;c) { t=a; a=c; c=t; } if(b&gt;c){ t=b; b=c; c=t; } printf(&quot;%5.2f,%5.2f,%5.2f\n&quot;, a,b,c); return 0; } 2.2 switch 选择switch 语句是多分支语句. 其一般表达式如下: switch(表达式) { case 常量_1 : 语句_1 ; break; case 常量_1 : 语句_1 ; break; ... ... default: 语句_n; } switch 后面括号内的”表达式”, 其值的类型应为整数类型(包括字符型); default 标号是可选的, 如果没有雨 switch 表达式相匹配的 case 常量, 则不执行任何语句; 各个 case 标号(包含 default)出现的次序不影响执行结果. 一个 switch 选择分支结构中, 最多只能执行一个标号语句; 多个 case 标号, 可以共用一组执行语句, 如: case &apos;a&apos;: case &apos;A&apos;: action(a); break; ... 每个 case 后面的的语句中, 最后都有一个 break 语句, 他的作用是使流程转到 switch 语句的末尾. #include &lt;stdio.h&gt; int main() { char grade; scanf(&quot;%c&quot;, &amp;grade); printf(&quot;Your score:&quot;); switch(grade) { case &apos;A&apos;: printf(&quot;85 ~ 100\n&quot;); break; case &apos;B&apos;: printf(&quot;70 ~ 84\n&quot;); break; case &apos;C&apos;: printf(&quot;60 ~ 69\n&quot;); break; case &apos;D&apos;: printf(&quot;&lt; 60\n&quot;); break; default: printf(&quot;enter data error!\n&quot;); } return 0; } 3. 循环3.1 for 循环一般形式: for(循环变量赋初值; 循环条件; 循环变量增值) 语句 说明: 循环变量赋初值, 只执行一次, 可以为零个, 一个或多个变量设置初值. 循环条件表达式, 用来判断是否继续循环, 在每次执行循环体之前, 先执行此表达式做判断. 作为循环的调整, 是在每次执行完循环体之后执行. for 语句形式与下列 while 语句无条件等价 循环变量赋初值; while 循环条件 { 语句; 循环变量增值; } 循环变量赋初值可以省略, 但其后的分号不能省略. for(;i&lt;100;i++) 循环条件也可以省略, 即不设置循环条件, 此时循环无终止进行, 即认为循环条件始终为真. for(i=1; ; i++) 循环变量增值, 也可省略, 但此时应另外设法保证循环能正常结束, 否则, 循环体无止境执行. for(i=1;i&lt;100;) 循环变量赋初值,循环条件,循环变量增值 三个可同时省略, 此时, 循环无终止运行. for(;;) 循环变量赋初值,循环变量增值 可以是一个简单的表达式, 也可以是一个逗号表达式, 即包含一个以上的简单表达式, 中间用逗号分隔. 在逗号表达式内, 按自左至右顺序求解, 整个逗号表达式的值为最右边的表达式的值. for(i=1;i&lt;=100;i++,i++) C99 允许在 for 语句的循环变量赋初值中定义变量并赋初值. 但所定义变量的有效范围仅限于for循环中, 在循环外不能使用此变量. for(int i=1;i&lt;100;i++) 3.2 while 循环while 语句的一般形式: 只要循环条件表达式为真, 就执行循环体. // 循环条件表达式控制循环体, 他的值只能为真或假. while(循环条件表达式) 循环体 程序示例: 求 1 ~ 100 之和 #include &lt;stdio.h&gt; int main() { int i=1, sum=0; while(i&lt;=100) { sum = sum + i; i++ ; } printf(&quot;sum=%d\n&quot;, sum); return 0; } 3.3 do … while 循环一般形式: 先无条件执行循环体, 然后判断循环条件是否成立. 即对于 do ... while 循环来说, 至少执行一次循环体. do 循环体 while(循环条件) 示例: 求 1 ~ 100 之和 #include &lt;stdio.h&gt; int main() { int i=1, sum=0; do { sum = sum + i; i++; }while(i&lt;=100); printf(&quot;sum=%d\n&quot;, sum); return 0; } while 和 do ... while 比较: 当 while 表达式的第一次的值为真时, 两个循环得到的结果相同, 否则不同. while 和 do ... while 都需要在循环体中实现循环条件控制变量的增减. 3.4 continue &amp; break break 用来从循环体中跳出循环体, 即提前结束整个循环, 接着执行循环后面的语句. break只能用于 循环语句 和 switch 语句之中, 而不能单独使用. continue 提前结束本次循环 , 而接着执行下次循环. 3.5 实例:斐波那契数列前 40 个数方法一 :#include &lt;stdio.h&gt; int main() { int f1=1, f2=1, f3; int i; printf(&quot;\t%12d\n\t%12d\n&quot;, f1, f2); for(i=1;i&lt;=38;i++) // 40 = 38 + 2 { f3 = f1 + f2; printf(&quot;%d\t%12d\n&quot;, i, f3); f1 = f2; f2 = f3; } return 0; } 方法二:#include &lt;stdio.h&gt; int main() { int f1=1, f2=1; int i; for(i=1;i&lt;=20;i++) // 每次输入两个数, 只需 20 次循环 { printf(&quot;%12d%12d&quot;,f1,f2 ); if(i%2==0) printf(&quot;\n&quot;); f1 = f1 + f2; // 此时 f1 为 第三个数 f2 = f2 + f1; // f2 是 第二个数(f2) + 第三个数(f1) 的和, 即第四个数. } } 输入一个大于 3 的数, 判断是否为素数(质数)方法一:#include &lt;stdio.h&gt; int main() { int f, i; int fl=0; scanf(&quot;%d&quot;, &amp;f); for(i=2; i&lt;f; i++) { if(f%i==0) { fl=1; break; } } if(fl==0) printf(&quot;%d is prime\n&quot;, f); else printf(&quot;%d is not prime\n&quot;, f); return 0; } 方法二:#include &lt;stdio.h&gt; int main() { int n,i; printf(&quot;Plz input a integer number, n\n&quot;); scanf(&quot;%d&quot;, &amp;n); for(i=2;i&lt;=n;i++) { if(n%i==0) break; // 当 n 为非质数, 会提前退出. // 当 n 为质数, 会一直循环到 n-1 而不退出. if(i==n-1) printf(&quot;%d is a prime\n&quot;, n); } return 0; } 方法三: 输入任意数字, 求 小于该数的所有质数#include &lt;stdio.h&gt; int main() { int f; int i; int num; int fl=0; scanf(&quot;%d&quot;, &amp;num); printf(&quot;Begin:\n&quot;); for(i=3;i&lt;=num;i++) { for(f=2;f&lt;i;f++) { if(i%f==0) { fl=1; break; } } if(fl==0) printf(&quot;\t%d\n&quot;, i); fl=0; } return 0; } 指针和数组一. 指针二. 数组1. 数组含义 数组是一组有序数据的集合, 数组中的各数据的排列是有顺序的, 下标代表数据在数组中的序号. 用一个数组名和下标来唯一的确定数组中的元素. 在 C 语言中, 下标使用方括号中的数字表示. 数组中的每一个元素都属于同一种数据类型, 不能把不同类型的数据放在同一个数组中. 2. 一维数组2.1 定义数组可变长数组 2.2 引用数组2.3 一维数组的初始化2.4 示例 示例: 10个元素赋值为 0-9, 并倒序输出 #include &lt;stdio.h&gt; int main() { int i,a[10]; for(i=0; i&lt;=9;i++) a[i]=i; for(i=9;i&gt;=0;i--) { printf(&quot;%d\t&quot;, a[i]); } printf(&quot;\n&quot;); return 0; } 示例: 使用数组,输出斐波那契数列的前 20 个数 #include &lt;stdio.h&gt; int main() { int i; int f[20]={1,1}; for(i=2;i&lt;=20;i++) f[i] = f[i-2] + f[i-1]; for(i=0;i&lt;20;i++) { if(i%5==0) printf(&quot;\n&quot;); printf(&quot;%12d&quot;, f[i]); } printf(&quot;\n&quot;); return 0; } 示例: 随机输入10个整数, 使用冒泡排序按从小到大的顺序输出. 冒泡排序: 如果有 n 个数, 则进行 n-1 趟比较, 第 1 趟比较中有 n - 1 此比较, 第 2 趟有 n-2 比较, 第 j 趟中有 n - j 趟比较. 在每趟比较中, 从第 1 个数字开始, 两两比较, 并将两者中的大者排到小者的后面, 以此类推. 第 1 趟比较中, 最大的数字将排到末尾, 第 2 趟比较中, 次大的数字将排到次末尾, 依次类推. #include &lt;stdio.h&gt; int main() { int a[10]; int i,j,t; // 获取输入 printf(&quot;input 10 numbers: \n&quot;); for(i=0;i&lt;10;i++) scanf(&quot;%d&quot;, &amp;a[i]); printf(&quot;\n&quot;); // 冒泡排序 for(j=0;j&lt;9;j++) for(i=0;i&lt;9-j;i++) if(a[i]&gt;a[i+1]) { t=a[i]; a[i]=a[i+1]; a[i+1]=t; } // 输出 printf(&quot;The Sorted Numbers: \n&quot;); for(i=0; i&lt;10;i++) printf(&quot;%d &quot;, a[i]); printf(&quot;\n&quot;); return 0; } 3. 二维数组二维数组常常成为矩阵. 用矩阵表示二维数组, 只是逻辑上的概念, 能形象的表示出行和列的关系. 但是在内存中, 各元素是连续存放的, 不是二维的, 是线性的. 除了 二维数组之外, C 语言还允许使用多维数组, 类似二维数组, 如 三维数组定义如下 float a[2][3][4]. 3.1 定义二维数组3.2 引用二维数组3.3 二维数组的初始化3.4 示例 示例1 : 将一个二维数组行和列的元素互换, 存到另一个数组中. 如将一个两行三列的数据转换为三行两列的数据. 核心算法: 将 a 数组中的元素 a[i][j] 存到 b 数组中的 b[j][i]. #include &lt;stdio.h&gt; int main() { int a[2][3] = {{1,2,3}, {4,5,6}}; int b[3][2], i,j; printf(&quot;array a: \n&quot;); for(i=0;i&lt;=1;i++) { for(j=0;j&lt;=2;j++) { printf(&quot;%5d&quot;, a[i][j]); b[j][i] = a[i][j]; } printf(&quot;\n&quot;); } printf(&quot;array b: \n&quot;); for(i=0;i&lt;=2;i++) { for(j=0;j&lt;=1;j++) printf(&quot;%5d&quot;, b[i][j]); printf(&quot;\n&quot;); } return 0; } // 输出如下: array a: 1 2 3 4 5 6 array b: 1 4 2 5 3 6 示例2 : 有一个 3x4 的矩阵, 求出其中最大的元素的值及其下标. 打擂台算法: 有 a[3][4] 数组, 从 a[0][0] 开始, 存到 max 中, a[3][4] 中的每个数依次与 max 比较大小, 大的 赋值并保存到 max 中, 最后, max 为最大值. #include &lt;stdio.h&gt; int main() { int i,j, row=0,colum=0,max; int a[3][4] = {{1,2,3,4},{9,8,7,6},{-10,10,-5,2}}; max=a[0][0]; for(i=0;i&lt;=2;i++) for(j=0;j&lt;=3;j++) if(a[i][j]&gt;max){ max = a[i][j]; row = i; colum = j; } printf(&quot;Max=%d\nrow=%d\ncolum=%d\n&quot;,max,row,colum ); return 0; } 4. 字符数组C 语言中没有字符串类型, 字符串是存放在字符型数组中的. 4.1 字符数组定义4.2 字符数组初始化4.3 字符数组引用4.4 字符数组处理函数include &lt;string.h&gt;puts – 输出字符串的函数gets – 输入字符串的函数strcat – 字符串连接函数strcpy strncpy – 字符串复制函数strcmp – 字符串比较函数strlen – 测字符串长度的函数strlwr – 转换为小写的函数strupr – 转换为大写的函数4.5 示例C语言中的 IO递归数据结构1. 结构体2. 结构体数组3. 链表]]></content>
      <categories>
        <category>计算机原理与操作系统</category>
      </categories>
      <tags>
        <tag>C语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux tcp_wrapper]]></title>
    <url>%2F2018%2F03%2F16%2Flinux-tcp-wrapper%2F</url>
    <content type="text"><![CDATA[一. 简介tcp_wrapper：tcp包装器, 工作于库中的. 访问控制 工具/组件 : 传输层 和 接近于应用层; 仅对使用tcp协议且在开发时调用了libwrap相关的服务程序有效. 二. 判断服务是否能够由tcp_wrapper进行访问控制： 动态编译：ldd命 令查看其链接至的库文件即可； $ ldd `which sshd` | grep libwrap 静态编译：strings 命令查看其结果中是否包含 hosts.allow hosts.deny 三. 配置文件tcp_wrapper通过读取配置文件中的访问控制规则来判断某服务是否可被访问 hosts.allow : 先检查, 匹配放行, 则放行; 没有匹配规则, 则使用 hosts.deny hosts.deny : 后检测. 有匹配则拒绝, 没有匹配则, 放行. 注意 默认规则 是放行. 发生修改后立即生效. 白名单: hosts.allow 放行 白名单. hosts.deny 拒绝所有. 四. 配置文件语法：daemon_list: client_list [:options] daemon_list ： 应用程序的文件名称，而非服务名； 应用程序的文件列表，使用逗号分隔； 例如：vsftpd, in.telnetd: 172.16.0.0/255.255.0.0 ALL: 所有受tcp_wrapper控制的应用程序； client_list: IP地址 ； 主机名 ； 网络地址 ：必须使用完整格式掩码，不能使用长度格式的掩码；所以172.16.0.0/16是不合法的； 简短格式的网络地址 ：172.16. 表示172.16.0.0/255.255.0.0 ALL : 所有客户端地址； KNOWN : 所有已知的主机, 即主机名可以被解析的. UNKNOWN ：主机名不能被解析的 PARANOID : 正向解析和反向解析不一致的主机. 特殊的变量 ：EXCEPT in.telnetd: 172.16. EXCEPT 172.16.100.3 [:options] deny: 用于在hosts.allow文件中实现拒绝访问的规则 allow：用于在hosts.deny文件中实现允许访问的规则 spawn: 启动一个额外程序； in.telnetd: ALL: spawn /bin/echo `date` login attempt from %c to %s, %d &gt;&gt; /var/log/telnet.log # man hosts.allow 示例控制vsftpd仅允许172.16.0.0/255.255.0.0网络中的主机访问，但172.16.100.3除外；对所被被拒绝的访问尝试都记录在/var/log/tcp_wrapper.log日志文件中； $ cat hosts.allow: vsftpd: 172.16. EXCEPT 172.16.100.3 $ cat hosts.deny: vsftpd: ALL : spawn /bin/echo # 并非所有都会记录. 如 172.16.100.3]]></content>
      <categories>
        <category>计算机原理与操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-资源汇总]]></title>
    <url>%2F2018%2F03%2F16%2Fpython-%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[python 最佳实践 (部分) 一. 结构化工程 文件 功能 README.rst readme LICENSE 许可证 setup.py 打包和发布管理 requirements.txt 开发依赖 sample/init.py 核心代码 sample/core.py 核心代码 sample/helpers.py 核心代码 docs/conf.py 文档 docs/index.rst 文档 tests/test_basic.py 单元测试 tests/test_advanced.py 单元测试 二. 开发环境vim :python-mode : 在 vim 中使用 Python 的综合解决方案. SuperTab : vim 小插件, 通过使用 &lt;tab&gt; 或任何其他指定的按键, 能够使代码补全变得更方便. Sublime TextPyCharm三. 虚拟环境virtualenv : [virtualenvwrapper](http://virtualenvwrapper.readthedocs.io/en/latest/index.html) : 命令的完整列表(http://virtualenvwrapper.readthedocs.io/en/latest/command_ref.html) [virtualenv-burrito](https://github.com/brainsik/virtualenv-burrito) : 能使用单行命令拥有 virtualenv + virtualenvwrapper 的环境. [autoenv](https://github.com/kennethreitz/autoenv) : 当 cd 进入一个包含 .env 的目录中, 就会自动激活那个环境. 四. 文档pydoc : 在安装 python 时自动安装的 工具, 允许在 shell 中快速检索文档,$ pydoc time # 查看 time 模块的文档. 五. PEP8 : Python 事实上的代码风格指南.pep8 : 检查代码的一致性.$ pip install pep8 $ pep8 optparse.py # 检查文件是否符合 PEP8 规范 autopep8 : 自动格式化为 PEP8 风格$ autopep8 [ARGS] optparse.py # 无参数, 则程序直接将更改的代码输出到控制台. --in-place # 直接修改文件. --aggressive # 执行更多实质性的变化, 可以执行多次, 已达到最佳效果. 六. 解包交换变量 :a,b = b,a 嵌套解包:a, (b,c) = 1, (2,3) 扩展解包: python 3a, *rest = range(10) # a = 0, rest = [1, 2, 3, 4, 5, 6, 7, 8, 9] a, *middle, c = range(11) # a = 0, middle = [1, 2, 3, 4, 5, 6, 7, 8, 9], c = 10 创建一个被忽略的变量:filename = &apos;foobar.txt&apos; basename,_,ext = filename.rpartition(&quot;.&quot;) 创建一个包含 N 个对象的列表:&gt;&gt;&gt; four_none = [None]*4 &gt;&gt;&gt; four_none [None, None, None, None] &gt;&gt;&gt; four_one = [1]*4 &gt;&gt;&gt; four_one [1, 1, 1, 1] 创建一个包含 N 个列表的列表four_list = [[] for _ in xrange(4)] 七. 约定 pythonnic检查变量是否等于常量 : 比较一个值是 True, None,False, 0 等 : 使用 ifif attr : print &quot;attr is truthy.&quot; if not attr: print &quot;attr is falsey.&quot; # since None is considered false , explicitly check for it . if attr is None: print &quot;attr is None.&quot; 访问字典元素:x in d dict.get() 示例: d = {&quot;hello&quot;: &quot;world&quot;} print d.get(&quot;hello&quot;, &quot;default_value&quot;) # &quot;world&quot; print d.get(&quot;thingy&quot;, &quot;default_value&quot;) # &quot;default_value&quot; if &quot;hello&quot; in d: print d[&quot;hello&quot;] 维护列表的捷径:列表推导map()filter()enumerate() : 或得列表中当前位置的计数. 示例: # 过滤大于 4 的元素 # 列表推到 a = range(10) b = [i for i in a if i &gt; 4] # filter b = filter(lambda x: x &gt; 4, a) # 列表的每个元素 + 3 # 列表推导 a = range(10) a = [i + 3 for i in a] # map a = map(lambda x: x + 3, a) 读取文件: with openwith open(&apos;file.txt&apos;) as f: for line in f: print line 行的延续: 当一个代码逻辑行的长度超多可接受的限制时, 需要将至分为多个物理行.使用括号. my_very_big_line = ( &quot;for a long time i used to go to bed early. Sometime ,&quot; &quot;when i had put out my candle , my eyes would close so quickly&quot; &quot;That i had not even time to say &apos;I&apos;m going to sleep.&apos; &quot; ) from some.deep.module.inside.a.moule import ( a_nice_function, another_nice_function, yet_another_nice_function ) 九. 密码学Cryptography : 提供了加密方法 recipes 和 primitives . Cryptography 分为两个层, 方法(recipes, 提供用于对称加密) 和 危险底层(hazardous materials,简称 hazmat, 提供底层的加密基元).PyCrypto : 提供安全的 哈希函数和各种加密算法. 十. 命令行应用Clint : 是一个Python模块，它包含了很多 对命令行应用开发有用的工具。它支持诸如CLI着色以及缩进，简洁而强大的列打印， 基于进度条的迭代以及参数控制的特性。Click : 它创建了一个命令行接口, 可以尽可能的简化组合代码。命令行接口创建工具（“Command-line Interface Creation Kit”,Click） 支持很多配置但也有开箱可用的默认值设定。docopt : 是一个轻量级，高度Pythonic风格的包，它支持 简单而直觉地创建命令行接口，它是通过解析POSIX-style的用法指示文本实现的。Plac : Python标准库 argparse [http://docs.python.org/2/library/argparse.html] 的简单封装，它隐藏了大量声明接口的细节：参数解析器是被推断的，其优于写命令明确处理. 这个模块的面向是不想太复杂的用户，程序员，系统管理员，科学家以及只是想写个只运行一次的脚本的人们，使用这个命令行接口的理由是它可以快速实现并且简单。Cliff : 是一个建立命令行程序的框架。 它使用setuptools入口点（entry points）来提供子命令，输出格式化，以及其他的扩展。这个框架 可以用来创建多层命令程序，如subversion与git，其主程序要进行一些简单的参数解析然后调用 一个子命令干活。 十一. 阅读代码Howdoi : 代码搜寻工具flask : 基于 Werkzeug 和 Jinja2 , 使用 Python 的微框架.Diamond : Python 的守护进程, 收集指标, 并将它们发布至 Graphite 或其他后端. 能收取 CPU,内存,网络,IO,负载和硬盘指标, 拥有实现自定义收集器的API, 该 API 几乎能从任何资源中获取指标.Werkzeug : WSGI 实用模型.包括强大的调试器，功能齐全的请求和响应对象，处理entitytags的HTTP工具，缓存控制标头，HTTP数据，cookie处理，文件上传，强大的URL路由系统和一些社区提供的插件模块。 十二. 测试通用规则 : 测试单元应该集中于小部分的功能, 并且证明他是对的. 每个测试单元都应该完全独立. 每个都能独立运行, 除了调用的命令, 都需在测试套件中. 测试单元应该加载最新的数据集, 之后在做一些清理. 如 setUp() 和 tearDown() 方法. 尽量使单元测试快速运行. 实现钩子(hook) 是一个非常好的主意. 因为一旦将代码放入仓库, 这个钩子可以运行所有的测试单元. 当调试代码的时候, 需要首先写一个精确定位 bug 的测试单元. 测试函数使用长且描述性的名字. 单元测试unittest unittest.TestCase doctest 文档测试. 模块查找零碎文本, 就像 Python 中 docstrings 内的交互式会话, 执行那些会话以正式工作正常. Nose : nose 集成测试单元, 能使测试更加容易. 自动化测试, 发现并节省人工创建测试组件的麻烦 tox : 自动化测试管理和针对多种解释器配置测试工具. mock : 测试库. unittest.mock 是 python 中用于测试的一个库. 十三. 持续集成Jenkins : 可扩展的持续集成引擎。Tox : 是一款为Python软件提供打包、测试和 开发的自动化工具，基于命令行或CI服务器。它是一个通用的虚拟环境管理和测试的命令行 工具]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[云计算生态]]></title>
    <url>%2F2018%2F03%2F16%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E7%94%9F%E6%80%81%2F</url>
    <content type="text"><![CDATA[一. 云计算生态CloudNativeLandscape 二. 容器引擎接口 (CRI, Container Runtime Interface) cir-o : kubernetes 主导 Docker : docker daemon 配置参数最佳实践 docker 内部组件 rkt : 三. 容器网络接口(CNI, Container Network Interface) CNI : kubernetes 主导, 容器网络规范 CNM : docker 主导, 容器网络规范 网络解决方案: Calico : 对物理网络侵入较多 flannel : Flannel基于大三层对tcp请求进行了封包与拆包, docker vxlan : 原生方案, 性能较 weave 较好 weave : 性能较差 Macvlan : 四. 容器存储接口(CSI, Container Storage Interface) volume 五. 容器 编排工具 docker swarm mesos kubernetes AWS ECS 六. docker 监控方案 cAdvisor Datadog Prometheus 七. 自动注册于服务发现 consul]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>云生态</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-点滴]]></title>
    <url>%2F2018%2F03%2F16%2Fgit-%E7%82%B9%E6%BB%B4%2F</url>
    <content type="text"><![CDATA[git commitgit commit 命令执行后, git 主要执行了三个操作: 为每一个文件生成一个快照 每一个文件其实是真的数据, 所以 git 会把整个文件内容转成二进制, 然后经过压缩直接存储在键值对数据库中, 对应的键值就是文件中的内容, 再加上一些头信息的 40 位校验 和 sha-1 . 文件快照的类型为 blob 类型(binary large object) , 即大型二进制对象类型. 为每一个文件夹生成一个快照 文件夹并不是直接的文字数据, 其主要记录的是文件夹的结构和每个文件或者文件夹对应的快照键值, 所以文件夹的快照内容是其包含的所有文件和文件夹的键值信息总和, 附加一些头信息, 如文件名,文件夹名. 对应快照键值为快照内容的 40位校验和 sha-1 , 文件夹快照对应的类型为 tree. 生成一个项目快照 即 生成一个 commit, 项目快照的内容摘要包含四部分信息, 根项目目录的快照/提交人信息/项目快照说明/父项目快照. 其中项目文件快照, 只要根目录的目录快照即可. 项目快照 commit 的键值为 项目快照内容的 40位校验和 sha-1. 项目快照类型为 commit 类型. git 中生成的所有 object 都存在 .git/objects/ 文件夹中, 每一个 object 保存时, 取其 40位检验和 sha-1 的前两位生成文件夹, 后 38 位作为文件名, 存储对应的数据. 只有变化的文件或文件夹才会形成新的快照, 没有变化的文件不会形成新的快照. git branchbranch 信息记录在 .git/refs/heads/ 目录下 $cat .git/refs/heads/master 1e3db1046b3f0d07aeb51d9704792e611a1a7a80 branche 仅仅是指向一个 commit 的指针而已, 指向一个 commit, 而一个 comit 同时指向其父 commit, 如此循环形成一个 branch. git HEAD 指针git 有一个独立的 HEAD 指针, 记录项目现在所在的位置. $cat .git/HEAD ref: refs/heads/master # 此时指针指向 master , 表示现在在 master 分支上. 当我们创建新的分支 test 时, git 会在 .git/refs/heads/ 目录下生成一个文件 test, 并将其指向当前 HEAD 所指向的分支 master 所指向的提交 , 并把 HEAD 指向新的分支 test . $cat .git/refs/heads/master 1e3db1046b3f0d07aeb51d9704792e611a1a7a80 $cat .git/refs/heads/test 1e3db1046b3f0d07aeb51d9704792e611a1a7a80 当我们在新的分支生成新的 commit 时, git 会将 HEAD 所指向的分支 test 所指向的 commit 作为新 commit 的父 commit, 然后将 HEAD 所指向的分支 test 移动指向新的提交.]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>代码管理</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-daemon-参数最佳实践.md]]></title>
    <url>%2F2018%2F03%2F16%2Fdocker-daemon-%E5%8F%82%E6%95%B0%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[一. Docker Daemon 配置参数 限制容器之间网络通信 在同一台主机上若不限制容器之间通信，容器之间就会暴露些隐私的信息，所以推荐关闭 docker daemon –icc=false 使用安全模式访问镜像仓库 Docker Daemon支持安全模式（默认）和非安全模式（–insecure-registry）访问镜像仓库，推荐镜像仓库配置CA证书，Docker Daemon配置安全访问模式，采用TLS安全传输协议； 使用Docker Registry v2版本 v2版本在性能与安全性方面比v1都增强了很多，如安全性上的镜像签名等. docker daemon –disable-legacy-registry; 为Docker Daemon配置TLS认证 推荐指定Docker Daemon的监听IP、端口及unix socket，并配置TLS认证，通过Docker Daemon的IP+端口访问 –tlsverify –tlscacert –tlscert –tlskey 为Docker Daemon开启用户空间支持 Docker Daemon支持Linux内核的user namespace，为Docker宿主机提供了额外的安全，容器使用有root权限的用户，则这个用户亦拥有其宿主机的root权限，外部可以通过容器反向来操控宿主机， docker daemon –userns-remap=default 为Docker Daemon配置默认的CGroup 某个程序可能会出现占用主机上所有的资源，导致其他程序无法正常运行，或者造成系统假死无法维护，这时候用 cgroups 就可以很好地控制进程的资源占用 docker daemon –cgroup-parent=/foobar 日志级别 日志级别设置为info：这样除了debug信息外，可以捕获所有的信息 docker daemon –iptables=true 为Docker配置集中的远程日志收集系统 Docker支持很多种日志驱动，配置集中的远程日志系统用来存储Docker日志是非常有必要的. docker run –log-driver=syslog –log-opt syslog-address=tcp://ip; Docker 支持的日志驱动, 官方文档 Driver Desc none No logs will be available for the container and docker logs will not return any output. json-file The logs are formatted as JSON, The default logging driver for docker syslog Writes logging messages to the syslog facility. The syslog daemon must be running on the host machine. journald Writes log messages to the journald. The journald daemon must be running on the host machine. gelf Write log messages to the Graylog Extended Log Format (GELF) endpoint such as Graylog or Logstash. fluentd Write log messages to fluentd (forward input). The fluentd deamon must be running on the host machine. awslogs Write log messages to Amazon CloudWatch Logs. splunk Writes log messages to splunk using the HTTP Event Collector. etwlogs Wrtites log message as Event Tracing for Windows (ETW). Only available on Windows platforms. gcplogs Write log messages to Google Cloud Platform (GCP) Logging. 存储驱动 推荐使用Overlayfs作为Docker的存储驱动：Docker支持很多种储存驱动，CentOS默认的Docker存储驱动为devicemapper，Ubuntu默认的Docker存储驱动为aufs， # 特点 优点 缺点 适用场景 Aufs 联合文件系统, 未并入内核主线文件级存储 作为 docker 的第一个存储驱动, 历史较久, 比较稳定,且在生产中大量实践过, 有较强的社区支持 有很多层, 在做写时复制操作时, 如果文件比较大,且存在比较低的层, 可能会慢一些 大并发但少IO 的场景 OverlayFS 联合文件系统, 并入内核主线文件级存储 只有两层 不管修改的内容大小都会复制整个文件, 对大文件进行修改显示比小文件要消耗更多的时间 大并发但少IO的场景 DeviceMapper 并入内核主线文件级存储 块级别, 无论是大文件还是小文件都只复制需要修改的块, 而不是整个文件 支持共享存储, 表示当有多个容器读同一个文件时, 需要生成多个复本, 在很多容器启停的情况下, 可能会导致磁盘溢出 适合IO密集的场景 Btrfs 并入内核主线文件级存储 可以向 DeviceMapper 直接操作底层设备, 支持动态添加设备 不支持共享存储, 表示当有多个容器读同一个文件时, 需要生成多个复本 不适合在高密度容器的 PaaS 平台上使用 ZFS 把所有设备集中到奥一个存储池中来进行管理 支持多个容器共享一个缓存块, 适合内存大的场景 COW 使碎片化问题更加严重, 文件在硬件上的物理地址变得不再连续, 顺序读会变得性能比较差 适合 PassS 和 高密度场景 二. Docker Daemon权限Docker Daemon相关文件和目录的属性及其权限关系到整个Docker运行时的安全.设置Docker Daemon一些相关配置文件的属性及其权限 配置文件 属性设置 权限设置 备注信息 docker.service root:root 644 docker.sock root:root 660 docker.json root:root 644 docker root:root 644 TLS CA certificate root:root 444 通过 –tlscacert 参数传递生成的文件属性 Docker server certificate root:root 444 通过 –tlscert 参数传递生成的文件属性 Docker server certificate key root:root 400 通过 –tlskey 参数传递生成的文件属性 /etc/docker root:root 755 容器认证及key信息 /etc/docker/certs.d/ root:root 444 registry 证书相关的文件]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker daemon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AngularJS高级程序设计读书笔记--大纲篇]]></title>
    <url>%2F2018%2F03%2F16%2FAngularJS%E9%AB%98%E7%BA%A7%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E5%A4%A7%E7%BA%B2%E7%AF%87%2F</url>
    <content type="text"><![CDATA[学习 AngularJS 的初衷是因为, 去年楼主开始尝试使用 Flask 开发自动化应用, 需要用到大量的表单, Flask-wtf 的功能不能满足要求, 并且不够灵活, 所以在某老猿的建议下开始尝试使用 AngularJS 来写表单. 第一感觉是惊艳, 原来可以这么 easy, 所以想深入的学习一下, 并买了若干本书. &lt;AngularJS高级程序设计&gt; 是去年买的, 网上的评价一般, 但是楼主觉得讲的比较轻松和易懂, 所以拿来做些笔记和总结. 下面是具体的大纲和链接. 这几篇文章只做总结和梳理, 方便个人查找. 一. 模块 模块基础 使用模块组织代码 二. 控制器控制器是一个 AngularJS 程序中最大的构件之一, 它扮演了模型和视图之间的渠道的角色. 大多数 AngularJS 项目拥有多个控制器, 每一个向应用程序的一部分提供所需的数据和逻辑. 三. 指令指令是最强大的 AngularJS 特性, 通过他们能扩展并增强 HTML, 从而创建丰富的 Web 应用程序. AngularJS 通过包含和增强 HTML 来创建 AngularJS 为web应用程序, 讲 HTML 当做构建应用程序特性的基础而不是要解决的问题来处理. (一) 内置指令1. 数据绑定指令 指令 用作 描述 ng-bind 属性, 类 绑定一个 HTML 元素的 innerText 属性 ng-bind-html 属性, 类 使用一个HTML 元素的 innerHTML 属性创建数据绑定, 这是有潜在风险的, 因为这意味着浏览器把内容解析为 HTML, 而不是内容本身. ng-bind-template 属性, 类 与 ng-bind 类似, 但允许在属性值中制定多个模板表达式 ng-model 属性, 类 创建一个双向数据绑定 ng-non-bindable 属性, 类 声明一块不会被执行数据绑定的区域 2. 模板指令 指令 用作 描述 ng-cloak 属性, 类 使用一个 css 样式隐藏内联绑定表达式{ {} }, 在文档第一个加载时会短暂的可见 ng-include 元素, 属性, 类 向 DOM 中加载,处理和插入一段 HTML ng-repeat 属性, 类 对数组中或对象某个属性中的每一个对象生成一个元素及其内容的若干新拷贝 ng-repeat-start 属性, 类 表示含有多个顶层元素的重复区域的开始部分 ng-repeat-end 属性, 类 表示含有多个顶层元素的重复区域的结束部分 ng-switch 属性, 类 根据数据绑定的值修改 DOM 中的元素. 3. 元素指令元素指令, 用于在 DOM 中对元素进行配置和渲染样式的. 指令 用作 描述 ng-if 属性 从 DOM 中添加和移除元素 ng-class 属性, 类 为某个元素设置 class 属性 ng-class-even 属性, 类 对 ng-repeat 指令生成的偶数元素设置 class 属性 ng-class-odd 属性, 类 对 ng-repeat 指令生成的奇数元素设置 class 属性 ng-hide 属性, 类 在 DOM 中显示和隐藏元素 ng-show 属性, 类 在 DOM 中显示和隐藏元素 ng-style 属性, 类 设置一个或多个 CSS 属性 4. 事件处理 指令 用作 描述 ng-blur 属性,类 为 blur 事件制定自定义行为, 在元素失去焦点时被触发 ng-change 属性,类 为 change 事件制定自定义行为, 在表单元素的内容状态发生变化时被触发(例如复选框被选中,输入框元素中的文本被修改等) ng-click 属性,类 为 click 事件指定自定义行为, 在用户点击鼠标/光标时被触发 ng-copy, ng-cut, ng-paste 属性,类 为 copy,cut,paste 事件指定自定义行为 ng-dbclick 属性,类 为 dbclick 事件指定自定义行为, 在用户双击鼠标/光标时被触发 ng-focus 属性,类 为 focus 事件指定自定义行为, 在元素获得焦点时被触发 ng-keydown, ng-keypress, ng-keyup 属性,类 为 keydown,keypress,keyup 事件指定自定义行为, 在用户按下,释放某个键时被触发 ng-mousedown, ng-mouseenter,ng-mouseleave, ng-mousemove,ng-mouseover,ng-mouseup 属性,类 为 6个标准鼠标事件事件指定自定义行为, 在用户使用鼠标/光标与元素发生交互时被触发 ng-submit 属性,类 为 submit 事件指定自定义行为, 在表单被提交时被触发 5. 布尔属性指令, 映射指令映射指令, 用于在 AngularJS 所依赖的数据绑定的方式和那些被称为布尔属性的 HTML 特性之间进行映射. 指令 用作 描述 ng-checked 属性 管理 checked 属性(在 input 元素上使用) ng-disabled 属性 管理 disabled 属性(在 input 和 button 上使用) ng-open 属性 管理 open 属性 (在 details 元素上使用) ng-readonly 属性 管理 readonly 属性(在 input 元素上使用) ng-selected 属性 管理 select 属性(在 option 元素上使用) ng-href 属性 在 a 元素上设置 href 属性 ng-src 属性 在 img 元素上设置 src 属性 ng-srcset 属性 在 img 元素上设置 srcset 属性. srcset 属性时扩展到 html5 的起草标准之一, 允许为显示不同的大小和像素密度而指定多张图片 6. 表单验证(二) 自定义指令四. 过滤器过滤器用于在视图中格式化展现给用户的数据. 一旦定义过滤器之后, 就可在整个模块中全面应用, 也就意味着可以用来保证跨多个控制器和视图之间的数据展示的一致性. (一) 过滤器的不同使用方式(二) 内置过滤器(三) 自定义过滤器五. 服务服务是提供在整个应用程序中所使用的任何功能的单例对象.单例 : 只用一个对象实例会被 AngularJS 创建出来, 并被程序需要服务的各个不同部分所共享. (一) 内置服务一些关键方法也被 AngularJS 成为服务. 如 $scope, $http. (二) 自定义服务 Module.service(name, constructor) Module.factory(name, provider) Module.provider(name, type) Module.value(name, value) 六. AngularJS 扩展(一) Angular-xeditable(二) angular-flash(三) Angular Advanced Searchbox(四) AngularUI七. 参考链接:AngularJS高级程序设计书中源代码]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>angularjs</tag>
        <tag>前端框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AngularJS高级程序设计读书笔记--指令篇之内置指令]]></title>
    <url>%2F2018%2F03%2F16%2FAngularJS%E9%AB%98%E7%BA%A7%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E6%8C%87%E4%BB%A4%E7%AF%87%E4%B9%8B%E5%86%85%E7%BD%AE%E6%8C%87%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[AngularJS 内置超过 50 个内置指令, 包括 数据绑定,表单验证,模板生成,时间处理 和 HTML 操作. 指令暴露了 AngularJS 的核心功能, 如 事件处理,表单验证,模板等. 一. 数据绑定指令数据绑定: 使用模型中的值, 并将其插入到 HTML 文档中.所有的数据绑定指令, 都可以当做一个属性或者类使用. 属性 : &lt;span ng-bind=&quot;todos.length&quot;&gt;&lt;/span&gt; 属性可能会导致其他开发工具的各种问题, 如某些 JavaScript 库对属性名做了若干假设, 而且某些限制性的版本控制系统不允许 HTML 内容中有非标准的属性. 类 : &lt;span class=&quot;ng-bind: todos.length&quot;&gt;&lt;/span&gt; 数据绑定: AngularJS 的数据绑定是动态的, 当绑定所关联的值在数据模型中发生变化时, HTML 元素也会被随之更新,显示新的值. 单向数据绑定 : 从数据模型中获得值并插入到 HTMl 元素中. 双向数据绑定 : 从两个方向同时跟踪变化, 允许元素从用户处收集数据已修改程序的状态. 双向数据绑定仅能用于那些允许用户输入数据值的元素上, 既 input,select,textarea 元素 数据绑定的一个很好的特性是, AngularJS 将在需要的时候动态的创建模型属性, 也就说无需费力的定义所有要使用的属性, 就可以和视图关联在一起. 在请求绑定到一个不存在的模型属性时, AngularJS 也不会报错, 因为他假定这个属性将会在之后创建. 指令 用作 描述 ng-bind 属性, 类 绑定一个 HTML 元素的 innerText 属性 ng-bind-html 属性, 类 使用一个HTML 元素的 innerHTML 属性创建数据绑定, 这是有潜在风险的, 因为这意味着浏览器把内容解析为 HTML, 而不是内容本身. ng-bind-template 属性, 类 与 ng-bind 类似, 但允许在属性值中制定多个模板表达式 ng-model 属性, 类 创建一个双向数据绑定 ng-non-bindable 属性, 类 声明一块不会被执行数据绑定的区域 示例代码 : &lt;!DOCTYPE html&gt; &lt;html ng-app=&quot;exampleApp&quot;&gt; &lt;head&gt; &lt;title&gt;Directives&lt;/title&gt; &lt;script src=&quot;angular.js&quot;&gt;&lt;/script&gt; &lt;link href=&quot;bootstrap.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;link href=&quot;bootstrap-theme.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&quot;defaultCtrl&quot;, function ($scope) { $scope.todos = [ { action: &quot;Get groceries&quot;, complete: false }, { action: &quot;Call plumber&quot;, complete: false }, { action: &quot;Buy running shoes&quot;, complete: true }, { action: &quot;Buy flowers&quot;, complete: false }, { action: &quot;Call family&quot;, complete: false }]; }); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;todoPanel&quot; class=&quot;panel&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;h3 class=&quot;panel-header&quot;&gt;To Do List&lt;/h3&gt; &lt;div&gt;There are { {todos.length} } items&lt;/div&gt; &lt;div&gt; There are &lt;span ng-bind=&quot;todos.length&quot;&gt;&lt;/span&gt; items &lt;/div&gt; &lt;div ng-bind-template= &quot;First: { {todos[0].action} }. Second: { {todos[1].action} }&quot;&gt; &lt;/div&gt; &lt;div ng-non-bindable&gt; AngularJS uses { { and } } characters for templates &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 1. ng-bind 与 { {} }内联绑定&lt;div&gt;There are { {todos.length} } items&lt;/div&gt; --- &lt;div&gt; There are &lt;span ng-bind=&quot;todos.length&quot;&gt;&lt;/span&gt; items &lt;/div&gt; 2. ng-bind-html3. ng-bind-template : 处理多个数据绑定.&lt;div ng-bind-template= &quot;First: { {todos[0].action} }. Second: { {todos[1].action} }&quot;&gt; &lt;/div&gt; 4. ng-non-bindable : 阻止 AngularJS 处理内联绑定.&lt;div ng-non-bindable&gt; AngularJS uses { { and } } characters for templates &lt;/div&gt; 5. ng-modelng-model 指令对所应用到的元素内容进行设置, 也通过更新数据模型的方式响应用户所做的更改.数据模型属性上的变化, 会被传播到所有的相关绑定上, 以保证在整个应用中的数据同步.在下面的代码中, input 元素属性的修改, 将会影响到 { {} } 内联绑定元素属性的修改. 原理: 当 input 元素的内容被修改时, AngularJS 使用标准 JavaScript 事件从 input 元素接受通知, 并且将这一变化通过 $scope 服务进行传播.可以通过浏览器的 开发者工具, 看到 AngularJS 所建立的事件处理器. &lt;div class=&quot;well&quot;&gt; &lt;div&gt;The first item is: { {todos[0].action} }&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-group well&quot;&gt; &lt;label for=&quot;firstItem&quot;&gt;Set First Item:&lt;/label&gt; &lt;input name=&quot;firstItem&quot; class=&quot;form-control&quot; ng-model=&quot;todos[0].action&quot; /&gt; &lt;/div&gt; 二. 模板指令AngularJS 包含了一组可使用模板生成 HTML 元素的指令, 使得使用数据集合进行工作, 以及向响应数据状态的模板中添加基本逻辑变得简单.可以帮助我们不用写任何 JavaScript 代码就可以向视图中添加简单逻辑. 指令 用作 描述 ng-cloak 属性, 类 使用一个 css 样式隐藏内联绑定表达式{ {} }, 在文档第一个加载时会短暂的可见 ng-include 元素, 属性, 类 向 DOM 中加载,处理和插入一段 HTML ng-repeat 属性, 类 对数组中或对象某个属性中的每一个对象生成一个元素及其内容的若干新拷贝 ng-repeat-start 属性, 类 表示含有多个顶层元素的重复区域的开始部分 ng-repeat-end 属性, 类 表示含有多个顶层元素的重复区域的结束部分 ng-switch 属性, 类 根据数据绑定的值修改 DOM 中的元素. 1 ng-repeat用于为数据集中的各项生成同样的内容. 基础形式 ng-repeat 指令属性值的基本形式是 in , 其中 source 是被控制器的 $scope 所定义的一个对象或者数组, 在本例中时 todos 数组. 该指令遍历数组中的对象, 创建元素及其内容的一个新实例, 并且处理所包含的模板. 在指令属性值中赋给 的名称可用于引用当前数据内容. &lt;div id=&quot;todoPanel&quot; class=&quot;panel&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;h3 class=&quot;panel-header&quot;&gt;To Do List&lt;/h3&gt; &lt;table class=&quot;table&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Action&lt;/th&gt; &lt;th&gt;Done&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr ng-repeat=&quot;item in todos&quot;&gt; &lt;td&gt;{ {item.action} }&lt;/td&gt; &lt;td&gt;{ {item.complete} }&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; ng-repeat 的嵌套使用: 用于遍历对象中的属性. &lt;table class=&quot;table&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Action&lt;/th&gt; &lt;th&gt;Done&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr ng-repeat=&quot;item in todos&quot;&gt; &lt;td ng-repeat=&quot;prop in item&quot;&gt;{ {prop} }&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; 外层 ng-repeat 指令对 todos 数组中的每个对象生成一个 tr 元素, 并且每个对象被赋给变量 item. 内层 ng-repeat 指令对 item 对象的每个属性生成一个 td 元素, 并将属性值赋给变量 prop. 最后 , prob 变量用于一个单项数据绑定, 作为 td 元素的内容. 该示例与前例相同, 但是却能够自适应的为数据对象中定义的任何新属性生成 td 元素. 使用数据对象的键值工作 &lt;tbody&gt; &lt;tr ng-repeat=&quot;item in todos&quot;&gt; &lt;td ng-repeat=&quot;(key, value) in item&quot;&gt; { {key} }={ {value} } &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; 内置变量 : 可用于提供被处理数据的上下文信息. 内置的 ng-repeat 变量, 索引从 0 开始 | 变量 | 描述 | | — | — | | $index | 返回当前对象或属性的位置 | | $first | 在当前对象为集合中的第一个元素时, 返回 true | | $middle | 在当前对象既不是集合的第一个也不是集合的最后一个时, 返回 true | | $last | 在当前对象为集合中的最后一个元素时, 返回 true | | $even | 对于集合中偶数编号的对象, 返回 true | | $odd | 对于集合中奇数编号的对象, 返回 true | 示例代码: &lt;table class=&quot;table&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;#&lt;/th&gt; &lt;th&gt;Action&lt;/th&gt; &lt;th&gt;Done&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tr ng-repeat=&quot;item in todos&quot;&gt; &lt;td&gt;{ {$index + 1} }&lt;/td&gt; &lt;td ng-repeat=&quot;prop in item&quot;&gt; { {prop} } &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; // ng-repeat 与 ng-class 联合使用, 实现条纹效果. &lt;style&gt; .odd { background-color: lightcoral} .even { background-color: lavenderblush} &lt;/style&gt; // ... &lt;table class=&quot;table&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;#&lt;/th&gt; &lt;th&gt;Action&lt;/th&gt; &lt;th&gt;Done&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tr ng-repeat=&quot;item in todos&quot; ng-class=&quot;$odd ? &apos;odd&apos; : &apos;even&apos;&quot;&gt; &lt;td&gt;{ {$index + 1} }&lt;/td&gt; &lt;td ng-repeat=&quot;prop in item&quot;&gt;{ {prop} }&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; // ng-repeat 与 ng-if, ng-class 联合使用 &lt;style&gt; .odd { background-color: lightcoral} .even { background-color: lavenderblush} &lt;/style&gt; // ... &lt;table class=&quot;table&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;#&lt;/th&gt; &lt;th&gt;Action&lt;/th&gt; &lt;th&gt;Done&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tr ng-repeat=&quot;item in todos&quot; ng-class=&quot;$odd ? &apos;odd&apos; : &apos;even&apos;&quot;&gt; &lt;td&gt;{ {$index + 1} }&lt;/td&gt; &lt;td&gt;{ {item.action} }&lt;/td&gt; &lt;td&gt;&lt;span ng-if=&quot;$first || $last&quot;&gt;{ {item.complete} }&lt;/span&gt;&lt;/td&gt; # 在不是 第一个或最后一个元素时, 移除 item.complete . &lt;/tr&gt; &lt;/table&gt; // track must be the last one. &lt;div ng-repeat=&quot;n in [42, 42, 43, 43] track by $index&quot;&gt; { {n} } &lt;/div&gt; ... &lt;div ng-repeat=&quot;model in collection | orderBy: &apos;id&apos; as filtered_result track by model.id&quot;&gt; { {model.name} } &lt;/div&gt; 2 ng-repeat-start 与 ng-repeat-end : 对每个数据对象重复生成多个顶层元素.在需要对每个处理的数据项生成多个表格行时, 最常用到.ng-repeat-start 指令的配置方法类似于 ng-repeat, 但是将会重复生成所有的顶层元素(及其内容)直到 ng-repeat-end 属性所对应的元素(也包含在内). This is item { {$index} } The action is: { {item.action} } Item { {$index} } is { {$item.complete? ‘’ : “not “} } complete 3 ng-include 与 局部视图 基本用法 ng-include 指令从服务器获取一段 HTML 片段, 编译并处理其中包含的任何指令, 并添加到 DOM 中去. 这些片段被称为局部视图. ng-include 允许创建可复用的局部视图. 当 AngularJS 处理 html 文件时, 当遇到 ng-include 指令, 就会自动发出一个 Ajax 请求获取 src 指定的文件, 处理文档内容并将其添加到文档中. 被 ng-include 指令所加载的文件内容的处理过程就像在原来的地方所定义的一样, 也就是说, 拥有访问数据模型和控制器中定义的行为的能力. ng-include 参数 | 名称 | 描述 | | — | — | | src | 指定要加载的内容的 URL, 参数为字符串变量, 用一对引号包含表示. 因为 src 属性是被当做 JavaScript 表达式进行计算的. 另, src 的设置是可以通过计算得到的. | | onload | 指定一个在内容被加载时调用计算的表达式 | | autoscroll | 指定在内容被加载时, AngularJS 是否应该滚动到这部分视图所在的区域. | : 必须指定开闭标签. 示例代码: // 主文件 &lt;!DOCTYPE html&gt; &lt;html ng-app=&quot;exampleApp&quot;&gt; &lt;head&gt; &lt;title&gt;Directives&lt;/title&gt; &lt;script src=&quot;angular.js&quot;&gt;&lt;/script&gt; &lt;link href=&quot;bootstrap.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;link href=&quot;bootstrap-theme.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&quot;defaultCtrl&quot;, function ($scope) { $scope.todos = [ { action: &quot;Get groceries&quot;, complete: false }, { action: &quot;Call plumber&quot;, complete: false }, { action: &quot;Buy running shoes&quot;, complete: true }, { action: &quot;Buy flowers&quot;, complete: false }, { action: &quot;Call family&quot;, complete: false }]; }); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;todoPanel&quot; class=&quot;panel&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;h3 class=&quot;panel-header&quot;&gt;To Do List&lt;/h3&gt; &lt;ng-include src=&quot;&apos;table.html&apos;&quot;&gt;&lt;/ng-include&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; // table.html &lt;table class=&quot;table&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;#&lt;/th&gt; &lt;th&gt;Action&lt;/th&gt; &lt;th&gt;Done&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tr ng-repeat=&quot;item in todos&quot; ng-class=&quot;$odd ? &apos;odd&apos; : &apos;even&apos;&quot;&gt; &lt;td&gt;{ {$index + 1} }&lt;/td&gt; &lt;td ng-repeat=&quot;prop in item&quot;&gt;{ {prop} }&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 动态选择局部视图. // list.html &lt;ol&gt; &lt;li ng-repeat=&quot;item in todos&quot;&gt; { {item.action} } &lt;span ng-if=&quot;item.complete&quot;&gt; (Done)&lt;/span&gt; &lt;/li&gt; &lt;/ol&gt; // table.html &lt;table class=&quot;table&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;#&lt;/th&gt; &lt;th&gt;Action&lt;/th&gt; &lt;th&gt;Done&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tr ng-repeat=&quot;item in todos&quot; ng-class=&quot;$odd ? &apos;odd&apos; : &apos;even&apos;&quot;&gt; &lt;td&gt;{ {$index + 1} }&lt;/td&gt; &lt;td ng-repeat=&quot;prop in item&quot;&gt;{ {prop} }&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; // index.html &lt;!DOCTYPE html&gt; &lt;html ng-app=&quot;exampleApp&quot;&gt; &lt;head&gt; &lt;title&gt;Directives&lt;/title&gt; &lt;script src=&quot;angular.js&quot;&gt;&lt;/script&gt; &lt;link href=&quot;bootstrap.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;link href=&quot;bootstrap-theme.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&quot;defaultCtrl&quot;, function ($scope) { $scope.todos = [ { action: &quot;Get groceries&quot;, complete: false }, { action: &quot;Call plumber&quot;, complete: false }, { action: &quot;Buy running shoes&quot;, complete: true }, { action: &quot;Buy flowers&quot;, complete: false }, { action: &quot;Call family&quot;, complete: false }]; $scope.viewFile = function () { return $scope.showList ? &quot;list.html&quot; : &quot;table.html&quot;; }; }); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;todoPanel&quot; class=&quot;panel&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;h3 class=&quot;panel-header&quot;&gt;To Do List&lt;/h3&gt; &lt;div class=&quot;well&quot;&gt; &lt;div class=&quot;checkbox&quot;&gt; &lt;label&gt; &lt;input type=&quot;checkbox&quot; ng-model=&quot;showList&quot;&gt; Use the list view &lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;ng-include src=&quot;viewFile()&quot;&gt;&lt;/ng-include&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; ng-include 用做属性 ng-include 属性可用于任何 HTML 元素, src 参数的值姜葱该属性值中取得.其他的指令配置参数以单独的元素表示, 可以从 onload 的属性中看到. 与 ng-include 用作自定义元素有相同的效果. &lt;!DOCTYPE html&gt; &lt;html ng-app=&quot;exampleApp&quot;&gt; &lt;head&gt; &lt;title&gt;Directives&lt;/title&gt; &lt;script src=&quot;angular.js&quot;&gt;&lt;/script&gt; &lt;link href=&quot;bootstrap.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;link href=&quot;bootstrap-theme.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&quot;defaultCtrl&quot;, function ($scope) { $scope.todos = [ { action: &quot;Get groceries&quot;, complete: false }, { action: &quot;Call plumber&quot;, complete: false }, { action: &quot;Buy running shoes&quot;, complete: true }, { action: &quot;Buy flowers&quot;, complete: false }, { action: &quot;Call family&quot;, complete: false }]; $scope.viewFile = function () { return $scope.showList ? &quot;list.html&quot; : &quot;table.html&quot;; }; $scope.reportChange = function () { console.log(&quot;Displayed content: &quot; + $scope.viewFile()); } }); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;todoPanel&quot; class=&quot;panel&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;h3 class=&quot;panel-header&quot;&gt;To Do List&lt;/h3&gt; &lt;div class=&quot;well&quot;&gt; &lt;div class=&quot;checkbox&quot;&gt; &lt;label&gt; &lt;input type=&quot;checkbox&quot; ng-model=&quot;showList&quot;&gt; Use the list view &lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div ng-include=&quot;viewFile()&quot; onload=&quot;reportChange()&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 4 ng-switch+on, ng-switch-when, ng-switch-default用于在已经存在于文档中的较小代码块之间进行切换.ng-switch+on : 可以被当做元素或属性使用, on 指定一个表达式, 用于计算并决定那部分内容将被显示出来.ng-switch-when : 只能被当做 属性 使用, 表示与所指定的值相关联的一块内容. 当属性值与 ng-switch 中的 on 属性所指定的表达式相匹配时, AngularJS 将会显示出 ng-switch-when 指令所应用到的元素.其他 ng-switch-when 指令代码块里的元素将被移除.ng-switch-default : 只能被当做 属性 使用, 用于指定没有任何一个 ng-switch-when 区域匹配到时应当显示的内容. &lt;!DOCTYPE html&gt; &lt;html ng-app=&quot;exampleApp&quot;&gt; &lt;head&gt; &lt;title&gt;Directives&lt;/title&gt; &lt;script src=&quot;angular.js&quot;&gt;&lt;/script&gt; &lt;link href=&quot;bootstrap.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;link href=&quot;bootstrap-theme.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&quot;defaultCtrl&quot;, function ($scope) { $scope.data = {}; $scope.todos = [ { action: &quot;Get groceries&quot;, complete: false }, { action: &quot;Call plumber&quot;, complete: false }, { action: &quot;Buy running shoes&quot;, complete: true }, { action: &quot;Buy flowers&quot;, complete: false }, { action: &quot;Call family&quot;, complete: false }]; }); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;todoPanel&quot; class=&quot;panel&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;h3 class=&quot;panel-header&quot;&gt;To Do List&lt;/h3&gt; &lt;div class=&quot;well&quot;&gt; &lt;div class=&quot;radio&quot; ng-repeat=&quot;button in [&apos;None&apos;, &apos;Table&apos;, &apos;List&apos;]&quot;&gt; &lt;label&gt; &lt;input type=&quot;radio&quot; ng-model=&quot;data.mode&quot; value=&quot;{ {button} }&quot; ng-checked=&quot;$first&quot; /&gt; { {button} } &lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div ng-switch on=&quot;data.mode&quot;&gt; &lt;div ng-switch-when=&quot;Table&quot;&gt; &lt;table class=&quot;table&quot;&gt; &lt;thead&gt; &lt;tr&gt;&lt;th&gt;#&lt;/th&gt;&lt;th&gt;Action&lt;/th&gt;&lt;th&gt;Done&lt;/th&gt;&lt;/tr&gt; &lt;/thead&gt; &lt;tr ng-repeat=&quot;item in todos&quot; ng-class=&quot;$odd ? &apos;odd&apos; : &apos;even&apos;&quot;&gt; &lt;td&gt;{ {$index + 1} }&lt;/td&gt; &lt;td ng-repeat=&quot;prop in item&quot;&gt;{ {prop} }&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;div ng-switch-when=&quot;List&quot;&gt; &lt;ol&gt; &lt;li ng-repeat=&quot;item in todos&quot;&gt; { {item.action} }&lt;span ng-if=&quot;item.complete&quot;&gt; (Done)&lt;/span&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; &lt;div ng-switch-default&gt; Select another option to display a layout &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 5 ng-cloak能够在 AngularJS 结束对内容的处理之前先将 内联元素指令 隐藏. ng-cloak 指令使用 CSS 对被应用到的元素进行隐藏. 不建议对 body 元素使用 ng-cloak 指令, 因为这样当 AngularJS 处理内容时, 用户只能看到一个空白的浏览器窗口. 建议有选择的对部分元素使用该指令, 将其只用到那些具有内联元素表达式的文档部分. &lt;div class=&quot;well&quot;&gt; &lt;div class=&quot;radio&quot; ng-repeat=&quot;button in [&apos;None&apos;, &apos;Table&apos;, &apos;List&apos;]&quot;&gt; &lt;label ng-cloak&gt; &lt;input type=&quot;radio&quot; ng-model=&quot;data.mode&quot; value=&quot;{ {button} }&quot; ng-checked=&quot;$first&quot;&gt; { {button} } &lt;/label&gt; &lt;/div&gt; &lt;/div&gt; 三. 元素指令元素指令, 用于在 DOM 中对元素进行配置和渲染样式的. 指令 用作 描述 ng-if 属性 从 DOM 中添加和移除元素 ng-class 属性, 类 为某个元素设置 class 属性 ng-class-even 属性, 类 对 ng-repeat 指令生成的偶数元素设置 class 属性 ng-class-odd 属性, 类 对 ng-repeat 指令生成的奇数元素设置 class 属性 ng-hide 属性, 类 在 DOM 中显示和隐藏元素 ng-show 属性, 类 在 DOM 中显示和隐藏元素 ng-style 属性, 类 设置一个或多个 CSS 属性 基础示例代码 : &lt;!DOCTYPE html&gt; &lt;html ng-app=&quot;exampleApp&quot;&gt; &lt;head&gt; &lt;title&gt;Directives&lt;/title&gt; &lt;script src=&quot;angular.js&quot;&gt;&lt;/script&gt; &lt;link href=&quot;bootstrap.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;link href=&quot;bootstrap-theme.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&quot;defaultCtrl&quot;, function ($scope) { $scope.todos = [ { action: &quot;Get groceries&quot;, complete: false }, { action: &quot;Call plumber&quot;, complete: false }, { action: &quot;Buy running shoes&quot;, complete: true }, { action: &quot;Buy flowers&quot;, complete: false }, { action: &quot;Call family&quot;, complete: false }]; }); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;todoPanel&quot; class=&quot;panel&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;h3 class=&quot;panel-header&quot;&gt;To Do List&lt;/h3&gt; &lt;table class=&quot;table&quot;&gt; &lt;thead&gt; &lt;tr&gt;&lt;th&gt;#&lt;/th&gt;&lt;th&gt;Action&lt;/th&gt;&lt;th&gt;Done&lt;/th&gt;&lt;/tr&gt; &lt;/thead&gt; &lt;tr ng-repeat=&quot;item in todos&quot;&gt; &lt;td&gt;{ {$index + 1} }&lt;/td&gt; &lt;td ng-repeat=&quot;prop in item&quot;&gt;{ {prop} }&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; 1. ng-hide, ng-show : 隐藏和显示元素ng-show 和 ng-hide 指令通过添加和移除一个名为 ng-hide(该名称容易与指令名混淆) 的 CSS 类来控制元素的可见性. ng-hide 这个类的 CSS 样式将 display 属性设置为 none, 从而从视图中移除钙元素. 注意 ng-show 和 ng-hide 指令仍会将所操作的元素保存在 DOM 内, 仅仅只是对用户隐藏. 对浏览器来说他并没有隐藏, 仍然在哪里, 因此类似这种根据位置进行选择的 CSS 选择器讲会把隐藏元素也计算在内. 例如在下面对 item.complete 进行渲染时, (Incomplete) 拥有加粗效果, 而 (Done) 则没有. &lt;style&gt; td &gt; *:first-child {font-weight: bold} &lt;/style&gt; // ... &lt;body&gt; &lt;div id=&quot;todoPanel&quot; class=&quot;panel&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;h3 class=&quot;panel-header&quot;&gt;To Do List&lt;/h3&gt; &lt;div class=&quot;checkbox well&quot;&gt; &lt;label&gt; &lt;input type=&quot;checkbox&quot; ng-model=&quot;todos[2].complete&quot; /&gt; Item 3 is complete &lt;/label&gt; &lt;/div&gt; &lt;table class=&quot;table&quot;&gt; &lt;thead&gt; &lt;tr&gt;&lt;th&gt;#&lt;/th&gt;&lt;th&gt;Action&lt;/th&gt;&lt;th&gt;Done&lt;/th&gt;&lt;/tr&gt; &lt;/thead&gt; &lt;tr ng-repeat=&quot;item in todos&quot;&gt; &lt;td&gt;{ {$index + 1} }&lt;/td&gt; &lt;td&gt;{ {item.action} }&lt;/td&gt; &lt;td&gt; &lt;span ng-hide=&quot;item.complete&quot;&gt;(Incomplete)&lt;/span&gt; &lt;span ng-show=&quot;item.complete&quot;&gt;(Done)&lt;/span&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt; &lt;/body&gt; 2. ng-if&lt;td&gt; &lt;span ng-if=&quot;!item.complete&quot;&gt;(Incomplete)&lt;/span&gt; &lt;span ng-if=&quot;item.complete&quot;&gt;(Done)&lt;/span&gt; &lt;/td&gt; 不能在同一个元素上, 同时使用 ng-repeat 和 ng-if 指令. 3. ng-class, ng-class-odd, ng-class-even用于将元素添加到类中或者设置单个 CSS 属性的指令.ng-class 可以管理一个元素的 class 属性. &lt;tr ng-repeat=&quot;item in todos&quot; ng-class=&quot;settings.Rows&quot;&gt; ... &lt;/tr&gt; ng-class-odd 和 ng-class-even 配置 ng-repeat 使用, 用于 仅对 奇数或偶数行的元素应用 CSS 类. &lt;tr ng-repeat=&quot;item in todos&quot; ng-class-even=&quot;settings.Rows&quot; ng-class-odd=&quot;settings.Columns&quot;&gt; 4. ng-style用于将元素添加到类中或者设置单个 CSS 属性的指令.使用 ng-style 直接设置 CSS 属性, 而不是通过一个 CSS 类. &lt;td ng-style=&quot;{&apos;background-color&apos;: settings.Columns}&quot;&gt; { {item.complete} } &lt;/td&gt; 四. 事件处理事件处理指令可以直接用于直接计算一个表达式, 或者调用控制器中的一个行为. 指令 用作 描述 ng-blur 属性,类 为 blur 事件制定自定义行为, 在元素失去焦点时被触发 ng-change 属性,类 为 change 事件制定自定义行为, 在表单元素的内容状态发生变化时被触发(例如复选框被选中,输入框元素中的文本被修改等) ng-click 属性,类 为 click 事件指定自定义行为, 在用户点击鼠标/光标时被触发 ng-copy, ng-cut, ng-paste 属性,类 为 copy,cut,paste 事件指定自定义行为 ng-dbclick 属性,类 为 dbclick 事件指定自定义行为, 在用户双击鼠标/光标时被触发 ng-focus 属性,类 为 focus 事件指定自定义行为, 在元素获得焦点时被触发 ng-keydown, ng-keypress, ng-keyup 属性,类 为 keydown,keypress,keyup 事件指定自定义行为, 在用户按下,释放某个键时被触发 ng-mousedown, ng-mouseenter,ng-mouseleave, ng-mousemove,ng-mouseover,ng-mouseup 属性,类 为 6个标准鼠标事件事件指定自定义行为, 在用户使用鼠标/光标与元素发生交互时被触发 ng-submit 属性,类 为 submit 事件指定自定义行为, 在表单被提交时被触发 $scope.handleEvent = function (e) { console.log(&quot;Event type: &quot; + e.type); $scope.data.columnColor = e.type == &quot;mouseover&quot; ? &quot;Green&quot; : &quot;Blue&quot;; } // ... &lt;table class=&quot;table&quot;&gt; &lt;thead&gt; &lt;tr&gt;&lt;th&gt;#&lt;/th&gt;&lt;th&gt;Action&lt;/th&gt;&lt;th&gt;Done&lt;/th&gt;&lt;/tr&gt; &lt;/thead&gt; &lt;tr ng-repeat=&quot;item in todos&quot; ng-class=&quot;data.rowColor&quot; ng-mouseenter=&quot;handleEvent($event)&quot; ng-mouseleave=&quot;handleEvent($event)&quot;&gt; &lt;td&gt;{ {$index + 1} }&lt;/td&gt; &lt;td&gt;{ {item.action} }&lt;/td&gt; &lt;td ng-class=&quot;data.columnColor&quot;&gt;{ {item.complete} }&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 五. 布尔属性指令映射指令, 用于在 AngularJS 所依赖的数据绑定的方式和那些被称为布尔属性的 HTML 特性之间进行映射. 指令 用作 描述 ng-checked 属性 管理 checked 属性(在 input 元素上使用) ng-disabled 属性 管理 disabled 属性(在 input 和 button 上使用) ng-open 属性 管理 open 属性 (在 details 元素上使用) ng-readonly 属性 管理 readonly 属性(在 input 元素上使用) ng-selected 属性 管理 select 属性(在 option 元素上使用) ng-href 属性 在 a 元素上设置 href 属性 ng-src 属性 在 img 元素上设置 src 属性 ng-srcset 属性 在 img 元素上设置 srcset 属性. srcset 属性时扩展到 html5 的起草标准之一, 允许为显示不同的大小和像素密度而指定多张图片 &lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&quot;defaultCtrl&quot;, function ($scope) { $scope.dataValue = false; }); &lt;/script&gt; // ... &lt;div class=&quot;checkbox well&quot;&gt; &lt;label&gt; &lt;input type=&quot;checkbox&quot; ng-model=&quot;dataValue&quot;&gt; Set the Data Value &lt;/label&gt; &lt;/div&gt; &lt;button class=&quot;btn btn-success&quot; ng-disabled=&quot;dataValue&quot;&gt;My Button&lt;/button&gt; 六 表单验证1 数据绑定1.1 ng-model 双向数据绑定双向数据绑定与表单元素有内在的关联性, 因为通过他可以接受用户输入数据并更新模型. &lt;table class=&quot;table&quot;&gt; &lt;thead&gt; &lt;tr&gt;&lt;th&gt;#&lt;/th&gt;&lt;th&gt;Action&lt;/th&gt;&lt;th&gt;Done&lt;/th&gt;&lt;/tr&gt; &lt;/thead&gt; &lt;tr ng-repeat=&quot;item in todos&quot;&gt; &lt;td&gt;{ {$index + 1} }&lt;/td&gt; &lt;td&gt;{ {item.action} }&lt;/td&gt; &lt;td&gt; &lt;input type=&quot;checkbox&quot; ng-model=&quot;item.complete&quot; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 1.2. 隐式的创建模型属性使用表单元素收集用户输入数据, 以便在数据模型中创建一个新的对象或属性. &lt;div class=&quot;well&quot;&gt; &lt;div class=&quot;form-group row&quot;&gt; &lt;label for=&quot;actionText&quot;&gt;Action:&lt;/label&gt; &lt;input id=&quot;actionText&quot; class=&quot;form-control&quot; ng-model=&quot;newTodo.action&quot;&gt; &lt;/div&gt; &lt;div class=&quot;form-group row&quot;&gt; &lt;label for=&quot;actionLocation&quot;&gt;Location:&lt;/label&gt; &lt;select id=&quot;actionLocation&quot; class=&quot;form-control&quot; ng-model=&quot;newTodo.location&quot;&gt; &lt;option&gt;Home&lt;/option&gt; &lt;option&gt;Office&lt;/option&gt; &lt;option&gt;Mall&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;button class=&quot;btn btn-primary btn-block&quot; ng-click=&quot;addNewItem(newTodo)&quot;&gt; Add &lt;/button&gt; &lt;/div&gt; # 当网页被首次加载时, newTodo 对象及其 action 和 location 属性并不存在. 在 input 元素或者 select 元素改变时, AngularJS 将会自动创建出 newTodo 对象, 并根据用户正在使用的是哪个元素, 赋值给该对象的 action 或 location 属性. 隐式创建和对象非常灵活, 但有时可能对象尚未创建. AngularJS 访问尚未创建的对象, 会报错, 因此检查所创建的数据模型对象尤其重要.angular.isDefined(obj[.attr])可以检查定义的属性或对象是否生成. $scope.addNewItem = function (newItem) { if (angular.isDefined(newItem) &amp;&amp; angular.isDefined(newItem.action) &amp;&amp; angular.isDefined(newItem.location)) { $scope.todos.push({ action: newItem.action + &quot; (&quot; + newItem.location + &quot;)&quot;, complete: false }); } }; 2 校验表单2.1 增加表单元素AngularJS 对表单校验的支持主要是基于对标准 HTML 元素进行替换的. &lt;form name=&quot;myForm&quot; novalidate ng-submit=&quot;addUser(newUser)&quot;&gt; name=&quot;myForm&quot;属性 替换表单元素的指令, 将会定义一些有用的变量, 用于表示表单数据的有效性, 并且通过 name 属性的值, 来访问这些变量值. novalidate属性 用于禁用浏览器支持的校验功能, 并启用 AngularJS 校验功能. novalidate 属性定义于 HTML5 规范之中, 用于告诉浏览器不要自己校验表单, 从而允许 AngularJS 不受干扰的工作. ng-submit=&quot;FUNC(param)&quot;指令 ng-submit 指令为表单提交事件指定了一个自定义的响应行为, 将在用户提交表单时触发. 2.2 使用校验属性将标准 HTML 校验属性应用到 input 元素上. &lt;label&gt;Name:&lt;/label&gt; &lt;input name=&quot;userName&quot; type=&quot;text&quot; class=&quot;form-control&quot; required ng-model=&quot;newUser.name&quot;&gt; &lt;label&gt;Email:&lt;/label&gt; &lt;input name=&quot;userEmail&quot; type=&quot;email&quot; class=&quot;form-control&quot; required ng-model=&quot;newUser.email&quot;&gt; name 属性 正如 form 元素那样, 为各个想要验证的元素添加 name 属性是非常重要的, 这样就可以访问到 AngularJS 所提供的各种特殊变量. type 属性 type 属性指定了 input 元素接收的数据类型. HTML5 为 input 元素定义了 type 属性值的一个新集合, 以及可以被 AngularJS 所校验的值. input 元素的 type 属性 | 属性值 | 描述 | | — | — | | checkbox | 创建一个复选框 | | email | 创建一个接受邮件地址作为输入值的文本输入框 | | number | 创建一个接受数值类型为值得文本输入框 | | radio | 创建一个单选框 | | text | 创建一个接受任何值的标准文本输入框 | | url | 创建一个接受 URL 作为值得输入框 | | 注意 | 邮件地址和 URL 的校验式校验格式, 而不是检查地址或 URL 是否存在或被使用. | 混合使用 html 标准属性和 AngularJS 指令, 实现进一步约束. required : 指定用户必须为待校验的表单提供一个输入值. 2.3 监控表单的有效性AngularJS 中用来替换标准表单元素的指令, 定义了一些特殊变量, 可以用来检查表单中各个元素或者整个表单的有效性状态. 这些变量可以联合使用, 以向用户展示校验错误的反馈信息. 表单指令所定义的校验变量 变量 描述 $pristine 如果用户没有与元素/表单产生交互, 返回 true $dirty 如果用户与元素/表单产生过交互, 返回 true $valid 当元素/表单内容的校验结果为有效时, 返回 true $invalid 当元素/表单内容的校验结果为无效时, 返回 true $error 提供校验错误的详细信息. 示例代码: &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary btn-block&quot; ng-disabled=&quot;myForm.$invalid&quot;&gt; OK &lt;/button&gt; // 当表单校验结果为 false 时, 表单提交按钮禁用. 3 表单校验反馈AngularJS 为报告实时校验信息, 提供两种机制: CSS 类 变量 3.1 使用 CSS 提供校验反馈AngularJS 通过在一个类的集合中增加或者移除被校验的元素, 来报告有效性检查结果, 这一机制可以与 CSS 联合使用, 通过改变元素样式来为用户提供反馈信息. AngularJS 校验中使用到的 CSS 类 变量 描述 ng-pristine 用户未曾交互过的元素, 被添加到这个类 ng-dirty 用户曾经交互过的元素, 被添加到这个类 ng-valid 校验结果为 有效 的元素在这个类中 ng-invalid 校验结果为 无效 的元素在这个类中 ① 基本 CSS 校验信息 在每次用户交互之后, AngularJS 会从这些类中添加或移除正在被校验的元素, 也就是说可以使用这些类来向用户提供按键和单击的及时反馈, 无论是这个表单还是单个元素. &lt;style&gt; form .ng-invalid.ng-dirty { background-color: lightpink; } form .ng-valid.ng-dirty { background-color: lightgreen; } span.summary.ng-invalid { color: red; font-weight: bold; } span.summary.ng-valid { color: green; } &lt;/style&gt; // ... &lt;div class=&quot;well&quot;&gt; Message: { {message} } &lt;div&gt; Valid: &lt;span class=&quot;summary&quot; ng-class=&quot;myForm.$valid ? &apos;ng-valid&apos; : &apos;ng-invalid&apos;&quot;&gt; { {myForm.$valid} } &lt;/span&gt; &lt;/div&gt; 在 HTML 页面中, 在发生交互之前, 所有元素都是 ng-pristine 类的成员. 内容有效的元素时 ng-valid 类的成员 内容无效的是 ng-invalid 类的成员, 在 CSS 选这起中将 ng-valid , ng-invalid, ng-dirty 联合使用时, 意味着直到用户开始与元素进行交互时, 才提供关于元素有效性的实时反馈. ② 扩展的校验信息 上面的表中的列出的类给出了一个校验元素的整体提示信息, 但是 AngularJS 也会将元素添加到类中, 已给出关于应用到该元素的每一个校验约束的具体信息. 所使用的名字是基于相应的元素的. &lt;style&gt; form .ng-invalid-required.ng-dirty { background-color: lightpink; } form .ng-invalid-email.ng-dirty { background-color: lightgoldenrodyellow; } // 这里将两个检验约束应用到一个 input 元素上, 使用 required 属性要求必须输入一个值, 并且将 type 属性设置为 email 要求改属性必须为邮箱地址格式. AngularJS 遵守 required 属性的限制, 将把该元素添加到 ng-valid-required 和 ng-invalid-required 类中, 并准守格式限制使用 ng-valid-email 和 ng-invalid-email 类. form .ng-valid.ng-dirty { background-color: lightgreen; } span.summary.ng-invalid {color: red; font-weight: bold; } span.summary.ng-valid { color: green } &lt;/style&gt; 使用这些类是必须小心, 因为对于一个元素来说,有可能对于一个约束是有效的, 但对于另一个却不是. 如 对于 type 属性为 email 的元素来说, 在输入为空时是有效的, 也就是说, 该元素此时即在 ng-valid-email 类中, 也在 ng-invalid-required 类中. 这是 HTML 规范的产物, 所以进行完整的测试时必要的. 3.2 使用特殊变量提供校验反馈 ng-disable &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary btn-block&quot; ng-disabled=&quot;myForm.$invalid&quot;&gt;OK&lt;/button&gt; ng-show &lt;div class=&quot;error&quot; ng-show=&quot;myForm.userEmail.$invalid &amp;&amp; myForm.userEmail.$dirty&quot;&gt; &lt;span ng-show=&quot;myForm.userEmail.$error.email&quot;&gt; Please enter a valid email address &lt;/span&gt; &lt;span ng-show=&quot;myForm.userEmail.$error.required&quot;&gt; Please enter a value &lt;/span&gt; &lt;/div&gt; 4 使用表单指令属性AngularJS 通过使用指令提供了一些自由的表单特性, 能够用于替换标准表单元素, 如 input,form,select . 这些指令都支持一些可选的属性, 可以用于将表单元素更紧密的集成到 AngularJS 风格的应用开发中去. 4.1 input 元素 名称 描述 ng-model 用于指定双向绑定的模型 ng-change 用于指定一个表达式, 该表达式在元素内容被改变时被计算求值 ng-minlength 设置一个合法元素的最小字符数 ng-maxlength 设置一个合法元素的最大字符数 ng-pattern 设置一个正则表达式, 合法的元素内容必须匹配该这则表达式 ng-required 通过数据绑定设置 required 属性 ***注意**: - 上表中的属性,仅在 input 元素**没有**使用 type 属性或者 type 属性为 text, url, email, 和 number 时适用. - 当 type 属性值为 email, url, member 时, AngularJS 将会自动设置 ng-pattern 属性为相应的正则表达式, 并检查格式是否匹配. 对于这些类型的 input 元素不应再设置 ng-pattern 属性. &lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&quot;defaultCtrl&quot;, function ($scope) { $scope.requireValue = true; $scope.matchPattern = new RegExp(&quot;^[a-z]&quot;); }); &lt;/script&gt; // ... &lt;div id=&quot;todoPanel&quot; class=&quot;panel&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;form name=&quot;myForm&quot; novalidate&gt; &lt;div class=&quot;well&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Text:&lt;/label&gt; &lt;input name=&quot;sample&quot; class=&quot;form-control&quot; ng-model=&quot;inputValue&quot; ng-required=&quot;requireValue&quot; ng-minlength=&quot;3&quot; ng-maxlength=&quot;10&quot; ng-pattern=&quot;matchPattern&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;well&quot;&gt; &lt;p&gt;Required Error: { {myForm.sample.$error.required} }&lt;/p&gt; &lt;p&gt;Min Length Error: { {myForm.sample.$error.minlength} }&lt;/p&gt; &lt;p&gt;Max Length Error: { {myForm.sample.$error.maxlength} }&lt;/p&gt; &lt;p&gt;Pattern Error: { {myForm.sample.$error.pattern} }&lt;/p&gt; &lt;p&gt;Element Valid: { {myForm.sample.$valid} }&lt;/p&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; 4.2 checkbox 元素当 type 属性为 checkbox 时, 可用于 input 元素的额外属性. 名称 描述 ng-model 指定双向绑定的模型 ng-chenge 用于指定一个表达式, 该表达式在元素内容被改变时被计算求值 ng-true-value 指定当元素被勾选中时所绑定的表达式的值 ng-false-value 指定当元素被取消勾选中时所绑定的表达式的值 &lt;form name=&quot;myForm&quot; novalidate&gt; &lt;div class=&quot;well&quot;&gt; &lt;div class=&quot;checkbox&quot;&gt; &lt;label&gt; &lt;input name=&quot;sample&quot; type=&quot;checkbox&quot; ng-model=&quot;inputValue&quot; ng-true-value=&quot;Hurrah!&quot; ng-false-value=&quot;Boo!&quot;&gt; This is a checkbox &lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;well&quot;&gt; &lt;p&gt;Model Value: { {inputValue} }&lt;/p&gt; &lt;/div&gt; &lt;/form&gt; // 此示例中, inputValue 的值等于 ng-true-value 或 ng-false-value 的值. ng-true-value 和 ng-false-value 属性的值将被用于设置所绑定的表达式的值, 但是只在当复选框的勾选状态被改变时生效, 也就是模型属性(如果被印式定义过的话)不会被自动创建, 直到有用户与元素的交互产生时才会被创建 (即使设置了 ng-checked 也是如此). 4.3 textare 元素 名称 描述 ng-model 用于指定双向绑定的模型 ng-change 用于指定一个表达式, 该表达式在元素内容被改变时被计算求值 ng-minlength 设置一个合法元素的最小字符数 ng-maxlength 设置一个合法元素的最大字符数 ng-pattern 设置一个正则表达式, 合法的元素内容必须匹配该这则表达式 ng-required 通过数据绑定设置 required 属性 &lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&quot;defaultCtrl&quot;, function ($scope) { $scope.requireValue = true; $scope.matchPattern = new RegExp(&quot;^[a-z]&quot;); }); &lt;/script&gt; // ... &lt;div id=&quot;todoPanel&quot; class=&quot;panel&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;form name=&quot;myForm&quot; novalidate&gt; &lt;div class=&quot;well&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Text:&lt;/label&gt; &lt;textarea name=&quot;sample&quot; cols=&quot;40&quot; rows=&quot;3&quot; ng-model=&quot;inputValue&quot; ng-required=&quot;requireValue&quot; ng-minlength=&quot;3&quot; ng-maxlength=&quot;10&quot; ng-pattern=&quot;matchPattern&quot;&gt;&lt;/textarea&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;well&quot;&gt; &lt;p&gt;Required Error: { {myForm.sample.$error.required} }&lt;/p&gt; &lt;p&gt;Min Length Error: { {myForm.sample.$error.minlength} }&lt;/p&gt; &lt;p&gt;Max Length Error: { {myForm.sample.$error.maxlength} }&lt;/p&gt; &lt;p&gt;Pattern Error: { {myForm.sample.$error.pattern} }&lt;/p&gt; &lt;p&gt;Element Valid: { {myForm.sample.$valid} }&lt;/p&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; 4.4 select 元素AngularJS 用于 select 元素的指令包括: 与 input 元素类似的 ng-required 属性 可用于从数组和对象中生成 option 元素的 ng-options 属性. &lt;script type=&quot;text/javascript&quot;&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&apos;defaultCtrl&apos;, function ($scope) { $scope.todos = [ {id: 100, action: &quot;Get groceries&quot;, complete: false}, {id: 200, action: &quot;Call plumber&quot;, complete: false}, {id: 300, action: &quot;Buy running shoes&quot;, complete: true}, {id: 400, action: &quot;Do somethins&quot;, complete: false}, ] }); &lt;/script&gt; // ... &lt;form name=&quot;myForm&quot; novalidate&gt; &lt;div class=&quot;well&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label&gt;Select a Action:&lt;/label&gt; &lt;select ng-model=&quot;selectValue&quot; ng-options=&quot;item.action for item in todos&quot;&gt; &lt;/select&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;well&quot;&gt; &lt;p&gt;Selected : { { selectValue || &quot;None&quot;} }&lt;/p&gt; &lt;/div&gt; &lt;/form&gt; ng-options的表现形式 基本形式 格式 : &lt;标签&gt; for &lt;项目&gt; in &lt;数组&gt; ng-model 的值为一个对象. &lt;select ng-model=&quot;selectValue&quot; ng-options=&quot;item.action for item in todos&quot;&gt; &lt;/select&gt; 改变第一个选项元素 ng-model 的值为一个对象. 当 AngularJS 在 ng-model 属性所指向的变量值为 undefined 时会生成这样的元素. 可以添加一个空值的 option 元素来代替默认的 option 元素. &lt;select ng-model=&quot;selectValue&quot; ng-options=&quot;item.action for item in todos&quot;&gt; &lt;option value=&quot;&quot;&gt;(pick one)&lt;/option&gt; &lt;/select&gt; // 当前情况下, 当用户选定选项时 ng-model 的值会被更新为 集合中的一个 对象 . 当没有指定第一项时, 第一项的结果为 &lt;option value=&quot;?&quot; selected=&quot;selected&quot;&gt;&lt;/option&gt; 改变选项值 表达式 : &lt;所选属性&gt; as &lt;标签&gt; for &lt;变量&gt; in &lt;数组&gt; &lt;select ng-model=&quot;selectValue&quot; ng-options=&quot;item.action as item.id for item in todos&quot;&gt; &lt;option value=&quot;&quot;&gt;(pick one)&lt;/option&gt; &lt;/select&gt; 选项组元素 ng-options 属性可以用来按照某个属性值将各个选项进行分组, 为每个选项值生成一组 optgroup 元素. &lt;script type=&quot;text/javascript&quot;&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&apos;defaultCtrl&apos;, function ($scope) { $scope.todos = [ {id: 100, action: &quot;Get groceries&quot;, complete: false, place: &quot;Store&quot;}, {id: 200, action: &quot;Call plumber&quot;, complete: false, place: &quot;Home&quot;}, {id: 300, action: &quot;Buy running shoes&quot;, complete: true, place: &quot;Store&quot;}, {id: 400, action: &quot;Do somethins&quot;, complete: false, place: &quot;Home&quot;}, ] }); &lt;/script&gt; // ... &lt;select ng-model=&quot;selectValue&quot; ng-options=&quot;item.action as item.id group by item.place for item in todos&quot;&gt; &lt;option value=&quot;&quot;&gt;(pick one)&lt;/option&gt; &lt;/select&gt;]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>angularjs</tag>
        <tag>前端框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AngularJS高级程序设计读书笔记--模块篇]]></title>
    <url>%2F2018%2F03%2F16%2FAngularJS%E9%AB%98%E7%BA%A7%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E6%A8%A1%E5%9D%97%E7%AF%87%2F</url>
    <content type="text"><![CDATA[一. 模块基础1. 创建模块1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html ng-app=&quot;exampleApp&quot;&gt;&lt;head&gt; &lt;title&gt;Test&lt;/title&gt; &lt;script type=&quot;text/javascript&quot;&gt; var myApp = angular.module(&quot;exampleApp&quot;, []); myApp.controller(&apos;dayCtrl&apos;, function ($scope) &#123; // controller statements will go here &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;panel&quot; ng-controller=&quot;dayCtrl&quot;&gt; &lt;!-- HTML code here --&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 模块的三种重要角色: 将一个 AngularJS 应用程序 与 HTML 文档中的一部分相关联 起到通往 AngularJS 框架的关键特性的门户作用. 帮助组织一个 AngularJS 应用程序中的代码和组件. angular.module 方法所接受的参数 名称 描述 name 新模块的名称 requires 该模块所以来的模块集合 config 盖默快的配置, 等效于调用 Module.config 方法. angular.module 方法返回一个 Module 对象. 该 Module 对象的成员方法如下表: 名称 描述 animation(name, factory) 支持动画特性, 见 第23章 config(callback) 注册一个在模块加载时对该模块进行配置的函数,见 9.4.1 constant(key, value) 定义一个返回一个常量的服务, 见 9.4.1 controller(name, constructor) 创建一个控制器, 见 13 章 directive(name, factory) 创建一个指令, 对标准HTML词汇进行扩展, 见 15-17 章 factory(name, provider) 创建一个服务, 见 14 章 filter(name, factory) 创建一个对显示给用户的数据进行格式化的过滤器.见 14 章 provider(name, type) 创建一个服务. name 返回模块名称 run(callback) 注册一个在 Angular 加载完毕后用于对所有模块进行配置的函数. service(name, constructor) 创建一个服务 value(name, value) 定义一个返回一个常量的服务. factory, service, provider 的区别 见 14,18 章 可以按照任何顺序创建组件, AngularJS 将保证在开始调用工厂函数和执行依赖注入之前一切都已正确创建. 2. fluent APIModule 对象定义的方法返回的结果仍然是 Module 对象本身. 这是的能够使用 fluent API , 即多个方法调用可以链式调用链接在一起.如下示例: &lt;script type=&quot;text/javascript&quot;&gt; angular.module(&apos;exampleApp&apos;, []) .controller(&apos;dayCtrl&apos;, [&apos;$scope&apos;, function ($scope) { var dayName = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Staturday&quot;] $scope.day = dayName[new Date().getDay()]; }]) .controller(&apos;tomorrowCtrl&apos;, [&apos;$scope&apos;, function ($scope) { var dayName = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Staturday&quot;] $scope.day = dayName[(new Date().getDay() + 1) % 7] }]) &lt;/script&gt; # angular.module 方法得到 Module 对象作为返回结果, 在这个对象上直接调用 controller 方法创建 dayCtrl 控制器. 从 controller 方法得到的结果与调用 angular.module 方法得到的结果是同一个 Module 对象, 所以可以使用它调用 controller 方法来创建 tomorrowCtrl . 3. ng-app 与 模块将 ng-app 指令应用到 HTML 中. ng-app 属性是在 AngularJS 生命周期的 bootstrap 阶段被使用. 4. 模块创建/查找陷阱12var myApp = angular.module(&apos;exampleApp&apos;); # 查找名称为 exampleApp 的模块var myApp = angular.module(&apos;exampleApp&apos;, []); # 创建名称为 exampleApp 的模块 二. 使用模块组织代码1. 模块依赖任何 AngularJS 模块都可以依赖于在其他模块中定义的组件, 在复杂的应用程序中这是一个能够使得组织代码更为容易的特性. 模块的定义可以按照任何顺序定义. AngularJS 会加载定义在程序中的所有模块并解析依赖, 将每个模块中包含的构件进行合并.这个合并使得无缝的使用来来自其他模块的功能成为可能.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;script&gt; var controllersModule = angular.module(&quot;exampleApp.Controllers&quot;, []) controllersModule.controller(&quot;dayCtrl&quot;, function ($scope, days) &#123; $scope.day = days.today; &#125;); controllersModule.controller(&quot;tomorrowCtrl&quot;, function ($scope, days) &#123; $scope.day = days.tomorrow; &#125;); angular.module(&quot;exampleApp.Filters&quot;, []).filter(&quot;dayName&quot;, function () &#123; var dayNames = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;]; return function (input) &#123; return angular.isNumber(input) ? dayNames[input] : input; &#125;; &#125;); var myApp = angular.module(&quot;exampleApp&quot;, [&quot;exampleApp.Controllers&quot;, &quot;exampleApp.Filters&quot;, &quot;exampleApp.Services&quot;, &quot;exampleApp.Directives&quot;]); // 依赖注入. angular.module(&quot;exampleApp.Directives&quot;, []) .directive(&quot;highlight&quot;, function ($filter) &#123; var dayFilter = $filter(&quot;dayName&quot;); return function (scope, element, attrs) &#123; if (dayFilter(scope.day) == attrs[&quot;highlight&quot;]) &#123; element.css(&quot;color&quot;, &quot;red&quot;); &#125; &#125; &#125;); var now = new Date(); myApp.value(&quot;nowValue&quot;, now); angular.module(&quot;exampleApp.Services&quot;, []) .service(&quot;days&quot;, function (nowValue) &#123; this.today = nowValue.getDay(); this.tomorrow = this.today + 1; &#125;);&lt;/script&gt;// 模块的定义可以按照任何顺序定义. AngularJS 会加载定义在程序中的所有模块并解析依赖, 将每个模块中包含的构件进行合并.这个合并使得无缝的使用来来自其他模块的功能成为可能.如 exmapleApp.service 模块中的 days 服务依赖来自于 exampleApp 模块中的 nowValue 值服务, exmapleApp.directives 模块中指令依赖于来自 exampleApp.filter 模块中的过滤器. 2. Module.controller(name, constructor) 控制器控制器是模型和视图之间的桥梁. 2.1 多个视图每个控制器可以支持多个视图, 者语序同一份数据以多种不同的形式展现, 或者有效的创建和管理紧密相关的数据. 12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;/html&gt;&lt;html ng-app=&quot;exampleAPP&quot;&gt; &lt;head&gt; &lt;title&gt;Hello AngularJS&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;bootstrap.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;bootstrap-theme.css&quot;&gt; &lt;script src=&apos;js/angular.js&apos;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var myApp = angular.module(&quot;exampleAPP&quot;, []); myApp.controller(&apos;dayCtrl&apos;, [&apos;$scope&apos;, function ($scope) &#123; var dayNames = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;]; $scope.dat = dayNames[new Date().getDay()]; $scope.tomorrow = dayNames[(new Date().getDay() + 1) % 7]; &#125;]); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;page-header&quot;&gt; &lt;h3&gt; AngularJS App&lt;/h3&gt; &lt;h4 ng-controller=&quot;dayCtrl&quot;&gt;Today is &#123;&#123;day || &quot;(unknown)&quot;&#125;&#125; &lt;/h4&gt; &lt;h4 ng-controller=&quot;dayCtrl&quot;&gt;Tomorrow is &#123;&#123;tomorrow || &quot;(unknown)&quot;&#125;&#125; &lt;/h4&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 2.2 多个控制器在多个控制器的场景下, 每个控制器负责程序功能的不同方面, 并且都具有自己的关于整个应用程序的作用域的一部分, 各自属性相互隔离.12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html ng-app=&quot;exampleAPP&quot;&gt; &lt;head&gt; &lt;title&gt;Hello AngularJS&lt;/title&gt; &lt;!-- &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;bootstrap.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;bootstrap-theme.css&quot;&gt; --&gt; &lt;script src=&apos;js/angular.js&apos;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var myApp = angular.module(&quot;exampleAPP&quot;, []); myApp.controller(&apos;dayCtrl&apos;, function ($scope) &#123; var dayNames = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;]; $scope.day = dayNames[new Date().getDay()]; &#125;); myApp.controller(&apos;tomorrowCtrl&apos;, function ($scope) &#123; var dayNames = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;]; $scope.day = dayNames[(new Date().getDay() + 1) % 7]; &#125;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;page-header&quot;&gt; &lt;h3&gt; AngularJS App&lt;/h3&gt; &lt;h4 ng-controller=&quot;dayCtrl&quot;&gt;Today is &#123;&#123;day || &quot;(unknown)&quot;&#125;&#125; &lt;/h4&gt; &lt;h4 ng-controller=&quot;tomorrowCtrl&quot;&gt;Tomorrow is &#123;&#123;day || &quot;(unknown)&quot;&#125;&#125; &lt;/h4&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 3. Module.directive 指令定义指令可以扩展并增强 HTML, 从而创建丰富的功能和 web 程序. 3.1 内置指令3.2 自定义指令.创建自定义指令, 有多种方法, 如下为一种之示例.1234567891011121314151617181920212223242526272829303132333435363738&lt;!DOCTYPE html&gt;&lt;html ng-app=&quot;exampleAPP&quot;&gt; &lt;head&gt; &lt;title&gt;Hello AngularJS&lt;/title&gt; &lt;!-- &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;bootstrap.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;bootstrap-theme.css&quot;&gt; --&gt; &lt;script src=&apos;js/angular.js&apos;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var myApp = angular.module(&quot;exampleAPP&quot;, []); myApp.controller(&apos;dayCtrl&apos;, function ($scope) &#123; var dayNames = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;]; $scope.day = dayNames[new Date().getDay()]; &#125;); myApp.controller(&apos;tomorrowCtrl&apos;, function ($scope) &#123; var dayNames = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;]; $scope.day = dayNames[(new Date().getDay() + 1) % 7]; &#125;); myApp.directive(&apos;highlight&apos;, function () &#123; return function (scope, element, attrs)&#123; // scope: 视图的作用域; element: 指令所应用的元素, jsLite 对象; attrs: 该元素的属性集合. if (scope.day == attrs[&quot;highlight&quot;]) &#123; element.css(&quot;color&quot;, &quot;red&quot;); &#125; &#125; &#125;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;page-header&quot;&gt; &lt;h3&gt; AngularJS App&lt;/h3&gt; &lt;h4 ng-controller=&quot;dayCtrl&quot; highlight=&quot;Sunday&quot;&gt;Today is &#123;&#123;day || &quot;(unknown)&quot;&#125;&#125; &lt;/h4&gt; &lt;h4 ng-controller=&quot;tomorrowCtrl&quot;&gt;Tomorrow is &#123;&#123;day || &quot;(unknown)&quot;&#125;&#125; &lt;/h4&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 4. Module.filter 过滤器过滤器用于在视图中格式化展现给用户的数据, 一旦定义过滤器之后, 就可在整个模块中全面应用. 过滤器本身是函数, 就收数据值并进行格式化. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;!DOCTYPE html&gt;&lt;html ng-app=&quot;exampleAPP&quot;&gt; &lt;head&gt; &lt;title&gt;Hello AngularJS&lt;/title&gt; &lt;!-- &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;bootstrap.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;bootstrap-theme.css&quot;&gt; --&gt; &lt;script src=&apos;js/angular.js&apos;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var myApp = angular.module(&quot;exampleAPP&quot;, []); myApp.controller(&apos;dayCtrl&apos;, function ($scope) &#123; var dayNames = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;]; $scope.day = dayNames[new Date().getDay()]; &#125;); myApp.controller(&apos;tomorrowCtrl&apos;, function ($scope) &#123; var dayNames = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;]; $scope.day = dayNames[(new Date().getDay() + 1) % 7]; &#125;); myApp.directive(&apos;highlight&apos;, function ($filter) &#123; // 将过滤器应用于 自定义指令. var dayFilter = $filter(&quot;dayName&quot;) return function (scope, element, attrs)&#123; // scope: 视图的作用域; element: 指令所应用的元素, jsLite 对象; attrs: 该元素的属性集合. if (dayFilter(scope.day) == attrs[&quot;highlight&quot;]) &#123; element.css(&quot;color&quot;, &quot;red&quot;); &#125; &#125; &#125;); // 定义过滤器 myApp.filter(&quot;dayName&quot;, function() &#123; var dayNames = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;]; return function(input) &#123; return angular.isNumber(input)? dayNames[input]: input; &#125;; &#125;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;page-header&quot;&gt; &lt;h3&gt; AngularJS App&lt;/h3&gt; &lt;h4 ng-controller=&quot;dayCtrl&quot; highlight=&quot;Sunday&quot;&gt;Today is &#123;&#123;day || &quot;(unknown)&quot;&#125;&#125; &lt;/h4&gt; &lt;h4 ng-controller=&quot;tomorrowCtrl&quot;&gt;Tomorrow is &#123;&#123;day || &quot;(unknown)&quot; | dayName&#125;&#125; &lt;/h4&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 5. 服务服务是提供在整个应用程序中所用的任何功能的额单例对象. 单例, 即只有一个对象实例被 AngularJS 创建出来, 并被程序需要服务的各种不同部分所共享. Module 对象所定义的方法, 有三种不同的方式来创建服务: service, factory, provide. 这三者时紧密相关的. 5.0 内置服务AngularJS 提供一些以 $ 开头的内置服务特性. $scope 该服务请求 AngularJS 为控制器提供作用域. 在创建控制器时制定给参数的 $scope 组件是用于向视图提供数据的, 只有通过 $scope 配置的数据才能用于表达式和数据绑定. 严格说来, $scope 并不是一个服务, 而是一个叫 $rootScope 的服务提供的对象. 在实际应用上, $scope 与服务极为相像, 所以简单起见, 可以成为一个服务. $filter 该服务可以访问所有已定义的过滤器, 包括自定义的过滤器. $filter(&quot;myFilter&quot;) $http 5.1 Module.valueModule.value 用于创建返回固定值和对象的服务. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;!DOCTYPE html&gt;&lt;html ng-app=&quot;exampleAPP&quot;&gt; &lt;head&gt; &lt;title&gt;Hello AngularJS&lt;/title&gt; &lt;!-- &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;bootstrap.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;bootstrap-theme.css&quot;&gt; --&gt; &lt;script src=&apos;js/angular.js&apos;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var myApp = angular.module(&quot;exampleAPP&quot;, []); myApp.controller(&apos;dayCtrl&apos;, function ($scope, days) &#123; $scope.day = days.today; &#125;); myApp.controller(&apos;tomorrowCtrl&apos;, function ($scope, days) &#123; $scope.day = days.tomorrow; &#125;); myApp.directive(&apos;highlight&apos;, function ($filter) &#123; var dayFilter = $filter(&quot;dayName&quot;); return function (scope, element, attrs)&#123; // scope: 视图的作用域; element: 指令所应用的元素, jsLite 对象; attrs: 该元素的属性集合. if (dayFilter(scope.day) == attrs[&quot;highlight&quot;]) &#123; element.css(&quot;color&quot;, &quot;red&quot;); &#125; &#125; &#125;); myApp.filter(&quot;dayName&quot;, function() &#123; var dayNames = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;]; return function(input) &#123; return angular.isNumber(input)? dayNames[input]: input; &#125;; &#125;); // Module.value var now = new Date(); myApp.value(&quot;nowValue&quot;, now) myApp.service(&quot;days&quot;, function(nowValue)&#123; this.today = nowValue.getDay(); this.tomorrow = this.today + 1; &#125;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;page-header&quot;&gt; &lt;h3&gt; AngularJS App&lt;/h3&gt; &lt;h4 ng-controller=&quot;dayCtrl&quot; highlight=&quot;Sunday&quot;&gt;Today is &#123;&#123;day | dayName&#125;&#125; &lt;/h4&gt; &lt;h4 ng-controller=&quot;tomorrowCtrl&quot;&gt;Tomorrow is &#123;&#123;day | dayName&#125;&#125; &lt;/h4&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 5.2 Module.constantModule.constant 与 Module.value 类似, 但是创建的服务能够作为 config 方法所声明的依赖使用( value 不可以). 1myApp.constant(&quot;startTime&quot;, new Date().toLocaleTimeString()); 5.3 Module.service12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;!DOCTYPE html&gt;&lt;html ng-app=&quot;exampleAPP&quot;&gt; &lt;head&gt; &lt;title&gt;Hello AngularJS&lt;/title&gt; &lt;!-- &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;bootstrap.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;bootstrap-theme.css&quot;&gt; --&gt; &lt;script src=&apos;js/angular.js&apos;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; var myApp = angular.module(&quot;exampleAPP&quot;, []); myApp.controller(&apos;dayCtrl&apos;, function ($scope, days) &#123; $scope.day = days.today; &#125;); myApp.controller(&apos;tomorrowCtrl&apos;, function ($scope, days) &#123; $scope.day = days.tomorrow; &#125;); myApp.directive(&apos;highlight&apos;, function ($filter) &#123; var dayFilter = $filter(&quot;dayName&quot;); return function (scope, element, attrs)&#123; // scope: 视图的作用域; element: 指令所应用的元素, jsLite 对象; attrs: 该元素的属性集合. if (dayFilter(scope.day) == attrs[&quot;highlight&quot;]) &#123; element.css(&quot;color&quot;, &quot;red&quot;); &#125; &#125; &#125;); myApp.filter(&quot;dayName&quot;, function() &#123; var dayNames = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;]; return function(input) &#123; return angular.isNumber(input)? dayNames[input]: input; &#125;; &#125;); myApp.service(&quot;days&quot;, function()&#123; this.today = new Date().getDay(); this.tomorrow = this.today + 1; &#125;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;page-header&quot;&gt; &lt;h3&gt; AngularJS App&lt;/h3&gt; &lt;h4 ng-controller=&quot;dayCtrl&quot; highlight=&quot;Sunday&quot;&gt;Today is &#123;&#123;day | dayName&#125;&#125; &lt;/h4&gt; &lt;h4 ng-controller=&quot;tomorrowCtrl&quot;&gt;Tomorrow is &#123;&#123;day | dayName&#125;&#125; &lt;/h4&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 5.4 Module.factory5.5 Module.provider6. Module.config传给 config 方法的函数在当前模块被加载后调用; config 方法接受一个函数, 该函数在调用方法的模块被加载后调用. config 方法通常通过注入来自其他服务的值(如连接的详细信息或用户凭证)的方式用于配置模块. 示例, 见Module.run的示例. 7. Module.run传给 run 方法的函数在所有模块被加载后调用 run 方法接受的函数只会在所有模块加载完成后以及解析完他们的依赖后才会被调用.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;script&gt; var myApp = angular.module(&quot;exampleApp&quot;, [&quot;exampleApp.Controllers&quot;, &quot;exampleApp.Filters&quot;, &quot;exampleApp.Services&quot;, &quot;exampleApp.Directives&quot;]); // constant 方法与 value 方法类似, 但是创建的能够作为 config 方法所声明的依赖使用 (value 服务做不到). myApp.constant(&quot;startTime&quot;, new Date().toLocaleTimeString()); myApp.config(function (startTime) &#123; console.log(&quot;Main module config: &quot; + startTime); &#125;); myApp.run(function (startTime) &#123; console.log(&quot;Main module run: &quot; + startTime); &#125;); angular.module(&quot;exampleApp.Directives&quot;, []) .directive(&quot;highlight&quot;, function ($filter) &#123; var dayFilter = $filter(&quot;dayName&quot;); return function (scope, element, attrs) &#123; if (dayFilter(scope.day) == attrs[&quot;highlight&quot;]) &#123; element.css(&quot;color&quot;, &quot;red&quot;); &#125; &#125; &#125;); var now = new Date(); myApp.value(&quot;nowValue&quot;, now); angular.module(&quot;exampleApp.Services&quot;, []) .service(&quot;days&quot;, function (nowValue) &#123; this.today = nowValue.getDay(); this.tomorrow = this.today + 1; &#125;) .config(function() &#123; console.log(&quot;Services module config: (no time)&quot;); &#125;) .run(function (startTime) &#123; console.log(&quot;Services module run: &quot; + startTime); &#125;);&lt;/script&gt;// 输出Services module config: (no time)Main moule config: 16:57:28Services module run: 16:57:28Main module run: 16:57:28 8. 内置函数 angular.isArray angular.isDate angular.isNumber angular.isString angular.isElement angular.isFunction angular.isObject angular.isDefined angular.isUndefined angular.bind angular.bootstrap angular.copy angular.element angular.equals angular.errorHandlingConfig angular.extend angular.forEach angular.fromJson angular.toJson angular.identity angular.injector angular.merge angular.module angular.noop angular.reloadWithDebugInfo angular.lowercase angular.uppercase]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>angularjs</tag>
        <tag>前端框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AngularJS高级程序设计读书笔记--过滤器篇]]></title>
    <url>%2F2018%2F03%2F16%2FAngularJS%E9%AB%98%E7%BA%A7%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E8%BF%87%E6%BB%A4%E5%99%A8%E7%AF%87%2F</url>
    <content type="text"><![CDATA[一. 过滤器基础过滤器用于在视图中格式化展现给用户的数据. 一旦定义过滤器之后, 就可在整个模块中全面应用, 也就意味着可以用来保证跨多个控制器和视图之间的数据展示的一致性. 过滤器将数据在被指令处理并显示到视图中之前进行转换, 而不必修改作用域中原有的数据, 这样能够允许同一份数据在应用中的不同部分以不同的形式得以展现. 过滤器可以执行任意类型的转换, 但是大多数情况下, 用于格式化或者对数据以某种方式排序. 二. 内置过滤器1. 过滤单个数据的值 名称 描述 currency 该过滤器对货币值进行格式化 date 对日期进行格式化 json 从 JSON 字符串中生成一个对象 number 对数字值进行格式化 uppercase/lowercase 将字符串格式化为全大写或全小写 // currency &lt;td class=&quot;text-right&quot;&gt;{ {p.price | currency:&quot;£&quot; } }&lt;/td&gt; &lt;td class=&quot;text-right&quot;&gt;{ {p.price | currency} }&lt;/td&gt; // number, number:0 , 0 表示显示的小数位数. &lt;td class=&quot;text-right&quot;&gt;${ {p.price | number:0 } }&lt;/td&gt; // date , 格式化日期, 这个日期可以是字符串,JavaScript 日期对象或毫秒数等 &lt;td&gt;{ {getExpiryDate(p.expiry) | date:&quot;dd MMM yy&quot;} }&lt;/td&gt; // uppercase/lowercase &lt;td&gt;{ {p.name | uppercase } }&lt;/td&gt; &lt;td&gt;{ {p.category | lowercase } }&lt;/td&gt; date 过滤器支持的格式化字符串date 过滤器支持的快捷格式化字符串 2. 过滤数据集合 过滤器名称 描述 limitTo 限制项目数量, 支持数组对象,也支持字符串 filter 从数组中华选出一些对象, 选取条件可以为一个表达式,或者一个用于匹配属性的 map 对象 orderBy 对数组中的对象进行排序 // limitTo , 支持正数和负数 &lt;tr ng-repeat=&quot;p in products | limitTo:limitVal&quot;&gt; // filter: {FIELD: NAME}, 只显示某个字段的数据. 如果通过一个函数过滤, 那么选出的项目,僵尸那些是的函数执行结果返回 true 的. &lt;tr ng-repeat=&quot;p in products | filter:{category: &apos;Fish&apos;}&quot;&gt; // 函数式筛选 $scope.selectItems = function (item) { return item.category == &quot;Fish&quot; || item.name == &quot;Beer&quot;; &lt;tr ng-repeat=&quot;p in products | filter:selectItems&quot;&gt; // orderBy: &lt;tr ng-repeat=&quot;p in products | orderBy:&apos;price&apos;&quot;&gt; // 根据对象的 price 属性进行排序. 注意引号 &lt;tr ng-repeat=&quot;p in products | orderBy:&apos;price&apos;&quot;&gt; // price 降序 // 使用排序函数 $scope.myCustomSorter = function (item) { return item.expiry &lt; 5 ? 0 : item.price; } &lt;tr ng-repeat=&quot;p in products | orderBy:myCustomSorter&quot;&gt; // 排序数组, 多次排序 &lt;tr ng-repeat=&quot;p in products | orderBy:[myCustomSorter, &apos;-price&apos;]&quot;&gt; 3. 链式过滤使用多个过滤器, 按照顺序对同一数据进行操作. &lt;tr ng-repeat=&quot;p in products | orderBy:[myCustomSorter, &apos;-price&apos;] | limitTo: 5&quot;&gt; 三. 自定义过滤器Module.filter方法用于定义过滤器, 其参数是新过滤器的名称以及一个在调用时将会创建过滤器的工厂函数. 过滤器本身就是函数, 接受数据值并进行格式化, 这样就可以显示该值了. 示例 : 用于过滤单个数据值的过滤器 // labelCase 用于将字符串格式化为 只有首字母大写. angular.module(&quot;exampleApp&quot;) // 此处用于查找 exampleApp 模块, 在这一段代码被当引用的时候, 应当放在 exampleApp 定义代码的后面. .filter(&quot;labelCase&quot;, function () { return function (value, reverse) { // value 参数是待被过滤的值, 在应用时由 AngularJS 提供; reverse 参数用于允许过滤器用途被颠倒过来. if (angular.isString(value)) { var intermediate = reverse ? value.toUpperCase() : value.toLowerCase(); return (reverse ? intermediate[0].toLowerCase() : intermediate[0].toUpperCase()) + intermediate.substr(1); } else { return value; } }; }); // 在 HTML 代码中使用 &lt;td&gt;{ {p.name | labelCase } }&lt;/td&gt; // 此处没有指定第二个参数, 则 AngularJS 会将 null 值传给过滤器的worker 函数的第二个参数. &lt;td&gt;{ {p.category | labelCase:true } }&lt;/td&gt; 示例 : 用于过滤数据集合的过滤器 // skip 用于返回数据集合中指定数量的元素. angular.module(&quot;exampleApp&quot;) .filter(&quot;labelCase&quot;, function () { return function (value, reverse) { if (angular.isString(value)) { var intermediate = reverse ? value.toUpperCase() : value.toLowerCase(); return (reverse ? intermediate[0].toLowerCase() : intermediate[0].toUpperCase()) + intermediate.substr(1); } else { return value; } }; }) .filter(&quot;skip&quot;, function () { return function (data, count) { if (angular.isArray(data) &amp;&amp; angular.isNumber(count)) { // 边界检查 if (count &gt; data.length || count &lt; 1) { // 边界检查 return data; } else { return data.slice(count); } } else { return data; } } }); // 调用 &lt;tr ng-repeat=&quot;p in products | skip:2 | limitTo: 5&quot;&gt; 示例 : 在已有的过滤器上搭建新的过滤器. // 将 skip 和 limitTo 的功能合并到单个过滤器中. angular.module(&quot;exampleApp&quot;) .filter(&quot;labelCase&quot;, function () { return function (value, reverse) { if (angular.isString(value)) { var intermediate = reverse ? value.toUpperCase() : value.toLowerCase(); return (reverse ? intermediate[0].toLowerCase() : intermediate[0].toUpperCase()) + intermediate.substr(1); } else { return value; } }; }) .filter(&quot;skip&quot;, function () { return function (data, count) { if (angular.isArray(data) &amp;&amp; angular.isNumber(count)) { if (count &gt; data.length || count &lt; 1) { return data; } else { return data.slice(count); } } else { return data; } } .filter(&quot;take&quot;, function ($filter) { // 声明对 $filter 服务的依赖, 这提供了对模块中所有已定义的过滤器的访问能力. 这些过滤器通过在 worker 函数中通过名称来访问和调用. return function (data, skipCount, takeCount) { var skippedData = $filter(&quot;skip&quot;)(data, skipCount); return $filter(&quot;limitTo&quot;)(skippedData, takeCount); } }); // html 中调用 &lt;tr ng-repeat=&quot;p in products | take:2:5&quot;&gt; // 多个参数.]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>angularjs</tag>
        <tag>前端框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AngularJS高级程序设计读书笔记--控制器篇]]></title>
    <url>%2F2018%2F03%2F16%2FAngularJS%E9%AB%98%E7%BA%A7%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E6%8E%A7%E5%88%B6%E5%99%A8%E7%AF%87%2F</url>
    <content type="text"><![CDATA[控制器通过作用域向视图提供数据和逻辑. 作用域组成了一个能够用于在控制器之间形成通信的体系结构. 当控制器声明了对 $scope 服务的依赖时, 就可以使得控制器通过其对应的作用于向试图提供各种能力. 作用于不仅定义了控制器和视图之间的关系, 而且对许多最重要的 AngularJS 特性提供了运转机制, 如数据绑定. 一. 控制器和作用域的基本原理控制器是一个 AngularJS 程序中最大的构件之一, 它扮演了模型和视图之间的渠道的角色. 大多数 AngularJS 项目拥有多个控制器, 每一个向应用程序的一部分提供所需的数据和逻辑. 控制器就像领域模型与视图之间的纽带, 他给视图提供数据与服务, 并且定义了所需的业务逻辑, 从而将用户行为转换成模型上的变化. 控制器从模型中暴露数据给视图, 以及基于用户与视图的交互使模型产生变化所需的逻辑. 控制器可用于向所支持的视图提供作用域. 示例代码:1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html ng-app=&quot;exampleApp&quot;&gt;&lt;head&gt; &lt;title&gt;Controllers&lt;/title&gt; &lt;script src=&quot;angular.js&quot;&gt;&lt;/script&gt; &lt;link href=&quot;bootstrap.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;link href=&quot;bootstrap-theme.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;script&gt; angular.module(&quot;exampleApp&quot;, []); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;well&quot;&gt; Content will go here. &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 1. 创建控制器控制器是通过 AngularJS 的 Module 对象所提供的的 controller 方法创建出来的. controller 方法的参数是新建控制器的名字和一个将被用于创建控制器的函数. 这个函数应被理解为构造器, 也可以看作为一个工厂函数. 控制器名称的命名习惯是使用 Ctrl 后缀. 工厂函数能够使用以来注入特性来声明对 AngularJS 服务的依赖. 几乎每个控制器都要使用 $scope 服务, 用于系那个视图提供作用域, 定义可被视图使用的数据和逻辑. 严格说来, $scope 并不是一个服务, 而是一个叫 $rootScope 的服务提供的对象. 在实际应用上, $scope 与服务极为相像, 所以简单起见, 可以成为一个服务. 区别控制器所支持的视图, 是通过 ng-controller 指令来完成的. 该指令所指定的值,必须与创建的控制器同名. 每一个控制器实例对应一个作用域.1234567891011&lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&quot;simpleCtrl&quot;, function ($scope) &#123; &#125;);&lt;/script&gt;// 将控制器应用于视图.&lt;div class=&quot;well&quot; ng-controller=&quot;simpleCtrl&quot;&gt; Content will go here.&lt;/div&gt; 控制器名称的命名习惯是使用 Ctrl 后缀. 传给 Module.controller 函数的参数用于声明控制器的依赖(依赖注入), 即控制器所需的 AngularJS 组件. 示例如下:123myApp.controller(&quot;dayCtrl&quot;, function($scope)&#123;...&#125;)$scope : 该服务请求 AngularJS 为控制器提供作用域. 控制器使用 $scope 组件, 这能够允许向视图传递数据. $scope 组件是用于向视图提供数据的, 只有通过 $scope 配置的数据才能用于表达式和数据绑定中. 当控制器生命了对 $scope 服务的依赖时, 就可以使得控制器通过其对应的作用域向视图提供各种能力. 作用于不仅定义了控制器和视图之间的关系, 而且对许多重要的 AngularJS 特性提供了运转机制, 如 数据绑定. 有两种方法, 通过控制器使用作用域: 定义数据 定义行为, 即可以在视图绑定的表达式或指令中调用 JavaScript 函数. 关于作用域最重要的一点是, 修改会传播下去, 自动更新所有相依赖的数据值, 即使是通过行为产生的. 2. 依赖注入(DI)一个 AngularJS 应用程序的一些组件将会依赖于其他的组件. 依赖注入简化了在组件之间处理依赖的过程(解决依赖).AngularJS 应用程序的一个组件通过在工厂函数的参数上声明依赖, 声明的名称要与所依赖的组件相匹配. 依赖注入改变了函数参数的用途. 没有依赖注入, 参数会被用于接受调用者想要传入的任何对象, 但是又累依赖注入后, 函数使用参数来提出需求, 告诉 AngularJS 他需要什么样的构件. AngularJS 中参数的顺序总是与声明依赖的顺序相匹配. 二. 组织控制器1 单块控制器简单, 无需担心各个作用域之间的通信问题, 而且行为将可以被整个 HTML 所用. 当使用一个单块控制器时, 实际上会对整个应用程序创建一个单独的视图. 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&quot;simpleCtrl&quot;, function ($scope) &#123; $scope.addresses = &#123;&#125;; $scope.setAddress = function (type, zip) &#123; console.log(&quot;Type: &quot; + type + &quot; &quot; + zip); $scope.addresses[type] = zip; &#125; $scope.copyAddress = function () &#123; $scope.shippingZip = $scope.billingZip; &#125; &#125;);&lt;/script&gt;// ...&lt;div class=&quot;well&quot;&gt; &lt;h4&gt;Billing Zip Code&lt;/h4&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;input class=&quot;form-control&quot; ng-model=&quot;billingZip&quot;&gt; &lt;/div&gt; &lt;button class=&quot;btn btn-primary&quot; ng-click=&quot;setAddress(&apos;billingZip&apos;, billingZip)&quot;&gt; Save Billing &lt;/button&gt;&lt;/div&gt;&lt;div class=&quot;well&quot;&gt; &lt;h4&gt;Shipping Zip Code&lt;/h4&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;input class=&quot;form-control&quot; ng-model=&quot;shippingZip&quot;&gt; &lt;/div&gt; &lt;button class=&quot;btn btn-primary&quot; ng-click=&quot;copyAddress()&quot;&gt; Use Billing &lt;/button&gt; &lt;button class=&quot;btn btn-primary&quot; ng-click=&quot;setAddress(&apos;shippingZip&apos;, shippingZip)&quot;&gt; Save Shipping &lt;/button&gt;&lt;/div&gt; 2 复用控制器 在同一个应用程序中创建多个视图,并复用同一个控制器. AngularJS 将会调用每个应用到控制器的工厂函数, 结果是每个控制器实例将会拥有自己的作用域. 这种方法能够简化控制器, 因为所需管理的只是在单块控制器下需要处理的数据值的一个子集. 这样能够工作的原因是, MVC 模式下能够分离职能, 意味着不同的视图能够以不同的方式对同一份数据和功能进行展示. 每个控制器向其作用域提供的数据和行为都是与另外一个控制相互独立的.1234567891011121314151617181920212223242526272829303132333435&lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&quot;simpleCtrl&quot;, function ($scope) &#123; $scope.setAddress = function (type, zip) &#123; console.log(&quot;Type: &quot; + type + &quot; &quot; + zip); &#125; $scope.copyAddress = function () &#123; $scope.shippingZip = $scope.billingZip; &#125; &#125;);&lt;/script&gt;// ... &lt;div class=&quot;well&quot; ng-controller=&quot;simpleCtrl&quot;&gt; &lt;h4&gt;Billing Zip Code&lt;/h4&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;input class=&quot;form-control&quot; ng-model=&quot;zip&quot;&gt; &lt;/div&gt; &lt;button class=&quot;btn btn-primary&quot; ng-click=&quot;setAddress(&apos;billingZip&apos;, zip)&quot;&gt; Save Billing &lt;/button&gt;&lt;/div&gt;&lt;div class=&quot;well&quot; ng-controller=&quot;simpleCtrl&quot;&gt; &lt;h4&gt;Shipping Zip Code&lt;/h4&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;input class=&quot;form-control&quot; ng-model=&quot;zip&quot;&gt; &lt;/div&gt; &lt;button class=&quot;btn btn-primary&quot; ng-click=&quot;copyAddress()&quot;&gt; Use Billing &lt;/button&gt; &lt;button class=&quot;btn btn-primary&quot; ng-click=&quot;setAddress(&apos;shippingZip&apos;, zip)&quot;&gt; Save Shipping &lt;/button&gt;&lt;/div&gt; 2.1 作用域之间的通信 作用域实际上是以层级结构的形式组织起来的, 顶层是 根作用域(root scope), 每个控制器都会被赋予一个新的作用域, 该作用域是根作用域的一个子作用域. 根作用域提供了在各种作用域之间发送事件的方法, 者意味着允许在各种控制器之间进行通信. 根作用域可以作为一个服务被使用, 所以在控制器中使用 $rootScope(AngularJS的内建服务) 名称声明了对他的依赖. 所有作用域, 包括 $rootScope 服务, 定义了若干可用于发送和接受事件的方法: 方法 描述 $broadcase(name,args) 向当前作用域下的所有子作用域发送一个事件. 参数是事件名称, 以及一个用于向事件提供额外数据的对象. $emit(name, args) 向当前作用域的父作用域发送一个事件, 直至根作用域 $on(name, handler) 注册一个事件处理函数, 该函数在特定的事件被当前作用域收到时会被调用. $broadcase 和 $emit 事件都是具有方向性的, 他们沿着作用域的层级结构向上发送事件直至根作用域或者向下发送直至每一个子作用域. 123456789101112131415161718192021222324252627&lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .controller(&quot;simpleCtrl&quot;, function ($scope, $rootScope) &#123; // $scope.$on 用来对 zipCodeUpdated 事件创建一个处理函数. // 这个事件处理函数接受一个 Event 对象以及一个参数对象, // 本例中, 对该参数对象定义了 type 和 zipCode 属性, 然后使用它们在本地作用域上定义一个属性. $scope.$on(&quot;zipCodeUpdated&quot;, function (event, args) &#123; $scope[args.type] = args.zipCode; &#125;); // 通过 $rootScope 对象上调用 $broadcast 方法实现同步, // 传入一个拥有 type 和 zipCode 属性的对象, 这个对象正是事件处理函数所期望得到的. $scope.setAddress = function (type, zip) &#123; $rootScope.$broadcast(&quot;zipCodeUpdated&quot;, &#123; type: type, zipCode: zip &#125;); console.log(&quot;Type: &quot; + type + &quot; &quot; + zip); &#125; $scope.copyAddress = function () &#123; $scope.zip = $scope.billingZip; &#125;; &#125;);&lt;/script&gt; 2.2 使用服务调节作用域事件AngularJS 中的习惯时使用服务来调解作用域之间的通信. 即 使用Module.service方法创建一个服务对象, 该服务可被控制器用来发送和接受事件, 而无需直接与作用域中的事件方法产生交互. 这种方法, 可以减少代码的重复.123456789101112131415161718192021222324252627282930&lt;script&gt; angular.module(&quot;exampleApp&quot;, []) // 声明对 $rootScope 服务的依赖 .service(&quot;ZipCodes&quot;, function($rootScope) &#123; return &#123; setZipCode: function(type, zip) &#123; this[type] = zip; $rootScope.$broadcast(&quot;zipCodeUpdated&quot;, &#123; type: type, zipCode: zip &#125;); &#125; &#125; &#125;) // 声明对 ZipCodes 的依赖. .controller(&quot;simpleCtrl&quot;, function ($scope, ZipCodes) &#123; $scope.$on(&quot;zipCodeUpdated&quot;, function (event, args) &#123; $scope[args.type] = args.zipCode; &#125;); $scope.setAddress = function (type, zip) &#123; ZipCodes.setZipCode(type, zip); console.log(&quot;Type: &quot; + type + &quot; &quot; + zip); &#125; $scope.copyAddress = function () &#123; $scope.zip = $scope.billingZip; &#125; &#125;);&lt;/script&gt; 3 控制器继承ng-controller 指令可被内嵌在 HTML 元素上, 产生一种被称为控制器继承的效果, 这是一种目的在于减少代码重复的特性, 可以在一个父控制器中定义公用功能, 并在一个或多个子控制器中使用. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889// js 代码var app = angular.module(&quot;exampleApp&quot;, []);app.controller(&quot;topLevelCtrl&quot;, function ($scope) &#123; $scope.dataValue = &quot;Hello, Adam&quot;; $scope.reverseText = function () &#123; $scope.dataValue = $scope.dataValue.split(&quot;&quot;).reverse().join(&quot;&quot;); &#125; $scope.changeCase = function () &#123; var result = []; angular.forEach($scope.dataValue.split(&quot;&quot;), function (char, index) &#123; result.push(index % 2 == 1 ? char.toString().toUpperCase() : char.toString().toLowerCase()); &#125;); $scope.dataValue = result.join(&quot;&quot;); &#125;;&#125;);app.controller(&quot;firstChildCtrl&quot;, function ($scope) &#123; $scope.changeCase = function () &#123; $scope.dataValue = $scope.dataValue.toUpperCase(); &#125;;&#125;);app.controller(&quot;secondChildCtrl&quot;, function ($scope) &#123; $scope.changeCase = function () &#123; $scope.dataValue = $scope.dataValue.toLowerCase(); &#125;; $scope.shiftFour = function () &#123; var result = []; angular.forEach($scope.dataValue.split(&quot;&quot;), function (char, index) &#123; result.push(index &lt; 4 ? char.toUpperCase() : char); &#125;); $scope.dataValue = result.join(&quot;&quot;); &#125;&#125;);// HTML 代码&lt;body ng-controller=&quot;topLevelCtrl&quot;&gt; &lt;div class=&quot;well&quot;&gt; &lt;h4&gt;Top Level Controller&lt;/h4&gt; &lt;div class=&quot;input-group&quot;&gt; &lt;span class=&quot;input-group-btn&quot;&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;reverseText()&quot;&gt;Reverse&lt;/button&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;changeCase()&quot;&gt;Case&lt;/button&gt; &lt;/span&gt; &lt;input class=&quot;form-control&quot; ng-model=&quot;dataValue&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;well&quot; ng-controller=&quot;firstChildCtrl&quot;&gt; &lt;h4&gt;First Child Controller&lt;/h4&gt; &lt;div class=&quot;input-group&quot;&gt; &lt;span class=&quot;input-group-btn&quot;&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;reverseText()&quot;&gt;Reverse&lt;/button&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;changeCase()&quot;&gt;Case&lt;/button&gt; &lt;/span&gt; &lt;input class=&quot;form-control&quot; ng-model=&quot;dataValue&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;well&quot; ng-controller=&quot;secondChildCtrl&quot;&gt; &lt;h4&gt;Second Child Controller&lt;/h4&gt; &lt;div class=&quot;input-group&quot;&gt; &lt;span class=&quot;input-group-btn&quot;&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;reverseText()&quot;&gt;Reverse&lt;/button&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;changeCase()&quot;&gt;Case&lt;/button&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;shiftFour()&quot;&gt;Shift&lt;/button&gt; &lt;/span&gt; &lt;input class=&quot;form-control&quot; ng-model=&quot;dataValue&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;// 该例子中, 首次交互为修改 Reverse 按钮时, 所有的 input 框中的内容都将改变; // 首次交互修改 第二或第三个 input 框中的内容时, 再次点击 Reverse , 则除了被修改的, 所有的都改变. 当通过 ng-controller 指令将控制器嵌入另一个控制器中时, 子控制器的作用域便继承了父控制器作用域中的数据和行为, 这种嵌套可以为任意层次. 每个控制器都用自己独有的作用域, 但是子控制器的作用域包含了其父作用域的数据值和行为. 当单击 Reverse 按钮时, 所有的输入框都会改变, 因为 Reverse 调用的 reverseText 行为在顶层控制器中被定义. 子控制器继承了数据值和行为. 子控制器可以在继承父控制器的基础上, 实现自定义的功能, 扩展被继承的数据和行为. 子控制器能够覆盖他们的父控制器中的数据和行为, 即数据值和行为能够被同名的局部数据和行为所覆盖. 当查找行为时, AngularJS 会从该指令所应用到的控制器作用域上开始查找, 如果该行为存在, 则执行. 如果不存在, AngularJS 会向作用域的上层继续查找, 直到具有指定名称的行为被找到. 可以利用这一特性在大多数时候使用父控制器提供的功能, 而只改写需要自定义的部分. AngularJS 对作用域上的数据值的继承的处理方式以及如何受ng-model指令影响 可以使用下面的示例代码与上面的代码做比较.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990// js 代码var app = angular.module(&quot;exampleApp&quot;, []);app.controller(&quot;topLevelCtrl&quot;, function ($scope) &#123; $scope.data = &#123; dataValue: &quot;Hello, Adam&quot; &#125;; $scope.reverseText = function () &#123; $scope.data.dataValue = $scope.data.dataValue.split(&quot;&quot;).reverse().join(&quot;&quot;); &#125;; $scope.changeCase = function () &#123; var result = []; angular.forEach($scope.data.dataValue.split(&quot;&quot;), function (char, index) &#123; result.push(index % 2 == 1 ? char.toString().toUpperCase() : char.toString().toLowerCase()); &#125;); $scope.data.dataValue = result.join(&quot;&quot;); &#125;;&#125;);app.controller(&quot;firstChildCtrl&quot;, function ($scope) &#123; $scope.changeCase = function () &#123; $scope.data.dataValue = $scope.data.dataValue.toUpperCase(); &#125;;&#125;);app.controller(&quot;secondChildCtrl&quot;, function ($scope) &#123; $scope.changeCase = function () &#123; $scope.data.dataValue = $scope.data.dataValue.toLowerCase(); &#125;; $scope.shiftFour = function () &#123; var result = []; angular.forEach($scope.data.dataValue.split(&quot;&quot;), function (char, index) &#123; result.push(index &lt; 4 ? char.toUpperCase() : char); &#125;); $scope.data.dataValue = result.join(&quot;&quot;); &#125;;&#125;);// html 代码&lt;body ng-controller=&quot;topLevelCtrl&quot;&gt; &lt;div class=&quot;well&quot;&gt; &lt;h4&gt;Top Level Controller&lt;/h4&gt; &lt;div class=&quot;input-group&quot;&gt; &lt;span class=&quot;input-group-btn&quot;&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;reverseText()&quot;&gt;Reverse&lt;/button&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;changeCase()&quot;&gt;Case&lt;/button&gt; &lt;/span&gt; &lt;input class=&quot;form-control&quot; ng-model=&quot;data.dataValue&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;well&quot; ng-controller=&quot;firstChildCtrl&quot;&gt; &lt;h4&gt;First Child Controller&lt;/h4&gt; &lt;div class=&quot;input-group&quot;&gt; &lt;span class=&quot;input-group-btn&quot;&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;reverseText()&quot;&gt;Reverse&lt;/button&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;changeCase()&quot;&gt;Case&lt;/button&gt; &lt;/span&gt; &lt;input class=&quot;form-control&quot; ng-model=&quot;data.dataValue&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;well&quot; ng-controller=&quot;secondChildCtrl&quot;&gt; &lt;h4&gt;Second Child Controller&lt;/h4&gt; &lt;div class=&quot;input-group&quot;&gt; &lt;span class=&quot;input-group-btn&quot;&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;reverseText()&quot;&gt;Reverse&lt;/button&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;changeCase()&quot;&gt;Case&lt;/button&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;shiftFour()&quot;&gt;Shift&lt;/button&gt; &lt;/span&gt; &lt;input class=&quot;form-control&quot; ng-model=&quot;data.dataValue&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;// 所有的按钮都可以影响所有的输入框元素, 而且编辑输入元素的内容也不会影响后续的变化. 原理: 当读取一个直接在作用域上定义的属性的值时, AngularJS 会检查在这个控制器的作用域上是否有一个局部属性, 如果没有, 就会沿着作用域层次结构向上查找是否有一个被继承的属性. 然而, 当使用 ng-model 指令来修改这一属性时, AngularJS 会检查当前作用域是否有这样一个名称的属性, 如果没有, 则假定该属性为隐式属性, 结果便是覆盖了该属性的值. 然而, 如果在作用域上定义一个对象然后在对象上定义数据属性, 则不会发生覆盖的行为. 这是因为 JavaScript 对继承的实现是基于原型继承, 这意味着, 使用 ng-model 指令时,将会创建局部变量, 并使用一个对象作为中介. 这个将确保 ng-model 会对在父作用域上定义的数据值进行更新. 总结: 如果你想数据值在开始的时候是共享的, 但在修改时会被复制一份, 就直接在作用域上定义数据属性; 如果想确保始终只有一份数据值, 就通过一个对象来定义数据属性. 4. 多控制器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// js&lt;script&gt; var app = angular.module(&quot;exampleApp&quot;, []); app.controller(&quot;firstController&quot;, function ($scope) &#123; $scope.dataValue = &quot;Hello, Adam&quot;; $scope.reverseText = function () &#123; $scope.dataValue = $scope.dataValue.split(&quot;&quot;).reverse().join(&quot;&quot;); &#125; &#125;); app.controller(&quot;secondController&quot;, function ($scope) &#123; $scope.dataValue = &quot;Hello, Jacqui&quot;; $scope.changeCase = function () &#123; $scope.dataValue = $scope.dataValue.toUpperCase(); &#125;; &#125;);&lt;/script&gt;// html&lt;body&gt; &lt;div class=&quot;well&quot; ng-controller=&quot;firstController&quot;&gt; &lt;h4&gt;First Controller&lt;/h4&gt; &lt;div class=&quot;input-group&quot;&gt; &lt;span class=&quot;input-group-btn&quot;&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;reverseText()&quot;&gt;Reverse&lt;/button&gt; &lt;/span&gt; &lt;input class=&quot;form-control&quot; ng-model=&quot;dataValue&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;well&quot; ng-controller=&quot;secondController&quot;&gt; &lt;h4&gt;Second Controller&lt;/h4&gt; &lt;div class=&quot;input-group&quot;&gt; &lt;span class=&quot;input-group-btn&quot;&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;changeCase()&quot;&gt; Case &lt;/button&gt; &lt;/span&gt; &lt;input class=&quot;form-control&quot; ng-model=&quot;dataValue&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; 5. 使无作用域的控制器如果应用程序无需使用继承,以及控制器间通信, 可以使用无作用域的控制器. 这些控制器可以在根本不需要使用作用域的情况下向视图提供数据和行为. 取而代之的是一个提供给视图的代表控制器的特殊变量.即 通过 JavaScript 的关键字 this 定义了自己的数据值和行为.12345678910111213141516171819202122232425// js 代码&lt;script&gt; var app = angular.module(&quot;exampleApp&quot;, []) .controller(&quot;simpleCtrl&quot;, function () &#123; this.dataValue = &quot;Hello, Adam&quot;; this.reverseText = function () &#123; this.dataValue = this.dataValue.split(&quot;&quot;).reverse().join(&quot;&quot;); &#125; &#125;);&lt;/script&gt;// html 代码&lt;body&gt; &lt;div class=&quot;well&quot; ng-controller=&quot;simpleCtrl as ctrl&quot;&gt; &lt;h4&gt;Top Level Controller&lt;/h4&gt; &lt;div class=&quot;input-group&quot;&gt; &lt;span class=&quot;input-group-btn&quot;&gt; &lt;button class=&quot;btn btn-default&quot; type=&quot;button&quot; ng-click=&quot;ctrl.reverseText()&quot;&gt;Reverse&lt;/button&gt; &lt;/span&gt; &lt;input class=&quot;form-control&quot; ng-model=&quot;ctrl.dataValue&quot;&gt; &lt;/div&gt; &lt;/div&gt;&lt;/body&gt; 要点总结 使用 JavaScript 的关键字 this ng-controller 指令的表达式格式有所不同 : &lt;要应用的控制器&gt; as &lt;变量名&gt; 在使用中使用 变量名 访问数据和行为. 三. 显式更新作用域主要用于与其他的 JavaScript 框架集成. 下表中的方法允许注册响应作用域上变化的处理函数, 以及从 AngularJS 代码之外向作用域内注入变化. 方法 描述 $apply(expression) 向作用域应用变化. 也可以向 $apply 方法传递函数, 在创建自定义指令时尤为有用, 允许在响应用户交互时, 使用指令所管理的元素自定义对作用域的更新方法. $apply 提供了对内集成的手段, 在其他框架中发生的变化, 可以引起 AngularJS 中的相应的变化. $watch(expression, handler) 注册一个处理函数, 当 expression 表达式所引用的值变化时, 该函数会被通知到. $watch 提供了对外集成的手段, 作用域上的某个变化可以出发调用另一个框架中的相应变化. $watchCollection(object, handler) 注册一个处理函数, 当指定的 object 对象的任意属性变化时, 该函数会被通知到 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// js 代码&lt;script src=&quot;//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;//ajax.googleapis.com/ajax/libs/jqueryui/1.10.3/jquery-ui.min.js&quot;&gt;&lt;/script&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;http://ajax.googleapis.com/ajax/libs/jqueryui/1.10.3/themes/sunny/jquery-ui.min.css&quot;&gt;&lt;script&gt; $(document).ready(function () &#123; $(&apos;#jqui button&apos;).button().click(function (e) &#123; // $apply 提供了对内集成的手段, 在其他框架中发生的变化, 可以引起 AngularJS 中的相应的变化. // angular.element 是一个 jQuery 的轻量级实现, 传递所关系元素的 id 属性值给该方法, 就能到到一个定义了 scope 方法的对象, 并返回所需的作用域. // scope 只是 jqLite 的特性之一, 还有其他方法. angular.element(angularRegion).scope().$apply(&apos;handleClick()&apos;); &#125;); &#125;); var app = angular.module(&quot;exampleApp&quot;, []) .controller(&quot;simpleCtrl&quot;, function ($scope) &#123; $scope.buttonEnabled = true; $scope.clickCounter = 0; $scope.handleClick = function () &#123; $scope.clickCounter++; &#125; // $watch 提供了对外集成的手段, 作用域上的某个变化可以出发调用另一个框架中的相应变化. $scope.$watch(&apos;buttonEnabled&apos;, function (newValue) &#123; $(&apos;#jqui button&apos;).button(&#123; disabled: !newValue &#125;); &#125;); &#125;);&lt;/script&gt;// html 代码&lt;body&gt; &lt;div id=&quot;angularRegion&quot; class=&quot;well&quot; ng-controller=&quot;simpleCtrl&quot;&gt; &lt;h4&gt;AngularJS&lt;/h4&gt; &lt;div class=&quot;checkbox&quot;&gt; &lt;label&gt; &lt;input type=&quot;checkbox&quot; ng-model=&quot;buttonEnabled&quot;&gt; Enable Button &lt;/label&gt; &lt;/div&gt; Click counter: &#123; &#123;clickCounter&#125; &#125; &lt;/div&gt; &lt;div id=&quot;jqui&quot; class=&quot;well&quot;&gt; &lt;h4&gt;jQuery UI&lt;/h4&gt; &lt;button&gt;Click Me!&lt;/button&gt; &lt;/div&gt;&lt;/body&gt;]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>angularjs</tag>
        <tag>前端框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AngularJS高级程序设计读书笔记--指令篇之自定义指令]]></title>
    <url>%2F2018%2F03%2F16%2FAngularJS%E9%AB%98%E7%BA%A7%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E6%8C%87%E4%BB%A4%E7%AF%87%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8C%87%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[一. 自定义指令(15-17 章)Module.directive(name, factory) 指令是专门用于在应用程序内或程序之间复用的, 应当避免产生硬链接的依赖关系, 包括引用被特定控制器所创建的数据. 0. AngularJS 对 属性 名称的解析 大写开头的会被当做一个单词. listProperty == list-property 以 data- 为前缀的, AngularJS 会自动移除该前缀. data-list-property == list-property == listProperty 1. 链接函数: 提供了将指令与 HTML 文档和作用域数据相连接的方法.当 AngularJS 建立指令的每个实例时, 链接函数便被调用, 并接受三个参数: 指令被应用到的视图的作用域(scope), 指令被应用到的 HTML 元素(element), HTML 元素的属性集合( attrs). scope : 指令并不声明对 $scope 服务的依赖, 取而代之的是, 传入的是指令被应用到的视图的控制器所创建的作用域, 因为他允许单个指令在一个应用程序中被使用多次, 而每个程序可能是在作用域层次结构上的不同作用域上工作的. attrs 是一个按照名字索引的属性集合. element jqLite 是 AngularJS 实现的一个剪裁版本的 jQuery, 他不具有 jQuery 的所有功能, 但拥有足够的与执行相工作的功能. jqLite 的功能通过传递给 链接函数的 element 参数暴露出来. 大多数 jqLite 方法返回的结果是拥有访问 jqLite 各种功能的另一个对象(称为 jqLite 对象), AngularJS 不会暴露浏览器所提供的 DOM API, 在任何时候想对元素进行操作, 都会期望接受一个 jqLite 对象. 如果没有 jqLite 对象, 却需要一个, 可以使用 angular.element 方法, 返回一个 jqLite 对象. 1234567891011121314151617181920212223242526272829303132333435363738// javascript&lt;script&gt; var app = angular.module(&quot;exampleApp&quot;, []) .directive(&apos;unorderedList&apos;, function () &#123; return function(scope, element, attrs)&#123; var data = scope[attrs[&quot;unorderedList&quot;]]; var propertyName = attrs[&quot;listProperty&quot;]; // 支持属性 if (angular.isArray(data))&#123; var listElem = angular.element(&quot;&lt;ul&gt;&quot;); element.append(listElem); for (var i=0; i &lt; data.length; i++)&#123; listElem.append(angular.element(&quot;&lt;li&gt;&quot;).text(data[i][propertyName])); &#125; &#125; &#125; &#125;) .controller(&quot;defaultCtrl&quot;, function ($scope) &#123; $scope.products = [ &#123;name: &quot;Apples&quot;, category: &quot;Fruit&quot;, price: 1.20, expire: 20&#125;, &#123;name: &quot;Bananas&quot;, category: &quot;Fruit&quot;, price: 2.42, expire: 7&#125;, &#123;name: &quot;Pears&quot;, category: &quot;Fruit&quot;, price: 2.02, expire: 6&#125;, ] &#125;)&lt;/script&gt;// html&lt;body ng-app=&quot;exampleApp&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;div class=&quot;panel panel-default&quot;&gt; &lt;div class=&quot;panel-heading&quot;&gt; &lt;h3&gt;Products&lt;/h3&gt; &lt;/div&gt; &lt;div class=&quot;panel-body&quot;&gt; &lt;div unordered-list=&quot;products&quot; list-property=&quot;name&quot;&gt;&lt;/div&gt; // 支持属性 &lt;/div&gt; &lt;/div&gt;&lt;/body&gt; 计算属性 scope.$eval: 让作用域将属性值当做一个表达式来进行计算, scope.$eval 方法接受 要计算的表示和需要用于计算的任意本地数据. 1234567891011121314151617181920212223242526272829303132333435363738// javascript&lt;script&gt; var app = angular.module(&quot;exampleApp&quot;, []) .directive(&apos;unorderedList&apos;, function () &#123; return function(scope, element, attrs)&#123; var data = scope[attrs[&quot;unorderedList&quot;]]; var propertyExpression = attrs[&quot;listProperty&quot;] if (angular.isArray(data))&#123; var listElem = angular.element(&quot;&lt;ul&gt;&quot;); element.append(listElem); for (var i=0; i &lt; data.length; i++)&#123; listElem.append(angular.element(&quot;&lt;li&gt;&quot;).text(scope.$eval(propertyExpression, data[i]))); // scope.$eval 将属性值当做表达式来计算. &#125; &#125; &#125; &#125;) .controller(&quot;defaultCtrl&quot;, function ($scope) &#123; $scope.products = [ &#123;name: &quot;Apples&quot;, category: &quot;Fruit&quot;, price: 1.20, expire: 20&#125;, &#123;name: &quot;Bananas&quot;, category: &quot;Fruit&quot;, price: 2.42, expire: 7&#125;, &#123;name: &quot;Pears&quot;, category: &quot;Fruit&quot;, price: 2.02, expire: 6&#125;, ] &#125;)&lt;/script&gt;// html&lt;body ng-app=&quot;exampleApp&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;div class=&quot;panel panel-default&quot;&gt; &lt;div class=&quot;panel-heading&quot;&gt; &lt;h3&gt;Products&lt;/h3&gt; &lt;/div&gt; &lt;div class=&quot;panel-body&quot;&gt; &lt;div unordered-list=&quot;products&quot; list-property=&quot;price | currency&quot;&gt;&lt;/div&gt; // 添加表达式 &lt;/div&gt; &lt;/div&gt;&lt;/body&gt; 响应作用域中数据变化的能力12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// JavaScript&lt;script&gt; var app = angular.module(&quot;exampleApp&quot;, []) .directive(&apos;unorderedList&apos;, function () &#123; return function(scope, element, attrs)&#123; var data = scope[attrs[&quot;unorderedList&quot;]]; var propertyExpression = attrs[&quot;listProperty&quot;] if (angular.isArray(data))&#123; var listElem = angular.element(&quot;&lt;ul&gt;&quot;); element.append(listElem); for (var i=0; i &lt; data.length; i++)&#123; (function()&#123; // IIFE, 自调用函数, 解决 JavaScript 闭包导致的引用函数外变量问题. 函数所访问的变量是在函数被调用时计算的, 而不是函数定义时. var itemElement = angular.element(&quot;&lt;li&gt;&quot;) listElem.append(itemElement); var index = i; // index 不会被 for 循环的下一个迭代更新, 即监听器函数可以从 index 访问到正确的变量. // 监听器函数, 基于作用域中的数据计算出一个值, 该函数在每次作用域发生变化时被调用. // 如果该函数返回值发生变化, 则 $watch 处理函数就会被调用. var watchFn = function(watchScope)&#123; return watchScope.$eval(propertyExpression, data[index]); &#125; // $watch 监视器, 监控作用域变化. scope.$watch(watchFn, function(newValue, oldValue)&#123; itemElement.text(newValue); &#125;) &#125;()); &#125; &#125; &#125; &#125;) .controller(&quot;defaultCtrl&quot;, function ($scope) &#123; $scope.products = [ &#123;name: &quot;Apples&quot;, category: &quot;Fruit&quot;, price: 1.20, expire: 20&#125;, &#123;name: &quot;Bananas&quot;, category: &quot;Fruit&quot;, price: 2.42, expire: 7&#125;, &#123;name: &quot;Pears&quot;, category: &quot;Fruit&quot;, price: 2.02, expire: 6&#125;, ]; $scope.incrementPrice = function()&#123; for (var i=0; i&lt;$scope.products.length; i++)&#123; $scope.products[i].price++; &#125; &#125; &#125;)&lt;/script&gt;// html&lt;body ng-app=&quot;exampleApp&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;div class=&quot;panel panel-default&quot;&gt; &lt;div class=&quot;panel-heading&quot;&gt; &lt;h3&gt;Products&lt;/h3&gt; &lt;/div&gt; &lt;div class=&quot;panel-body&quot;&gt; &lt;!-- 涨价按钮 --&gt; &lt;button class=&quot;btn btn-primary&quot; ng-click=&quot;incrementPrice()&quot;&gt;Change Prices&lt;/button&gt; &lt;/div&gt; &lt;div class=&quot;panel-body&quot;&gt; &lt;div unordered-list=&quot;products&quot; list-property=&quot;price | currency&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/body&gt; 2. 编译函数: 可以与指令相关联的函数.1. 创建自定义指令的方法 Module.directive(name, factory) 示例 : &lt;script&gt; var myApp = angular.module(&apos;exampleApp&apos;, []) myApp.contorller(&apos;dayCtrl&apos;, function($scope){ var dayName = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Staturday&quot;] $scope.day = dayName[new Date().getDay()]; }); myApp.directive(&quot;highlight&quot;, function(){ return function(scope, element, attrs){ if (scope.day == attrs[&quot;highlight&quot;]{ element.css(&quot;color&quot;, &quot;red&quot;) }) } }); &lt;/script&gt; &lt;body ng-app=&apos;exampleAPP&apos;&gt; &lt;h4 ng-controller=&quot;dayCtrl&quot; highlight=&quot;Monday&quot;&gt; Today is { {day || &quot;(unknown)&quot;} } &lt;/h4&gt; &lt;/body&gt; # scope, element, attrs 分别为 : 视图的作用域, 指令所应用到的元素, 该元素的属性. # scope 参数用于检查在视图中可用的数据, 该示例中, 该参数能获得 day 属性的值. # attrs 参数提供了指令所应用到的元素的属性的完整集合, 包括让指令起作用的那个属性, 即获取 highlight 属性的值. # element 是一个 jqLite 对象, 如果 highlight 属性的值与作用于中 day 变量的值相等, 就调用 element 参数来设置 HTML 内容. css 方法可以设置一个 css 属性值. 2. 自定义指令的作用点 被当作属性使用 当做自定义 HTML 元素使用 二. 工厂函数与工人函数所有的可用于创建 AngularJS 构件的 Module 的方法都可以接受函数作为参数. 这些函数通常被称为 工厂函数, 因为他们负责创建那些将被 AngularJS 用来执行工作的对象. 工厂函数通常会返回一个工人函数, 也就是说将被 AngularJS 用来执行工作的对象也是一个函数. myApp.directive(&quot;highlight&quot;, function(){ // 此处 function 是一个 工厂函数 return function(scope, element, attrs){ // 工人函数 if (scope.day == attrs[&quot;highlight&quot;]{ element.css(&quot;color&quot;, &quot;red&quot;) }) } }); 不能够依赖于工厂函数或工人函数在某个特定时刻被调用当希望注册一个构件时, 调用 Module 的方法;当建立构件时 AngularJS 将调用工厂函数;然后当需要使用该构件时就会调用工人函数.这三个事件并一定会按照顺序立即调用. 三. 定义复杂指令使用一个返回链接函数的工厂函数来创建自定义指令, 是最简单的一种办法, 这也意味着许多可由指令自定义选项使用的是默认值, 要自定义这些选项, 工厂函数必须返回一个定义对象, 这是一个 javascritp 对象, 可用下表中的一些或全部属性. 名称 描述 compile 指定一个编译函数 controller 为指令创建一个控制器函数 link 指定一个链接函数 replace 指定模板内容是否替换指令所应用到的元素. require 声明对某个控制器的依赖. restrict 指定指令如何被使用 scope 为指令创建一个新的作用域或者一个隔离的作用域. template 指定一个将被插入到 HTML 文档的模板 templateUrl 指定一个将被插入到 HTML 文档的外部模板 transclude 指定指令是否被用于包含任意内容 当只返回一个链接函数时, 所创建的指令只能被当做一个属性来使用. 编译函数与连接函数: 严格来说, 应当使用由 compile 定义属性指令的编译函数, 只用来修改 DOM; 并且只使用连接函数来执行比如创建监听器和设置事件处理器等任务. 编译/连接分离有助于改善特别复杂或者处理大量数据的指令的性能. 1. restrict : 指定指令如何被使用 字母 描述 E 允许指令被用作一个元素 A 允许指令被用作一个属性 C 允许指令被用作一个类 M 允许指令被用作一个注释 在实际使用中, restrict 定义属性最常见值是 A,E 或者 AE, 但是也可以四个一起使用, 如 EACM. 即, 只要有可能就应该将指令当做元素或属性来使用, 应为这种方式更容易让人看懂指令应用到何处. 1234567891011121314151617181920212223242526272829303132&lt;script&gt; angular.module(&quot;exampleApp&quot;, []) .directive(&quot;unorderedList&quot;, function () &#123; return &#123; link: function (scope, element, attrs) &#123; var data = scope[attrs[&quot;unorderedList&quot;] || attrs[&quot;listSource&quot;]]; var propertyExpression = attrs[&quot;listProperty&quot;] || &quot;price | currency&quot;; if (angular.isArray(data)) &#123; var listElem = angular.element(&quot;&lt;ul&gt;&quot;); if (element[0].nodeName == &quot;#comment&quot;) &#123; element.parent().append(listElem); &#125; else &#123; element.append(listElem); &#125; for (var i = 0; i &lt; data.length; i++) &#123; var itemElement = angular.element(&quot;&lt;li&gt;&quot;) .text(scope.$eval(propertyExpression, data[i])); listElem.append(itemElement); &#125; &#125; &#125;, restrict: &quot;EACM&quot; &#125; &#125;).controller(&quot;defaultCtrl&quot;, function ($scope) &#123; $scope.products = [ &#123; name: &quot;Apples&quot;, category: &quot;Fruit&quot;, price: 1.20, expiry: 10 &#125;, &#123; name: &quot;Bananas&quot;, category: &quot;Fruit&quot;, price: 2.42, expiry: 7 &#125;, &#123; name: &quot;Pears&quot;, category: &quot;Fruit&quot;, price: 2.02, expiry: 6 &#125; ]; &#125;)&lt;/script&gt; 1.1 将指令当做一个元素来使用AngularJS 的习惯是将那些通过定义属性 template 和 templateUrl 管理模板的指令当做元素来使用. 将指令当做一个 unordered-list 元素来使用, 并在元素上使用属性对其进行配置. 123456&lt;div class=&quot;panel-body&quot;&gt; &lt;unordered-list list-source=&quot;products&quot; list-property=&quot;price | currency&quot; /&gt;&lt;/div&gt;// 需要对指令的链接函数做一个修改.var data = scope[attrs[&quot;unorderedList&quot;] || attrs[&quot;listSource&quot;]]; 1.2 将指令当做一个属性来使用123&lt;div class=&quot;panel-body&quot;&gt; &lt;div unordered-list=&quot;products&quot; list-property=&quot;price | currency&quot;&gt;&lt;/div&gt; &lt;/div&gt; 1.3 将指令当做一个类的属性值来使用123&lt;div class=&quot;panel-body&quot;&gt; &lt;div class=&quot;unordered-list: products&quot; list-property=&quot;price | currency&quot;&gt;&lt;/div&gt;&lt;/div&gt; 1.4 将指令当做一个注释来使用容易使得其他开发者不容易看懂代码, 还可能引起某些构建工具的问题(因为有些工具为了缩减文件体积而去除注释). 注释必须以单词 directive 开始, 跟随一个冒号, 指令名以及可选的配置参数. 1234567891011&lt;div class=&quot;panel-body&quot;&gt; &lt;!-- directive: unordered-list products --&gt;&lt;/div&gt;// 需要修改链接函数的操作方式已支持注释方式.if (element[0].nodeName == &quot;#comment&quot;) &#123; element.parent().append(listElem);&#125; else &#123; element.append(listElem);&#125; 2. template, templateUrl: 指定指令模板2.1 使用函数作为末班2.2 使用外部模板2.3 使用函数选择一个外部模板2.4 替换元素3. scope: 管理指令作用域.]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>angularjs</tag>
        <tag>前端框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AngularJS高级程序设计读书笔记--jqLite]]></title>
    <url>%2F2018%2F03%2F16%2FAngularJS%E9%AB%98%E7%BA%A7%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--jqLite%E7%AF%87%2F</url>
    <content type="text"><![CDATA[jqLite 是 AngularJS 实现的一个剪裁版的 jQuery, 可以与 AngularJS 一起工作创建, 操作, 管理 HTML 元素. jqLite 的每一个方法的实现, 都对应一个 jQuery 的同名方法. jQuery API. 1. 对文档对象模型(DOM)导航AngularJS 用于表示 HTML 元素的对象( jqLite对象 ), 实际上可以表示零个, 一个或多个 HTML 元素. 因此, 有些 jqLite 方法会将 jqLite 对象当做一个集合处理. 名称 描述 children() 返回一组子元素(直接定义在该元素下的元素), 该方法的 jqLite 实现不支持 jQuery 所提供的选择器特性. partent() 返回父元素, 该方法的 jqLite 实现不支持 jQuery 所提供的选择器特性. next() 获得下一个兄弟元素, 该方法的 jqLite 实现不支持 jQuery 所提供的选择器特性. eq(index) 从一个元素集合中, 返回制定索引下的元素. find(tag) 按照制定的 tag 名称定位所有的后代元素. jQuery 的实现为选择元素提供了额外选项, 但该方法的 jqLite 实现中并不可用. 1234567891011121314151617181920212223242526272829303132333435// JavaScript&lt;script&gt; var app = angular.module(&quot;exampleApp&quot;, []) .directive(&apos;demoDirective&apos;, function () &#123; return function(scope, element, attrs)&#123; // var items = element.children(); // 查找所有子元素. var items = element.find(&quot;li&quot;); // 查找所有后代元素. for (var i=0; i&lt;items.length; i++)&#123; if (items.eq(i).text() == &quot;Oranges&quot;)&#123; items.eq(i).css(&quot;font-weight&quot;, &quot;bold&quot;); &#125; &#125; &#125; &#125;) .controller(&quot;defaultCtrl&quot;, function ($scope) &#123; // controller code here &#125;)&lt;/script&gt;// HTML&lt;body ng-app=&quot;exampleApp&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;h3&gt;Fruit&lt;/h3&gt; &lt;ol demo-directive&gt; &lt;li&gt;Apples&lt;/li&gt; &lt;ul&gt; &lt;li&gt;Bananas&lt;/li&gt; &lt;li&gt;Cherries&lt;/li&gt; &lt;li&gt;Oranges&lt;/li&gt; &lt;/ul&gt; &lt;li&gt;Oranges&lt;/li&gt; &lt;li&gt;Pears&lt;/li&gt; &lt;/ol&gt;&lt;/body&gt; 2. 修改元素jqLite 提供了修改元素内容和属性的方法. 名称 描述 attr(name), attr(name, value) 获得 jqLite 对象中的第一个元素的指定特性的值, 或者为所有元素设置指定值. css(name), css(name, value) 获得 jqLite 对象中的第一个元素的指定 CSS 属性的值, 或者为所有元素设置指定值. prop(name), prop(name, value) 获得 jqLite 对象中的第一个元素的指定属性的值, 或者为所有元素设置指定值. text(), text(value) 获得 jqLite 对象中所有元素的文本内容拼接后的结果, 或者设置所有元素的文本内容. val(), val(value) 获取 jqLite 对象中的第一个元素的 value 特性, 或者设置所有元素的 value 特性. hasClass(name) 如果 jqLite 对象中有任一对象属于指定的 class 时, 返回 true. addClass(name) 将 jqLite 对象中的所有元素添加到指定的 class removeClass(name) 从 jqLite 对象中移除具有指定 class 的元素. removeAttr(name) 从 jqLite 对象的所有元素中, 移除某个特性 toggleClass(name) 为 jqLite 对象中的所有元素切换指定 class 的所属资格. 那些不在 class 中的元素将被添加到其中, 而那些在 class 中的元素将会从中移除. 1234567891011121314151617var app = angular.module(&quot;exampleApp&quot;, []) .directive(&apos;demoDirective&apos;, function () &#123; return function(scope, element, attrs)&#123; // var items = element.children(); // 查找所有子元素. var items = element.find(&quot;li&quot;); // 查找所有后代元素. items.css(&quot;color&quot;, &quot;red&quot;); // 设置所有元素的 css color 属性. for (var i=0; i&lt;items.length; i++)&#123; if (items.eq(i).text() == &quot;Oranges&quot;)&#123; items.eq(i).css(&quot;font-weight&quot;, &quot;bold&quot;); &#125; else &#123; items.eq(i).css(&quot;font-weight&quot;, &quot;normal&quot;) &#125; &#125; console.log(items.length) console.log(items.css(&quot;font-weight&quot;)) // 获取第一个元素的 css font-weight 属性. &#125; &#125;) 特性与属性prop 方法处理的是被 DOM API HTMLElement 对象所定义的的属性;attr 方法处理的是被标记语言中的 HTML 元素所定义的特性. 通常, 特性和属性是一致的, 但并非总是如此, 如 class 特性在 HTMLElement 对象中使用 className 属性表示的. 一般来说, prop 方法会是应该使用的选择, 因为他返回的对象与特性值相比更容易使用. 这些对象都是 DOM API 所定义的 3. 创建和移除元素 名称 描述 angular.element(html) 创建一个代表特定 HTML 字符串的元素的 jqLite 对象. after(elements) 在调用方法的元素后面插入特定内容. append(elements) 在调用方法的 jqLite 对象的每一个元素上, 将特定元素作为最后一个子元素插入. clone() 从方法调用的对象复制元素并作为一个新的 jqLite 对象返回. prepend(elements) 在调用方的的 jqLite 对象的每一个元素上, 将特定元素作为第一个子元素插入 remove() 从 DOM 中删除 jqLite 对象的元素 replaceWith(elements) 用指定元素替换调用方法的 jqLite 对象的元素 wrap(elements) 使用特定元素包装 jqLite 对象中的每个元素. 需要注意, jQuery fluent API . 这意味着, 许多这类方法返回的 jqLite 对象中包含了原来在调用方法的 jqLite 对象中就存在的元素, 而不是那些参数中的元素. 如下示例中的 var listItem = element.append(&quot;&lt;ol&gt;&quot;);, append 方法返回的是一个表示操作被执行的元素的 jqLite 对象, 即 div 元素, 而非 ol 元素. 解决这个问题的一个有效方法就是, 使用 angular.element 方法来创建 jqLite 对象并在单独的语句中对他们执行各种操作. 12345678910111213141516171819202122232425262728293031&lt;script&gt; var app = angular.module(&quot;exampleApp&quot;, []) .directive(&apos;demoDirective&apos;, function () &#123; return function(scope, element, attrs)&#123; // 错误版本 // var listItem = element.append(&quot;&lt;ol&gt;&quot;); // append 方法返回的是一个表示操作被执行的元素的 jqLite 对象, 即 div 元素, 而非 ol 元素 // for (var i=0; i&lt;scope.names.length; i++)&#123; // listItem.append(&quot;&lt;li&gt;&quot;).append(&quot;&lt;span&gt;&quot;).text(scope.names[i]); // &#125; // 正确版本 var listItem = angular.element(&quot;&lt;ol&gt;&quot;); element.append(listItem); for (var i=0; i&lt;scope.names.length; i++)&#123; listItem.append( angular.element(&quot;&lt;li&gt;&quot;).append(angular.element(&quot;&lt;span&gt;&quot;).text(scope.names[i])) ); &#125; &#125; &#125;) .controller(&quot;defaultCtrl&quot;, function ($scope) &#123; $scope.names = [&quot;Apples&quot;, &quot;Namamas&quot;, &quot;Oranges&quot;] &#125;)&lt;/script&gt;&lt;/head&gt;&lt;body ng-app=&quot;exampleApp&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;h3&gt;Fruit&lt;/h3&gt; &lt;div demo-directive&gt;&lt;/div&gt;&lt;/body&gt; 4. 处理事件jqLite 支持处理元素所发生的事件, 这些方法与那些内置的事件指令, 用来接收和处理事件的方法是同样的方法. 名称 描述 on(events, handler) 为 jqLite 对象所代表的元素发生事件注册一个处理器. 本方法的 jqLite 实现不支持 jQuery 提供的选择器或事件数据特性. off(events, handler) 为 jqLite 对象所代表的元素发生的事件移除一个之前已注册的处理器. 本方法的 jqLite 实现不支持 jQuery 提供的选择器或事件数据特性. triggerHandler(event) 对 jqLite 对象所代表的所有元素上注册的指定事件触发所有处理器. 123456789101112131415161718192021222324252627282930313233343536373839&lt;script&gt; var app = angular.module(&quot;exampleApp&quot;, []) .directive(&apos;demoDirective&apos;, function () &#123; return function(scope, element, attrs)&#123; // 错误版本 // var listItem = element.append(&quot;&lt;ol&gt;&quot;); // for (var i=0; i&lt;scope.names.length; i++)&#123; // listItem.append(&quot;&lt;li&gt;&quot;).append(&quot;&lt;span&gt;&quot;).text(scope.names[i]); // &#125; // 正确版本 var listItem = angular.element(&quot;&lt;ol&gt;&quot;); element.append(listItem); for (var i=0; i&lt;scope.names.length; i++)&#123; listItem.append( angular.element(&quot;&lt;li&gt;&quot;).append(angular.element(&quot;&lt;span&gt;&quot;).text(scope.names[i])) ); &#125;; var buttons = element.find(&quot;button&quot;); // 注册 click 事件 buttons.on(&quot;click&quot;, function(e)&#123; element.find(&quot;li&quot;).toggleClass(&quot;bold&quot;) // 切换 bold class 属性. &#125;) &#125; &#125;) .controller(&quot;defaultCtrl&quot;, function ($scope) &#123; $scope.names = [&quot;Apples&quot;, &quot;Namamas&quot;, &quot;Oranges&quot;] &#125;)&lt;/script&gt;&lt;/head&gt;&lt;body ng-app=&quot;exampleApp&quot; ng-controller=&quot;defaultCtrl&quot;&gt; &lt;h3&gt;Fruit&lt;/h3&gt; &lt;div demo-directive&gt; &lt;button&gt;Click Me&lt;/button&gt; &lt;/div&gt;&lt;/body&gt; 5. 其他 jqLite 方法 名称 描述 data(key), data(key, value) 将任意数据与 jqLite 对象代表的所有元素关联起来, 或者从 jqLite 对象代表的第一个元素中获取制定 key 的值. removeData(key) 从 jqLite 对象代表的元素中移除与指定 key 相关联的数据 html() 返回 jqLite 对象所代表的第一个元素的内容的 HTML 表达上形式. ready(handler) 注册一个监听器函数, 该函数将在 DOM 的内容被完全加载时调用一次. 6. 从 jqLite 访问 AngularJS 特性jqLite 还提供了一些方法, 可以提供对 AngularJS 专属的特性的访问. 名称 描述 controller(), controller(name) 返回与当前元素或其父元素相关联的控制器. 控制器可以与指令交互. injector() 返回与当前元素相关的注入器. isolatedScope() 如果当前元素有相关联的独立的作用域, 则返回该作用域. scope() 返回与当前元素或其父元素相关联的作用域. inheritedData(key) 该方法与 jQuery 的 data 方法执行同样的功能, 但是会沿着元素层次结构向上查找与制定 key 相匹配的值.]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>angularjs</tag>
        <tag>前端框架</tag>
        <tag>jqLite</tag>
        <tag>jQuery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AngularJS高级程序设计读书笔记--服务篇]]></title>
    <url>%2F2018%2F03%2F16%2FAngularJS%E9%AB%98%E7%BA%A7%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0--%E6%9C%8D%E5%8A%A1%E7%AF%87%2F</url>
    <content type="text"><![CDATA[服务是提供在整个应用程序中所使用的任何功能的单例对象.单例 : 只用一个对象实例会被 AngularJS 创建出来, 并被程序需要服务的各个不同部分所共享. 一. 内置服务一些关键方法也被 AngularJS 成为服务. 如 $scope, $http. 二. 自定义服务1. Module.service(name, constructor)service 方法由两个参数: 服务名和调用后用来创建服务对象的工厂函数. 当 AngularJS 调用工厂函数时, 会分配一个可通过 this 关键字访问的新对象, 我们就可以使用这个对象来定义 today 和 tomorrow 属性. 示例代码:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;!DOCTYPE html&gt;&lt;html ng-app=&quot;exampleApp&quot;&gt;&lt;head&gt; &lt;title&gt;AngularJS Demo&lt;/title&gt; &lt;link href=&quot;bootstrap.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;link href=&quot;bootstrap-theme.css&quot; rel=&quot;stylesheet&quot; /&gt; &lt;script src=&quot;angular.js&quot;&gt;&lt;/script&gt; &lt;script&gt; var myApp = angular.module(&quot;exampleApp&quot;, []); myApp.controller(&quot;dayCtrl&quot;, function ($scope, days) &#123; // 依赖注入服务 $scope.day = days.today; &#125;); myApp.controller(&quot;tomorrowCtrl&quot;, function ($scope, days) &#123; // 依赖注入服务 $scope.day = days.tomorrow; &#125;); myApp.directive(&quot;highlight&quot;, function ($filter) &#123; var dayFilter = $filter(&quot;dayName&quot;); return function (scope, element, attrs) &#123; if (dayFilter(scope.day) == attrs[&quot;highlight&quot;]) &#123; element.css(&quot;color&quot;, &quot;red&quot;); &#125; &#125; &#125;); myApp.filter(&quot;dayName&quot;, function () &#123; var dayNames = [&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;]; return function (input) &#123; return angular.isNumber(input) ? dayNames[input] : input; &#125;; &#125;); myApp.service(&quot;days&quot;, function () &#123; // 创建服务 this.today = new Date().getDay(); this.tomorrow = (this.today + 1)%7; &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;page-header&quot;&gt; &lt;h3&gt;AngularJS App&lt;/h3&gt; &lt;/div&gt; &lt;h4 ng-controller=&quot;dayCtrl&quot; highlight=&quot;Monday&quot;&gt; Today is &#123; &#123;day || &quot;(unknown)&quot; | dayName&#125; &#125; &lt;/h4&gt; &lt;h4 ng-controller=&quot;tomorrowCtrl&quot;&gt; Tomorrow is &#123; &#123;day || &quot;(unknown)&quot; | dayName&#125; &#125; &lt;/h4&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 2. Module.factory(name, provider)3. Module.provider(name, type)4. Module.value(name, value)用于创建返回固定值和对象的服务, 这意味着可以为任何值或对象使用依赖注入, 而不仅仅是 module 方法创建的那些对象. 示例代码:12345678910&lt;script&gt; var myAPP = angular.module(&quot;exampleApp&quot;, []) var now = new Date(); // 将 Date() 对象赋给自定义的 now 变量 myApp.value(&quot;nowValue&quot;, now) // 创建一个值服务 myApp.service(&quot;days&quot;, function(nowValue)&#123; // 定义对 nowValue 服务的依赖. this.today = nowValue.getDay(); this.tomorrow = this.today + 1; &#125;);&lt;/script&gt;]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>angularjs</tag>
        <tag>前端框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 markdown 写 PPT]]></title>
    <url>%2F2018%2F03%2F16%2Ftools-landslide%2F</url>
    <content type="text"><![CDATA[TODO: 选择 theme 写 notes Landslide是基于Google的html5slides的一个Slide生成工具，可将markdown、ReST 或者 textile文件转化成HTML5的slide。 Landslide 基于 Python 开发，最大的优点就是简洁，从安装到编写，到生成的 slides 风格都十分简洁。整个过程，用户只需要懂 Markdown 语法就可以. 该转化支持内联模式，即生成一个具有完整功能的HTML文件，将依赖的css等东西放入其中，很容易用来分享。 项目地址: https://github.com/adamzap/landslide 安装 使用12345678910111213141516171819--- 安装$ pip install landslide--- 使用$ landslide file.md -d name_you_like.html--- PPT 支持的快捷键h: 展示帮助← →: 上/下一张幻灯片t： 显示目录ESC: 展示PPT总览n: 显示当前是第几张幻灯片b: 屏幕全黑e: 使当前幻灯片最大化2: 展示 幻灯片 笔记, 指定的 .notes 宏里的内容3: 展示伪3D效果c: 取消显示前后幻灯片预览，只显示当前幻灯片S: 展示每个幻灯片文件的 源地址 链接. 123456789101112131415161718192021222324252627282930313233343536373839404142434445--- 帮助$ landslide --help Usage: landslide [options] input.md ... Generates an HTML5 or PDF slideshow from Markdown or other formats Options: --version show program&apos;s version number and exit -h, --help show this help message and exit -c, --copy-theme Copy theme directory into current presentation source directory -b, --debug Will display any exception trace to stdout -d FILE, --destination=FILE The path to the to the destination file: .html or .pdf extensions allowed (default: presentation.html) -e ENCODING, --encoding=ENCODING The encoding of your files (defaults to utf8) -i, --embed Embed stylesheet and javascript contents, base64-encoded images in presentation to make a standalone document -l LINENOS, --linenos=LINENOS How to output linenos in source code. Three options availables: no (no line numbers); inline (inside &lt;pre&gt; tag); table (lines numbers in another cell, copy-paste friendly) -o, --direct-output Prints the generated HTML code to stdout; won&apos;t work with PDF export -P, --no-presenter-notes Don&apos;t include presenter notes in the output -q, --quiet Won&apos;t write anything to stdout (silent mode) -r, --relative Make your presentation asset links relative to current pwd; This may be useful if you intend to publish your html presentation online. -t THEME, --theme=THEME A theme name, or path to a landlside theme directory -v, --verbose Write informational messages to stdout (enabled by default) -x EXTENSIONS, --extensions=EXTENSIONS Comma-separated list of extensions for Markdown -w, --watch Watch source directory for changes and regenerate slides -m, --math-output Enable mathematical output using MathJax Note: PDF export requires the `prince` program: http://princexml.com/ markdown 写作提要 Markdown 源文件, 必须以 .md/.markdn/.mdwn/.mdown/.markdown --- : 三个以上的 横线 表示强制分页. 每个 slide 页面应该用一个 # 来表示 渲染 h1 标题 open NAME.html iterm2 会自动用浏览器打开该 html 页面. open 命令会使用系统定义的 文件默认打开程序 打开文件.]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>PPT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 微信接口 -- itchat 文档]]></title>
    <url>%2F2018%2F03%2F16%2Fpython-itchat-weixin-api%2F</url>
    <content type="text"><![CDATA[itchat一. 安装$ pip install itchat 特殊的字典使用方式通过打印 itchat 的用户以及注册消息的参数, 可以发现这些值都是字典. 但实际上 itchat 精心构造了相应的消息,用户,群聊,公众号等. 其所有的键值都可以通过这一方式访问: @itchat.msg_register(TEXT) def _(msg): # equals to print(msg[&apos;FromUserName&apos;]) print(msg.fromUserName) 属性名为键值首字母小写后的内容. author = itchat.search_frients(nickName=&quot;LittleCoder&quot;)[0] author.send(&quot;greeting , LittleCoder!&quot;) 二. 登录一般而言, 会在完成消息的注册后登录. 强调三点: 登录状态缓存, 短时间关闭重连, 关闭程序后一定时间内不需要扫码即可登录. 由于目前微信网页版提供上一次登录的微信号不扫码直接手机确认登录, 所以如果开启登录状态暂存, 将会自动使用这一功能. 命令行二维码, 自定义登录内容(如更改提示语, 二维码出现后邮件发送等). 1. 短时间关闭程序后重连.即使程序关闭，一定时间内重新开启也可以不用重新扫码. 使用 auto_login 方法传入值为真的 hotReload.该方法会生成一个静态文件 itchat.pkl, 用于存储登录的状态. import itchat from itchat.content import TEXT @itchat.msg_register(TEXT) def simple_reply(TEXT): print(msg.text) itchat.auto_login(hotReload=True) itchat.run() 通过设置 statusStorageDir 可以将静态文件指定为其他的值. 这一内置选项,相当于使用了以下两个函数的这一段程序: import itchat from itchat.content import TEXT if itchat.load_login_status(): # itchat.load_login_status() 用于读取设置 @itchat.msg_register(TEXT): def simple_reply(msg): print(msg[&quot;Text&quot;]) itchat.run() itchat.dump_login_status() # itchat.dump_login_status() 用于导出设置 else: itchat.auto_login() itchat.dump_login_status() print(&quot;Config stored, so exit.&quot;) 通过设置传入的 fileDir 的值, 可以设定导入导出的文件. 2. 命令行二维码通过如下命令在登录的时候, 使用命令行显示 二维码. itchat.auto_login(enableCmdQR=True) 部分系统可能字符宽度有出入, 可以通过将 enableCmdQR 赋值为特定的倍数进行调整. # 如部分 Linux 系统, 块字符的宽度为一个字符(正常为两个字符), 故赋值为 2 itchat.auto_login(enableCmdQR=2) 默认控制台背景颜色为暗色(黑色), 若背景色为浅色, 可将 enableCmdQR 赋值为负值: itchat.auto_login(enableCmdQR=-1) 3. 自定义登录过程itchat 提供了登录所需的每一步的方法, 登录的过程按殊勋为:1) 获取二维码 uuid, 并返回该 uuid - 方法名称: `get_QRuuid()` - 参数: 无 - 返回值: 成功返回 uuid, 失败返回 None 2) 获取二维码 : 根据uuid获取二维码并打开. - 方法名: `get_QR()` - 参数: uuid - 返回值: True, False 3) 判断是否已登录成功 - 方法名称: `check_login()` - 参数: uuid - 返回值: 200 登录成功, 201 以扫描二维码, 408 二维码失效, 0 未获取到信息. 4) 获取初始化数据: 获取微信用户信息以及心跳所需要的数据. - 方法名称: `web_init()` - 参数: 无 - 返回值: 存储登录微信用户信息的字典. 5) 获取微信通讯录, 获取微信的所有好友信息并更新 - 方法名称: `get_frients()` - 参数: 无 - 返回值: 存储好友信息的列表 6) 更新微信手机登录状态, 在手机上显示登录状态. - 方法名称: `show_mobile_login()` - 参数: 无 - 返回值: 无 7) 循环扫描新信息(开启心跳) - 方法名称: `start_receiving()` - 参数: 无 - 返回值: 无 4. auto_login的实现代码:import itchat, time, sys def output_info(msg): print(&apos;[INFO] %s&apos; % msg) def open_QR(): for get_count in range(10): output_info(&quot;Getting uuid&quot;) uuit = itchat.get_QRuuid() while uuid is None: uuitd = itchat.get_QRuuid(); time.sleep(1) output_info(&quot;Getting QR code&quot;) if itchat.get_QR(uuid): break elif get_coun &gt;= 9: output_info(&quot;Failed to get QR code, plz restart the program&quot;) sys.exit() output_info(&quot;Plz scan the QE Code&quot;) return uuid uuid = open_QR() waitForConfirm = False while 1: status = itchat.check_login(uuid) if status == &apos;200&apos;: break elif status = &apos;201&apos;: if waitForConfirm: output_info(&quot;Plz press confirm&quot;) waitForConfirm = True elif status == &apos;408&apos;: output_info(&quot;Reloading QR Code&quot;) uuid = open_QR() waitForConfirm = False userInfo = itchat.web_init() itchat.show_mobile_login() itchat.get_friends(True) output_info(&quot;Login successfully as %s&quot; % userInfo[&quot;NickName&quot;]) itchat.start_receiving() # start auto-replying @itchat.msg_register def simple_reply(msg): if msg[&quot;Type&quot;] == &quot;Text&quot;: return &quot;I received: %s&quot; % msg[&quot;Content&quot;] itchat.run() 5. 退出及登录完成后调用的特定方法登录完成后的方法需要赋值在 loginCallback 中退出后的方法,需要赋值在 exitCallback 中. import itchat, time def lc(): print(&quot;Finash Login!&quot;) def ec(): print(&quot;exit&quot;) itchat.auto_login(loginCallback=lc, exitCallback=ec) time.sleep() itchat.logout() 若不设置 loginCallback 的值, 将会自动删除二维码图片并清空命令行显示. 6. 用户多开import itchat netInstance = itchat.new_instance() netInstance.auto_login(hotReload=True, statusStorageDir=&quot;newInstance.pkl&quot;) @newInstance.msg_register(TEXT) def reply(msg): return msg.text netInstance.run() 三. 回复五种回复方法, 建议直接使用 send 方法 1. send 方法: send(msg=&quot;Text Message&quot;, toUserName=None) 参数: msg : 文本消息内容 @fil@path_to_file : 发送文件 @img@path_to_img : 发送图片 @vid@path_to_video : 发送视频 toUserName : 发送对象, 如果留空, 将发送给自己. 返回值: True, False 示例代码: # coding-utf-8 import itchat itchat.auto_login() itchat.send(&quot;Hello World!&quot;) ithcat.send(&quot;@fil@%s&quot; % &apos;/tmp/test.text&apos;) ithcat.send(&quot;@img@%s&quot; % &apos;/tmp/test.png&apos;) ithcat.send(&quot;@vid@%s&quot; % &apos;/tmp/test.mkv&apos;) 2. send_msg 方法: send_msg(msg=&#39;Text Message&#39;, toUserName=None) 参数: msg: 消息内容 toUserName: 发送对象, 如果留空, 将发送给自己. 返回值: True, False 示例代码: import itchat itchat.auto_login() itchat.send_msg(&quot;hello world.&quot;) 3. send_file 方法: send_file(fileDir, toUserName=None) 参数: fileDir : 文件路径, 当文件不存在时, 将打印无此文件的提醒. toUserName : 发送对象, 如果留空, 将发送给自己. 返回值: True, False 示例代码: import itchat itchat.auto_login() itchat.send_file(&quot;/tmp/test.txt&quot;) 4. send_img 方法: send_img(fileDir, toUserName=None) 参数: fileDir : 文件路径, 当文件不存在时, 将打印无此文件的提醒. toUserName : 发送对象, 如果留空, 将发送给自己. 返回值: True, False 示例代码: import itchat itchat.auto_login() itchat.send_img(&quot;/tmp/test.txt&quot;) 5. send_video 方法: send_video(fileDir, toUserName=None) 参数: fileDir : 文件路径, 当文件不存在时, 将打印无此文件的提醒. toUserName : 发送对象, 如果留空, 将发送给自己. 返回值: True, False 示例代码: import itchat itchat.auto_login() itchat.send_video(&quot;/tmp/test.txt&quot;) 四. 注册消息方法itchat 将根据接受到的消息类型寻找对应的已注册的方法. 如果一个消息类型没有对应的注册方法, 该消息将会被舍弃. 在运行过程中也可以动态注册方法, 注册方式与结果不变. 1. 注册方法:两种方法注册消息. 不带具体对象注册, 将注册为普通消息的回复方法. import itchat from itchat.content import * @itchat.msg_register(TEXT) def simple_reply(msg): return &quot;T reveived: %s&quot; % msg[&quot;Text&quot;] 带对象参数注册, 对应消息对象将调用该方法. import itchat from itchat.content import * @itchat.msg_register(TEXT, isFriendChat=True, isGroupChat=True,isMpChat=True) def text_reply(msg): msg.user.send(&quot;%s : %s&quot; % (mst.type, msg.text)) 2. 消息类型向注册方法传入的 msg 包含微信返回的字典的所有内容. itchat 增加 Text, Type(也就是参数) 键值, 方便操作. itcaht.content 中包含所有的消息类型参数, 如下表: 参数 类型 Text 键值 TEXT 文本 文本内容 MAP 地图 位置文本 CARD 名片 推荐人字典 NOTE 通知 通知文本 SHARING 分享 分享名称 PICTURE 图片/表情 下载方法 RECORDING 语音 下载方法 ATTACHMENT 附件 下载方法 VIDEO 小视频 下载方法 FRIENDS 好友邀请 添加好友所需参数 SYSTEM 系统消息 更新内容的用户或群聊的UserName组成的列表 代码示例: 存储接受的文件 @itchat.msg_register(ATTACHMENT) def download_files(msg): msg[&quot;Text&quot;](msg[&quot;FileName&quot;]) 附件的下载与发送itchat 的附件下载方法存储在 msg 的 Text 键中. 发送的文件名(图片给出的默认文件名), 都存储在 msg 的 FileName 键中. 下载方法, 接受一个可用的位置参数(包括文件名), 并将文件响应的存储. @itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO]) def download_files(msg): msg.download(msg.fileName) itchat.send(&apos;@%s@%s&apos; % (&apos;img&apos; if msg[&apos;Type&apos;] == &apos;Picture&apos; else &apos;fil&apos;, msg[&quot;FileName&quot;]), msg[&quot;FromUserName&quot;]) return &quot;%s received&quot; % msg[&quot;Type&quot;] 如果不需要下载到本地, 仅需要读取二进制串进一步处理可以不传入参数, 方法将会返回图片的二进制串. @itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO]) def download_files(msg): with open(msg.fileName, &apos;wb&apos;) as f: f.write(msg.download()) 群消息增加了三个键值: isAt : 判断是否 @ 本号 ActualNickName : 实际 NickName Content : 实际 Content 测试程序: import itcaht from itchat.content import TEXT @itchat.msg_register(TEXT, isGroupChat=True) def text_reply(msg): print(msg.isAt) print(msg.actualNickName) print(msg.text) itchat.auto_login() itchat.run() 3. 注册消息的优先级优先级规则: 后注册消息 &gt; 先注册消息 带参数消息 &gt; 不带参数消息 4. 动态注册消息 将 itchat.run() 放入另一线程 import thread thread.start_new_thread(itcaht.run(), ()) 使用 configured_reply() 方法处理消息. while 1: itcaht.configured_reply() # some other functions time.sleep() 示例: #coding=utf-8 import thread import itchat from itchat.content import * replyToGroupChat = True functionStatus = False def change_function(): if replyToGroupChat != functionStatus: if replyToGroupChat: @itchat.msg_register(TEXT, isGroupChat=True) def group_text_reply(msg): if u&apos;关闭&apos; in msg[&quot;Text&quot;]: replyToGroupChat = False return u&quot;以关闭&quot; elif u&quot;开启&quot; in msg[&quot;Text&quot;]: return u&quot;已经在运行&quot; return u&apos;输入&quot;关闭&quot; 或者 &quot;开启&quot; 测试功能&apos; else: @itcaht.msg_register(TEXT, isGroupCaht=True) def group_text_reply(msg): if u&quot;开启&quot; in msg[&quot;Text&quot;]: replyToGroupChat = True return u&quot;重新开启成功&quot; functionStatus = replyToGroupChat thread.start_new_thread(itcaht.run, ()) while 1: change_function() time.sleep(1) # 各类消息的注册: 通过如下代码, 微信已经可以就日常的各种信息进行获取与回复. import itchat, time from itchat.content import * @itchat.msg_register([TEXT, MAP, NOTE, SHARING]) def text_replay(msg): msg.user.send(&apos;%s %s&apos; % (msg.type, msg.text)) @itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO]) def download_file(msg): msg.download(msg.fileName) typeSymbol = { PICTURE: &apos;img&apos;, VIDEO: &apos;vid&apos;, }.get(msg.type, &apos;fil&apos;) return &quot;@%s@%s&quot; % (typeSymbol, msg.fileName) @itchat.msg_register(FRIENDS) def add_friend(msg): msg.user.verify() msg.user.send(&quot;Nice to meet you!&quot;) @itchat.msg_register(TEXT, isGroupChat=True) def text_replay(msg): if msg.isAt: msg.user.send(u&apos;@$s\u2005I received: %s&apos; % (msg.actualNickName, msg.text)) itchat.auto_login(True) itchat.run(True) 五. 消息内容1. 微信一般消息内容微信回复的所有消息都遵循这一格式. { &quot;FromUserName&quot;: &quot;&quot;, &quot;ToUserName&quot;: &quot;&quot;, &quot;Content&quot;: &quot;&quot;, &quot;StatusNotifyUserName&quot;: &quot;&quot;, &quot;ImgWidth&quot;: 0, &quot;PlayLength&quot;: 0, &quot;RecommendInfo&quot;: {}, &quot;StatusNotifyCode&quot;: 0, &quot;NewMsgId&quot;: &quot;&quot;, &quot;Status&quot;: 0, &quot;VoiceLength&quot;: 0, &quot;ForwardFlag&quot;: 0, &quot;AppMsgType&quot;: 0, &quot;Ticket&quot;: &quot;&quot;, &quot;AppInfo&quot;: {}, &quot;Url&quot;: &quot;&quot;, &quot;ImgStatus&quot;: 0, &quot;MsgType&quot;: 0, &quot;ImgHeight&quot;: 0, &quot;MediaId&quot;: &quot;&quot;, &quot;MsgId&quot;: &quot;&quot;, &quot;FileName&quot;: &quot;&quot;, &quot;HasProductId&quot;: 0, &quot;FileSize&quot;: &quot;&quot;, &quot;CreateTime&quot;: 0, &quot;SubMsgType&quot;: 0 } 2. 消息具体内容1) 初始化消息MsgType: 51 FromUserName: 自己ID ToUserName: 自己ID StatusNotifyUserName: 最近联系的联系人ID Content: &lt;msg&gt; &lt;op id=&apos;4&apos;&gt; &lt;username&gt; # 最近联系的联系人 filehelper,xxx@chatroom,wxid_xxx,xxx,... &lt;/username&gt; &lt;unreadchatlist&gt; &lt;chat&gt; &lt;username&gt; # 朋友圈 MomentsUnreadMsgStatus &lt;/username&gt; &lt;lastreadtime&gt; 1454502365 &lt;/lastreadtime&gt; &lt;/chat&gt; &lt;/unreadchatlist&gt; &lt;unreadfunctionlist&gt; # 未读的功能账号消息，群发助手，漂流瓶等 &lt;/unreadfunctionlist&gt; &lt;/op&gt; &lt;/msg&gt; 2) 文本消息MsgType: 1 FromUserName: 发送方ID ToUserName: 接收方ID Content: 消息内容 3) 图片消息itchat 增加了 Text 键, 键值为 下载该图片的方法. MsgType: 3 FromUserName: 发送方ID ToUserName: 接收方ID MsgId: 用于获取图片 Content: &lt;msg&gt; &lt;img length=&quot;6503&quot; hdlength=&quot;0&quot; /&gt; &lt;commenturl&gt;&lt;/commenturl&gt; &lt;/msg&gt; 4) 小视频消息itchat 增加了 Text 键, 键值为 下载该视频的方法. MsgType: 62 FromUserName: 发送方ID ToUserName: 接收方ID MsgId: 用于获取小视频 Content: &lt;msg&gt; &lt;img length=&quot;6503&quot; hdlength=&quot;0&quot; /&gt; &lt;commenturl&gt;&lt;/commenturl&gt; &lt;/msg&gt; 5) 地理位置消息itchat 增加了 Text 键, 键值为 该地点的文本形式. MsgType: 1 FromUserName: 发送方ID ToUserName: 接收方ID Content: http://weixin.qq.com/cgi-bin/redirectforward?args=xxx 6) 名片消息itchat 增加了 Text 键, 键值为 该调用 add_friend 需要的属性. MsgType: 42 FromUserName: 发送方ID ToUserName: 接收方ID Content: &lt;?xml version=&quot;1.0&quot;?&gt; &lt;msg bigheadimgurl=&quot;&quot; smallheadimgurl=&quot;&quot; username=&quot;&quot; nickname=&quot;&quot; shortpy=&quot;&quot; alias=&quot;&quot; imagestatus=&quot;3&quot; scene=&quot;17&quot; province=&quot;&quot; city=&quot;&quot; sign=&quot;&quot; sex=&quot;1&quot; certflag=&quot;0&quot; certinfo=&quot;&quot; brandIconUrl=&quot;&quot; brandHomeUrl=&quot;&quot; brandSubscriptConfigUrl=&quot;&quot; brandFlags=&quot;0&quot; regionCode=&quot;&quot; /&gt; RecommendInfo: { &quot;UserName&quot;: &quot;xxx&quot;, # ID &quot;Province&quot;: &quot;xxx&quot;, &quot;City&quot;: &quot;xxx&quot;, &quot;Scene&quot;: 17, &quot;QQNum&quot;: 0, &quot;Content&quot;: &quot;&quot;, &quot;Alias&quot;: &quot;xxx&quot;, # 微信号 &quot;OpCode&quot;: 0, &quot;Signature&quot;: &quot;&quot;, &quot;Ticket&quot;: &quot;&quot;, &quot;Sex&quot;: 0, # 1:男, 2:女 &quot;NickName&quot;: &quot;xxx&quot;, # 昵称 &quot;AttrStatus&quot;: 4293221, &quot;VerifyFlag&quot;: 0 } 7) 语音消息itchat 增加了 Text 键, 键值为 下载该语音文件的方法. MsgType: 34 FromUserName: 发送方ID ToUserName: 接收方ID MsgId: 用于获取语音 Content: &lt;msg&gt; &lt;voicemsg endflag=&quot;1&quot; cancelflag=&quot;0&quot; forwardflag=&quot;0&quot; voiceformat=&quot;4&quot; voicelength=&quot;1580&quot; length=&quot;2026&quot; bufid=&quot;216825389722501519&quot; clientmsgid=&quot;49efec63a9774a65a932a4e5fcd4e923filehelper174_1454602489&quot; fromusername=&quot;&quot; /&gt; &lt;/msg&gt; 8) 动画表情itchat添加了Text键，键值为下载该图片表情的方法。 由于版权问题，部分微信商店提供的表情是无法下载的，注意。 MsgType: 47 FromUserName: 发送方ID ToUserName: 接收方ID Content: &lt;msg&gt; &lt;emoji fromusername = &quot;&quot; tousername = &quot;&quot; type=&quot;2&quot; idbuffer=&quot;media:0_0&quot; md5=&quot;e68363487d8f0519c4e1047de403b2e7&quot; len = &quot;86235&quot; productid=&quot;com.tencent.xin.emoticon.bilibili&quot; androidmd5=&quot;e68363487d8f0519c4e1047de403b2e7&quot; androidlen=&quot;86235&quot; s60v3md5 = &quot;e68363487d8f0519c4e1047de403b2e7&quot; s60v3len=&quot;86235&quot; s60v5md5 = &quot;e68363487d8f0519c4e1047de403b2e7&quot; s60v5len=&quot;86235&quot; cdnurl = &quot;http://emoji.qpic.cn/wx_emoji/eFygWtxcoMF8M0oCCsksMA0gplXAFQNpiaqsmOicbXl1OC4Tyx18SGsQ/&quot; designerid = &quot;&quot; thumburl = &quot;http://mmbiz.qpic.cn/mmemoticon/dx4Y70y9XctRJf6tKsy7FwWosxd4DAtItSfhKS0Czr56A70p8U5O8g/0&quot; encrypturl = &quot;http://emoji.qpic.cn/wx_emoji/UyYVK8GMlq5VnJ56a4GkKHAiaC266Y0me0KtW6JN2FAZcXiaFKccRevA/&quot; aeskey= &quot;a911cc2ec96ddb781b5ca85d24143642&quot; &gt;&lt;/emoji&gt; &lt;gameext type=&quot;0&quot; content=&quot;0&quot; &gt;&lt;/gameext&gt; &lt;/msg&gt; 9) 普通链接或应用分享消息MsgType: 49 AppMsgType: 5 FromUserName: 发送方ID ToUserName: 接收方ID Url: 链接地址 FileName: 链接标题 Content: &lt;msg&gt; &lt;appmsg appid=&quot;&quot; sdkver=&quot;0&quot;&gt; &lt;title&gt;&lt;/title&gt; &lt;des&gt;&lt;/des&gt; &lt;type&gt;5&lt;/type&gt; &lt;content&gt;&lt;/content&gt; &lt;url&gt;&lt;/url&gt; &lt;thumburl&gt;&lt;/thumburl&gt; ... &lt;/appmsg&gt; &lt;appinfo&gt; &lt;version&gt;&lt;/version&gt; &lt;appname&gt;&lt;/appname&gt; &lt;/appinfo&gt; &lt;/msg&gt; 10) 音乐链接消息MsgType: 49 AppMsgType: 3 FromUserName: 发送方ID ToUserName: 接收方ID Url: 链接地址 FileName: 音乐名 AppInfo: # 分享链接的应用 { Type: 0, AppID: wx485a97c844086dc9 } Content: &lt;msg&gt; &lt;appmsg appid=&quot;wx485a97c844086dc9&quot; sdkver=&quot;0&quot;&gt; &lt;title&gt;&lt;/title&gt; &lt;des&gt;&lt;/des&gt; &lt;action&gt;&lt;/action&gt; &lt;type&gt;3&lt;/type&gt; &lt;showtype&gt;0&lt;/showtype&gt; &lt;mediatagname&gt;&lt;/mediatagname&gt; &lt;messageext&gt;&lt;/messageext&gt; &lt;messageaction&gt;&lt;/messageaction&gt; &lt;content&gt;&lt;/content&gt; &lt;contentattr&gt;0&lt;/contentattr&gt; &lt;url&gt;&lt;/url&gt; &lt;lowurl&gt;&lt;/lowurl&gt; &lt;dataurl&gt; http://ws.stream.qqmusic.qq.com/C100003i9hMt1bgui0.m4a?vkey=6867EF99F3684&amp;amp;guid=ffffffffc104ea2964a111cf3ff3edaf&amp;amp;fromtag=46 &lt;/dataurl&gt; &lt;lowdataurl&gt; http://ws.stream.qqmusic.qq.com/C100003i9hMt1bgui0.m4a?vkey=6867EF99F3684&amp;amp;guid=ffffffffc104ea2964a111cf3ff3edaf&amp;amp;fromtag=46 &lt;/lowdataurl&gt; &lt;appattach&gt; &lt;totallen&gt;0&lt;/totallen&gt; &lt;attachid&gt;&lt;/attachid&gt; &lt;emoticonmd5&gt;&lt;/emoticonmd5&gt; &lt;fileext&gt;&lt;/fileext&gt; &lt;/appattach&gt; &lt;extinfo&gt;&lt;/extinfo&gt; &lt;sourceusername&gt;&lt;/sourceusername&gt; &lt;sourcedisplayname&gt;&lt;/sourcedisplayname&gt; &lt;commenturl&gt;&lt;/commenturl&gt; &lt;thumburl&gt; http://imgcache.qq.com/music/photo/album/63/180_albumpic_143163_0.jpg &lt;/thumburl&gt; &lt;md5&gt;&lt;/md5&gt; &lt;/appmsg&gt; &lt;fromusername&gt;&lt;/fromusername&gt; &lt;scene&gt;0&lt;/scene&gt; &lt;appinfo&gt; &lt;version&gt;29&lt;/version&gt; &lt;appname&gt;摇一摇搜歌&lt;/appname&gt; &lt;/appinfo&gt; &lt;commenturl&gt;&lt;/commenturl&gt; &lt;/msg&gt; 11) 群消息itchat 增加了三个群聊相关的键值: isAt : 判断是否 @ 本号 ActualNickName : 实际 NickName Content : 实际 Content MsgType: 1 FromUserName: @@xxx ToUserName: @xxx Content: @xxx:&lt;br/&gt;xxx 12) 红包消息MsgType: 49 AppMsgType: 2001 FromUserName: 发送方ID ToUserName: 接收方ID Content: 未知 13) 系统消息MsgType: 10000 FromUserName: 发送方ID ToUserName: 自己ID Content: &quot;你已添加了 xxx ，现在可以开始聊天了。&quot; &quot;如果陌生人主动添加你为朋友，请谨慎核实对方身份。&quot; &quot;收到红包，请在手机上查看&quot; 六. 账号类型itchat 为三种账号都提供了 整体获取方法与搜索方法. 群聊多出了获取用户列表方法以及创建群聊,增加/删除用户的方法. 1. 好友 get_friends : 返回完整的好友列表 每个好友为一个字典, 其中第一项为本人的账号信息; 传入 update=True, 将更新好友列表并返回, get_friends(update=True). search_friends : 好友搜索, 有四种搜索方式 仅获取自己的用户信息 # 获取自己的用户信息，返回自己的属性字典 itchat.search_friends() 获取特定 UserName 的用户信息 # 获取特定UserName的用户信息 itchat.search_friends(userName=&apos;@abcdefg1234567&apos;) 获取备注,微信号, 昵称中的任何一项等于name键值的用户. (可以与下一项配置使用.) # 获取任何一项等于name键值的用户 itchat.search_friends(name=&apos;littlecodersh&apos;) 获取备注,微信号, 昵称分别等于相应键值的用户. (可以与上一项配置使用.) # 获取分别对应相应键值的用户 itchat.search_friends(wechatAccount=&apos;littlecodersh&apos;) # 三、四项功能可以一同使用 itchat.search_friends(name=&apos;LittleCoder机器人&apos;, wechatAccount=&apos;littlecodersh&apos;) update_friend : 好友更新 特定用户: 传入用户UserName, 返回指定用户的最新信息. 用户列表: 传入 UserName 组成的列表, 返回用户最新信息组成的列表. memberList = itchat.update_friend(&#39;@abcdefg1234567&#39;) 2. 公众号 get_mps : 将返回完整的工作号列表. 每个公众号为一个字典, 传入 update=True 将更新公众号列表, 并返回. search_mps : 有两种搜索方法: 获取特定UserName的公众号 # 获取特定UserName的公众号，返回值为一个字典 itchat.search_mps(userName=&apos;@abcdefg1234567&apos;) 获取名字中还有特定字符的公众号. # 获取名字中含有特定字符的公众号，返回值为一个字典的列表 itchat.search_mps(name=&apos;LittleCoder&apos;) 当两项都是勇士, 将仅返回特定UserName的公众号. 3. 群聊 get_chatrooms : 返回完整的群聊列表. search_chatrooms : 群聊搜索. update_chatroom : 获取群聊用户列表或更新该群聊. 群聊在首次获取中不会获取群聊的用户列表, 所以需要调用该命令才能获取群聊成员. 传入群聊的 UserName , 返回特定群聊的详细信息. 传入UserName组成的列表, 返回指定用户的最新信息组成的列表. memberList = itchat.update_chatroom(&#39;@@abcdefg1234567&#39;, detailedMember=True) 创建群聊,增加/删除群聊用户: 由于之前通过群聊检测是否被好友拉黑的程序, 目前这三个方法都被严格限制了使用频率. 删除群聊需要本账号为管理员, 否则无效. 将用户加入群聊有直接加入与发送邀请, 通过 useInvitation 设置. 超过 40 人的群聊无法使用直接加入的加入方式. memberList = itchat.get_frients()[1:] # 创建群聊, topic 键值为群聊名称. chatroomUserName = itchat.create_chatroom(memberList, &quot;test chatroom&quot;) # 删除群聊内的用户 itchat.delete_member_from_chatroom(chatroomUserName, memberList[0]) # 增加用户进入群聊. itchat.add_member_into_chatroom(chatroomUserName, memberList[0], useInvitation=False) 4. Uins : 通过Uin唯一的确定好友与群聊。Uin 是微信中用于标识用户的方式, 每一个用户/群聊都有唯一且不同的 Uin.通过 Uin, 即使退出了重新登录, 也可以轻松的确认正在对话的是上一次登录的哪一个用户. Uin 与其他值不同, 微信后台做了一些限制, 必须通过特殊的操作才能获取. 首次点开登录用的手机端的某个好友或者群聊, itchat 就能获取到该好友或者群聊 Uin. 如果想要通过程序获取, 可以用程序将某个好友或者群聊置顶(取消置顶). 示例程序: import re, sys, json import itchat from itchat.content import * itcaht.auto_login() @itchat.msg_register(SYSTEM) def get_uin(msg): if msg[&quot;SystemInfo&quot;] != &apos;unis&apos;: return ins = itchat.instanceList[0] fullContact = ins.memberList + ins.chatroomList + ins.mpList print(&quot;** Uin updated **&quot;) for username in msg[&quot;Text&quot;]: member = itchat.utils.search_dict_list(fullContact, &apos;UserName&apos;, username) print((&quot;%s: %s&quot; % (member.get(&quot;NickName&quot;, &apos;&apos;), member[&quot;Uin&quot;])).encode(sys.stdin.encoding, &apos;replace&apos;)) itchat.run(True) 每当 Uin 更新了, 就会打印相应的更新情况. 同样, 吐过希望获取 Uin 更新的情况, 也统过获取SYSTEM类型的消息实现. 七. Q &amp; A1. 中文文件名文件上传Q: 为什么中文的文件没有办法上传？ A: 这是由于requests的编码问题导致的。若需要支持中文文件传输，将fields.py(py3版本见这里)文件放入requests包的packages/urllib3下即可 2. 命令行显示二维码Q: 为什么我在设定了itchat.auto_login()的enableCmdQR为True后还是没有办法在命令行显示二维码？ A: 这是由于没有安装可选的包pillow，可以使用右边的命令安装：pip install pillow 3. 如何通过itchat实现控制器Q: 如何通过这个包将自己的微信号变为控制器？ A: 有两种方式：发送、接受自己UserName的消息；发送接收文件传输助手（filehelper）的消息 八. itchat 方法汇总:itchat.add_friend itchat.new_instance itchat.add_member_into_chatroom itchat.originInstance itchat.auto_login itchat.returnvalues itchat.check_login itchat.run itchat.components itchat.search_chatrooms itchat.config itchat.search_friends itchat.configured_reply itchat.search_mps itchat.content itchat.send itchat.core itchat.send_file itchat.Core itchat.send_image itchat.create_chatroom itchat.send_msg itchat.delete_member_from_chatroom itchat.send_raw_msg itchat.dump_login_status itchat.send_video itchat.get_chatrooms itchat.set_alias itchat.get_contact itchat.set_chatroom_name itchat.get_friends itchat.set_logging itchat.get_head_img itchat.set_pinned itchat.get_mps itchat.show_mobile_login itchat.get_msg itchat.start_receiving itchat.get_QR itchat.storage itchat.get_QRuuid itchat.update_chatroom itchat.instanceList itchat.update_friend itchat.load_login_status itchat.upload_file itchat.log itchat.utils itchat.login itchat.VERSION itchat.logout itchat.web_init itchat.msg_register 九. Githubitchat]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>PyPi</tag>
        <tag>itchat</tag>
        <tag>微信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django之零--入门篇]]></title>
    <url>%2F2018%2F03%2F16%2Fdjango%E4%B9%8B%E9%9B%B6--%E5%85%A5%E9%97%A8%E7%AF%87%2F</url>
    <content type="text"><![CDATA[本质上来说， Django 只不过是用 Python 编写的一组类库。 用 Django 开发站点就是使用这些类库编写 Python 代码。 因此，学习 Django 的关键就是学习如何进行 Python 编程并理解 Django 类库的运作方式。 学习Django就是学习她的命名规则和API。 Django 的可选 GIS(地理信息系统) 支持需要 Python 2.4 到 2.6 . Django 支持的数据库: pgsql (Django的可选GIS支持，它为PostgreSQL提供了强大的功能) 安装 psycopg2 SQLite3 Mysql 安装 MySQLdb Oracle 安装 cx_Oracle 一. 安装 django$ pip install django (env)$ python &gt;&gt; import django &gt;&gt; django.VERSION &gt;&gt; django.get_version() 二.开始一个项目项目是 django 实例的一系列设置的集合, 它包括数据库配置, Django 特定选项以及应用程序的特定设置. $ django-admin.py startproject mysite $ python manage.py help $ tree mysite mysite/ ├── manage.py # 命令行工具, 允许以多种方式与该 Django 项目交互 └── mysite ├── __init__.py # 将该目录当成一个 包. ├── settings.py # 该 Django 项目的设置或配置. ├── urls.py # Django 项目的 URL 设置. └── wsgi.py # For the full list of settings and their values, see # https://docs.djangoproject.com/en/1.10/ref/settings/ $ python manage.py runserver 8000 # 启动服务器. 文件职责介绍: urls.py : 网址入口,关联到对应的 views.py 的中的一个函数(或generic类),访问网址对应一个函数. views.py : 处理用户发出的请求, 从 urls.py 中对应过来, 通过渲染 templates 中的网页可以将显示的内容. models.py : 与数据库操作有关,存入或存取数据时使用,可以不用. forms.py : 表单,用户在浏览器上输入数据提交,对数据的验证工作以及输入框的生成等工作,可以不用. templates 文件夹 : views.py 中的函数渲染 templates 中的html模板,得到动态内容网页,可用缓存来提升速度. admin.py : 后台,可以用少量的代码,拥有一个强大的后台. settings.py : Django的设置,配置文件,比如 DEBUG 开关,静态文件的位置等. 每个视图函数至少需要一个参数, 通常叫做 request , 这是一个触发这个视图, 包含当前 web 请求信息的对象, 是类 django.http.HttpRequest 的一个实例. 一个视图就是 Python 的一个函数, 这个函数第一个参数的类型是 HttpRequest, 它返回一个 HttpResponse 实例, 为了使一个 Python 的函数成为一个 Django 可识别的函数, 它必须满足这两个条件. 三. urlsThe urlpatterns list routes URLs to views. For more information please see: https://docs.djangoproject.com/en/1.10/topics/http/urls/Examples: Function views Add an import: from my_app import views Add a URL to urlpatterns: url(r&#39;^$&#39;, views.home, name=&#39;home&#39;) Class-based views Add an import: from other_app.views import Home Add a URL to urlpatterns: url(r&#39;^$&#39;, Home.as_view(), name=&#39;home&#39;) Including another URLconf Import the include() function: from django.conf.urls import url, include Add a URL to urlpatterns: url(r&#39;^blog/&#39;, include(&#39;blog.urls&#39;)) 将代码放置在文档根目录之外的某些目录中. 运行 开发服务器 $ python manage.py runserver [0.0.0.0:8080] $ python manage.py runserver --help $ vim mysite/mysite/settings.py ALLOWED_HOSTS = [&apos;192.168.100.128&apos;] # 配置 开发服务器 IP. 开发服务器会自动监测代码改动并自动重新载入，所以不需要手工重启 四. 命令汇总# 新建一个 django project $ django-admin.py startproject PROJECT_NAME # 新建 app $ python manage.py startapp APP_NAME $ django-admin.py startapp APP_NAME # 同上 ** 一般一个项目有多个app,当然通用的app也可以在多个项目中使用 # 同步数据库 $ python manage.py syncdb ** 当 Django 1.7.1 及以上版本需使用以下命令: $ python manage.py makemigrations $ python manage.py migrate ** 这种方法可以创建表,当你在 models.py 中新增了类时,运行它就可以自动在数据库中创建表了,不用手动创建. ** 对已有的 models 进行修改，Django 1.7 之前的版本的Django都是无法自动更改表结构的, 不过有第三方工具 south # 使用开发服务器 : 开发服务器，即开发时使用，一般修改代码后会自动重启，方便调试和开发，但是由于性能问题，建议只用来测试，不要用在生产环境。 $ python manage.py runserver $ python manage.py runserver 8001 $ python manage.py runserver 0.0.0.0:8000 # 清空数据库 : $ python manage.py flush # 会询问 yes 还是 no. yes 会把数据全部清空,只留下空表. # 创建超级管理员 : $ python manage.py createsuperuser # 用户名,密码必填,邮箱可留空. $ python manage.py changepassword username # 修改用户密码. # 导入导出数据 $ python manage.py dumpdata appname &gt; appname.json $ python manage.py loaddata appname.json # Django 项目环境终端. $ python manage.py shell # 如果你安装了 bpython 或 ipython 会自动用它们的界面，推荐安装 bpython。 ** 这个命令和 直接运行 python 或 bpython 进入 shell 的区别是：你可以在这个 shell 里面调用当前项目的 models.py 中的 API，对于操作数据，还有一些小测试非常方便。 # 数据库命令行 $ python manage.py dbshell Django 会自动进入在settings.py中设置的数据库，如果是 MySQL 或 postgreSQL,会要求输入数据库用户密码。 在这个终端可以执行数据库的SQL语句。 # 更多命令 : $ python manage.py # 查看命令列表. $ python manage.py help &lt;subcommand&gt; # 获取帮助 : $ python manage.py --help $ python manage.py help [SUB_CMD] # 后台管理密码 $ python manage.py createsuperuser user : admin password : 123456 $ curl http://example.com/admin]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>web development</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django之一--视图篇]]></title>
    <url>%2F2018%2F03%2F16%2Fdjango%E4%B9%8B%E4%B8%80--%E8%A7%86%E5%9B%BE%E7%AF%87%2F</url>
    <content type="text"><![CDATA[一. Django 请求处理流程每个 view 函数的第一个参数是一个 HttpRequest 对象 所有均开始于 setting.py 文件. 当运行 python manage.py runserver 时, 脚本将会在 manage.py 同一个目录下查找名为 settings.py 的文件. 这个文件包含了所有关于这个 Django 项目的配置信息, 均采用大写形式表示 : TEMPLATE_DIRS,DATABASE_NAME 等. 最重要的设置是 ROOT_URLCONF, 它将作为 URLconf 告诉 django 在这个站点中那些 Python 的模块将被用到. ROOT_URLCONF = &apos;mysite.urls&apos; 当访问某个 URL 时, Django 根据 ROOT_URLCONF 的设置装载 URLconf. 然后按顺序逐个匹配 URLconf 里的 URLpattern, 直到找到一个匹配的. 当找到这个匹配的 URLpattern 就调用相关联的 view 函数, 并把 HttpRequest 对象作为第一个参数 传给 view 函数. 一个视图函数必须返回一个 HttpResponse . 一旦做完, Django 将完成剩余的转换 Python 对象到一个合适的代用 HTTP 头和 body 的 Web Response. 总结如下: 进来的请求转入/hello/. Django通过在ROOT_URLCONF配置来决定根URLconf. Django在URLconf中的所有URL模式中，查找第一个匹配/hello/的条目。 如果找到匹配，将调用相应的视图函数, 并将HttpRequest作为第一个参数, 传给被调用的视图函数. 视图函数返回一个HttpResponse Django转换HttpResponse为一个适合的HTTP response， 以Web page显示出来 Django 视图: 默认时区为 America/Chicago , 是 Django 的诞生地. 可以修改 settings.py 中的 TIME_ZONE = &#39;Time/Zone&#39; 做修改. 二. 编写视图函数 :# views.py from django.http import HttpResponse def hello(request): return HttpResponse(&quot;Hello world&quot;) 每个视图函数至少要有一个参数, 通常被叫做 request. 这是一个触发这个函数, 包含当前 web 请求信息的对象, 是 类 django.http.HttpRequest 的一个实例. 它必须是视图的第一个参数. 视图函数的名称并不重要. 它只是一个普通的函数, 方便记忆与理解即可. 一个视图就是 Python 的一个函数, 这个函数第一个参数的类型是 HttpRequest; 它返回一个 HttpResponse 实例. 三. 配置视图函数: URLconfURLconf : 即 urls.py文件, 本质是 URL 模式以及要为该 URL 模式调用的 视图函数之间的 映射表. $ cat urls.py from django.contrib import admin from mysite.views import hello # 导入视图函数 hello urlpatterns = [ url(r&apos;^admin/&apos;, admin.site.urls), url(&apos;^hello&apos;, hello), # 加入到映射列表中.所有指向 URL /hello/ 的请求都应由 hello 这个视图函数来处理。 url(&apos;^$&apos;, my_homepage_view), # 网站根目录视图函数 ] 应该注意是 urlpatterns 变量， Django 期望能从 ROOT_URLCONF 模块中找到它。 该变量定义了 URL 以及用于处理这些 URL 的代码之间的映射关系。 1. URLpattern 语法: Django 在检查 URL 模式之前, 移除每一个申请的 URL 开头的 斜杠(/). 这意味着我们为 /hello/ 写 URL 模式不用包含开头的斜杠(/). 模式包含了一个尖号(^)和一个美元符号($). 这些都是正则表达式符号. 大多数的 URL 模式会以\^开始, 以\$结束, 但是拥有复杂匹配的灵活性会更好. 如果访问 尾部没有斜杠(/) 如 /hello, 则该请求会被重定向至尾部包含斜杠(/)的URL(/hello/). 该行为受到 setting 中的 APPEND_SLASH 选项的控制. 2. URLpattern 支持的正则表达式Django URLconfs 允许你使用任意的正则表达式来做强有力的 URL 映射. 符号 匹配 . (dot) 任意单一字符 \d 任意一位数字 [A-Z] A 到 Z中任意一个字符（大写） [a-z] a 到 z中任意一个字符（小写） [A-Za-z] a 到 z中任意一个字符（不区分大小写） + 匹配一个或更多 (例如, \d+ 匹配一个或 多个数字字符) [^/]+ 一个或多个不为‘/’的字符 ? 零个或一个之前的表达式（例如：\d? 匹配零个或一个数字） * 匹配0个或更多 (例如, \d* 匹配0个 或更多数字字符) {1,3} 介于一个和三个（包含）之前的表达式（例如，\d{1,3}匹配一个或两个或三个数字） 3. URL 配置和松耦合Django 和 URL 配置背后哲学: 松耦合原则. 简单的说, 松耦合是一个重要的保证互换性的软件开发方法. Django 的 URL 配置就是一个很好的例子, 在 Django 的应用程序中, URL 定义和视图函数之间是松耦合的, 换句话说, 决定 URL 返回那个视图函数和实现这个视图函数是在两个不同的地方. 这使得开发人员可以修改一块而不会影响另一块. urlpatterns = [ url(r&apos;^admin/&apos;, admin.site.urls), url(&apos;^hello/$&apos;, hello), url(&apos;^time/$&apos;, current_datetime), url(&apos;^another-time/$&apos;, current_datetime), ] 四. URLconf 高级技巧1. 函数对象方法from django.contrib import admin from mysite.views import hello # 导入视图函数 hello urlpatterns = [ url(r&apos;^admin/&apos;, admin.site.urls), url(&apos;^hello&apos;, hello), url(&apos;^$&apos;, my_homepage_view), ] 2. 字符串方法2.1 为某个特别的模式指定视图函数:传入一个包含模块名和函数名的字符串, 而不是函数对象本身. Django 会在第一次需要他时根据字符串所描述的视图函数的名字和路径, 导入合适的视图函数. from django.conf.urls.defaults import * # 注意视图函数名前后的引号, urlpatterns = patterns(&apos;&apos;, (r&apos;^hello/$&apos;, &apos;mysite.views.hello&apos;), (r&apos;^time/$&apos;, &apos;mysite.views.current_datetime&apos;), ) 2.2 提取公共视图前缀, 仅限于使用字符串视图函数的时候.from django.conf.urls.defaults import * # 注意视图函数名前后的引号, urlpatterns = patterns(&apos;mysite.views&apos;, (r&apos;^hello/$&apos;, &apos;hello&apos;), (r&apos;^time/$&apos;, &apos;current_datetime&apos;), ) 2.3 多个视图前缀整个框架关注的是存在一个名为 urlpatterns 的模块级别的变量. 该变量可动态生成. patterns() 返回的对象是可相加的. from django.conf.urls.defaults import * urlpatterns = patterns(&apos;mysite.views&apos;, (r&apos;^hello/$&apos;, &apos;hello&apos;), (r&apos;^time/$&apos;, &apos;current_datetime&apos;), (r&apos;^time/plus/(\d{1,2})/$&apos;, &apos;hours_ahead&apos;), ) urlpatterns += patterns(&apos;weblog.views&apos;, (r&apos;^tag/(\w+)/$&apos;, &apos;tag&apos;), ) 3. 动态 urlpatterns 与 调试模式在 django 的调试模式下修改 URLconf 的行为, 只需在运行时检查 DEBUGF 配置项的值即可. from django.conf import settings from django.conf.urls.defaults import * from mysite import views urlpatterns = patterns(&apos;&apos;, (r&apos;^$&apos;, views.homepage), (r&apos;^(\d{4})/([a-z]{3})/$&apos;, views.archive_month), # ) # URL链接 /debuginfo/ 只在你的 DEBUG 配置项设为 True 时才有效。 if settings.DEBUG: urlpatterns += patterns(&apos;&apos;, (r&apos;^debuginfo/$&apos;, views.debug) ) 4. 正则表达式实现的 动态 URL4.1 使用正则表达式 无命名组使用 无命名正则表达式组，即，在我们想要捕获的URL部分上加上小括号，Django 会将捕获的文本作为位置参数传递给视图函数。 # urls.py urlpatterns = [ # ... url(r&apos;^time/plus/(\d{1,2})/$&apos;, hours_ahead), # (\d{1,2}) 实质是 参数. # ... ] # views.py def hours_ahead(request,offset): try: offset = int(offset) except ValueError: raise Http404() dt = datetime.datetime.now() + datetime.timedelta(hours=offset) html=&quot;&lt;html&gt;&lt;body&gt;In %s hours, it will be %s.&lt;/body&gt;&lt;/html&gt;&quot; % (offset, dt) return HttpResponse(html) 4.2 使用正则表达式 命名组使用命名正则表达式来捕获 URL, 并将其做为关键字参数传给视图. 命名组的语法为 (?P&lt;NAME&gt;PATTERN), NAME 是命名组的名称, PATTERN 是 匹配的模式. 命名组可以是 URLconf 更加清晰 ,可读性更强, 减少搞混参数次序的潜在 BUG , 还可以在视图函数中从新定义参数的顺序. # 使用无名组 URLconf from django.conf.urls.defaults import * from mysite import views urlpatterns = patterns(&apos;&apos;, (r&apos;^articles/(\d{4})/$&apos;, views.year_archive), (r&apos;^articles/(\d{4})/(\d{2})/$&apos;, views.month_archive), ) # url /articles/2006/03/ 将使用如下调用: month_archive(request, &apos;2006&apos;, &apos;03&apos;) # 使用命名组 URLconf from django.conf.urls.defaults import * from mysite import views urlpatterns = patterns(&apos;&apos;, (r&apos;^articles/(?P&lt;year&gt;\d{4})/$&apos;, views.year_archive), (r&apos;^articles/(?P&lt;year&gt;\d{4})/(?P&lt;month&gt;\d{2})/$&apos;, views.month_archive), ) # url /articles/2006/03/ 将使用如下调用: month_archive(request, year=&apos;2006&apos;, month=&apos;03&apos;) 命名组和非命名组不能同时出现在一个 URLconf 中,URLconf解释器有关正则表达式中命名组和 非命名组所遵循的算法: 如果有任何命名组, django 会忽略非命名组, 而直接使用命名组. 否则, django 会把所有非命名组 以位置参数的形式传递. 在以上的两种情况，Django同时会以关键字参数的方式传递一些额外参数. 5 向视图函数传递额外参数.5.1 URL 中向后端视图函数传入的, 是 纯 Python 字符串, 而无论正则表达式中的匹配格式.# 如下 year 参数, 传入到 year_archive 方法的数据类型是字符串, 而不是数字, 在视图函数中需要做一次转换. (r&apos;^articles/(?P&lt;year&gt;\d{4})/$&apos;, views.year_archive) 5.2 视图函数传参URLconf 里面的每一个模式都可以包含第三个参数, 一个关键字参数的字典. # url /foo/ 和 /bar/ 除了 使用的模板不同之外, 其他都一样. # urls.py from django.conf.urls.defaults import * from mysite import views urlpatterns = patterns(&apos;&apos;, (r&apos;^foo/$&apos;, views.foobar_view, {&quot;template_name&quot;: &quot;template1.html&quot;}), (r&apos;$bar/$&apos;, views.foobar_view, {&quot;template_name&quot;: &quot;template1.html&quot;}), ) # views.py from django.shortcuts import render_to_response from mysite.models import MyModel def foobar_view(request, template_name): m_list = MyModel.objects.filter(is_new=True) return render_to_response(template_name, {&apos;m_list&apos;: m_list}) 伪造捕捉到的 URLconf 值 # urls.py urlpatterns = patterns(&apos;&apos;, (r&apos;^mydata/birthday/$&apos;, views.my_view, {&apos;month&apos;: &apos;jan&apos;, &apos;day&apos;: &apos;06&apos;}), # 使用第三参数 (r&apos;^mydata/(?P&lt;month&gt;\w{3})/(?P&lt;day&gt;\d\d)/$&apos;, views.my_view), # 使用命名组 ) # views.py def my_view(request, month, day): # .... 当额外参数与正则表达式命名组同时存在的时候, 额外参数具有更高的优先级 urlpatterns = patterns(&apos;&apos;, (r&apos;^mydata/(?P&lt;id&gt;\d+)/$&apos;, views.my_view, {&apos;id&apos;: 3}) ) 5.3 视图函数的缺省参数给视图函数提供默认参数, 这样, 当没有给这个参数赋值的时候, 将会使用默认值. # urls.py from django.conf.urls.defaults import * from mysite import views urlpatterns = patterns(&apos;&apos;, (r&apos;^blog/$&apos;, views.page), # 没有参数时, 匹配视图函数的默认值. (r&apos;^blog/page(?P&lt;num&gt;\d+/$)&apos;, views.page) ) # views.py def page(request, num=&apos;1&apos;): # 此处 1 为字符串, 为了和 传入的参数保持一致. # ... # ... 6. URLconf 短路逻辑当两个匹配模式都可以匹配到同一个 URL 时, URLconf 讲采用自顶向下的方法顺序解析, 并在匹配过程中采用短路逻辑. urlpatterns = patterns(&apos;&apos;, # ... (&apos;^auth/user/add/$&apos;, views.user_add_stage), (&apos;^([^/]+)/([^/]+)/add/$&apos;, views.add_stage), # ... ) 7. 请求方法与 URL在解析 URLconf 时 , 请求方法(如 GET, POST, HEAD) 并不会被考虑. 换言之, 对于相同的 URL 的所有请求方法将会被导向到相同的函数中, 因此, 根据请求方法来处理分支是视图函数的责任. # views.py from django.http import Http404, HttpResponseRedirect from django.shortcuts import render_to_response def method_splitter(request, GET=None, POST=None): if request.method == &quot;GET&quot; and GET is not None: return GET(request) elif request.method == &quot;POST&quot; and POST is not None: returnn POST(request) raise Http404 # 另一种写法, 支持更多的参数 def method_splitter(request, *args, **kwargs): get_view = kwargs.pop(&quot;GET&quot;, None) post_view = kwargs.pop(&quot;POST&quot;, None) if request.method == &quot;GET&quot; and get_view is not None: return get_view(request, *args, **kwargs) elif request.method == &quot;POST&quot; and post_view is not None: return post_view(request, *args, **kwargs) raise Http404 def some_page_get(request): assert request.method == &quot;GET&quot; do_something_for_get() return render_to_response(&quot;page.html&quot;) def some_page_post(request): assert request.method == &quot;POST&quot; return HttpResponseRedirect(&quot;/someurl/&quot;) # urls.py from django.conf.urls.defaults import * from mysite import views urlpatterns = patterns(&apos;&apos;, # ... (r&apos;^somepage/$&apos;, views.method_splitter, {&quot;GET&quot;: views.some_page_get, &quot;POST&quot;: views.some_page_post}), # ... ) 8. 包装视图函数假如在不同的视图函数中出现了大量的重复代码, 如下, 每个视图都检查 return.user 是否已经认证: def my_view1(request): if not request.user.is_authenticated(): return HttpResponseRedirect(&apos;/accounts/login/&apos;) # ... return render_to_response(&apos;template1.html&apos;) def my_view2(request): if not request.user.is_authenticated(): return HttpResponseRedirect(&apos;/accounts/login/&apos;) # ... return render_to_response(&apos;template2.html&apos;) def my_view3(request): if not request.user.is_authenticated(): return HttpResponseRedirect(&apos;/accounts/login/&apos;) # ... return render_to_response(&apos;template3.html&apos;) 可以通过一个视图包装, 来实现去除重复代码: def requires_login(view): def new_view(request, *args, **kwargs): if not request.user.is_authenticated(): return HttpResponseRedirect(&quot;/accounts/login/&quot;) return view(return, *args, **kwargs) return new_view 然后再 URLconf 中实现包装: from django.conf.urls.defaults import * from mysite.views import requires_login, my_view1, my_view2, my_view3 urlpatterns = patterns(&apos;&apos;, (r&apos;^view1/$&apos;, requires_login(my_view1)), (r&apos;^view2/$&apos;, requires_login(my_view2)), (r&apos;^view3/$&apos;, requires_login(my_view3)), ) 9. include9.1 URLconf 可以包含其他 URconf 模块,# urls.py from django.conf.urls.defaults import * urlpatterns = patterns(&apos;&apos;, (r&apos;^weblog/&apos;, include(&quot;mysite.blog.urls&quot;)), (r&apos;^photos/&apos;, include(&quot;mysite.photos.urls&quot;)), (r&apos;^about/$&apos;, &apos;mysite.views.about&apos;) ) # mysite.blog.urls from django.conf.urls.defaults import * urlpatterns = patterns(&apos;&apos;, (r&apos;^(\d\d\d\d)/$&apos;, &apos;mysite.blog.views.year_detail&apos;), (r&apos;^(\d\d\d\d)/(\d\d)/$&apos;, &apos;mysite.blog.views.month_detail&apos;), ) 指向 include() 的正则表达式并不包含一个 $, 但是包含一个 /. 每当 django 遇到 include()时, 他将截断匹配的 URL, 并把剩余的字符串发往包含的 URLconf 做进一步处理. 9.2 正则表达式参数与 include() 协作一个被包含的 URLconf 接受任何来自 pattern URLconfs 的被捕获的参数. 这个被捕获的参数总是传递到被包含的 URLconf 中的每一行, 不管这些行对应的视图是否需要这些参数. 因此, 这个技巧, 只有在确定需要那个被传递的参数的时候才显得有用. # root urls.py from django.conf.urls.defaults import * urlpatterns = patterns(&apos;&apos;, (r&apos;^(?P&lt;username&gt;\w+)/blog/&apos;, include(&apos;foo.urls.blog&apos;)), ) # foo/urls/blog.py from django.conf.urls.defaults import * urlpatterns = patterns(&apos;&apos;, (r&apos;^$&apos;, &apos;foo.views.blog_index&apos;), (r&apos;^archive/$&apos;, &apos;foo.views.blog_archive&apos;) ) 9.3 额外参数与 include() 协作可以传递额外的 URLconf 选项到 include(), 就像可以通过字典传递额外的 URLconf 选项到普通的视图, 当使用该技巧时, 被包含 URLconf 的每一行都会受到那些额外的参数, 无论其是否需要. # urls.py from django.conf.urls.defaults import * urlpatterns = patterns(&quot;&quot;, (r&apos;^blog/&apos;, include(&apos;inner&apos;), {&apos;blogid&apos;: 3}), ) # inner.py from django.conf.urls.defaults import * urlpatterns = patterns(&apos;&apos;, (r&apos;^archive/$&apos;, &apos;mysite.views.archive&apos;), (r&apos;^about/$&apos;, &apos;mysite.views.about&apos;), (r&apos;^rss/$&apos;, &apos;mysite.views.rss&apos;), )]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>web development</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django之二--模板篇]]></title>
    <url>%2F2018%2F03%2F16%2Fdjango%E4%B9%8B%E4%BA%8C--%E6%A8%A1%E6%9D%BF%E7%AF%87%2F</url>
    <content type="text"><![CDATA[一. 概述模板系统是一个 Python 库, 你可以在任何地方使用它, 而不仅仅是在Django 的视图中. 模板是一个文本, 用于分离文档的表现形式和内容. 模板定义了占位符以及各种用于规范文档如何显示的各部分基本逻辑(模板标签). 模板通常用于产生 HTML, 但是 Django 的模板也能产生任何基于文本格式的文档. 在 Python 代码中使用 Django 模板的最基本方式: 写模板 –&gt; 创建 Template 对象 –&gt; 创建 Context –&gt; 调用 render() 方法. 使用原始的模板代码字符串创建一个Template对象, Django 同样支持用指定模板文件路径的方式来创建 Template 对象. 调用模板对象的 render 方法, 并且传入一套变量 context, 它将返回一个基于模板的展现字符串, 模板中的变量和标签会被 context 值替换. $ python manage.py shell &gt;&gt; from django import template # 当创建一个 Template 对象, 模板系统在内部编译这个模板到内部格式, 并做优化, 做好渲染准备. &gt;&gt; t = template.Template(&quot;My name is { { name } }&quot;) # 使用 context 来传递数据, 一个 context 是一系列变量和值的结合. # context 在 Django 里表现为 Context 类, 在 django.Template 模块里. 他的构造函数有一个可选参数: 一个字典映射变量和他的值. &gt;&gt; c = template.Context({&quot;name&quot;:&quot;tom&quot;}) # 调用 Template.render() 方法并传递 context 的值来填充模板. # t.render(c) 返回的值是一个 Unicode 对象, 不是普通的 Python 字符串. &gt;&gt; print t.render(c) My name is tom python manage.py shell : 在启动解释器之前,它告诉Django 使用哪个设置文件. Django 框架大部分子系统, 包括模板系统, 都依赖于配置文件; 如果 Django 不知道使用哪个配置文件, 这些系统将不能工作. Django 搜索 DJANGO_SETTINGS_MODULE 环境变量, 它被设置在 settings.py 文件中. 执行命令 python manage.py shell , 他将自动帮你处理 DJANGO_SETTINGS_MODULE 环境变量. Django 模板解析非常快捷. 大部分的解析工作都是在后台通过对简短正则表达式一次性调用来完成. 二. 变量{ { VAR } } : 变量的值将在页面渲染的时候, 被取代. 默认情况下, 如果一个变量不存在, 模板系统会把他展示位一个空字符串, 不做任何事情来表示失败. 三. 模板中的复杂数据类型在 Django 模板中遍历复杂数据结构的关键是 句点字符(.) . 句点查找规则 : 字典&gt;属性&gt;方法&gt;索引 和 短路逻辑(系统使用找到的第一个有效类型) 字典类型查找, 如 foo[&quot;bar&quot;] 属性查找, 如 foo.bar 方法调用, 如 foo.bar() 列表类型索引查找, 如 foo[1] 列表索引 不允许使用负数列表索引 &gt;&gt;&gt; from django.template import Template, Context &gt;&gt;&gt; t = Template(&apos;Item 2 is { { items.2 } }.&apos;) &gt;&gt;&gt; c = Context({&apos;items&apos;: [&apos;apples&apos;, &apos;bananas&apos;, &apos;carrots&apos;]}) &gt;&gt;&gt; t.render(c) u&apos;Item 2 is carrots.&apos; 字典 &gt;&gt;&gt; from django.template import Template, Context &gt;&gt;&gt; person = {&apos;name&apos;: &apos;Sally&apos;, &apos;age&apos;: &apos;43&apos;} &gt;&gt;&gt; t = Template(&apos;{ { person.name } } is { { person.age } } years old.&apos;) &gt;&gt;&gt; c = Context({&apos;person&apos;: person}) &gt;&gt;&gt; t.render(c) u&apos;Sally is 43 years old.&apos; 属性 &gt;&gt;&gt; from django.template import Template, Context &gt;&gt;&gt; import datetime &gt;&gt;&gt; d = datetime.date(1993, 5, 2) &gt;&gt;&gt; d.year 1993 &gt;&gt;&gt; d.month 5 &gt;&gt;&gt; d.day 2 &gt;&gt;&gt; t = Template(&apos;The month is { { date.month } } and the year is { { date.year } }.&apos;) &gt;&gt;&gt; c = Context({&apos;date&apos;: d}) &gt;&gt;&gt; t.render(c) u&apos;The month is 5 and the year is 1993.&apos; 使用自定义的类, 如下方法使用与任意的对象. &gt;&gt;&gt; from django.template import Template, Context &gt;&gt;&gt; class Person(object): ... def __init__(self, first_name, last_name): ... self.first_name, self.last_name = first_name, last_name &gt;&gt;&gt; t = Template(&apos;Hello, { { person.first_name } } { { person.last_name } }.&apos;) &gt;&gt;&gt; c = Context({&apos;person&apos;: Person(&apos;John&apos;, &apos;Smith&apos;)}) &gt;&gt;&gt; t.render(c) u&apos;Hello, John Smith.&apos; 方法 在调用方法时, 并没有使用圆括号, 你只能调用不需要参数的方法. &gt;&gt;&gt; from django.template import Template, Context &gt;&gt;&gt; t = Template(&apos;{ { var } } -- { { var.upper } } -- { { var.isdigit } }&apos;) &gt;&gt;&gt; t.render(Context({&apos;var&apos;: &apos;hello&apos;})) u&apos;hello -- HELLO -- False&apos; &gt;&gt;&gt; t.render(Context({&apos;var&apos;: &apos;123&apos;})) u&apos;123 -- 123 -- True&apos; 在方法查找过程中, 如果某方法抛出一个异常, 除非该异常有一个 silent_variable_failure=True 设置, 否则的话他将被传播. 如果异常被被传播, 模板里的指定变量会被设置为空字符串. &gt;&gt;&gt; t = Template(&quot;My name is { { person.first_name } }.&quot;) &gt;&gt;&gt; class PersonClass3: ... def first_name(self): ... raise AssertionError, &quot;foo&quot; &gt;&gt;&gt; p = PersonClass3() &gt;&gt;&gt; t.render(Context({&quot;person&quot;: p})) Traceback (most recent call last): ... AssertionError: foo &gt;&gt;&gt; class SilentAssertionError(AssertionError): ... silent_variable_failure = True &gt;&gt;&gt; class PersonClass4: ... def first_name(self): ... raise SilentAssertionError &gt;&gt;&gt; p = PersonClass4() &gt;&gt;&gt; t.render(Context({&quot;person&quot;: p})) u&apos;My name is .&apos; 深层嵌套 在下面这个例子中 { {person.name.upper} } 会转换成字典类型查找（ person[&#39;name&#39;] ) 然后是方法调用（ upper() ): &gt;&gt;&gt; from django.template import Template, Context &gt;&gt;&gt; person = {&apos;name&apos;: &apos;Sally&apos;, &apos;age&apos;: &apos;43&apos;} &gt;&gt;&gt; t = Template(&apos;{ { person.name.upper } } is { { person.age } } years old.&apos;) &gt;&gt;&gt; c = Context({&apos;person&apos;: person}) &gt;&gt;&gt; t.render(c) u&apos;SALLY is 43 years old.&apos; context对象 : 可以通过传递一个完全填充(full populater)的字典给 Context() 来初始化上下文(context). 初始化之后, 可以使用标准的 Python 字典语法给 context 对象添加或删除条目. &gt;&gt;&gt; from django.template import Context &gt;&gt;&gt; c = Context({&quot;foo&quot;: &quot;bar&quot;}) &gt;&gt;&gt; c[&apos;foo&apos;] &apos;bar&apos; &gt;&gt;&gt; del c[&apos;foo&apos;] &gt;&gt;&gt; c[&apos;foo&apos;] Traceback (most recent call last): ... KeyError: &apos;foo&apos; &gt;&gt;&gt; c[&apos;newvariable&apos;] = &apos;hello&apos; &gt;&gt;&gt; c[&apos;newvariable&apos;] &apos;hello&apos; 四. 标签 if/else { % if today_is_weekend % } &lt;p&gt;Welcome to the weekend!&lt;/p&gt; { % else % } &lt;p&gt;Get back to work.&lt;/p&gt; { % endif % } 在 Python 和 Django 模板系统中, 以下这些对象相当于布尔值的 False. 空列表 : [] 空元组 : () 空字典 : {} 空字符串 : &#39;&#39; 零值 : 0 特殊对象 : None 对象 : False { % if % } 标签接受 and,or,not 关键字来对多个变量做判断. 但是, 不允许在同一个标签里同时使用 and 和 or, 因为逻辑上可能是模糊的. { % if athlete_list and coach_list % } Both athletes and coaches are available. { % endif % } { % if not athlete_list % } There are no athletes. { % endif % } { % if athlete_list or coach_list % } There are some athletes or some coaches. { % endif % } { % if not athlete_list or coach_list % } There are no athletes or there are some coaches. { % endif % } { % if athlete_list and not coach_list % } There are some athletes and absolutely no coaches. { % endif % } 一定要使用{ % endif % } 来关闭每一个 { % if % } 标签. for, 关键字 reversed 可实现反向迭代. { % for athlete in athlete_list reversed % } ... { % endfor % } { % empty % } 分句 : 通过该标签, 可以定义当列表为空时输出内容. { % for athlete in athlete_list % } &lt;p&gt;{ { athlete.name } }&lt;/p&gt; { % empty % } &lt;p&gt;There are no athletes. Only computer programmers.&lt;/p&gt; { % endfor % } # 与上面等价 { % if athlete_list % } { % for athlete in athlete_list % } &lt;p&gt;{ { athlete.name } }&lt;/p&gt; { % endfor % } { % else % } &lt;p&gt;There are no athletes. Only computer programmers.&lt;/p&gt; { % endif % } forloop 模板变量 : 提供一些提示循环进度信息的属性. 仅能在循环中使用 forloop.counter : 表示当前循环的执行次数的整数计数器. 计数器从 1 开始技术. forloop.counter0 : 同上, 但计数器从 0 开始. forloop.revcounter : 表示循环中剩余项的整型变量. 初始值为 序列中项的总数, 最后一次循环执行中, 这个变量为 1. forloop.revcounter0 : 同上, 但是从 0 计数. forloop.first : 布尔值, 如果该迭代的第一个执行, 则为 True. forloop.last : 布尔值, 在最后一个执行循环时被置为 True. { % for link in links % }{ { link } }{ % if not forloop.last % } | { % endif % }{ % endfor % } # 输出 : Link1 | Link2 | Link3 | Link4 { % for p in places % }{ { p } }{ % if not forloop.last % }, { % endif % }{ % endfor % } # 输出 : Link1 , Link2 , Link3 , Link4 forloop.parentloop : 一个指向当前循环的上一级循环的 forloop 对象的引用(在嵌套情况下). { % for country in countries % } &lt;table&gt; { % for city in country.city_list % } &lt;tr&gt; &lt;td&gt;Country #{ { forloop.parentloop.counter } }&lt;/td&gt; &lt;td&gt;City #{ { forloop.counter } }&lt;/td&gt; &lt;td&gt;{ { city } }&lt;/td&gt; &lt;/tr&gt; { % endfor % } &lt;/table&gt; { % endfor % } Context 和 forloop 变量 : 在一个 { % for % } 块中, 已存在的变量会被移除, 以避免 forloop 变量被覆盖. Django 会把这个变量移动到 forloop.parentloop 中. 通常我们不用担心这个问题, 但是一旦我们在模板中定义了 forloop 这个变量(不推荐这样做), 在 { % for % } 块中他会在 forloop.parentloop 被重新命名. ifequal/ifnotequal : { % ifequal % } 标签比较两个值, 当他们相等时, 显示在 { % ifequal % } 和 { % ifnotequal % }之中的所有的值. # 比较两个变量 user, currentuser { % ifequal user currentuser % } &lt;h1&gt;Welcome!&lt;/h1&gt; { % endifequal % } # 参数可以是硬编码的字符串 { % ifequal section &apos;sitenews&apos; % } &lt;h1&gt;Site News&lt;/h1&gt; { % endifequal % } # 支持可选的 { % else % } 标签 { % ifequal section &apos;sitenews&apos; % } &lt;h1&gt;Site News&lt;/h1&gt; { % else % } &lt;h1&gt;No News Here&lt;/h1&gt; { % endifequal % } 只有模板变量, 字符串, 整数, 小数可以作为 { % ifequal % } 标签的参数. 其他任何类型, 均不能用在 { % ifequal % } 中. 五. 注释: 单行注释 : 多行注释 : { % comment % } { % comment % } This is a multi-line comment. { % endcomment % } 六. 过滤器 : |过滤器主要是转换变量输出格式. 过滤器可以嵌套(一个过滤器管道的输出, 可以作为另一个管道的输入). { { my_list|first|upper } } # 寻找列表的第一个元素, 并将其转换为大写. 有些过滤器有参数: { { bio|truncatewords:&quot;30&quot; } } 常用过滤器: addslashes : 添加反斜杠到任何反斜杠, 单引号, 或者双引号前面. 处理包含 JavaScript 的文本时非常有用. date : 按指定的格式字符串参数化格式 date 或者 datetime 对象. { { pub_date|date:&quot;F j, Y&quot; } } length : 返回变量的长度. 对于列表或字符串, 则返回其元素或字符的个数. 七. 模板加载与模板目录: { % include % }django.template.loader.get_template() 函数手动从文件系统加载模板, 该函数以模板名称为参数, 在文件系统中找出模块的位置, 打开文件并返回一个编译好的 Template 对象. $ mkdir templates $ vim settings.py TEMPLATES = [ { # ... &apos;DIRS&apos;: [os.path.join(os.path.dirname(__file__), &apos;templates&apos;),], # ... }, ] $ vim views.py from django.http import HttpResponse, Http404 from django.template import Context from django.template.loader import get_template import datetime def current_datetime(request): now=datetime.datetime.now() t = get_template(&apos;time.html&apos;) html = t.render(Context({&apos;current_date&apos;: now})) return HttpResponse(html) django.shortcuts.render_to_response() 一次性加载某个模板, 并一次作为 HttpResponse 对象返回. render_to_response() 的第一个参数必须是要使用的模板名称, 如果给定第二个参数, 那么该参数必须是为该模板创建 Context 使用的字典. 如果不使用第二个参数, render_to_response() 使用一个空字典. from django.shortcuts import render_to_response import datetime def current_datetime(request): now = datetime.datetime.now() return render_to_response(&apos;current_datetime.html&apos;, {&apos;current_date&apos;: now}) 模板子目录: 把模板放在模板目录的子目录中. t = get_template(&apos;dateapp/current_datetime.html&apos;) return render_to_response(&apos;dateapp/current_datetime.html&apos;, {&apos;current_date&apos;: now}) include 模板标签{ % include % } 允许在(模板中)包含其他的模板的内容. 标签的参数是所要包含的模板名称, 可以是一个变量, 也可以是硬编码的字符串路径. 和 get_template() 中的一样, 对模板的文件名进行判断时会在所调取的模板名称之前加上来自TEMPLATE_DIRS的模板目录. { % include &apos;includes/nav.html&apos; % } { % include template_name % } 如果你用一个包含 current_section 的上下文去渲染 mypage.html 这个模板文件, 这个变量将存在于它所 include 的模板里. # mypage.html &lt;html&gt; &lt;body&gt; { % include &quot;includes/nav.html&quot; % } &lt;h1&gt;{ { title } }&lt;/h1&gt; &lt;/body&gt; &lt;/html&gt; # includes/nav.html &lt;div id=&quot;nav&quot;&gt; You are in: { { current_section } } &lt;/div&gt; 如果{ % include % }标签指定的模板没有找到, Django 的处理方式如下: 如果 DEBUG=True, 将会在 Django 错误信息页面看到 TemplateDoesNotExist 异常. 如果 DEBUG=False, 该标签不会引发错误信息. 八. 模板继承 : { % extends % }basic.html &lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01//EN&quot;&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;title&gt;{ % block title % }{ % endblock % }&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;My helpful timestamp site&lt;/h1&gt; { % block content % }{ % endblock % } { % block footer % } &lt;hr&gt; &lt;p&gt;Thanks for visiting my site.&lt;/p&gt; { % endblock % } &lt;/body&gt; &lt;/html&gt; 继承: # current_datetime.html { % extends &quot;base.html&quot; % } { % block title % }The current time{ % endblock % } { % block content % } &lt;p&gt;It is now { { current_date } }.&lt;/p&gt; { % endblock % } 使用模板继承注意事项: 如果在模板中使用 { % extends % } 必须保证其为模板中的第一个模板标记. 否则, 模板继承将不起作用. 一般来讲, 基础模板中的 { % block % } 标签越多越好. 子模板不必定义父模板中所有的代码块, 因此你可以用合理的缺省值对一些代码进行填充, 然后只对子模板所需的代码进行重定义. 如果发现自己在多个模板之间拷贝代码, 应该考虑将代码段放置到父模板中的某个 { % block % }中. 如果需要访问父模板的块中的内容, 请使用 { { block.super } }, 该变量会展现出父模板中的内容. 如果只想在上级代码块基础上添加内容, 而不是全部重载, 应该使用该标签. 不允许在同一个模板中, 定义多个同名的 { % block % } . 存在这样的限制, 是因为 block 标签的工作方式是双向的. { % extends % } 对所传入模板名称使用的加载方法和 get_template() 相同. { % extends % } 的参数可以是字符串, 也可以是变量. 九. html 转义1.1 自动转义默认开启 &gt; –&gt; &amp;lt; &lt; –&gt; &amp;gt; &#39; (单引号) –&gt; &amp;#39; &quot; (双引号) –&gt; &amp;quot; &amp; –&gt; &amp;amp; 1.2 关闭自动转义可以基于站点级别, 模板级别或者变量级别来关闭自动转义 1.2.1 变量级别 : 使用 safe 过滤器.This will not be escaped: { { data|safe } } 1.2.2 模板级别 : 用标签 autoescape 来包装这个模板或模板中的部分.autoescape 标签有两个参数on和off 有时,你可能想阻止一部分自动转意,对另一部分自动转意。 { % autoescape off % } Hello { { name } } { % endautoescape % } Auto-escaping is on by default. Hello { { name } } { % autoescape off % } This will not be auto-escaped: { { data } }. Nor this: { { other_data } } { % autoescape on % } Auto-escaping applies again: { { name } } { % endautoescape % } { % endautoescape % } 1.2.3 过滤器参数中的字符串常量的自动转义.所有字符常量没有经过转义就被插入模板,就如同它们都经过了safe过滤。 这是由于字符常量完全由模板作者决定,因此编写模板的时候他们会确保文本的正确性。 # good { { data|default:&quot;3 &amp;lt; 2&quot; } } # bad { { data|default:&quot;3 &lt; 2&quot; } }]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>web development</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django之三--模型篇]]></title>
    <url>%2F2018%2F03%2F16%2Fdjango%E4%B9%8B%E4%B8%89--%E6%A8%A1%E5%9E%8B%E7%AF%87%2F</url>
    <content type="text"><![CDATA[1. MTVDjango 的 MVC 含义: M , 数据存取部分, 有 Django 数据库层处理. V, 选择显示哪些要显示以及怎样显示的部分, 由视图和模板处理; C, 根据用户输入委派视图的部分, 有 django 框架根据 URLconf 设置, 对给定 URL 调用适当的 Python 函数. 由于 C 由框架自行处理, 而 Django 里更关注的是模型(Model), 模板(Template), 视图(view), Django 也被称为 MTV 框架. M : 代表模型(Model), 即数据存取层. 该层处理与数据相关的所有事务: 如何存取, 如何验证有效性, 包含哪些行为以及数据之间的关系灯. T : 代表模板(Template). 表现层, 该层处理与表现相关的决定: 如何在页面或其他类型文档中显示. V : 代表视图(View). 即业务逻辑. 该层包含存取模型及调用恰当模板的相关逻辑. 可以视作 模型与模板之间的桥梁. 2. 数据库配置 DATABASE_ENGINE = ‘[postgresql_psycopg2|mysql|sqlite3|oracle]’ DATABASE_NAME = ‘’ DATABASE_USER = ‘’ DATABASE_PASSWORD = ‘’ DATABASE_HOST = ‘’ DATABASE_PORT = ‘’ 测试数据库配置 &gt;&gt;&gt; from django.db import connection &gt;&gt;&gt; cursor = connection.cursor() 3. django models &amp; app :app 一个包含模型,视图和 django 代码, 并且形式为独立的 Python 包的完整 Django 应用. project 和 app 区别: 一个是配置, 一个是代码; 一个 project 包含许多个 django app 以及对他们的配置 技术上, project 的作用是提供配置文件. 一个 app 是一套 Django 功能的集合, 通常包含模型和视图, 按 Python 的包结构的方式存在. Django 本身内建一些 app, 例如注释系统和自动管理界面, app 的一个关键点是他们很容易移植到其他 project 和 被多个 project 复用. 系统对 app 有一个约定: 如果使用了 django 的数据库层(模型), 就必须创建一个 django app. 模型必须放在 apps 中. Django 模型使用 Python 代码形式表述的数据在数据库中的定义.对数据库层来说他等同于 CREATE TABLE 语句, 只不过执行的是 python 代码而不是 SQL, 而且还包含了比数据字段定义更多的含义. Django 用模型在后台执行 SQL 代码并把结果用 Python 的数据结构来描述. Django 也是用模型来呈现 SQL 无法处理的高级概念. Django 提供了使用工具来从现有的数据库表中自动扫描生成模型.这对已有的数据库来说是非常快捷有用的 $ cd mysite $ python manage.py startapp books # 创建 app $ cd books $ vim models.py class Publisher(models.Model): name = models.CharField(max_length=30) address = models.CharField(max_length=35) city = models.CharField(max_length=60) state_province = models.CharField(max_length=30) country = models.CharField(max_length=50) website = models.URLField() # 添加模块的字符串表现. 返回一个unicode对象. def __unicode__(self): return self.name # 指定缺省排序方式.附录B 中有 Meta 中所有可选项的完整参考 class Meta: ordering = [&apos;name&apos;] class Author(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=40) email = models.EmailField() # 添加模块的字符串表现. 返回一个unicode对象. def __unicode__(self): return u&apos;%s %s&apos; % (self.first_name, self.last_name) class Book(models.Model): title = models.CharField(max_length=100) authors = models.ManyToManyField(Author) publisher = models.ForeignKey(Publisher) publication_date = models.DateField() # 添加模块的字符串表现. 返回一个unicode对象. def __unicode__(self): return self.title 每个数据模型都是 django.db.models.Model 的子类. 它的父类 Model 包含了所有必要的和数据库交互的方法, 并提供了一个简洁的定义数据库字段的方法. 每个模型相当于单个数据库表, 每个属性也是这个表中的一个字段. 属性名就是字段名, 它的类型相当于数据库的字段类型. 每个数据库表对应一个类, 这条规则的例外情况是多对多关系. 如上示例中, Book 有一个多对多字段叫做 authors. 该字段表明一本书籍有一个或多个作者, 但 Book 数据表并没有 authors 字段. 相反, Django 创建了一个额外的表(多对多链接表)来处理书籍和作者之间的映射关系. 主键: 除非单独指明, 否则 Django 会自动为每个模型生成一个自增长的整数主键字段, 每个 Django 模型都要求有单独的主键, id. 4. 模型安装与基本使用4.1. 在 Django 项目中激活这些模型: 将 books app 添加到配置文件的已安装应用列表中即可.$ vim settings.py MIDDLEWARE_CLASSES = ( # &apos;django.middleware.common.CommonMiddleware&apos;, # &apos;django.contrib.sessions.middleware.SessionMiddleware&apos;, # &apos;django.contrib.auth.middleware.AuthenticationMiddleware&apos;, ) INSTALLED_APPS = ( # &apos;django.contrib.auth&apos;, # &apos;django.contrib.contenttypes&apos;, # &apos;django.contrib.sessions&apos;, # &apos;django.contrib.sites&apos;, &apos;mysite.books&apos;, ) 4.2. 验证模型的有效性# 检查模型的语法和逻辑是否正确. $ python manage.py validate 4.3. 生成数据库$ python manage.py sqlall books # 该命令只是打印创建数据库的sql语句. $ python manage.py syncdb # 同步数据模型到数据库. 如果表不存在,则会创建表. 但 syncdb 不能讲模型的修改或删除同步到数据库.如果修改或删除了一个模型, 并向把他提交到数据库, syncdb 不会做任何处理. 生成的表名为 app名称和模型的小写名称, 如 books_authors. 每个表自动添加 id 主键 Django 添加 _id 后缀到外键字段名. syncdb 是幂等的, 他不会重复执行 SQL 语句. 可以使用 python manage.py dbshell 作为数据库客户端连接到数据库查看. 4.4. 基本数据访问&gt;&gt;&gt; from books.models import Publisher # 创建对象与保存对象到数据库. &gt;&gt;&gt; p1 = Publisher(name=&apos;Apress&apos;, address=&apos;2855 Telegraph Avenue&apos;, ... city=&apos;Berkeley&apos;, state_province=&apos;CA&apos;, country=&apos;U.S.A.&apos;, ... website=&apos;http://www.apress.com/&apos;) &gt;&gt;&gt; p1.save() &gt;&gt;&gt; p2 = Publisher(name=&quot;O&apos;Reilly&quot;, address=&apos;10 Fawcett St.&apos;, ... city=&apos;Cambridge&apos;, state_province=&apos;MA&apos;, country=&apos;U.S.A.&apos;, ... website=&apos;http://www.oreilly.com/&apos;) &gt;&gt;&gt; p2.save() &gt;&gt;&gt; publisher_list = Publisher.objects.all() &gt;&gt;&gt; publisher_list [&lt;Publisher: Publisher object&gt;, &lt;Publisher: Publisher object&gt;] # 一次性完成对象的创建与存储 &gt;&gt;&gt; p1 = Publisher.objects.create(name=&apos;Apress&apos;, ... address=&apos;2855 Telegraph Avenue&apos;, ... city=&apos;Berkeley&apos;, state_province=&apos;CA&apos;, country=&apos;U.S.A.&apos;, ... website=&apos;http://www.apress.com/&apos;) p.save() Publisher.objects.all() objects 属性, 被称为管理器, 他管理者所有针对数据包含, 及数据查询的表格级操作. all() : 返回数据库中所有的记录, 他是一个 QuerySet 对象, 是数据库中一些记录的集合. Publisher.objects.filter(name=&quot;Apress&quot;[, country=&quot;U.S.A.&quot;]) : 过滤器. 和 Python 一样, Django 使用双下划线来表明会进行一些魔法操作: contains : 被翻译成 LIKE 语句. &gt;&gt; Publisher.objects.fileer(name__contains=&quot;press&quot;) icontains : 大小写无关的 LIKE 语句. startswith : endswith : range : SQL BETWEEN 查询. Publisher.objects.get(name=&quot;Apress&quot;) : 获取单个对象. 如果结果是多个对象, 会抛出异常. 没有返回结果也抛出异常. Publisher.objects.order_by(&quot;[-]name&quot;[, &quot;address&quot;]) : 数据排序. 减号表示逆序. 限制返回的数据 : Publisher.objects.order_by(&#39;name&#39;)[0:2], 不支持负索引. 链式查询: Publisher.objects.filter(country=&quot;U.S.A.&quot;).order_by(&quot;-name&quot;) 更改某一指定的列 : Publisher.objects.filter(id=52).update(name=&#39;Apress Publishing&#39;), update()方法对于任何结果集（QuerySet）均有效，这意味着你可以同时更新多条记录。 删除对象: 调用对象的 delete 方法: &gt; p = Publisher.objects.get(name=&quot;O&apos;Reilly&quot;) &gt; p.delete() 只删除部分数据 &gt; Publisher.objects.filter(country=&apos;USA&apos;).delete() 删除某表内的所有数据: &gt; Publisher.objects.all().delete() # 必须显示调用 all() 方法. 补充: 数据模型:from django.db import models class Publisher(models.Model): name = models.CharField(max_length=30) address = models.CharField(max_length=50) city = models.CharField(max_length=60) state_province = models.CharField(max_length=30) country = models.CharField(max_length=50) website = models.URLField() def __unicode__(self): return self.name class Author(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=40) email = models.EmailField() def __unicode__(self): return u&quot;%s %s&quot; % (self.first_name, self.last_name) class Book(models.Model): title = models.CharField(max_length=100) authors = models.ManyToManyField(Author) publiser = models.ForeignKey(Publisher) publication_date = models.DateFie() def __unicode__(self): return self.title 5. 外键与多对多关系5.1 外键5.1.1 从多的一端查询一, 返回相关的数据模型对象.&gt;&gt; b = Book.objects.get(id=50) &gt;&gt; b.publisher &lt;Publisher: Apress Publisheing&gt; &gt;&gt; b.publisher.website u&quot;http://www.appress.com/&quot; 5.1.2 从一的一端查询多, 需要使用 QuerySet 对象&gt;&gt; p = Publisher.objects.get(name=&quot;Apress Publishing&quot;) &gt;&gt; p.book_set.all() [&lt;Book: The Django Book&gt;, &lt;Book: Dive Into Python&gt;, ...] boot_set 只是一个 QuerySet, 他可以实现数据的过滤分切. &gt;&gt; p = Publisher.objects.gte(name=&quot;Apress Publisher&quot;) &gt;&gt; p.book_set.filter(name__icontains=&quot;django&quot;) [&lt;Book: The Django Book&gt;, &lt;Book: Pro Django&gt;] 属性名称 book_set 是由模型名称的小写(肉 book)加 _set 组成的. 5.2 多对多关系多对多关系和外键工作方式相同, 只不过处理的是QuerySet而不是模型实例. # 查看书籍作者. &gt;&gt; b = Book.objects.get(id=50) &gt;&gt; b.authors.all() [&lt;Author: Adrian Holovaty&gt;, &lt;Author: Jacob Kaplan-Moss&gt;] &gt;&gt; b.authors.filter(first_name=&quot;Adrian&quot;) [&lt;Author: Adrian Holovaty&gt;] # 查看一个作者的所有书籍, 使用 author.book_set &gt;&gt; a = Author.objects.get(first_name=&quot;Adrian&quot;, last_name=&apos;Holovaty&apos;) &gt;&gt; a.book_set.all() [&lt;Book: The Django Book&gt;, &lt;Book: Adrian&apos;s Other Book&gt;] 6. 更改数据库模式( Database Schema)syncdb 仅仅创建数据库里还没有的表, 他并不对数据模型的修改进行同步, 也不处理数据模型的删除. 当新增或者修改数据模型里的字段, 或者删除了一个数据模型, 需要手动在数据库中做相应的修改. 当处理模型修改的时候, Django 的数据库层的工作流程: 如果模型包含一个未曾在数据库里建立的字段, Django 会报错. 当第一次用 Django 的数据库 API 请求表中不存在的字段时会导致报错(在运行时报错). Django 并不关心数据库表中是否存在未在模型中定义的列. Django 并不关系数据库中是否存在未被模型表示的表格. 改变模型的模式架构意味着需要按照顺序更改 Python 代码和数据库. 6.1. 添加字段利用 Django 不关心表里是否包含 model 里所没有的列的特性. 策略 : 先在数据库里添加字段, 然后同步 Django 的模型以包含新的字段. 首先在测试环境实现变化,步骤如下: 进入开发环境, 在模型里添加子弹 运行manage.py sqlall YOUR_APP来测试模型新的 CREATE TABLE语句.注意为新字段的列定义. 开启 数据库交互命令行界面. 执行 ALTER TABLE语句来添加新列. 使用 Python 的 manage.py shell, 通过导入模型和选中表单, 来验证新的字段是否被正确的添加(如, MyModel.objects.all()[:5]), 如果一切顺利, 所有的语句都不会报错. 然后, 在产品服务器上实施步骤: 启动数据库的命令行界面; 执行在开发环境步骤中, 第三步的 ALTER TABLE语句; 将新的字段加入到模型中. 然后在生产环境更新代码. 重新启动 Web server, 使修改生效 6.2. 删除字段步骤如下: 从模型中删除字段, 然后重新启动 web 服务器. 用一下命令从数据库中删除字段 ALTER TABLE books_book DROP COLUMN num_pages; 6.3. 删除多对多关联字段步骤如下: 从模型中删除ManyToManyField, 然后重启 web 服务器. 用下面的命令从数据库中删除关联表. DROP TABLE books_book_authors; 6.4. 删除模型步骤如下: 从模型文件中删除你想要删除的模型, 然后重启 web 服务器. 用一下命令从数据库中删除表 DROP TABLE books_book; 当需要从数据库中删除任何有依赖的表时要注意(既任何与表 books_book 有外键的表). 7. Managers : 模型对象的行级别功能在语句 Book.objects.all() 中, objects 时一个特殊的属性, 需要通过他来查询数据库. 这就是模块的manager. 模块manager 是一个对象, Django 模块通过他进行数据库查询. 每个 Django 模块至少有一个 manager , 可以创建自定义的 manager 以定制数据库访问. 7.1 增加额外的 Manager 方法增加额外的 manager 方法是为模块添加表级功能的首选办法. # 为 Book 模型定义一个 title_count() 方法, 返回包含指定关键字的书的数量. # models.py from django.db import models # ... Author and Publisher models here ... class BookManager(models.Manager): def title_count(self, keyword): return self.filter(title__icontains=keyword).count() class Book(models.Model): title = models.CharField(max_length=100) authors = models.ManyToManyField(Author) publisher = models.ForeignKey(Publisher) publication_date = models.DateField() num_pages = models.IntegerField(blank=True, null=True) objects = BookManager() def __unicode__(self): return self.title # 使用方法 &gt;&gt; Book.objects.title_count(&apos;django&apos;) 4 &gt;&gt; Book.objects.title_count(&quot;python&quot;) 19 说明: 创建的 BookManager 类, 继承自 django.db.models.Manager, 这个类只有一个title_count()方法, 用来做统计. 该方法使用了 self.filter() , 此处 self 指 manager 本身 将 BookManager() 赋值给模型的 objects 属性, 它将取代模型的默认 manager(objects, 如果没有特别定义, 将被自动创建). 将他命名为 objects 是为了与自动创建的 Manager 保持一致. 7.2 修改初始 Manager QuerySetmanager 的基本 QuerySet 返回系统中的所有对象. 可以通过覆盖 Manager.get_query_set() 方法重写 manager 的基本 QuerySet, 返回一个自定义的 QuerySet. get_query_set() 返回的是一个 QuerySet 对象, 所以可以使用 filter(),exclude() 和其他一些 QuerySet 的方法. # 模型有两个 manager, 返回不同的值. from django.db import models # First, define the Manager subclass. class DahlBookManager(models.Manager): def get_query_set(self): return super(DahlBookManager, self).get_query_set().filter(author=&apos;Roald Dahl&apos;) # then hook it into the Book model explicitly. class Book(models.Model): title = Model.CharField(max_length=100) author = Model.CharField(max_length=50) # ... objects = models.Manager() # the default manager dahl_objects = DahlBookManager() # the Dahl-specific manager 以上模型中, Book.objects.all() 返回数据库中的所有书本, 而 Book.dahl_objects.all() 只返回作者是 Roald Dahl 的书. 以上示例中, 也指出了其他有趣的技术: 在一个模型中使用多个 Manager, 这是为模型添加通用过滤器的简单方法. 使用自定义 Manager 对象, 需要注意, Django 会把第一个 Manger 定义为默认 Manager, Django 的许多部分(不包括 admin 应用)将会明确的为模型使用这个 Manager, 所以需要小心的选择默认的 Manager. 8. 模型方法: 模型对象的行级别功能给对象添加行级功能, 需要一个自定义方法, 有鉴于 manager 疆场被用来用一些整表操作, 模型方法应该只针对特殊模型实例起作用. 这是一项在模型的一个地方集中业务逻辑的技术. # 模型自定义方法 from django.contrib.localflavor.us.models import USStateField from django.db import models class Person(models.Model): first_name = models.CharField(max_length=50) last_name = models.CharField(max_length=50) birth_date = models.DateField() address = models.CharField(max_length=100) city = models.CharField(max_length=50) state = USStateField() def bady_boomer_status(self): &quot;Return the person&apos;s bady-boomer status&quot; import datetime if datetime.date(1945,8,1) &lt;= self.birth_date &lt;= datetime.date(1964,12,31): return &quot;Baby boomer&quot; if self.birth_date &lt; datetime.date(1945,8,1): return &quot;Pre-boomer&quot; return &quot;Post-boomer&quot; def is_midwestern(self): &quot;Return True if this person is from the Midwest&quot; return self.state in (&quot;IL&quot;, &quot;WI&quot;,&quot;MI&quot;,&quot;IN&quot;,&quot;OH&quot;,&quot;IA&quot;,&quot;MO&quot;) def _get_full_name(self): &quot;Return the persion&apos;s full name&quot; return u&quot;%s %s&quot; % (self.first_name, self.last_name) full_name = property(_get_full_name) # 使用方法 &gt;&gt; p = Person.objects.get(first_name=&quot;Barack&quot;, last_name=&quot;Obama&quot;) &gt;&gt; p.birth_date datetime.date(1962,8,4) &gt;&gt; p.baby_boomer_status() &quot;Boby boomer&quot; &gt;&gt; p.is_midwestern() True &gt;&gt; p.full_name u&quot;Barack Obama&quot; 9. 执行原始 SQL 查询通过导入django.db.connection 对象来实现, 他代表当前数据库连接. 要使用 connection.cursor() 得到一个游标对象; connection.execute(sql,[params]), 来执行SQL 语句; 使用 cursor.fetchone() 或 cursor.fetchall() 来返回记录集. &gt;&gt; from django.db import connection &gt;&gt; cursor = connection.cursor() &gt;&gt; cursor.execute(&quot;&quot;&quot; SELECT DISTINCT first_name FROM people_person WHERE last_name = %s &quot;&quot;&quot;, [&quot;Lennon&quot;]) &gt;&gt; row = cursor.fetchone() &gt;&gt; print row [&quot;John&quot;] 不要把视图代码和 django.db.connection.cursor 语句混杂在一起, 推荐把他们放在自定义模型或者自定义 manager 方法中. # 定义代码 from django.db import connection, models class PersonManager(models.Manager): def first_names(self, last_name): cursor = connection.cursor() cursor.execute(&quot;&quot;&quot; SELECT DISTINCT first_name FROM people_person WHERE last_name = %s&quot;&quot;&quot;, [last_name]) return (row[0] for row in cursor.fetchone()) class Person(models.Model): first_name = models.CharField(max_length=50) last_name = models.CharField(max_length=50) objects = PersonManager() # 使用示例 &gt;&gt; Person.objects.first_name(&apos;Lennon&apos;) [&apos;John&apos;, &quot;Cynthia&quot;] 补充: Unicode 普通的python字符串是经过编码的，意思就是它们使用了某种编码方式（如ASCII，ISO-8859-1或者UTF-8）来编码。 如果你把奇特的字符（其它任何超出标准128个如0-9和A-Z之类的ASCII字符）保存在一个普通的Python字符串里，你一定要跟踪你的字符串是用什么编码的，否则这些奇特的字符可能会在显示或者打印的时候出现乱码。 当你尝试要将用某种编码保存的数据结合到另外一种编码的数据中，或者你想要把它显示在已经假定了某种编码的程序中的时候，问题就会发生。 我们都已经见到过网页和邮件被???弄得乱七八糟。 ?????? 或者其它出现在奇怪位置的字符：这一般来说就是存在编码问题了。1但是Unicode对象并没有编码。它们使用Unicode，一个一致的，通用的字符编码集。 当你在Python中处理Unicode对象的时候，你可以直接将它们混合使用和互相匹配而不必去考虑编码细节。Django 在其内部的各个方面都使用到了 Unicode 对象。 模型 对象中，检索匹配方面的操作使用的是 Unicode 对象，视图 函数之间的交互使用的是 Unicode 对象，模板的渲染也是用的 Unicode 对象。 通常，我们不必担心编码是否正确，后台会处理的很好。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>web development</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django之五--表单]]></title>
    <url>%2F2018%2F03%2F16%2Fdjango%E4%B9%8B%E4%BA%94--%E8%A1%A8%E5%8D%95%2F</url>
    <content type="text"><![CDATA[HttpRequest对象 和 Form对象 HttpRequest 对象HttpRequest对象包含当前请求URL的一些信息. 属性/方法 说明 举例 request.path 除域名以外的请求路径, 以正斜杠开头. /hello/ request.get_host() 主机名, 域名 127.0.0.1:8000 or www.example.com request.get_full_path() 请求路径, 可能包含查询字符串 /hello/?print=true request.is_secure() 如果通过 HTTPS 访问, 则该方法返回 True, 否则返回 False True/False request.META 一个 字典, 包含所有本次HTTP请求的Header信息. “” request.GET 用户提交信息, 可能来自&lt;form&gt;提交,也可能来自URL中的查询字符串. request.POST 用户提交信息, 来自&lt;form&gt;标签的提交. 注意: request.META 所包含的Header信息的完整列表取决于用户所发送的 Header 信息和服务端设置的 Header 信息. HTTP Header 信息是由用户的浏览器提交的, 不应该给予信任的额外数据.因为 request.META 是一个普通的字典, 所以当试图访问一个不存在的键时, 会触发一个KeyError异常, 应当使用 try/except语句或者dict.get()方法来处理 request.META 字典. def ua_dispaly_v1(request): try: ua = request.META[&quot;HTTP_USER_AGENT&quot;] except KeyError: ua = &quot;unknown&quot; return HttpResponse(&quot;You browser is %s&quot; % us) def ua_dispaly_v1(request): ua = request.META.get(&quot;HTTP_USER_AGENT&quot;, &quot;unknown&quot;) return HttpResponse(&quot;You browser is %s&quot; % us) 类字典对象 : request.GET 和 request.POST是类字典对象, 即他们的行为像 Python 标准的字典对象, 但在技术底层上, 他们不是标准字典数据. 如 request.GET 和 request.POST 都有 get(),keys(),values()方法, 可以被迭代等. 同时, request.GET 和 request.POST也有一些标准字典没有的方法. 一个简单的表单处理示例改进表单表单验证Contact 表单Form 类在视图中使用 Form 对象改变字段显示设置最大长度设置初始值自定义校验规则指定标签定制 Form 设计]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>web development</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django之四--Admin管理工具]]></title>
    <url>%2F2018%2F03%2F16%2Fdjango%E4%B9%8B%E5%9B%9B--Admin%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[一. 概述1. 简介管理界面是以网页和有限的可信任管理者为基础的界面. Django 自动管理界面工作原理: 读取模型中的元数据, 然后提供给用户一个强大而且可以使用的界面, 网站管理者可以使用它立即工作. 2. Admin 工作原理当服务启动时, Django 从 urls.py 引导 URLconf, 然后执行 admin.autodiscover() 语句. 该函数遍历 INSTALLED_APPS 配置, 并且寻找相关的 admin.py 文件, 如果在执行的 app 目录下找到 admin.py , 他就执行其中的代码. 模块注册 : 在 books 应用程序的目录下的 admin.py 文件中, 每次调用 admin.site.register() 都将会将该模块注册到管理工具中, 管理工具只为那些明确注册了的模块显示一个编辑/修改页面. 应用程序 django.contrib.auth 包含自身的 admin.py, 所以 Users 和 Groups 能在管理工具中自动显示. 其他的 django.contrib 应用程序, 如 django.contrib.redirects, 其他从网上下载的第三方 Django 应用程序一样, 都会自行添加到管理工具. 管理工具实际就是一个 Django 应用程序, 包含自己的 模块,模板,视图和 URLpatterns. 需要向添加自己的视图一样, 将它添加到 URLconf 里面. 可以在 Django 基本代码中的 django/contrib/admin 目录下查看他的模板,视图和 URLpatterns, 但不要尝试修改其中的代码.如果确实想浏览 django 管理工具的代码, 请谨记他在读取关于模块的元数据过程中做了些不简单的工作, 因此最好花些时间阅读和理解那些代码. 二. django.contrib 包Django 自动管理工具集(admin)是 django.contrib的一部分. django.contrib 是一套庞大的功能集, 他是 Django 基本代码的组成部分, Django 框架就是有众多包含附加组件(add-on)的基本代码构成的. 可以把 django.contrib 看作是可选的 Python 标准库或普遍模式的实际实现. 他们与 Django 捆绑在一起, 这也就无需开发者重复造轮子了. django.contrib 组成部分: django.contrib.admin : 自动管理工具. django.contrib.auth : 用户认证系统. django.contrib.sessions : 支持匿名会话. django.contrib.comments : 用户评论系统. 三. 激活管理界面 将 django.contrib.admin加入 setting 的INSTALLED_APPS的配置中. 保障INSTALLED_APPS中包含 django.contrib.auth,django.contrib.contenttypes,django.contrib.sessions django 管理工具需要这三个包. 确保MIDDLEWARE_CLASSES包含django.middleware.common.CommonMiddleware,django.contrib.sessions.middleware.SessionMiddleware,和django.contrib.auth.middleware.AuthenticationMiddleware. 运行 python manage.py syncdb, 用于生成管理界面使用的额外数据库表. 首次运行该命令, 会交互式提醒创建一个**. 否则需要使用python manage.py createsuperuser 来创建一个 admin 用户账号. 只用当 INSTALLED_APP 包含 django.contrib.auth 时, python manage.py createsuperuser 这个命令才可用** 将admin添加到URLconf配置中. # urls.py from django.contrib import admin admin.autodiscover() urlpatterns = patterns(&apos;&apos;, # Uncomment the next line to enable the admin: (r&apos;^admin/&apos;, include(admin.site.urls)), ) 四. 使用管理工具1. 基本使用两个默认的管理-编辑模块: 用户组(Group), 用户(User). 在 Django 管理页面中, 每种数据类型都有 change list 和 edit form. 前者显示数据库中所有的可用对象; 后者可以添加,更改,删除数据库的某条记录. 2. 将 Model 添加到 Admin 管理中.将自定义的 Models 添加到 Admin 管理中. $ touch mysite/books/admin.py $ cat mysite/books/admin.py from django.contrib import admin from mysite.books.models import Publisher,Author,Book admin.site.register(Publisher) admin.site.register(Author) admin.site.register(Book) $ python manage.py runserver 0.0.0.0:8000 管理工具处理外键和多对多关系的方法是: 外键使用一个选择框显示, 多对多关系使用一个多选框显示. 3.设置字段可选 : blank=True# mysite/books/models.py class Author(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=40) email = models.EmailField(blank=True) 4.设置日期型和数字型字段可选 : blank=True, null=TrueDjango生成CREATE TABLE语句自动为每个字段显式加上NOT NULL. 日期型、时间型和数字型字段不接受空字符串。 如果你想允许一个日期型（DateField、TimeField、DateTimeField）或数字型（IntegerField、DecimalField、FloatField）字段为空，你需要使用null=True 和. blank=True。 class Book(models.Model): title = models.CharField(max_length=100) authors = models.ManyToManyField(Author) publisher = models.ForeignKey(Publisher) publication_date = models.DateField(blank=True, null=True)ssss **null=True 改变了数据的定义, 即改变了 CREATE TABLE 语句, 把 publication_date 字段上的 NOT NULL 删除了, 要完成这些, 需要更新数据库: $ python manage.py dbshell ALTER TABLE books_book ALTER COLUMN publication_date DROP NOT NULL; 5.自定义字段标签 : verbose_name=NAME在编辑页面中, 每个字段的标签都是从模板的字段名称生成的, 规则: 用空格替换下划线, 首字母大写. class Author(model.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=40) email = models.EmailField(blank=True, verbose_name=&quot;e-mail&quot;) # 或者, 如下方式不适用于 ManyToManyField, ForeignKey 字段, 因为他们的第一个参数必须为模块类. email = models.EmailField(&quot;e-mail&quot;, blank=True) 五. 自定义 ModelAdmin 类django 提供大量选项让你针对特别的模块自定义管理工具, 这些选项都在 ModelAdmin classes 里面, 这些类包含了管理工具中针对特别模块的配置. 1. 自定义列表 : list_display,search_fields在列表中可以看到作者的邮箱地址, 并且按姓氏或名字排序. 为了达到这个目的, 将为 Author 模块定义一个 ModelAdmin 类, 该类是自定义管理工具的关键: from django.contrib import admin from mysite.books.models import Publisher,Author,Book class AuthorAdmin(admin.ModelAdmin): list_display=(&quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot;) admin.site.register(Author, AuthorAdmin) admin.site.register(Publisher) admin.site.register(Book) AuthorAdmin 是从 django.contrib.admin.ModelAdmin 中派生出来的子类, 保存着一个类的自定义配置, 以供管理工具使用. list_display 是一个字段名称的元组, 用于列表显示. 这些字段名称必须是模块中有的. admin.site.register(Author,AuthorAdmin) 可以理解为 使用 AuthorAdmin 选项注册 Author 模块. admin.site.register() 函数接受一个 ModelAdmin 子类作为第二个参数. 如果没有第二个参数, django 将使用默认选项. 添加一个快速查询栏(大小写敏感) : search_fields class AuthorAdmin(admin.ModelAdmin): list_display = (&quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot;) search_fields = (&quot;first_name&quot;, &quot;last_name&quot;) 2. 字段过滤器 Django为日期型字段提供了快捷过滤方式，它包含：今天、过往七天、当月和今年。这些是开发人员经常用到的。 class BookAdmin(admin.ModelAdmin): list_display = (&quot;title&quot;, &quot;publisher&quot;, &quot;publication_date&quot;) list_filter = (&quot;publication_date&quot;) admin.site.register(Book, BookAdmin) 过滤器同样适用于其他类型的字段, 而不单是日期型, 请在 布尔型和外键字段上试试. 当有两个以上值时, 过滤器就会显示. 3. 日期过滤器 : date_hierarchy**class BookAdmin(admin.ModelAdmin): list_display = (&quot;title&quot;, &quot;publisher&quot;, &quot;publication_date&quot;) list_filter = (&quot;publication_date&quot;) date_hierarchy = &quot;publication_date&quot; date_hierarchy 接受的是字符串, 而不是元组, 因为只能对一个日期型字段进行层次划分. 4. 排序: ordering列表字段默认按照模块 class Meta 中的 ordering 所指的列排序. ordering 选项基本像模块中 class Meta 的 ordering 那样工作. 见许仅需在传入的元素或者元组的字段前加上一个减号(-). class BookAdmin(admin.ModelAdmin): list_display = (&quot;title&quot;, &quot;publisher&quot;, &quot;publication_date&quot;) list_filter = (&quot;publication_date&quot;) date_hierarchy = &quot;publication_date&quot; ordering = (&quot;-publication_date&quot;) 5. 自定义编辑表单5.1 自定义字段顺序: fields默认的, 表单中的字段顺序是与模块中定义的一致的. 可以使用ModelAdmin子类中的fields选项来改变他. class BookAdmin(admin.ModelAdmin): list_display = (&quot;title&quot;, &quot;publisher&quot;, &quot;publication_date&quot;) list_filter = (&quot;publication_date&quot;) date_hierarchy = &quot;publication_date&quot; ordering = (&quot;-publication_date&quot;) fields = (&quot;title&quot;, &quot;authors&quot;, &quot;publisher&quot;, &quot;publication_date&quot;) 完成之后, 编辑表单将按照指定顺序显示各字段. fields选项可以排除一些不想被其他人编辑的 fields. 当 admin 用户只是被信任可以更改某一部分数据时, 或者, 数据被一些外部的程序自动处理而改变了, 可以使用该功能. fields = (&quot;title&quot;, &quot;authors&quot;, &quot;publisher&quot;) 可以实现无法对 publication_date 进行改动. 当一个用户使用后这个不包含完整信息的表单添加一本新书时, Django会简单的将 publication_date 设置为 None, 以确保这个字段满足 null=True 的条件. 5.2 多选框 : filter_horizontal, filter_vertical –&gt; 用于多对多字段.主要用于多对对字段, 它实现了一个简单的搜索框和两个选择区域, 可以将搜索到的多个选项在选择区域之间移动. class BookAdmin(admin.ModelAdmin): list_display = (&quot;title&quot;, &quot;publisher&quot;, &quot;publication_date&quot;) list_filter = (&quot;publication_date&quot;) date_hierarchy = &quot;publication_date&quot; ordering = (&quot;-publication_date&quot;) filter_horizontal = (&quot;authors&quot;,) 如上代码, 会在 Author 区中有一个 JavaScript 过滤器, 它允许搜索选项, 然后将选中的 author 从 Available 框移到 Chosen 框,还可以移回来. filter_horizontal, filter_vertical 只能用于多对多字段, 不能用于 ForeignKey 字段. 5.3 文本框: raw_id_fields –&gt; ForeignKeyraw_id_fields 是一个包含外键字段名称的元组, 他包含的字段将被展现为文本框, 而不是默认的raw_id_fields 是一个包含外键字段名称的元组, 他包含的字段将被展现为文本框, 而不是默认的**. class BookAdmin(admin.ModelAdmin): list_display = (&quot;title&quot;, &quot;publisher&quot;, &quot;publication_date&quot;) list_filter = (&quot;publication_date&quot;) date_hierarchy = &quot;publication_date&quot; ordering = (&quot;-publication_date&quot;) filter_horizontal = (&quot;authors&quot;,) raw_id_fields = (&apos;publisher&apos;,) 六. 用户,用户组,权限管理工具有一个用户权限系统, 通过他你可以根据用户的需要来指定他们的权限, 从而达到部分访问系统的目的. 通过管理界面可以变价用户及其许可. 用户对象有标准的用户名,密码,邮箱地址和真实姓名, 同时还有关于使用管理界面的权限定义. 如下三种布尔型标记: 活动标志 : 控制用户是否已经激活. 成员标识 : 用来控制该用户是否可以登录管理界面. 用用户系统可以被用于控制公众界面(非管理页面)的访问权限, 这个标志可用来区分公众用户和管理用户. 超级用户标识 : 赋予用户在管理界面中添加,修改,删除任何项目的权限. 如果一个用户有该标志, 那么所有权限设置都会被忽略. 普通的活跃,非超级用户的管理用户可以根据一套设定好的许可进入. 管理界面中每种可编辑的对象(如 books, author, publishers)都有三种权限: 创建许可, 编辑许可, 删除许可. 给一个用户授权就表明该用户可以进行许可描述的操作. 当创建一个用户时, 他没有任何权限, 该有什么权限由你决定. 这些权限时定义在模块级别上的, 而不是对象级别上的. 如 你可以让 tom 账户修改任何图书, 但不能让他仅仅修改由 机械工业出版社 出版的图书. 后面这种基于对象级别的权限设置比较复杂, 可以查看官方文档. 可以给组中分配用户, 组简化了组中所有成员应用一套许可的动作. 组在给大量用户特定权限的时候很有用. 管理界面不应当成为一个公众数据访问接口, 也不允许对数据进行复杂的排序和查询. 它仅提供给可信任的管理员.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>web development</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django之六--部署篇]]></title>
    <url>%2F2018%2F03%2F16%2Fdjango%E4%B9%8B%E5%85%AD--%E9%83%A8%E7%BD%B2%E7%AF%87%2F</url>
    <content type="text"><![CDATA[django 之六 部署篇]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>web development</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-Ipython自动重载]]></title>
    <url>%2F2018%2F03%2F16%2Fpython-Ipython%E8%87%AA%E5%8A%A8%E9%87%8D%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[一. 使用示例In [1]: %load_ext autoreload In [2]: %autoreload 2 # Reload all modules (except those excluded by %aimport) every time before executing the Python code typed. In [3]: from foo import some_function In [4]: some_function() Out[4]: 42 In [5]: # open foo.py in an editor and change some_function to return 43 In [6]: some_function() Out[6]: 43 二. Magic Commands.The following magic commands are provided: %autoreload : Reload all modules (except those excluded by %aimport) automatically now. %autoreload 0 : Disable automatic reloading. %autoreload 1 : Reload all modules imported with %aimport every time before executing the Python code typed. %autoreload 2 : Reload all modules (except those excluded by %aimport) every time before executing the Python code typed. %aimport : List modules which are to be automatically imported or not to be imported. %aimport foo : Import module ‘foo’ and mark it to be autoreloaded for %autoreload 1 %aimport -foo : Mark module ‘foo’ to not be autoreloaded.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>PyPi</tag>
        <tag>Ipython</tag>
        <tag>自动重载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kvm虚拟化之自动化脚本篇]]></title>
    <url>%2F2018%2F03%2F16%2Fkvm%E8%99%9A%E6%8B%9F%E5%8C%96%E4%B9%8B%E8%87%AA%E5%8A%A8%E5%8C%96%E8%84%9A%E6%9C%AC%E7%AF%87%2F</url>
    <content type="text"><![CDATA[一. 环境准备1. 基本原理 使用 nmap 等网络工具, 获取局域网内未使用IP地址, 使用 guestfish 工具编辑 镜像内的网关网络配置文件. 使用自定义的 centos 镜像, 以及 镜像配置 xml 配置, 创建虚拟机. 虚拟机网络环境使用桥接. 虚拟机内部启用 vnc , 用于在 ssh 无法使用时的替代品. 2. 基本环境. 所有虚拟机及配置都位于 /data 目录下, 可以修改. /data/base 下存放的是基础文件, 包含相关脚本, 虚拟机模板文件, 虚拟机镜像文件等. 1234567891011base/├── bin│ ├── kvm_add_vm.sh│ └── kvm_auto_install.sh├── centos6-BASE.qcow2├── centos7-BASE.qcow2├── ip_pool│ ├── gen_ip_list.sh│ ├── unused_ip.list│ └── used_ip.list└── template.xml 虚拟机的管理使用 virsh 管理名利集. 配置完成的虚拟宿主机, 可以使用 virsh 工具实现远程管理. 虚拟网段使用 192.169 开头的网段. 二. 系统环境初始化1. 脚本示例123456789101112131415161718192021222324252627282930313233343536373839404142434445$ cat kvm_auto_install.sh# 所有相关的镜像,脚本,模板 从局域网可以访问的一台文件服务器上下载到本地.set -eKVM_IMG_DIR=/data/kvm_imgBASE_IMG=http://myftp.example.com/iso/base-img.tar.gzLOCAL_INTERFACE=`ls /etc/sysconfig/network-scripts/ |grep ifcfg-e |head -1 |sed s/ifcfg-//g`# 判断系统是否支持kvm, 是否有kvm相关模块.lsmod | grep kvm &amp;&gt;/dev/null &amp;&amp; lsmod |grep -E '(kvm_intel|kvm_amd)' &amp;&gt;/dev/nullif [ $? -ne 0 ];then exit 2 &amp;&amp; echo 'KVM mode is not loaded!'fi# 判断 cpu 是否支持 kvm 虚拟化.grep -E "(vmx|svm)" /proc/cpuinfo &amp;&gt;/dev/nullif [ $? -ne 0 ];then exit 3 &amp;&amp; echo 'You computer is not SUPPORT Virtual Tech OR the VT is NOT OPEN!'fi# 虚拟宿主机是否可以联网, 主要用于 BASE_IMG 的下载, 如果在局域网, 可以注释掉.ping 114.114.114.114 -c 2if [ $? -ne 0 ];then exit 4 &amp;&amp; echo 'Cannot connect to Internet,PLZ check you Network!'fi# 安装相关镜像管理工具, 网络管理工具, 虚拟机管理工具, 及 BASE_IMG.function GET_KVM_PACKAGES()&#123; yum -y install qemu-kvm qemu-kvm-tools &amp;&amp; ln -sv /usr/libexec/qemu-kvm /usr/bin/qemu-kvm yum -y install libvirt libvirt-client virt-install virt-manager virt-viewer &amp;&amp; service libvirtd start yum -y install libguest* libvirt* wget tigervnc tigervnc-server bridge-utils nmap # grep 192.168.1.211 /etc/hosts || echo "192.168.1.211 myftp.example.com" &gt;&gt;/etc/hosts mkdir -pv $KVM_IMG_DIR cd /tmp &amp;&amp; wget $BASE_IMG &amp;&amp; tar xf /tmp/base-img.tar.gz -C $KVM_IMG_DIR &amp;&amp; chown -R qemu:qemu $KVM_IMG_DIR &#125;# 创建网桥function ADD_NET_BRIDGE() &#123; yum -y install bridge-utils virsh iface-bridge $LOCAL_INTERFACE br0&#125; GET_KVM_PACKAGESADD_NET_BRIDGE 2. 脚本使用方法1$ bash kvm_auto_install.sh 三. kvm 镜像模板1. 模板示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;domain type='kvm'&gt; &lt;name&gt;%VM_NAME%&lt;/name&gt; &lt;uuid&gt;%VM_UUID%&lt;/uuid&gt; &lt;memory unit='KiB'&gt;4194304&lt;/memory&gt; &lt;currentMemory unit='KiB'&gt;%VM_MEM_NOW%&lt;/currentMemory&gt; &lt;vcpu placement='static' current='%VM_VCPU%'&gt;6&lt;/vcpu&gt; &lt;os&gt; &lt;type arch='x86_64' machine='%VM_MACHINE%'&gt;hvm&lt;/type&gt; &lt;/os&gt; &lt;features&gt; &lt;acpi/&gt; &lt;apic/&gt; &lt;/features&gt; &lt;cpu match='exact'&gt; &lt;model fallback='allow'&gt;kvm64&lt;/model&gt; &lt;feature policy='require' name='vmx'/&gt; &lt;/cpu&gt; &lt;clock offset='localtime'/&gt; &lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt; &lt;on_reboot&gt;restart&lt;/on_reboot&gt; &lt;on_crash&gt;restart&lt;/on_crash&gt; &lt;pm&gt; &lt;suspend-to-mem enabled='no'/&gt; &lt;suspend-to-disk enabled='no'/&gt; &lt;/pm&gt; &lt;devices&gt; &lt;emulator&gt;/usr/libexec/qemu-kvm&lt;/emulator&gt; &lt;disk type='file' device='disk' &gt; &lt;driver name='qemu' type='qcow2' cache='none'/&gt; &lt;source file='%VM_DISK_PATH%'/&gt; &lt;target dev='vda' bus='virtio'/&gt; &lt;boot order='1'/&gt; &lt;/disk&gt; &lt;controller type='virtio-serial' index='0'&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/&gt; &lt;/controller&gt; &lt;interface type='bridge'&gt; &lt;mac address='%VM_NET_MAC%'/&gt; &lt;source bridge='br0'/&gt; &lt;model type='virtio'/&gt; &lt;target dev='vnet0'/&gt; &lt;alias name='net0'/&gt; &lt;/interface&gt; &lt;interface type='bridge'&gt; &lt;mac address='%VM_NET_MAC2%'/&gt; &lt;source bridge='virbr0'/&gt; &lt;model type='virtio'/&gt; &lt;target dev='vnet1'/&gt; &lt;alias name='net1'/&gt; &lt;/interface&gt; &lt;serial type='pty'&gt; &lt;target port='0'/&gt; &lt;/serial&gt; &lt;console type='pty'&gt; &lt;target type='serial' port='0'/&gt; &lt;/console&gt; &lt;input type='tablet' bus='usb'/&gt; &lt;input type='mouse' bus='ps2'/&gt; &lt;graphics type='vnc' port='5900' autoport='yes' listen='0.0.0.0' keymap='en-us'&gt; &lt;listen type='address' address='0.0.0.0'/&gt; &lt;/graphics&gt; &lt;video&gt; &lt;model type='vga' vram='9216' heads='1'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/&gt; &lt;/video&gt; &lt;memballoon model='virtio'&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x05' function='0x0'/&gt; &lt;/memballoon&gt; &lt;/devices&gt;&lt;/domain&gt; 2. 说明 类似 %XXX% 格式的为变量, 在 创建虚拟机 即运行 kvm_add_vm.sh 脚本时, 会自动替换为相关参数. 模板中的系统相关配置根据需要修改, 如平台类型等. 虚拟机默认开始 vnc , 用于创建 console 连接到虚拟机, 作为 ssh 无法使用或不支持时的替代方案. 网络,磁盘 等IO设备, 默认使用virtio方式增强性能. 虚拟机会有两张网卡. 同时支持 centos6 和 centos7. 四. 自动添加 kvm 虚拟机脚本1. 脚本示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687$ cat kvm_add_vm.shset -eSYS_KVMIMG_DIR=/data/kvm_imgSYS_REMOTE_IMGURL=http://myftp.example.com/iso/Base-Img.tar.gzSYS_LOCAL_NETINTERFACE=`ls /etc/sysconfig/network-scripts/ |grep ifcfg-e |head -1 |sed s/ifcfg-//g`NET_PREFIX='192.168'NET_POOL=`ip addr |grep -A 3 '\&lt;br0:' |awk -F'.' '/inet\&gt;/&#123;print $3&#125;'`# 脚本使用语法格式if [ $# -ne 3 ] ;then echo -e "Usage : $0 VM_CPU VM_MEM(Gb) [ centos6|centos7 ]\nExample : $0 2 4 centos7 " &amp;&amp; exit 5fi # 获取虚拟机IP地址(私网)function GET_VM_IP() &#123; mkdir -pv $SYS_KVMIMG_DIR/base/ip_pool/ UNUSED_IP_LIST=$SYS_KVMIMG_DIR/base/ip_pool/unused_ip.list USED_IP_LIST=$SYS_KVMIMG_DIR/base/ip_pool/used_ip.list :&gt; $UNUSED_IP_LIST :&gt; $USED_IP_LIST for i in &#123;19..253&#125; ;do echo $NET_PREFIX.$NET_POOL.$i &gt;&gt;$UNUSED_IP_LIST ;done nmap -n -sP -PI -PT $NET_PREFIX.$NET_POOL.0/24 |awk '/^Nmap/&#123;print $5&#125;' |grep $NET_PREFIX &gt; $USED_IP_LIST for m in `cat $&#123;USED_IP_LIST&#125;`;do sed -i "/$m/d" $UNUSED_IP_LIST ;done&#125;GET_VM_IPVM_NET_IP=$(head -$((`echo $RANDOM`%`cat $SYS_KVMIMG_DIR/base/ip_pool/unused_ip.list |wc -l`)) $SYS_KVMIMG_DIR/base/ip_pool/unused_ip.list |tail -1)# 虚拟机 CPU,MEM,OS_Version, MAC, GATEWAY 等配置.VM_VCPU=$1VM_MEM_NOW=$(($2*1024*1024))VM_VERSION=`echo $3 |tr A-Z a-z`VM_NAME=$VM_VERSION-$VM_NET_IPVM_UUID=`uuidgen`VM_MACHINE=`qemu-kvm -machine ? |grep default |awk '&#123;print $1&#125;'`VM_DISK_PATH=$SYS_KVMIMG_DIR/$VM_NET_IP/$&#123;VM_NAME&#125;.qcow2VM_NET_MAC=52:54:00:b0:0$NET_POOL:`echo $VM_NET_IP |awk -F'.' '&#123;print $4&#125;' |xargs printf %x`VM_NET_MAC2=52:54:00:b1:0$NET_POOL:`echo $VM_NET_IP |awk -F'.' '&#123;print $4&#125;' |xargs printf %x`VM_NET_GATEWAY=`echo $VM_NET_IP |awk -F'.' '&#123;print $1"."$2"."$3"."1&#125;'`function CONFIG_TEMPLATE() &#123; mkdir $SYS_KVMIMG_DIR/$VM_NET_IP &amp;&amp; cp $SYS_KVMIMG_DIR/base/$VM_VERSION-BASE.qcow2 $SYS_KVMIMG_DIR/$VM_NET_IP/$&#123;VM_NAME&#125;.qcow2 &amp;&amp; cp $SYS_KVMIMG_DIR/base/template.xml $SYS_KVMIMG_DIR/$VM_NET_IP/$&#123;VM_NAME&#125;.xml &amp;&amp; chown -R qemu:qemu $SYS_KVMIMG_DIR/$VM_NET_IP/ sed -i "s/%VM_NAME%/$VM_NAME/g" $SYS_KVMIMG_DIR/$VM_NET_IP/$&#123;VM_NAME&#125;.xml sed -i "s/%VM_UUID%/$VM_UUID/g" $SYS_KVMIMG_DIR/$VM_NET_IP/$&#123;VM_NAME&#125;.xml sed -i "s/%VM_MEM_NOW%/$VM_MEM_NOW/g" $SYS_KVMIMG_DIR/$VM_NET_IP/$&#123;VM_NAME&#125;.xml sed -i "s/%VM_VCPU%/$VM_VCPU/g" $SYS_KVMIMG_DIR/$VM_NET_IP/$&#123;VM_NAME&#125;.xml sed -i "s/%VM_MACHINE%/$VM_MACHINE/g" $SYS_KVMIMG_DIR/$VM_NET_IP/$&#123;VM_NAME&#125;.xml sed -i "s@%VM_DISK_PATH%@$VM_DISK_PATH@g" $SYS_KVMIMG_DIR/$VM_NET_IP/$&#123;VM_NAME&#125;.xml sed -i "s@%VM_NET_MAC%@$VM_NET_MAC@g" $SYS_KVMIMG_DIR/$VM_NET_IP/$&#123;VM_NAME&#125;.xml sed -i "s@%VM_NET_MAC2%@$VM_NET_MAC2@g" $SYS_KVMIMG_DIR/$VM_NET_IP/$&#123;VM_NAME&#125;.xml&#125;# 修改镜像中的网络配置.function PUT_IP_IN() &#123;# if [ $VM_VERSION = 'centos6' ];then# VM_NET_CONFIG=eth1# else VM_NET_CONFIG=`virt-ls -a $SYS_KVMIMG_DIR/$VM_NET_IP/$&#123;VM_NAME&#125;.qcow2 /etc/sysconfig/network-scripts/ |awk -F'-' '/ifcfg-eth0/&#123;print $2&#125;'`# fi cat &lt;&lt;EOF &gt;&gt; $SYS_KVMIMG_DIR/$VM_NET_IP/ifcfg-$VM_NET_CONFIGTYPE=EthernetBOOTPROTO=staticDEVICE=$VM_NET_CONFIGONBOOT=yes IPADDR=$VM_NET_IPNETMASK=255.255.255.0GATEWAY=$VM_NET_GATEWAYDNS1=114.114.114.114EOF virt-copy-in -a $VM_DISK_PATH $SYS_KVMIMG_DIR/$VM_NET_IP/ifcfg-$VM_NET_CONFIG /etc/sysconfig/network-scripts/&#125;# 创建虚拟机, 并展示创建结果.function START_VM() &#123; virsh define $SYS_KVMIMG_DIR/$VM_NET_IP/$&#123;VM_NAME&#125;.xml &amp;&amp; virsh start $VM_NAME &amp;&amp; echo -e "\nVM IPADDRESS: $VM_NET_IP" &amp;&amp; virsh dominfo $VM_NAME &#125;CONFIG_TEMPLATEPUT_IP_INSTART_VM 2. 使用方法1$ kvm_add_vm.sh VM_CPU VM_MEM(Gb) [ centos6|centos7 ] 3. 查看生成虚拟机名称格式为 VM_NAME=$VM_VERSION-$VM_NET_IP, 如 centos6_192.168.1.1. 生成虚拟机之后, 可以使用 virsh 相关命令实现本机或远程虚拟主机管理.12$ virsh list$ virsh dominfo centos6_192.168.1.1 五. 虚拟镜像管理利器: guestfish &amp;&amp; virshguestfish 是一套虚拟机镜像管理的利器，提供一系列对镜像管理的工具，也提供对外的API。guestfish主要包含以下工具： guestfish interactive shell 挂载镜像，并提供一个交互的shell。 guestmount mount guest filesystem in host 将镜像挂载到指定的目录。 guestumount unmount guest filesystem 卸载镜像目录。 命令行说明: 命令 说明 virt-alignment-scan 镜像块对齐扫描。 virt-builder quick image builder 快速镜像创建。 virt-cat(1) display a file 显示镜像中文件内容。 virt-copy-in(1) copy files and directories into a VM 拷贝文件到镜像内部。 virt-copy-out(1) copy files and directories out of a VM 拷贝镜像文件出来。 virt-customize(1) customize virtual machines 定制虚拟机镜像 virt-df(1) free space 查看虚拟机镜像空间使用情况。 virt-diff(1) differences 不启动虚拟机的情况下，比较虚拟机内部两份文件差别。 virt-edit(1) edit a file 编辑虚拟机内部文件。 virt-filesystems(1) display information about filesystems, devices, LVM 显示镜像文件系统信息。 virt-format(1) erase and make blank disks 格式化镜像内部磁盘。 virt-inspector(1) inspect VM images 镜像信息测试。 virt-list-filesystems(1) list filesystems 列出镜像文件系统。 virt-list-partitions(1) list partitions 列出镜像分区信息。 virt-log(1) display log files 显示镜像日志。 virt-ls(1) list files 列出镜像文件。 virt-make-fs(1) make a filesystem 镜像中创建文件系统。 virt-p2v(1) convert physical machine to run on KVM 物理机转虚拟机。 virt-p2v-make-disk(1) make P2V ISO 创建物理机转虚拟机ISO光盘。 virt-p2v-make-kickstart(1) make P2V kickstart 创建物理机转虚拟机kickstart文件。 virt-rescue(1) rescue shell 进去虚拟机救援模式。 virt-resize(1) resize virtual machines 虚拟机分区大小修改。 virt-sparsify(1) make virtual machines sparse (thin-provisioned) 镜像稀疏空洞消除。 virt-sysprep(1) unconfigure a virtual machine before cloning 镜像初始化。 virt-tar(1) archive and upload files 文件打包并传入传出镜像。 virt-tar-in(1) archive and upload files 文件打包并传入镜像。 virt-tar-out(1) archive and download files 文件打包并传出镜像。 virt-v2v(1) convert guest to run on KVM 其他格式虚拟机镜像转KVM镜像。 virt-win-reg(1) export and merge Windows Registry keys windows注册表导入镜像。 libguestfs-test-tool(1) test libguestfs 测试libguestfs libguestfs-make-fixed-appliance(1) make libguestfs fixed appliance hivex(3) extract Windows Registry hive 解压windows注册表文件。 hivexregedit(1) merge and export Registry changes from regedit-format files 合并、并导出注册表文件内容。 hivexsh(1) Windows Registry hive shell window注册表修改交互的shell。 hivexml(1) convert Windows Registry hive to XML 将window注册表转化为xml hivexget(1) extract data from Windows Registry hive 得到注册表键值。 guestfsd(8) guestfs daemon guestfs服务。]]></content>
      <categories>
        <category>云计算与虚拟化</category>
      </categories>
      <tags>
        <tag>kvm</tag>
        <tag>guestfish</tag>
        <tag>libvirsh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django-模板原理及扩展]]></title>
    <url>%2F2018%2F03%2F16%2Fdjango-%E6%A8%A1%E6%9D%BF%E5%8E%9F%E7%90%86%E5%8F%8A%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[模板可以使用模板标签和模板变量. 模板标签 模板标签是在一个模板中起作用的标记. 区块标签 ‘{ % TAG % }’ 变量 : 一个在模板里用来输出值的标记 { { TAG } } context : 是一个传递给模板的名称到值的映射(类似Python字典) 渲染: 通过从 contex 获取值来替换模板中的变量, 并执行所有的模板标签. 1. RequestContext 和 Context 处理器1.1 Context一段解析模板的 context 是 django.template.Context 的实例. 1.2 RequestContextdjango.template.RequestContext 默认在模板 context 中加入一些变量. 如 HttpRequest对象或者当前登录用户的相关信息. 创建 RequestContext 和 Context 处理器就是为了解决这个问题. Context 处理器允许设置一些变量, 他们会在每个 context 中自动被设置好, 而不必每次调用 render_to_response() 时都指定. 要点就是, 当你渲染模板时, 使用 RequestContext 而不是 Context . 最直接的做法就是用 context 处理器来创建一些处理器并传递给 RequestContext. RequestContext 的第一个参数需要传递一个 HttpRequest 对象，就是传递给视图函数的第一个参数（ request ）. RequestContext 有一个可选的参数 processors ，这是一个包含context处理器函数的列表或者元组. # 原始视图: 使用手动载入模板 from django.template import loader, Context def view_1(request): # ... t = loader.get_template(&apos;template1.html&apos;) c = Context({ &apos;app&apos;: &apos;My app&apos;, &apos;user&apos;: request.user, &apos;ip_address&apos;: request.META[&quot;REMOTE_ADDR&quot;], &apos;message&apos;: &quot;I am view1&quot; }) return t.render(c) def view_2(request): # ... t = loader.get_template(&apos;template2.html&apos;) c = Context({ &apos;app&apos;: &apos;My app&apos;, &apos;user&apos;: request.user, &apos;ip_address&apos;: request.META[&quot;REMOTE_ADDR&quot;], &apos;message&apos;: &quot;I am the second view.&quot; }) return t.render(c) # 使用处理器: 用 context 处理器创建一些处理器, 并传递给 RequestContext. from django.template import loader, RequestContext def custom_proc(request): &quot;A context processor that provides &apos;app&apos;, &apos;user&apos;, and &apos;ip_address&apos;&quot; return { &apos;app&apos;: &apos;My app&apos;, &apos;user&apos;: request.user, &apos;ip_address&apos;: request.META[&quot;REMOTE_ADDR&quot;] } def view_1(request): # ... t = loader.get_template(&apos;template1.html&apos;) c = RequestContext(request, {&quot;message&quot;: &quot;I am view 1.&quot;}, processors=[custom_proc]) return t.render(c) def view_2(request): # ... t = loader.get_template(&apos;template2.html&apos;) c = RequestContext(request, {&quot;message&quot;: &quot;I am the second view.&quot;}, processors=[custom_proc]) return t.render(c) render_to_response() 可以简化调用 loader.get_template() , 然后创建一个 Context 对象, 最后再调用模板对象的 render() 过程. 使用 render_to_response() 作为 context 的处理器, 就需要使用 context_instance 参数. from django.shortcuts import render_to_response from django.template import RequestContext def custom_proc(request): &quot;A context processor that provides &apos;app&apos;, &apos;user&apos;, and &apos;ip_address&apos;&quot; return { &apos;app&apos;: &quot;My app&quot;, &apos;user&apos;: request.user, &apos;ip_address&apos;: request.META[&quot;REMOTE_ADDR&quot;] } def view_1(request): # ... return render_to_response(&apos;template1.html&apos;, {&apos;message&apos;: &apos;I am view 1.&apos;}, context_instance=RequestContext(request, processors=[custom_proc])) def view_2(request): # ... return render_to_response(&apos;template2.html&apos;, {&apos;message&apos;: &apos;I am view 2.&apos;}, context_instance=RequestContext(request, processor=[custom_proc])) 全局 context 处理器支持. TEMPLATE_CONTEXT_PROCESSORS 指定了哪些 context processors 总是默认被使用. 这样就省去了每次使用 RequestContext 都指定 processors 的麻烦. # 默认 TEMPLATE_CONTEXT_PROCESSORS 设置: TEMPLATE_CONTEXT_PROCESSORS = ( &apos;django.core.context_processors.auth&apos;, &apos;django.core.context_processors.debug&apos;, &apos;django.core.context_processors.i18n&apos;, &apos;django.core.context_processors.media&apos;, ) 这个设置项是一个可调用函数的元组, 其中的每个函数使用了和上文中 custom_proc 相同的接口, 他们都以 request 对象作为参数, 返回一个会被合并传给 context 的字典: 接受一个 request 对象作为参数, 返回一个包含了将被合并到 context 中的项的字典. 每个处理器竟会按照顺序应用, 也就是说如果在第一个处理器中向 context 添加了一个变量, 而第二个处理器添加了同样名字的变量, 那么第二个将会覆盖第一个. django.core.context_processors.auth 如果 TEMPLATE_CONTEXT_PROCESSORS 包含该处理器, 则每个 RequestContext 将包含这些变量: user: 一个 django.contrib.auth.models.User 实例, 描述当前登录用户(或 AnonymousUser ) messages: 一个当前登录用户的消息列表(字符串). 在后台对每个请求, 这个变量都调用 request.user.get_and_delete_messages() 方法. 这个方法收集用户的消息然后把他们从数据库中删除. perms: django.core.context_processors.PermWrapper 实例, 包含了当前登录用户的所有权限. django.core.context_processors.debug 该处理器把 调试信息发送到模板层. 如果 TEMPLATE_CONTEXT_PROCESSORS 包含该处理器, 则每个 RequestContext 将包含这些变量: debug : 设置的 DEBUG 的值(True/False). 可以在模板里调用该变量, 测试是否在 debug 模式. sql_queries : 包含类似于 “{‘sql’: …, ‘time’: …}” 的字典的一个列表, 记录了该请求期间的每个 SQL 查询以及查询所消耗的时间. 该列表按请求顺序排列. 该 Context 处理器只有当同时满足一下两个条件时, 才有效: DEBUG : 设置为 True; 请求的 IP 包含在 INTERNAL_IPS的设置里面. DEBUG 模板变量的值, 永远不可能是 False, 因为如果 DEBUG 是 False, 那么 debug 模板变量一开始就不会被 RequestContext 所包含. django.core.context_processors.i18n&#39; 如果TEMPLATE_CONTEXT_PROCESSORS` 包含该处理器, 则每个 RequestContext 将包含这些变量: LANGUAGES : LANGUAGES 选项的值. LANGUAGE_CODE : 如果 LANGUAGE_CODE存在, 就等于它 , 否则 等同于 LANGUAGE_COde 设置. `django.core.context_processors.request’ 如果启用这个处理器，每个 RequestContext 将包含变量 request ， 也就是当前的 HttpRequest 对象。 注意这个处理器默认是不启用的，你需要激活它。 # 在模板中使用 { { request.REMOTE_ADDR } } 写 Context 处理器的一些建议: 使 每个 context 处理器完成尽可能小的功能. 使用多个处理器是很容易的, 所以, 可以根据逻辑块来分解功能以便将来复用. 要注意 TEMPLATE_CONTEXT_PROCESSORS 里的 context processor 将会在基于这个 settings.py 的每个模板中有效, 所以变量的命名不要和模板的变量冲突. 变量名是大小写敏感的, 所以 processor 的变量全用大写是个好主意. 不论他们存放在哪个路径下, 只要在 python 的搜索路径中, 就可以在TEMPLATE_CONTEXT_PROCESSORS 设置里指向他们. 建议吧他们放在应用或者工程目录下名为 context_processors.py 的文件里. 2. 模板加载器2.1 加载模板相关变量 TEMPLATE_DIRS : 模板存放目录 TEMPLATE_LOADERS : 是一个字符串的元组, 其中每个字符都表示一个模板加载器. 这些模板加载器岁 Django 一起发布. Django按照 TEMPLATE_LOADERS 设置中的顺序使用模板加载器. 它逐个使用每个加载器直到找到一个匹配的模板 2.2 默认加载模板方法 django.template.loader.get_template(template_name) get_template 根据给定的模板名称返回一个已编译的模板(一个 Template对象). 如果模板不存在, 就触发 TemplateDoesNotExist 异常. django.template.loader.select_template(template_name_list) select_template 以模板名称的列表作为参数, 他会返回列表中存在的第一个模板, 如果模板都不存在, 将会触发 TemplateDoesNotExist 异常. 2.3 其他模板加载器 django.template.loader.filesystem.load_template_source: 该加载器根据TEMPLATE_DIRS 的设置从问加你系统加载模板. 该加载器默认可用. django.template.loaders.app_directories.load_template_source 该加载器从文件系统上的 Django 应用中加载模板. 对 INSTALLED_APPS 中的每个应用, 这个加载器会查找 templates 子目录. 如果该目录存在, Django 就在那里寻找模板. 这意味着可以把模板和应用一起保存, 从而使得 Django 应用更容易和默认模板一起发布. 加载器在首次被导入的时候, 会执行一个优化: 它会缓存一个列表, 这个列表包含了 INSTALLED_APPS 中的带有 templates 子目录的包. 该加载器默认启用. django.template.loaders.eggs.load_template_source 该加载器类似 app_directories, 只不过他从 Python eggs 而不是文件系统中加载模板. 这个加载器默认禁用. Python eggs 可以将 Python 代码压缩到一个文件中. 3. 扩展模板系统绝大部分的模板定制是以自定义标签/过滤器的方式来完成的. 3.1 创建模板库(Django 能够导入的基本结构)3.1.1 决定模板库应该放在哪个 Django 应用下.可以将模板库放在某个应用下, 也可以为模板库单独创建一个应用(推荐, filter 可能在后来的工程中有用). 3.1.2 在适当的 Django 应用包里创建一个 templatetags 目录. 该目录应该和 models.py , views.py等处于同一层次. 3.1.3 在 templatetags 中创建两个空文件: __init__ 一旦创建了 Python 模块, 只需根据要编写过滤器还是标签来响应的编写一些 Python 代码即可. 该文件名稍后用来加载标签. 如, 自定义标签/过滤器 存放在一个名为 poll_extras.py 的文件中. 需要在模板中写入如下内容: { % load poll_extras % } { % load % } 标签检查 INSTALL_APPS 中的设置, 仅允许加载已安装的 Django 应用程序的模板库. 它可以让你在一台电脑上部署很多的模板库的代码, 而不用吧他们暴露给每一个 Django 安装. 对于在 templatetags 包中放置多少个模块没有做任何的限制. 需要了解的是: { % load % } 语句时通过指定的 Python 模块名而不是应用名来加载标签/过滤器的. Django 默认的过滤器和标签源码: django/template/defaultfilters.py 和 django/template/defaulttags.py 作为合法的标签库, 模块需要包含一个名为 register 的模块级变量. 这个变量时 template.Library 的实例, 时所有注册标签和过滤器的数据结构. from django import template register = template.Library() 创建 register 变量后，你就可以使用它来创建模板的过滤器和标签了。 3.1.4 自定义模板过滤器自定义过滤器上就是有一个或者两个参数的 Python 函数: 输入变量的值, 参数的值(可以是默认值或者留空). 例如, 在过滤器 { { var|foo:”bar” } } 中 ，过滤器 foo 会被传入变量 var 和默认参数 bar。 过滤器函数应该总有返回值. 而且不能触发异常, 他们都应该静静的失败, 如果出现错误, 应该返回一个原始输入或者空字符串, 这回更有意义. # 1. 定义过滤器 def cut(value, args): &quot;remove all values of arg from the given string&quot; return value.replace(arg, &apos;&apos;) # 使用方法: { { somevariable | cut:&quot; &quot; } } def lower(value): &quot;Converts a strings into all lovercase&quot; return value.lower() # 2. 使用 Library 注册过滤器 register.filter(&apos;cut&apos;, cut) register.filter(&apos;lower&apos;, lower) # Library.filter() 本身需要两个参数: 过滤器名称 和 过滤器函数本身. # 使用装饰器的注册过滤器 @register.filter(name=&apos;cut&apos;) # name 指定过滤器名称, 不指定为函数名. def cut(value, arg): return value.replace(arg, &apos;&apos;) @register.filter def lower(value): return value.lower() 完成的模板库例子, 包含一个 cut 过滤器: from django import template register = template.Library() @register.filter(name=&apos;cut&apos;) def cut(value, arg): return value.replace(arg, &apos;&apos;) 3.1.5 自定义模板标签自定义标签要比过滤器复杂些. 当 Django 编译一个模板时, 它将原始模板分成一个个节点, 每个节点都是 django.template.Node 的一个实例, 并且具备 render() 方法. 一个已编译的模板就是节点对象的一个列表. Hello, { { person.name } }. { % ifequal name.birthday today % } Happy birthday! { % else % } Be sure to come back on your birthday for a splendid surprise message. { % endifequal % } 被编译的模板表现为节点列表的形式： 1. 文本节点： &quot;Hello, &quot; 2. 变量节点： person.name 3. 文本节点: &quot;.\n\n&quot; 4. IfEqual节点: name.birthday和today 当调用一个已编译模板的 render() 方法时, 模板就会用给定的 context 来调用每个在他的节点列表上的所有节点的 render() 方法. 这些渲染的结果合并起来, 形成模板的输出. 因此, 要自定义模板标签, 需要指明原始模板标签如何转换成节点(编译函数) 和 节点的 render() 方法完成的功能. render() 应当总是返回一个字符串, 即使是空字符串. 3.1.5.1 编写编译函数当遇到一个模板标签(template tag)时, 模板解析器就会把标签包含的内容, 以及模板解析器自己作为参数调用一个 Python 函数. 这个函数负责返回一个和当前模板标签内容相对应的节点(Node)实例. 使用的标签&lt;p&gt;The time is { % current_time &quot;%Y-%m-%d %I:%M %p&quot; % }.&lt;/p&gt; 函数的分析器会获取参数并创建一个 Node 对象: from django import template register = template.Library() def do_current_time(parser, token): try: # split_contents() knows not to split quoted strings. tag_name, format_string = token.split_contents() except ValueError: msg = &quot;%r tag requires a single argument&quot; % token.split_contents()[0] return CurrentTimeNode(format_string[1:-1]) 每个标签编译函数有两个参数: parser 和 token. parser 是模板解析器对象, token 是被解析的语句. token.contents 是包含有变迁原始内容的字符串. 在本例中为 current_time &quot;%Y-%m-%d %I:%M %P&quot; token.split_contents() 方法按空格拆分参数, 同时保证引号中的字符串不拆分. 应该避免使用, 因为他不够健壮. django.template.TemplateSyntaxError 异常提供所有语法错误的有用信息. token.split_contents()[0] 记录标签的名字, 就算标签没有任何参数. 不要把便签名硬编码在错误信息中, 因为这样会把标签名称和函数耦合在一起. 函数返回一个CurrentTimeNode, 它包含了节点需要知道的关于这个标签的全部信息. 模板标签编译函数必须返回一个 Node 子类, 返回其他值都是错的. 3.1.5.2 编写模板节点定义一个拥有 render() 方法的 Node 子类. 如上例中的 CurrentTimeNode. 两个函数__init__() 和 render() 与模板处理中的两步(编译与渲染) 直接对应. 这样, 初始化函数仅仅需要存储后要用到的格式字符串, 而 render() 函数才做真正的工作. 与模板过滤器一样, 这些渲染函数应该静静的捕获错误, 而不是抛出错误. 模板标签只允许在编译的时候抛出错误. import datetime class CurrentTimeNode(template.Node): def __init__(self, format_string): self.format_string = format_string def render(self, context): now = datetime.datetime.now() return now.strftime(self.format_string) 3.1.5.3 注册标签只需实例化一个 template.Library 实例然后调用它的 tag(TAG_NAME, TAG_FUNC) 方法即可. # tag() register.tag(&apos;current_time&apos;, do_current_time) # 装饰器格式 @register.tag(name=&quot;current_time&quot;) def do_current_time(parser, token): # ... 3.1.5.4 在上下文中设置变量要在上下文中设置变量, 在 render() 函数的 context 对象上使用字典赋值即可. # 设置上下文变量 class CurrentTimeNode2(template.Node): def __init__(self, format_string): self.format_string = format_string def render(self, context): now = datetime.datetime.now() context[&quot;current_time&quot;] = now.strftime(self.format_string) return &apos;&apos; # 在模板中使用标签: { % current_time2 &quot;%Y-%m-%d %I:%M %p&quot; % } &lt;P&gt;The time is { { current_time } }.&lt;/p&gt; 上例中的变量名是硬编码的, 去除硬编码的更简洁的方案如下: # 在模板中使用标签 { % get_current_time &quot;%Y-%M-%d %I:%M %p&quot; as my_current_time % } &lt;p&gt;The current time is { { my_current_time } }.&lt;/p&gt; # 编译函数和 Node 类 import re class CurrentTimeNode3(template.Node): def __init__(self, format_string, var_name): self.format_string = format_string self.var_name = var_name def render(self, context): now = datetime.datetime.now() context[self.var_name] = now.strftime(self.format_string) return &apos;&apos; # do_current_time() 把格式字符串和变量名传递给 CurrentTimeNode3 def do_current_time(parser, token): # This version use a regular expression to parser tag contents. try: # Splitting by None == splitting by spaces. tag_name, arg = token.contents.split(None, 1) expect ValueError: msg = &quot;%r tag requires arguments&quot; $ token.contents[0] raise template.TemplateSyntaxError(msg) m = re.search(r&apos;(.*?) as (\w+)&apos;, arg) if m: fmt, var_name = m.groups() else: msg = &quot;%r tag had invalid arguments&quot; % tag_name raise template.TemplateSyntaxError(msg) if not (fmt[0] == fmt[-1] and fmt[0] in (&quot;&apos;&quot;, &apos;&quot;&apos;)): msg = &quot;%r tag&apos;s arguments should be in quotes&quot; % tag_name raise template.TemplateSyntaxError(msg) return CurrentTimeNode3(fmt[1:-1], var_name) 3.1.5.5 标签对 : 分析直至另一个模板标签在编译函数中使用 parser.parser() # 标准的 { % comment % } 标签实现 def do_comment(parser, token): nodelist = parser.parser((&apos;endcommend&apos;,)) parser.delete_first_token() return CommentNode() class CommentNode(template.Node): def render(self, context): return &apos;&apos; parser.parser() 接受一个包含了需要分析的模板标签名的元组作为参数. 它返回一个django.template.NodeList 实例. 他是一个包含了所有 Node 对象的列表. 这些对象是解析器在解析到任一元组中指定的标签之前遇到的内容. 上面的代码中, nodelist 实在 { % comment % } 和 { % endcomment % } 之间所有节点的列表, 不包括 { % comment % } 和 { % endcomment % } 自身. 在 parser.parser() 被调用之后, 分析器还没有清除{ % endcommend % } 标签, 因此代码需要显式的调用 parser.delete_first_token() 来防止该标签被处理两次. 之后 CommentNode.render() 只是简单的返回一个空字符串, 在 { % comment % } 和 { % endcomment % } 之间的所有内容被忽略. 修改和利用标签之间的内容: # 解析器代码 def do_upper(parser, token): nodelist = parser.parse((&apos;endupper&apos;,)) parser.delete_first_token() return UpperNode(nodelist) class UpperNode(template.Node): def __init__(self, nodelist): self.nodelist = nodelist def render(self, context): # self.nodelist.render(context) 对节点列表中的每个 Node 简单的调用 render() output = self.nodelist.render(context) return output.upper() # 在模板中使用: { % upper % } This will appear in uppercase, { { user_name } } { % endupper % } 3.1.5.6 简单标签的快捷方式: django.template.Library.simple_tag()许多模板标签接受单一的字符串参数或者一个模板变量引用, 然后独立的根据输入变量和一些其他外部信息进行处理并返回一个字符串. 为了简化这类标签, Django 提供了一个帮助函数simple_tag(). 该函数是 django.template.Library 的一个方法. 它接受一个只有一个参数的函数作为参数. 把他包装在 render函数 和之前提及过的其他的必要单位中, 然后通过模板系统注册标签. # 解析器代码 def current_time(format_string): try: return datetime.datetiem.now().strftime(str(format_string)) except UnicodeEncodeError: return &apos;&apos; register.simple_tag(current_time) # 装饰器实现代码 @register.simple_tag def current_time(token): # ... simple_tag() 函数注意事项: 传递给该函数的只有单个 参数 在函数被调用的时候, 检查必需参数个数的工作已经完成. 参数两边的引号(如果有的话), 已经被截掉, 所有函数接收到一个普通 Unicode 字符串. 3.1.5.7 包含标签: 通过渲染其他模板显示数据.实现结果: # 在模板中调用 { % books_for_author author % } # 输出结构: &lt;ul&gt; &lt;li&gt;The Cat in Hat&lt;/li&gt; &lt;li&gt;Hop On Pop&lt;/li&gt; &lt;li&gt;Green Eggs And Ham&lt;/li&gt; &lt;/ul&gt; 实现过程: # 1. 定义函数, 通过给定的参数生成一个字典形式的结果. 只需返回字典类型的结果就行, 无需返回更复杂的东西. def books_for_author(author): books = Book.objects.filter(authors_id=author.id) return {&apos;books&apos;: books} # 2. 创建用于渲染的模板: &lt;ul&gt; { % for book in books % } &lt;li&gt; { { book.title } } &lt;/li&gt; { % endfor % } &lt;/ul&gt; # 3. 通过 Library 对象使用 inclusion_tag() 方法来创建并注册这个包含标签. register.inclusion_tag(&apos;book_snippet.html&apos;)(books_for_author) @register.inclusion_tag(&apos;book_snippet.html&apos;) def books_for_author(author): # ... Django 为包含标签提供了一个takes_context 选项, 用于在包含标签中访问父模板的 context. 如果在创建模板标签时, 指明了这个选项, 这个标签就不需要参数, 并且下面的 Python 函数会带一个参数: 就是当这个标签被调用时的模板 context. # 一个包含标签, 该标签包含有指向主页的 home_link 和 home_title 变量. @register.inclusion_tag(&apos;link.html&apos;, tokes_context=True) def jump_link(context): return { &apos;link&apos;: context[&apos;home_link&apos;], &apos;title&apos;: context[&apos;home_title&apos;] } # link.html Jump directly to &lt;a href=&quot;{ { link } }&quot;&gt; { { title } } &lt;/a&gt; # 使用自定义标签时, 就可以加载它的库, 然后不带参数的调用它. { % jump_link % } 4. 编写自定义模板加载器模板加载器, 也就是TEMPLATE_LOADERS 中的每一项, 都有要能被下面这个接口调用: load_template_source(template_name, template_dirs=None) template_name : 所加载模板的名称. template_dirs : 一个可选的代替 TEMPLATE_DIRS 的搜索目录列表. 如果加载器能够成功加载一个模板, 他应当返回一个元组(template_source, template_path). template_source 就是将被模板引擎编译的模板字符串; template_path 是被加载的模板的路径. 如果加载器加载模板失败, 那么就会触发 django.template.TemplateDoesNotExist 异常. 每个加载函数都应该有一个 is_usable 的函数属性. 这个属性是一个布尔值, 用于告知模板引擎, 这个加载器是否在当前安装的 Python 中可用. 编写自定义模板加载器分两步: 编写模板加载器代码 将模板加载器名称加入到 TEMPLATE_LOADERS 示例: 一个可以从 ZIP 文件中加载模板的模板加载函数. 他使用了自定义的设置 TEMPLATE_ZIP_FILES 来取代 TEMPLATE_DIRS 用做查找路径, 并且他假设在此路径上的每一个文件都是包含模板的 ZIP 文件. from django.conf import settings from django.template import TemplateDoesNotExist import zipfile def load_template_source(template_name, template_dirs=None): &quot;Template loader that load templates from a ZIP file.&quot; template_zipfiles = getattr(settings, &quot;TEMPLATE_ZIP_FILES&quot;, []) # Try each ZIP file in TEMPLATE_ZIP_FILES . for fname in template_zipfiles: try: z = zipfile.ZipFile(fname) source = z.read(template_name) except (IOError, KeyError): continue z.close() # We found a tmeplate , so return the source. template_path = &quot;%s:%s&quot; % (fname, template_name) return (source, template_path) # If we reach here, the template couldn&apos;t be loaded raise TemplateDoesNotExist(template_name) # This loadder is always usable (since zipfile is included with Python) load_template_source.is_usable = True # 还需要将上面的代码, 加入到 TEMPLATE_LOADERS 中. # 如果代码放在 mysite.zip_loader 的包中, 那么我们要把 mysite.zip_loader.load_template_source 加入到 TEMPLATE_LOADERS 中.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>web development</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 扩展之--flask-sse]]></title>
    <url>%2F2018%2F03%2F16%2FflaskExt--flask-sse%2F</url>
    <content type="text"><![CDATA[flask-sse 1. Server-Sent Events, SSEServer-Sent Events 让服务器向客户端流式发送文本消息, 如服务器生生成的实时通知或者更新. SSE 提供的是一个高效, 跨浏览器的 XHR 流实现, 消息交付只使用一个长 HTTP 连接. 与我们自己实现的 XHR 流不同, 浏览器会帮我们管理连接, 解析消息, 从而让我们只关注业务逻辑. 1.1 SSE 组件 浏览器中的 EventSource API : 可以让客户端以 DOM 事件的形式, 接收到服务器推送的通知. 事件流 数据格式 : 新数据格式用于交付每一次更新. 1.1.1 EventSource API1.1.1.1 APIEventSource 接口通过一个简单的浏览器 API 隐藏了所有的底层细节: 包括建立链接和解析消息. 使用 SSE , 只需指定 SSE 事件流资源的 URL, 并在该对象上注册响应的 Javascript 事件监听器即可. // 示例代码 // 打开到流终点的 SSE 连接 var source = new EventSource(&quot;/path/to/stream-url&quot;) // 可选回调, 建立连接时调用 source.onopen = function () { ... } // 可选回调, 连接失败时调用 source.operrpr = function () { ... } // 监听 &quot;foo&quot; 事件, 调用自定义代码 source.addEventListener(&quot;foo&quot;, function (event) { processFoo(event.data); }) // 监听所有事件, 不明确指定事件类型. source.onmessage = function (event) { log_message(event.id, event.data); // 如果 服务器发送 &quot;CLOSE&quot; 消息 ID, 关闭 SSE 连接. if (event.id == &quot;CLOSE&quot;) { source.close(); } } EventSource 可以像常规 XHR 一样利用 CORS 许可及选择同意机制, 实现客户端到远程服务器的流式事件数据传输. 以上是 客户端API 的全部. 浏览器会帮我们处理一切: 协商建立连接, 接受并递增的解析数据, 标识消息范围, 最终触发 DOM 事件. 1.1.1.2 自动重连机制EventSource 接口能自动重新连接并跟踪最近接受的消息: 如果链接断开了, EventSource 会自动重新连接到服务器, 还可以向服务器发送上一次收到的消息 ID, 一遍服务器重传跌势的消失并恢复流. 浏览器如何确定每个消息的 ID, 类型 和 范围: 使用事件流协议. EventSource API 和 定义完善的数据格式, 密切协同, 使得浏览器中的应用完全不必理会底层数据协议. 1.1.2 Event Strema 协议SSE 事件流是以流式 HTTP 响应形式交付的: 客户端发起常规 HTTP 请求, 服务器以自定义的 “text/event-stream” 内容类型响应, 然后交付 UTF-8 编码的事件数据. =&gt; 请求 GET /stream HTTP/1.1 # 客户端通过 EventSource 接口发起连接 Host: example.com Accept: text/event-stream &lt;= 响应 HTTP/1.1 200 OK Connection: keep-alive Content-Type: text/event-stream # 服务器以 &quot;text/event-stream&quot; 内容类型响应 Transfer-Encoding: chunked retry: 15000 # 服务器设置连接中断后重新连接的时间间隔 data: First message is a simple string # 不带消息类型的简单文本事件 data: {&apos;message&apos;: &apos;JSON payload&apos;} # 不带消息类型的 JSON 数据载荷 evnet: foo # 类型为 foo 的简单文本事件 data: Message of type &quot;foo&quot; id: 42 # 带消息 ID 和类型的多行时间 event: bar data: Multi-line message of data: type &quot;bar&quot; and id &quot;42&quot; id: 43 # 带可选 ID 的简单文本事件 data: Last message, id &quot;43&quot; 以上事件流协议, 容易理解, 容易实现: 事件载荷就是一个或多个相邻 data 字段的值 事件可以带 ID 和 event 表示事件类型 事件边界用换行符标识 在接收端, EventSource API 通过检查换行分割符来解析到来的数据流, 从 data 字段中提取有效载荷, 检查可选的 ID 和类型, 最后再分派一个 DOM 事件告知应用. 如果存在某个类型, 那么就会触发自定义的 DOM 事件处理程序, 否则, 就会调动通用的 onmessage 回调. EventSource 不会对实际载荷进行任何额外处理, 从多个 data 字段中提取出的消息, 会被拼接起来直接交给应用. 因此, 服务器可以推送任何文本格式(字符串, JSON等), 应用必须自己解码. 所有事件源数据都是 UTF-8 编码的, SSE 不是传输 二进制载荷 而设计的, 但可以把二进制对象编码为 base64 格式, 然后使用 SSE, 但会导致很高(33%)的开销. SSE 连接本质上是 HTTP 流式响应, 因此响应时可以压缩的, 就跟压缩其他 HTTP 响应一样, 而且是动态压缩. 除了自动解析事件数据, SSE 还内置支持断线重连, 以及恢复客户端因断线而丢失的消息. 默认情况下, 如果连接中断, 浏览器会自动重新连接, SSE 规范建议间隔时间为 2~3 s, 这也是大多数浏览器采用的默认值. 服务器也可以设置一个自定义的时间间隔, 只要在推送任何消息时, 向客户端发送一个 retry 命令即可. 服务器还可以给每条消息关联任意 ID 字符串. 浏览器会自定记录最后一次收到的消息ID, 并在发送重连请求时自动在 HTTP 首部追加 Last-Event-ID 值. # 既有 SSE 连接 retry: 4500 // 服务器将客户端的重连事件设置为 4.5s id: 43 // 简单文本事件, ID 43 data: Lorem ipsum # 连接断开, 4500 ms 之后 =&gt; 请求 GET /stream HTTP/1.1 // 带 Last-Event-ID 的客户端重连请求. Host: example.com Accept: text/event-stream Last-Event-ID: 43 &lt;= 响应 HTTP/1.1 200 OK // 服务器响应. Content-Type: text/event-stream Connection: keep-alive Transfer-Encoding: chunked id: 44 // 简单文本事件, ID 44 data: dolor sit amet 浏览器负责重新连接和记录上一次事件 ID , 然后服务器根据应用的要求和数据流, 采取不同实现策略来恢复: 如果丢失消息可以接受, 就无需事件 ID 或特殊逻辑, 只要让客户端重连并恢复数据流即可. 如果必须恢复消息. 同样, 服务器也需要实现某种形式的本地缓存, 以便恢复并向客户端重传错过的数据. 1.2 特点 与局限 特点 通过一个长连接低延迟交付 高效的浏览器消息解析, 不会出现无限缓冲 自动跟踪最后看到的消息及自动重新连接. 消息通知在客户端以 DOM 事件形式呈现. 局限 只能从服务器向客户端发送数据, 不能满足需要请求流的场景. 事件流协议设计为只能传输 UTF-8 数据, 即使可以传输二进制数据, 效率也不高. SSE 在服务端和客户端都比较容易实现, 但网络中间设备如 代理, 防火墙等不支持 SSE, 因此, 中间设备可能会缓冲事件流数据, 导致额外延迟, 甚至彻底毁掉 SSE 链接, 可以考虑通过 TLS 发送 SSE 事件流. 2. flask-sse2.1 安装Server-sent event do not work with Flask’s built-in development server, because it handlers HTTP requests one at a time. The SSE stream is intended to be an infinite stream of events, so it will never complete. You must use a web server with asychronous workers, like gunicorn with gevent. You will also need a Redis server running locally for this example to work. $ pip install gunicorn flask flask-sse gevent 2.2 简单示例# cat sse.py from flask import Flask, render_template from flask_sse import sse app = Flask(__name__) app.config[&quot;REDIS_URL&quot;] = &quot;redis://localhost&quot; app.register_blueprint(sse, url_prefix=&quot;/stream&quot;) @app.route(&quot;/&quot;) def index(): return render_template(&apos;index.html&apos;) @app.route(&apos;/hello&apos;) def publish(&apos;/hello&apos;): sse.publish({&quot;message&quot;: &quot;Hello!&quot;}, type=&quot;greeting&quot;) return &quot;Message Sent!&quot; # cat templates/index.html &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt; Flask-SSE Quickstart &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Flash-SSE Quickstart&lt;/h1&gt; &lt;script&gt; var source = new EventSource(&quot;{{ url_for('sse.stream') }}&quot;) source.addEventListener(&apos;greeting&apos;, function(event){ var data = JSON.parse(event.data); alert(&quot;The Server Says: &quot; + data.message); }, false); source.addEventListener(&quot;error&quot;, function(event){ alert(&quot;Failed to connect to event stream.&quot;) }, false); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; # run code $ gunicorn sse:app --worker-class gevent --bind 127.0.0.1:8000 $ curl 127.0.0.1:8000 2.3 配置2.3.1 RedisIn order to use Flask-SSE , you need a Redis server to handle pubsub. Flask-SSE will search the application config for a Redis connection URL to use. It will try the following configuration values, in order: SSE_REDIS_URL REDIS_URL If it doesn’t find a Redis connection URL, Flask-SSE will raise a **KeyError any time a client tries to access the SSE stream. If the Redis server has a password: app.config[&quot;REDIS_URL&quot;] = &quot;redis://:password@localhost&quot; 2.3.2 应用服务器Flask-SSE does not work with Flask’s built-in development server, due to the nature of the server-sent events protocol. This protocol uses long-lived HTTP requests to push data from the server to the client, which means that an HTTP request to the event stream will effectively never complete. Flask’s built-in development server is single threaded, so it can only handle one HTTP request at a time. Once a client connects to the event stream, it will not be able to make any other HTTP requests to your site. Instead, you must use a web server with asychronous workers. Asynchronous workers allow one worker to continuously handle the long-lived HTTP request that server-sent events require, while other workers simultaneously handle other HTTP requests to the server. Gunicorn is an excellent choice for an application server, since it can work with gevent to use asychronous workers. 2.4 高级设置2.4.1 ChannelsSometimes, you may not want all events to be published to all clients. When publishing an event, you can select which channel to direct the event to. If you do , only clients that are checking that particular channel will receive the event. # this event will be sent to the `users.social` channel sse.publish({&apos;user&apos;: &quot;alice&quot;, &apos;status&apos;: &apos;Life is short, I use python&apos;}, channel=&quot;users.social&quot;) Channel names can be any string you want, and are created dynamically as soon as they are referenced. The default channel name that Flask-SSE uses is “sse”. To subscribe to a channel , the client only needs to be provide a channel query parameter when connecting to the event stream. # event stream is at /stream, and you channel is &quot;users.social&quot; the url is as follow: /stream?channel=users.social # url_for() function url_for(&quot;sse.stream&quot;, channel=&quot;users.social&quot;) By default, all channels are publicly accessible to all users. 2.4.2 Access ControlSince Flask-SSE is implemented as a blueprint, you can attach a before_request() handler to implement access control. @sse.before_request def check_access(): if request.args.get(&quot;channel&quot;) == &quot;analytucs&quot; and not g.user.is_admin(): abort(403) 3. AngularJS &amp; SSE]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Flask 扩展</tag>
        <tag>sse</tag>
        <tag>Server-Sent Event</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 扩展之--flask-socketio]]></title>
    <url>%2F2018%2F03%2F16%2FflaskExt--flask-socketio%2F</url>
    <content type="text"><![CDATA[WebSocket 可以实现客户端与服务器之间的双向的, 基于消息的文本或二进制数据传输. 其极简的 API 可以让我们在客户端和服务器之间以数据流的形式实现各种应用数据交换(包含JSON 及自定义的二进制消息格式). 自定义数据交换协议的问题通常也在于自定义, 因为应用必须考虑状态,压缩,缓存及其原来有浏览器提供的服务. 功能: 连接协商和同源策略 与既有HTTP基础设施的互操作 基于消息的通信和高效消息分帧 子协议协商及可扩展能力 WebSocket 由多个标准组成: WebSocket API 有 W3C 定义; WebSocket 协议(RFC 6455) 及其扩展由 IETF 定义 一. WebSocket 协议1. WebSocket API1.1 代码示例var ws = new WebSocket(&quot;wss://example.com/socket&quot;) // 建立安全的 ws 连接 ws.onerror = function(error) { ... } // 可选回调, 在连接出错时调用 ws.oncloes = function() { ... } // 可选回调, 在连接关闭时调用 ws.onopen = function () { // 可选回调, 在连接建立时调用 ws.send(&quot;Connection established, Hello Server!&quot;) // 客户端向服务器发送一条消息 } ws.onmessage = function(msg) { // 回调函数, 服务器每发送一条消息就调用一次. if (msg.data instanceof Blob) { // 判断接收到的消息是二进制还是文本处理. processBlob(msg.data) } else { processText(msg.data) } } 在选择 Socket.IO 这样的腻子脚本或”实时框架”时, 一定要留心其底层实现, 以及客户端和服务器的配置: 保证尽可能利用原生 WebSocket 接口以求最佳性能, 然后确保备用传输机制能满足你的性能要求. 1.2 WS 与 WSSWebSocket 资源 URL 采用了自定义模式: ws 表示 存文本 通信. wss 表示使用加密信道通信(TCP+TLS) 1.3 接收文本和二进制数据WebSocket 通信只涉及消息, 应用代码无需担心缓冲,解析,重建接收到的数据. 如 服务器发送一个 1MB 的净荷, 应用的 onmessage 回调只会在客户端接收到全部数据时才会被调用. WebSocket 协议不做格式假设, 对应用的净荷也没有后限制: 文本或者二进制数据都可以. 从内部看, 协议只关注消息的两个信息: 净荷长度(一个可变长度字段) 和 数据类型, 据以区别 UTF-8 数据和 二进制数据. 文本数据 : 浏览器会自动将其转换为 DOMString 对象. 二进制数据或 Blob 对象: 将其直接转交给应用. 或者 告诉浏览器把接收到的二进制数据转换成 ArrayBuffer 而非 Blob. var ws = new WebSocket(&apos;wss://example.com/socket&apos;); // 如果接收到二进制数据, 则强制转换为 ArrayBuffer. ws.binaryType = &quot;arraybuffer&quot;; ws.onmessage = function(msg) { if (msg.data instanceof ArrayBuffer) { processArrayBuffer(msg.data); } else { processText(msg.data); } } Blob 代表一个不可变的文件对象或者原始数据. 通常用于处理无需修改或者切分的数据块. ArrayBuffer 表示一个普通的,固定长度的二进制数据缓冲, 通常用于接受需要再次处理的二进制数据. 可以用 ArrayBuffer 创建一个或多个 ArrayBufferView 对喜爱那个, 每一个都可以通过特定的格式来展示缓冲中的内容. 所有二进制数据类型只是为了简化 API : 在传输中, 只通过一位 (bit) 即可将 WebSocket 帧标记为二进制或文本. 假如应用或服务器需要传输其他的内容类型, 就必须通过其他机制来沟通这个信息. 1.4 发送文本和二进制数据WebSocket 提供的是一个双向通信的信道, 即, 在同一个 TCP 连接上, 可以双向传输数据. var ws = new WebSocket(&quot;wss://example.com/socket&quot;) ws.open = function() { socket.send(&quot;hello server!&quot;); socket.send(JSON.stringify({&apos;msg&apos;: &apos;payload&apos;})); var buffer = new ArrayBuffer(128); socket.send(buffer); var intview = new Unit32Array(buffer): socket.send(intview) var blob = new Blob(buffer); socket.send(blob); } 这里 send() 方法是异步的: 提供的数据会在客户端排队, 而函数则立即返回. 特别是在传输大文件的时候, 千万别因为返回快, 就错误的以为数据已经发送出去了. 要监控在浏览器中排队的数据量, 可以查询套接字的 bufferdAmount 属性 var ws = new WebSocket(&quot;wss://example.com/socket&quot;) ws.onopen = function() { subscribeToApplicationUpodates(function(env) { if (ws.bufferedAmount == 0) ws.send(evt.data); }); }; 所有 WebSocket 消息都会按照他们在客户端排队的次序逐个发送. 因此, 大量排队的消息, 甚至一个大消息, 都可能导致排在他后面的消息延迟– 队首阻塞. 为解决该问题, 应用可以将大消息切分成小块, 通过监控bufferedAmount的值来避免队首阻塞. 甚至还可以实现自己的优先队列, 而不是盲目都把他们送到套接字上排队. 要实现最优化传输, 应用必须关心任意时刻在套接字上排队的是什么消息. 1.5 子协议协商1.5.1 子协议协商实现策略WebSocket 协议对每条消息的格式实现不做任何假设, 仅用一位标记消息是文本还是二进制, 以便客户端和服务器有效的解码数据, 除此之外的消息内容就是未知的. WebSocket 没有实现元数据沟通的机制, 如果需要沟通关于消息的元数据, 客户端和服务器必须达成沟通这一数据的子协议. 可以有以下实现方式: 客户端和服务器可以提前确定一种固定的消息格式.而 必要的元数据作为这种数据结构的一部分. 如果客户端和服务器要发送不同的数据类型, 那么他们可以确定一个双发都知道的消息首部, 利用它来沟通说明信息或有关净荷的其他解码信息. 混合使用文本和二进制消息, 可以沟通净荷和元数据, 比如用文本消息实现 HTTP 首部的功能, 后跟包含应用净荷的二进制消息. 1.5.2 子协议协商API客户端可以在初次链接握手时, 告诉服务器自己支持那种协议. var ws = new WebSocket(&apos;wss://example.com/socket&apos;, [&apos;appProtocol&apos;, &apos;appProtocol-v2&apos;]) // 在 WebSocket 握手期间发送子协议数组. ws.onopen = function () { if (ws.protocol == &quot;appProtocol-v2&quot;) { // 检查服务器选择了那个子协议 // ... } else { // ... } } 子协议有应用自己定义, 且在初次 HTTP 握手期间发送给服务器, 除此之外, 指定的子协议对核心 WebSocket API 不会有任何影响. 如果子协议协商成功, 会触发客户端的 onopen 回调, 应用可以查询 WebSocket 对象上的 protocol 属性, 从而得知服务器选定的协议. 另一方面, 服务器如果不支持客户端声明的任何一个协议, 则 WebSocket 握手时不完整的, 此时会触发 onerror 回调, 连接断开. 2. WebSocket 协议WebSocket 协议包含两个高层组件: 开放性 HTTP 握手 , 用于协商连接参数 二进制消息分帧, 用于支持低开销的基于消息的文本和二进制数据传输. WebSocket 协议尝试在既有 HTTP 基础设施中实现双向的 HTTP 通信, 因此, 也是用 HTTP 的 80 和 443 端口. WebSocket 协议是一个独立完善的协议, 可以在浏览器之外实现. 2.1 二进制分帧客户端和服务器 WebSocket 应用通过基于消息的 API 通信: 发送端提供任意 UTF-8 或二进制的净荷, 接收端整个消息可用时收到通知. 为此, WebSocket 使用了自定义的二进制分帧格式, 把每个应用消息切分成一个或多个帧, 发送到目的地之后再组装起来, 等接收到完整的消息后, 再通知接收端. 所有 WebSocket 通信都是通过交换帧实现的, 而帧将净荷视为不透明的应用数据块. 帧 : 最小的通信单位, 包含可变长度的帧首部和净荷部分, 净荷可能包含完整或部分应用消息. 是否把消息分帧由客户端和服务器实现决定. 消息, 一系列帧, 与应用消息对等. 每一帧的第一位(FIN), 表示当前帧是不是消息的最后一帧, 一条消息有可能只有对应一帧. 操作码(4位), 表示被传输帧的类型, 传输应用数据时 1 : 文本 2 : 二进制数据 连接有效性检查时 8 : 关闭 9 : 呼叫(ping) 10 : 回应(pong) 掩码位, 表示净荷是否有掩码(只适用于客户端发送给服务器的消息) 净荷长度, 有可可变长度字段表示 1 ~ 125 : 净荷长度 126 : 则接下来的 2 字节表示的 16 位无符号整数才是这一帧的长度 127 : 则接下来的 8 字节表示的 64 位无符号整数才是这一帧的长度 掩码键, 包含 32 位值, 用于给净荷加掩护 净荷包含应用数据, 如果客户端和服务器在建立连接时协商过, 也可以包含自定义的扩展数据. 2.2 协议扩展WebSocket 规范允许对协议进行扩展: 数据格式和 WebSocket 协议的语义可以通过新的操作码和数据字段扩展. 即, 允许客户端和服务器在基本的 WebSocket 分帧层之上实现更多的功能, 而无需应用代码介入或协作. 协议扩展: 多路复用扩展 : 可以将 WebSocket 的逻辑链接独立出来, 实现共享底层的 TCP 链接. 压缩扩展 : 为 WebSocket 协议添加了压缩功能. 2.3 HTTP 协议(握手)协商利用 HTTP 完成握手, 有多个好处: 让 WebSocket 与现有 HTTP 协议基础设置兼容. 让 WebSocket 可以运行在 80 或 443 端口. 可以重用并扩展 HTTP 的 Upgrade 流, 为其添加自定义的 WebSocket 首部, 已完成协商. 2.3.1 可用 HTTP 首部以下协商字段, 用于在客户端和服务器之间进行 HTTP Upgrade 并协商新的 WebSocket 连接 : Sec-WebSocket-Version : 客户端发送, 表示其使用的 WebSocket 协议版本(13 表示 RFC 6455). 如服务器不支持该版本, 则必须回应自己支持的版本. Sec-WebSocket-Key : 客户端发送, 自动生成的一个键, 作为一个对服务器的”挑战”, 以验证服务器支持的协议版本. Sec-WebSocket-Accept : 服务器响应, 包含 Sec-WebSocket-Key 的签名值, 证明他支持请求的协议版本. Sec-WebSocket-Protocol : 用于协商应用子协议: 客户端发送支持的协议列表, 服务器必须只回应一个协议名. Sec-WebSocket-Extensions : 用于 协商本次链接要使用的 WebSocket 扩展: 客户端发送支持的扩展, 服务器通过返回相同的首部, 确认自己支持一个或多个扩展. HTTP 协商示例: GET /socket HTTP/1.1 Host: thirdparty.com Origin: http://example.com Connection: Upgrade Upgrade: websocket // 请求升级到 WebSocket Sec-WebSocket-Version: 13 // 客户端使用的 WebSocket 协议版本 Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ== // 自动生成的键, 以验证服务器对协议的支持. Sec-WebSocket-Protocol: appProtocol, appProtocol-v2 // 可选的应用指定的子协议列表 Sec-WebSocket-Extensions: x-webkit-deflate-message,x-custom-extension // 可选的客户端支持的协议扩展列表. WebSocket 请求也必须遵守同源策略: 浏览器会自动在升级握手请求中追加 Origin 首部, 远程服务器可能使用 CORS 判断接受或拒绝跨源请求. 要完成握手, 服务器必须返回一个成功的 “Switching Protocols(切换协议)” 响应, 并确认选择了客户端发送的那个选项: HTTP/1.1 101 Switching Protocol // 101 响应确认升级到 websocket 协议. Upgrade: websocket Connection: Upgrade Acess-Control-Allow-Origin: http://example.com // CORS 首部表示选择同意跨源链接 Sec-WebSocket-Accept: s3pPLmBiTxaQ9kYGzzhZRbk+x0o // 签名的键值验证协议支持. Sec-WebSocket-Protocol: appProtocol-v2 // 服务器选择的应用子协议 Sec-WebSocket-Extensions: x-custom-extension // 服务器选择的 WebSocket 扩展. 所有兼容 RFC 6455 的 WebSocket 服务器都使用相同的算法计算客户端挑战的答案: 将 Sec-WebSocket-Key 的内容与标准定义的唯一的 GUID 字符串拼接起来, 计算出 SHA1 散列值, 结果是一个 base-64 编码的字符串, 将这个字符串发送给客户端即可. 握手成功后, 该连接就可以作为双向通信信道交换 WebSocket 消息, 客户端和服务器之间的通信有 WebSocket 协议接管. 3. 性能检查表 使用安全 WebSocket 密切关注 腻子脚本的性能 利用子协议协商确定应用协议 优化二进制净荷以最小化传输数据 考虑压缩 UTF-8 内容 设置正确的二进制类型以接受二进制净荷 监控客户端缓冲数据的量 切分应用消息以避免队首阻塞 合用的情况下, 利用其它传输机制. 二. Flask-socketio1. 初始化from flask import Flask, render_template from flask_socketio import SocketIO app = Flask(__name__) app.config[&quot;SECRET_KEY&quot;] = &apos;secret!&apos; socketio = SocketIO(app) if __name__ == &quot;__main__&quot;: socketio.run(app[,host=&quot;0.0.0.0&quot;]) The init_app() style of initialization is also supported. Note the way the web server is starded. The socketio.run() function encapsulates the start up of the web server and replaces the app.run() standard Flask development server start up. When the application is in debug mode the Werkzeug development server is still uead and configured properly inside socketio.run(). In production mode the eventlet web server is used if available , else the gevent web server is used. If eventlet and gevent are not installed , the Werkzeug development web server is used. client page: &lt;script type=&quot;text/javascript&quot; src=&quot;//cdnjs.cloudflare.com/ajax/libs/socket.io/1.3.6/socket.io.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt; var socket = io.connect(&apos;http://&apos; + document.domain + &apos;:&apos; + location.port); socket.on(&apos;connect&apos;, function() { socket.emit(&apos;my event&apos;, {data: &apos;I\&apos;m connected!&apos;}); }); &lt;/script&gt; 2. socketio handler function2.1 装饰器模式@socketio.on(&quot;my event&quot;) def handle_my_custom_event(json): print &quot;Reveived json: &quot; + str(json) 2.2 on_event() 方法def my_function_handler(data): pass socketio.on_event(&quot;my event&quot;, my_function_handler, namespace=&quot;/test&quot;) 3. 接受消息When using SocketIO, messages are received by both parties as events. On the client side Javascript callbacks are used. With Flask-SocketIO the server needs to register handlers for these events, similarly to how routes are hanled by view function. 3.1 unnamed events3.1.1 String date@socketio.on(&apos;message&apos;) def hanle_message(message): print &quot;Received message:&quot; + message 3.1.2 JSON data@socketio.on(&apos;json&apos;) def handle_json(json): print &quot;Received JSON:&quot; + str(JSON) 3.2 Custom Names eventsThe message data for these events can be string, byes, int, or JSON. @socketio.on(&quot;my event&quot;) def handle_my_custom_event(json): print &quot;Received json&quot;: str(json) # multiple arguments: @socketio.on(&quot;my event&quot;) def handle_my_custom_event(arg1,arg2,arg3): print &quot;Received args: &quot; + arg1 + arg2 + arg3 Names events are the most flexible , as they eliminate the need to include additional metadata to describe the message type. Event names connect, disconnect, message, json are special events generated by SocketIO. Any other event names are considered custom events. The connect and disconnect events are self-explanatory. The message event delivers a payload of type string, and the json and custom events deliver a JSON payload, in the form of a Python dictionary. 3.3 SocketIO namespacesNamespaces allow a client to open multiple connections to the server that are multiplexed on a single socket. When a namespace is not specified the events are attached to the default global namespace. 3.3.1 Decorator-Based NamespaceSocketIO namespace allow the client to multiplex several independent connections on the same physical socket: @socketio.on(&quot;my event&quot;, namespace=&quot;/test&quot;) def handle_my_custom_namespace_event(json): print &quot;Received json: &quot; + str(json) When a namespace is not specified a default global namespace with the name ‘/‘ is used. 3.3.2 Class-Based NamespacesThe events handlers that belong to a namespace cna be created as methods of a class. The flask_socketio.Namespace() is provided as a base class to create class-based namespaces: from flask_socketio import Namespace, emit class MyCustomNamespace(Namespace): def on_connect(self): pass def on_disconnect(self): pass def on_my_event(self, data): emit(&quot;my_response&quot;, data) socketio.on_namespace(MyCustomNamespace(&quot;/test&quot;)) 当使用基于类的名称空间时, 所有服务器收到的 events 都会被分发给 on_EVENT-NAME 的方法去处理. 没有该方法, 则该 events 被忽略. 因此, 在基于类的名称空间中,所有 evnet 的名称必须同时也是合法的方法名称. As a convenience to methods defied in a class-based namespace, the namespace instance includes versions of several of the methods in the flask_socketio.SocketIO class that default to the proper namespace when the namespace argument is not given. 如果一个 event 同时被 基于类的名称空间和 基于装饰器的名称空间 所定义, 则 基于装饰器的名称空间拥有更高的优先级. 3.4 return &amp;&amp; client callback functionClients may request an acknowledgement callback that confirm receipt of a message . Any values returned from the handler function will be passed to the client as arguments in the callbak function: @socketio.on(&quot;my event&quot;) def handle_my_custom_event(json): print &quot;received json: &quot; + str(json) return &quot;one&quot;, 2 In the above exampel, the client callback function will be invoked with two arguments, “one” and 2. If a handler function does not return any values, the client callback function will be invoked without arguments. 4. 发送消息SocketIO event handlers defined as shown in the previous section can send reply message to the connected client using the send() and emit() functions. send() : sends a standard message of string or JSON type to the client. emit() : sends a message under a custom event name. 4.1 working with unnamed and named events# 回音壁 from flask_socketio import send, emit @socketio.on(&quot;message&quot;) def handle_messgae(message): send(message) @socketio.on(&quot;json&quot;) def handle_json(json): send(json, json=True) @socketio.on(&quot;my event&quot;) def handle_my_event(json): emit(&quot;my response&quot;, json) 4.2 working with namespaces.By default send() and emit() use the namespace of the incoming message by default. A different namespace can be specified with the optional namespace argumenbt. @socketio.on(&quot;message&quot;) def handler_message(message): send(message, namespace=&quot;/chat&quot;) @socketio.on(&quot;my event&quot;) def handler_my_event(json): emit(&apos;my response&apos;, json, namespace=&quot;/chat&quot;) # emit with multiple arguments, send a tuple @socketio.on(&quot;my event&quot;) def handle_my_event(json): emit(&quot;my response&quot;, (&apos;foo&apos;, &apos;bar&apos;, json), namespace=&quot;/chat&quot;) 4.3 acknowledgement callbackSockIO supports acknowledgement callbacks that confirm that a message war received by the client. def ack(): print &quot;Message war receiverd&quot; @socketio.on(&quot;my event&quot;) def handle_my_custom_event(json): emit(&quot;My response&quot;, json, callback=ack) When using callbacks the Javascript client receives a callback function to invoke upon receipt of the message. After the client application invokes the callback function the server invokes the corresponding server-side callback. If the client-side callback returns any values, these are provided as arguments to servier-side callback. The client application can also request an acknoledgement callback for an event sent to the server. If the server wants to provide arguments for this callback, it must return them from the event handler function: @socketio.on(&quot;My event&quot;) def handle_my_custom_event(json): # ... handle the event # client callback will reveive these 3 arguments. return &apos;foo&apos;,&apos;bar&apos;, 123 5. 广播: BroadcastingFlask-SocketIO supports broadcasting with the broadcast=True optional argument to send() and emit() @socketio.on(&quot;my event&quot;) def handle_my_custom_event(data): emit(&quot;my response&quot;, data, broadcast=True) When a message is sent with the broadcast option enabled, all clients connected to the namespace receive it, including the sender. When namespaces are not used, the clients connected to the global namespace receive the message. Note that callbacks are not invoked for broadcast message. In some scenes, the server needs to be the originator of a messag. This can be useful to send notifications to client of events that originated in the server, for example in a background thread. The socketio.send() and socketio.emit() methods can be used to broadcast to all connected clients: def some_function(): socketio.emit(&quot;Some event&quot;, {&apos;data&apos;: 42}) Note that socketio.send() and socketio.emit() are not the same functions as the context-aware send() and emit() 6. RoomsFor many applications it is necessary to group users into subsets that can be addressed together. Flask-SocketIO supports this concept of rooms through the join_room() and leave_room() functions. from flask_socketio import join_room, leave_room @socketio.on(&quot;join&quot;) def on_join(data): username = data[&quot;username&quot;] room = data[&quot;room&quot;] join_room(room) send(username + &quot; has entered the room.&quot;, room=room) @socketio.on(&quot;leave&quot;) def on_leave(data): username = data[&quot;username&quot;] room = data[&quot;room&quot;] leave_room(room) send(username + &quot; has left the room.&quot;, room=room) The send() and emit() functions accept an optional room argument that cause the message to be send to all clients that are in the given room. All client are assigned a room when they connect , nameed with the session ID of the connection, which can be obtained from request.sid. A givent client can join any rooms, which can be given any names. When a client disconnects it is removed from all the rooms it was in. The context-free socketio.send() and socketio.emit() functions also accept a room argument to broadcast to all clients in a room. Since all clients are assigned a personal room, to address a message to a single client, the session ID of the client can be used as the room argument. 7. Connection EventsFlask-SocketIO also dispatches connection and disconnection events. @socket.on(&apos;connect&apos;, namespace=&quot;/chat&quot;) def test_connect(): emit(&quot;my response&quot;, {&apos;data&apos;: 42}) @socketio.on(&quot;disconnect&quot;, namespace=&quot;/chat&quot;) def test_disconnect(): print &quot;Client disconnected.&quot; The connection event handler can optionally return False to reject the connection. This is so that the client can be authenticated at this point. Note that connection and disconnection events are sent individually on each namespace used. 8. Error HandlingFlask-SocketIO can also deal with exceptions. Error handler functions take the exception object as an argument. # handles the default namespace @socketio.on_error() def error_handler(e): pass # handler the &apos;/chat&apos; namespace @socketio.on_error(&quot;/chat&quot;) def error_handler_chat(e): pass # handlers all namespace without an sxplicit error handler @socketio.on_error_default def default_error_handler(e): pass The message and data arguments of the current request can also be inspected with the request.event variables, which is useful for error logging and debugging outside the event handler. from flask import request @socketio.on(&quot;my error event&quot;) def on_my_event(data): raise RuntimeError() @socketio.on_error_default def default_error_default(e): print request.event[&quot;message&quot;] # my error event print request.event[&quot;args&quot;] # (data, ) 9. Access to Flask’s Context GlobalsAll SocketIO events generatred for a client occur in the context of a single long running request. Flask-SocketIO 上下文变量与 常规 HTTP 上下文异同 An application context is pushed before invoking an event handler making current_app and g available to the handler. A request context is also pushed before invoking a handler, also making request and session available. But note that WebSocket events do not have individual requests associated with them, so the request context that started the connection is pushed for all the events that are dispatched during the life of the connection. request.sid is set to a unique session ID for the connection. This value is used as an initial room where the client is added. request.namespace contain the currently handled namespace. request.event contain the event arguments , which is a dict with message and args keys. The session context global behaves in a different way than in regular requests. A copy of the user session at the time the SocketIO connettion is established is made available to handlers invoke in the context oif that connection. If a SocketIO handler modifies the session , the modified session will be preserved for future SocketIO handlers, but regular HTTP route handlers will not see these changes. Effectively, when a SocketIO handler modifies the session , a fork of the session is created exclusively for these handlers. The technical reason for this limitation is that to save the user session a cookie needs to be sent to the client, and that requires HTTP request and response, which do not exist in a SocketIO connection. When using server-side sessions such as those provieded by the Flask-Session or Flask-KVSession extensions, changes make to the session in HTTP route handlers can be seen by SocketIO handlers , as long as the session is not modified in the SocketIO handlers. the before_request and after_request hooks are not invoked for SocketIO event handlers. SocketIO handlers can take custom decorators , but most Flask decorators will not be appropriate to use for a SocketIO handler, givent that there is no concept of a Response object during a SocketIO connection. 10. AuthenticationIn most cases it is more convenient to perform the traditional authentication process(using web form and HTTP requests) before the SocketIO connection is established . The user’s identify can then be recorded in the user session or in a cookie, and later when the SocketIO connettin is established that informatin will be accessible to SocketIO event handlers. 10.1 Using Flask-Login with Flask-SocketIOFlask-SocketIO can access login information maintained by Flask-Login . After a regular Flask-Login authentication is performed and the login_user() function is called to record the user in the user session, any SocketIO connections will have access to the current_user context variable: @socketio.on(&apos;connect&apos;) def connect_handler(): if current_user.is_authenticated: emit(&quot;My response&quot;, {&apos;message&apos;: &quot;{0} has joined&quot;.format(current_user.name)}, broadcast=True) else: return False # not allowed here Note that the login_required decorator cannot be used with SocketIO event handlers, but a custom decorator that disconnects non-authticated users can be created as follow: import functools from flask import request from flask_login import current_user from flask_socketio import disconnect def authenticated_only(f): @functools.wraps(f) def wrapped(*args, **kwargs): if not current_user.is_authenticated: disconnect() else: return f(*args, **kwargs) return wrapped @socketio.on(&apos;my event&apos;) @authenticated_only def handle_my_custom_event(data): emit(&quot;my response&quot;, {&apos;message&apos;: &quot;{0} has joined&quot;.format(current_user.name)}, broadcast=True) 11. Deployment11.1 Embedded ServerThe simplest deployment strategy is to have eventlet or gevent installed, and start the web server by calling socketio.run(app) as shown in examples above. This will run the application on the eventlet or gevent web servers, whichever is installed. Note that socketio.run(app) runs a production ready server when eventlet or gevent are installed. If neither of these are installed, then the application runs on Flask’s development web server, which is not appropriate for production use. Unfortunately this option is not available when using gevent with uWSGI. See the uWSGI section below for information on this option. 11.2 Gunicorn Web Servermodule is the Python module or package that defines the application instance, and app is the application instance itself. # start eventlet server via gunicorn $ gunicorn --worker-class eventlet -w 1 module:app # use gevent $ gunicorn -k gevent -w 1 module:app 11.3 uWSGI Web ServerWhen using the uWSGI server in combination with gevent , the SocketIO server can take advantage if uWSGI’s native WebSocket support. $ uwsgi --http :5000 --gevent 1000 --http-websockets --master --wsgi-file app.py --callable app 11.4 Using nginx as a WebSocket Reverse ProxyOnly releases of nginx 1.4 and newer support proxying of the WebSocket protocol. # single WebSocket service server { listen 80; server_name _; locatioin / { include proxy_params; proxy_pass http://127.0.0.1:5000; } location /socket.io { include proxy_params; proxy_http_version 1.1; proxy_buffering off; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;Upgrade&quot;; proxy_pass http://127.0.0.1:5000/socket.io; } } # multi WebSocket service upstream socketio_nodes { ip_hash; server 127.0.0.1:5000; server 127.0.0.1:5001; server 127.0.0.1:5002; # to scale the app, just add more nodes here! } server { listen 80; server_name _; location / { include proxy_params; proxy_pass http://127.0.0.1:5000; } location /socket.io { include proxy_params; proxy_http_version 1.1; proxy_buffering off; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;Upgrade&quot;; proxy_pass http://socketio_nodes/socket.io; } } 11.5 Using Multiple WorkersFlask-SocketIO supports multiple workers behind a load balancer starting with release 2.0. Deploying multiple workers gives applications that use Flask-SocketIO the ability to spread the client connections among multiple processes and hosts, and in this way scale to support very large numbers of concurrent clients. Requirements The LB must be configured to forward all HTTP request from a given client always to the worker. This is sometimes referenced as sticky sessions. For nginx , use the ip_hash directive to archieve this. Gunicorn cannot be used with multiple workers because its LB algorithm does not support sticky session. $ pip install redis Since each of the servers owns only a subset of the client connections , a message queue such as Redis or RabbitMQ is used by the servers to coordinate complex operations such as broadcasting and rooms. $ pip install kombu If eventlet or gevent are used , then monkey patching the Python standard library is normally required to force the message queue package to use coroutine friendly functions and classes. Useage socketio = SocketIO(app, message_queue=&apos;redis://&apos;) 11.6 Emitting from an External ProcessFor many types of applications, it is necessary to emit events from a process that is not the SocketIO server, for a example a Celery worker. If the SocketIO server or servers are configured to listen on a message queue as shown in the previous section, then any other process can create its own SocketIO instance and use it to emit events in the same way the server does. For example, for an application that runs on an eventlet web server and uses a Redis message queue, the following Python script broadcasts an event to all clients: socketio = SocketIO(message_queue=&apos;redis://&apos;) socketio.emit(&apos;my event&apos;, {&apos;data&apos;: &apos;foo&apos;}, namespace=&apos;/test&apos;) When using the SocketIO instance in this way, the Flask application instance is not passed to the constructor. The channel argument to SocketIO can be used to select a specific channel of communication through the message queue. Using a custom channel name is necessary when there are multiple independent SocketIO services sharing the same queue. Flask-SocketIO does not apply monkey patching when eventlet or gevent are used. But when working with a message queue, it is very likely that the Python package that talks to the message queue service will hang if the Python standard library is not monkey patched. It is important to note that an external process that wants to connect to a SocketIO server does not need to use eventlet or gevent like the main server. Having a server use a coroutine framework, while an external process does not is not a problem. For example, Celery workers do not need to be configured to use eventlet or gevent just because the main server does. But if your external process does use a coroutine framework for whatever reason, then monkey patching is likely required, so that the message queue accesses coroutine friendly functions and classes.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Flask 扩展</tag>
        <tag>socketio</tag>
        <tag>websocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-pyecharts-文档笔记]]></title>
    <url>%2F2018%2F03%2F16%2Fpython-pyecharts-%E6%96%87%E6%A1%A3%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[pyecharts 项目地址 https://github.com/chenjiandongx/pyecharts pyecharts 文档地址 https://github.com/chenjiandongx/pyecharts/blob/master/document/zh-cn/documentation.mdhttps://github.com/chenjiandongx/pyecharts/blob/master/example.mdhttps://github.com/chenjiandongx/pyecharts/blob/master/document/zh-cn/doc_flask.md 1. 安装$ pip install pyecharts 1.1 简单使用降水量与蒸发量柱状图 attr = [&quot;{} 月&quot;.format(i) for i in range(1,13)] v1 = [2.0,4.9,7.0,23.2,25.6,76.7,135.6,162.1,32.6,20.0,6.4,3.3] v2 = [2.6,5.9,9.0,26.2,28.6,70.7,175.6,182.1,48.6,18.0,6.4,2.3] bar = Bar(&quot;降水量与蒸发量&quot;) bar.add(&apos;蒸发量&apos; ,attr, v1, mark_line=[&apos;average&apos;], mark_point=[&quot;max&quot;,&quot;min&quot;]) bar.add(&apos;降水量&apos; ,attr, v2, mark_line=[&apos;average&apos;], mark_point=[&quot;max&quot;,&quot;min&quot;]) bar.render(&apos;./rain.html&apos;) 饼图 - 玫瑰图 from pyecharts import Pie attr = [&quot;衬衫&quot;, &quot;羊毛衫&quot;,&quot;雪纺衫&quot;, &quot;裤子&quot;, &quot;高跟鞋&quot;,&quot;袜子&quot;] v1 = [11,12,13,10,10,10] v2 = [19,21,32,20,20,33] pie = Pie(&quot;饼图-玫瑰图示例&quot;, title_pos=&quot;center&quot;, width=1200) pie.add(&quot;商品A&quot;, attr, v1, center=[25,50], is_random=True, radius=[30,75], rosetype=&quot;radius&quot;) pie.add(&quot;商品B&quot;, attr,v2, center=[75,50], is_random=True, radius=[30,75], rosetype=&quot;area&quot;, is_legend_show=False,is_label_show=True) pie.render(&apos;./rose.html&apos;) 图标嵌套与叠加 from pyecharts import Bar,Line,Overlap attr = [&apos;A&apos;, &quot;B&quot;,&quot;C&quot;,&apos;D&apos;,&apos;E&apos;,&apos;F&apos;] v1 = [10,20,30,40,50,60] v2 = [38,28,58,48,78,68] bar = Bar(&quot;Line-Bar Example&quot;) bar.add(&apos;bar&apos;,attr,v1) line =Line() line.add(&apos;line&apos;,attr,v2) overlap = Overlap() overlap.add(bar) overlap.add(line) overlap.render(&apos;./overlap.html&apos;) 2. 基本使用2.1 基本套路基本上所有的图标类型都可使用如下的套路去绘制: chart_name = Type() : 初始化具体类型图表 add() : 添加数据及配置项 render() : 生成 html 文件. from pyecharts import Bar bar = Bar(“My First Bar”, “Second Title Here”) bar.add(“服装”, [“衬衫”, “羊毛衫”, “雪纺衫”, “裤子”, “高跟鞋”, “袜子”], [5, 20, 36, 10, 75, 90]) bar.show_config() bar.render() bar.render_embed() Bar.add() # 主要方法, 用于添加图表的数据和设置各种配置项. add() 的数据一般为两个列表(长度一致), 如果数据是字典或者带元组的字典, 可使用 cast() 方法转换. cast() : 转换数据序列, 将带字典和元组类型的序列转换为 k_lst, v_lst 两个列表. 如下示例: 元组列表[(A1, B1), (A2, B2), (A3, B3), (A4, B4)] –&gt; k_lst[ A[i1, i2...] ], v_lst[ B[i1, i2...] ] 字典列表[{A1: B1}, {A2: B2}, {A3: B3}, {A4: B4}] –&gt; k_lst[ A[i1, i2...] ], v_lst[ B[i1, i2...] ] 字典{A1: B1, A2: B2, A3: B3, A4: B4} – &gt; k_lst[ A[i1, i2...] ], v_lst[ B[i1, i2...] ] Bar.show_config() # 打印输出图表的所有配置项 Bar.render(“/path/to/myrender.html”) # 默认在当前目录下, 生成一个 render.html 文件, 支持 path 参数. 文件可用浏览器打开; Bar.render_embed() # 生成 html 内嵌的 script 代码. 2.2 图表类初始化接受的参数(所有类型的图表都一样) title -&gt; str 主标题文本，支持 \n 换行，默认为 “” subtitle -&gt; str 副标题文本，支持 \n 换行，默认为 “” width -&gt; int 画布宽度，默认为 800（px） height -&gt; int 画布高度，默认为 400（px） title_pos -&gt; str/int 标题距离左侧距离，默认为’left’，有&#39;auto&#39;, &#39;left&#39;, &#39;right&#39;, &#39;center&#39;可选，也可为百分比或整数 title_top -&gt; str/int 标题距离顶部距离，默认为’top’，有&#39;top&#39;, &#39;middle&#39;, &#39;bottom&#39;可选，也可为百分比或整数 title_color -&gt; str 主标题文本颜色，默认为 ‘#000’ subtitle_color -&gt; str 副标题文本颜色，默认为 ‘#aaa’ title_text_size -&gt; int 主标题文本字体大小，默认为 18 subtitle_text_size -&gt; int 副标题文本字体大小，默认为 12 background_color -&gt; str 画布背景颜色，默认为 ‘#fff’ is_grid -&gt; bool 是否使用 grid 组件，grid 组件用于并行显示图表。 具体实现参见 用户自定义. 2.3 通用配置项(均在 add() 中设置)2.3.1 xyAxis: 直角坐标系中的 x, y 轴(Line, Bar, Scatter, EffectScatter, Kline) is_convert -&gt; bool 是否交换 x 轴与 y 轴 is_xaxislabel_align -&gt; bool x 轴刻度线和标签是否对齐，默认为 False is_yaxislabel_align -&gt; bool y 轴刻度线和标签是否对齐，默认为 False x_axis -&gt; list x 轴数据项 xaxis_interval -&gt; int x 轴刻度标签的显示间隔，在类目轴中有效。默认会采用标签不重叠的策略间隔显示标签。设置成 0 强制显示所有标签。设置为 1，表示『隔一个标签显示一个标签』，如果值为 2，表示隔两个标签显示一个标签，以此类推 xaxis_margin -&gt; int x 轴刻度标签与轴线之间的距离。默认为 8 xaxis_name -&gt; str x 轴名称 xaxis_name_size -&gt; int x 轴名称体大小，默认为 14 xaxis_name_gap -&gt; int x 轴名称与轴线之间的距离，默认为 25 xaxis_name_pos -&gt; str x 轴名称位置，有’start’，’middle’，’end’可选 xaxis_min -&gt; int/float x 坐标轴刻度最小值，默认为自适应。 xaxis_max -&gt; int/float x 坐标轴刻度最大值，默认为自适应。 xaxis_type -&gt; str x 坐标轴类型‘value’：数值轴，适用于连续数据。‘category’：类目轴，适用于离散的类目数据，为该类型时必须通过 data 设置类目数据。‘time’：时间轴，适用于连续的时序数据，与数值轴相比时间轴带有时间的格式化，在刻度计算上也有所不同，例如会根据跨度的范围来决定使用月，星期，日还是小时范围的刻度。‘log’：对数轴。适用于对数数据。 xaxis_rotate -&gt; int x 轴刻度标签旋转的角度，在类目轴的类目标签显示不下的时候可以通过旋转防止标签之间重叠。默认为 0，即不旋转。旋转的角度从 -90 度到 90 度。 y_axis -&gt; list y 坐标轴数据 yaxis_interval -&gt; int y 轴刻度标签的显示间隔，在类目轴中有效。默认会采用标签不重叠的策略间隔显示标签。设置成 0 强制显示所有标签。设置为 1，表示『隔一个标签显示一个标签』，如果值为 2，表示隔两个标签显示一个标签，以此类推 yaxis_margin -&gt; int y 轴刻度标签与轴线之间的距离。默认为 8 yaxis_formatter -&gt; str y 轴标签格式器，如 ‘天’，则 y 轴的标签为数据加’天’(3 天，4 天),默认为 “” yaxis_name -&gt; str y 轴名称 yaxis_name_size -&gt; int y 轴名称体大小，默认为 14 yaxis_name_gap -&gt; int y 轴名称与轴线之间的距离，默认为 25 yaxis_name_pos -&gt; str y 轴名称位置，有’start’, ‘middle’，’end’可选 yaxis_min -&gt; int/float y 坐标轴刻度最小值，默认为自适应。 yaxis_max -&gt; int/float y 坐标轴刻度最大值，默认为自适应。 yaxis_type -&gt; str y 坐标轴类型‘value’：数值轴，适用于连续数据。‘category’：类目轴，适用于离散的类目数据，为该类型时必须通过 data 设置类目数据。‘time’：时间轴，适用于连续的时序数据，与数值轴相比时间轴带有时间的格式化，在刻度计算上也有所不同，例如会根据跨度的范围来决定使用月，星期，日还是小时范围的刻度。‘log’：对数轴。适用于对数数据。 yaxis_rotate -&gt; int y 轴刻度标签旋转的角度，在类目轴的类目标签显示不下的时候可以通过旋转防止标签之间重叠。默认为 0，即不旋转。旋转的角度从 -90 度到 90 度。 2.3.2 dataZoom: dataZoome 组件用于区域缩放, 从而能自由关注细节的数据信息, 或者概览数据整体, 或者去除离群点的影响, (Line, Bar, Scatter, EffectScatter, Kline ) is_datazoom_show -&gt; bool 是否使用区域缩放组件，默认为 False datazoom_type -&gt; str 区域缩放组件类型，默认为’slider’，有’slider’, ‘inside’可选 datazoom_range -&gt; list 区域缩放的范围，默认为[50, 100] datazoom_orient -&gt; str datazomm 组件在直角坐标系中的方向，默认为 ‘horizontal’，效果显示在 x 轴。如若设置为 ‘vertical’ 的话效果显示在 y 轴。 2.3.3 legend: 图例组件. 图例组件展现了不同系列的标记(Symbol), 颜色和名字. 可以通过点击图例控制那些系列不显示. is_legend_show -&gt; bool 是否显示顶端图例，默认为 True legend_orient -&gt; str 图例列表的布局朝向，默认为’horizontal’，有’horizontal’, ‘vertical’可选 legend_pos -&gt; str 图例组件离容器左侧的距离，默认为’center’，有’left’, ‘center’, ‘right’可选 legend_top -&gt; str 图例组件离容器上侧的距离，默认为’top’，有’top’, ‘center’, ‘bottom’可选 legend_selectedmode -&gt; str/bool 图例选择的模式，控制是否可以通过点击图例改变系列的显示状态。默认为’multiple’，可以设成 ‘single’ 或者 ‘multiple’ 使用单选或者多选模式。也可以设置为 False 关闭显示状态。 2.3.4 label: 图形上的文本标签, 可用于说明图形的一些数据信息, 如值,名称等. is_label_show -&gt; bool 是否正常显示标签，默认不显示。标签即各点的数据项信息 is_emphasis -&gt; bool 是否高亮显示标签，默认显示。高亮标签即选中数据时显示的信息项。 label_pos -&gt; str 标签的位置，Bar 图默认为’top’。有’top’, ‘left’, ‘right’, ‘bottom’, ‘inside’,’outside’可选 label_text_color -&gt; str 标签字体颜色，默认为 “#000” label_text_size -&gt; int 标签字体大小，默认为 12 is_random -&gt; bool 是否随机排列颜色列表，默认为 False is_random 可随机打乱图例颜色列表，算是切换风格 label_color -&gt; list 自定义标签颜色。全局颜色列表，所有图表的图例颜色均在这里修改。如 Bar 的柱状颜色，Line 的线条颜色等等。 formatter -&gt; list 标签内容格式器，有’series’, ‘name’, ‘value’, ‘percent’可选。如 [“name”, “value”] series：图例名称 name：数据项名称 value：数据项值 percent：数据的百分比（主要用于饼图） 2.3.5 lineStyle : 带线图形的线的风格选项, (Line, Polar, Radar, Graph, Parallel) line_width -&gt; int 线的宽度，默认为 1 line_opacity -&gt; float 线的透明度，0 为完全透明，1 为完全不透明。默认为 1 line_curve -&gt; float 线的弯曲程度，0 为完全不弯曲，1 为最弯曲。默认为 0 line_type -&gt; str 线的类型，有’solid’, ‘dashed’, ‘dotted’可选。默认为’solid’ 2.3.6 grib3D : 3D 笛卡尔坐标系组配置项, 适用于 3D 图形. (Bar3D, Line3D, Scatter3D) grid3D_width -&gt; int 三维笛卡尔坐标系组件在三维场景中的高度。默认为 100 grid3D_height -&gt; int 三维笛卡尔坐标系组件在三维场景中的高度。默认为 100 grid3D_depth -&gt; int 三维笛卡尔坐标系组件在三维场景中的高度。默认为 100 is_grid3D_rotate -&gt; bool 是否开启视角绕物体的自动旋转查看。默认为 False grid3D_rotate_speed -&gt; int 物体自传的速度。单位为角度 / 秒，默认为 10 ，也就是 36 秒转一圈。 grid3D_rotate_sensitivity -&gt; int 旋转操作的灵敏度，值越大越灵敏。默认为 1, 设置为 0 后无法旋转。 2.3.7 axis3D : 3D 笛卡尔坐标系 X,Y,Z 轴配置项.2.3.7.1 X轴 xaxis3d_name -&gt; str x 轴名称，默认为 “” xaxis3d_name_size -&gt; int x 轴名称体大小，默认为 16 xaxis3d_name_gap -&gt; int x 轴名称与轴线之间的距离，默认为 25 xaxis3d_min -&gt; int/float x 坐标轴刻度最小值，默认为自适应。 xaxis3d_max -&gt; int/float x 坐标轴刻度最大值，默认为自适应。 xaxis3d_interval -&gt; int x 轴刻度标签的显示间隔，在类目轴中有效。默认会采用标签不重叠的策略间隔显示标签。 设置为 0, 强制显示所有标签。 设置为 1，表示『隔一个标签显示一个标签』， 设置为 2，表示隔两个标签显示一个标签， 以此类推 xaxis3d_margin -&gt; int x 轴刻度标签与轴线之间的距离。默认为 8 2.3.7.2 Y轴 yaxis3d_name -&gt; str y 轴名称，默认为 “” yaxis3d_name_size -&gt; int y 轴名称体大小，默认为 16 yaxis3d_name_gap -&gt; int y 轴名称与轴线之间的距离，默认为 25 yaxis3d_min -&gt; int/float y 坐标轴刻度最小值，默认为自适应。 yaxis3d_max -&gt; int/float y 坐标轴刻度最大值，默认为自适应。 yaxis3d_interval -&gt; int y 轴刻度标签的显示间隔，在类目轴中有效。默认会采用标签不重叠的策略间隔显示标签。 设置为 0, 强制显示所有标签。 设置为 1，表示『隔一个标签显示一个标签』， 设置为 2，表示隔两个标签显示一个标签， 以此类推 yaxis3d_margin -&gt; int y 轴刻度标签与轴线之间的距离。默认为 8 2.3.7.3 Z轴 zaxis3d_name -&gt; str z 轴名称，默认为 “” zaxis3d_name_size -&gt; int z 轴名称体大小，默认为 16 zaxis3d_name_gap -&gt; int z 轴名称与轴线之间的距离，默认为 25 zaxis3d_min -&gt; int/float z 坐标轴刻度最小值，默认为自适应。 zaxis3d_max -&gt; int/float z 坐标轴刻度最大值，默认为自适应。 zaxis3d_margin -&gt; int z 轴刻度标签与轴线之间的距离。默认为 8 2.3.8 visualMap : 是视觉映射组件, 用于进行 视觉编码, 也就是将数据映射视觉元素(视觉通道) is_visualmap -&gt; bool 是否使用视觉映射组件 visual_type -&gt; str 制定组件映射方式，默认为’color‘，即通过颜色来映射数值。有’color’, ‘size’可选。’szie’通过数值点的大小，也就是图形点的大小来映射数值。 visual_range -&gt; list 指定组件的允许的最小值与最大值。默认为 [0, 100] visual_text_color -&gt; list 两端文本颜色。 visual_range_text -&gt; list 两端文本。默认为 [‘low’, ‘hight’] visual_range_color -&gt; list 过渡颜色。默认为 [‘#50a3ba’, ‘#eac763’, ‘#d94e5d’] visual_range_size -&gt; list 数值映射的范围，也就是图形点大小的范围。默认为 [20, 50] visual_orient -&gt; str visualMap 组件条的方向，默认为’vertical’，有’vertical’, ‘horizontal’可选。 visual_pos -&gt; str/int visualmap 组件条距离左侧的位置，默认为’left’。有’right’, ‘center’, ‘right’可选，也可为百分数或整数。 visual_top -&gt; str/int visualmap 组件条距离顶部的位置，默认为’top’。有’top’, ‘center’, ‘bottom’可选，也可为百分数或整数。 is_calculable -&gt; bool 是否显示拖拽用的手柄（手柄能拖拽调整选中范围）。默认为 True 2.2 Python2 的编码问题#!/usr/bin/python #coding=utf-8 # 通知编辑器, 使用 UTF-8 编码, from __future__ import unicode_literals # 告知 python 解释器, 所有字符均是 UTF-8 编码 3. Bar (柱状图/条形图)全局配置项要在最后一个 add() 上设置，否侧设置会被冲刷掉。 3.1 Bar 数据堆叠Bar.add(name, x_axis, y_axis, is_stack=False, **kwargs) name –&gt; str 图例名称 x_axis –&gt; list x 坐标轴数据 y_axis –&gt; list y 坐标轴数据 is_stack –&gt; bool 数据堆叠, 同个类目轴上系列配置相同的 stack 值可以堆叠放置. 数据堆叠示例 from pyecharts import Bar attr = [&quot;衬衫&quot;, &quot;羊毛衫&quot;, &quot;雪纺衫&quot;, &quot;裤子&quot;, &quot;高跟鞋&quot;, &quot;袜子&quot;] v1 = [5, 20, 36, 10, 75, 90] v2 = [10, 25, 8, 60, 20, 80] bar = Bar(&quot;柱状图数据堆叠示例&quot;) bar.add(&quot;商家A&quot;, attr, v1, is_stack=True) bar.add(&quot;商家B&quot;, attr, v2, is_stack=True) bar.render() 3.2 标记线和标记点可选项: mark_point -&gt; list 标记点，有’min’, ‘max’, ‘average’可选 mark_line -&gt; list 标记线，有’min’, ‘max’, ‘average’可选 mark_point_symbol -&gt; str 标记点图形，，默认为’pin’，有’circle’, ‘rect’, ‘roundRect’, ‘triangle’, ‘diamond’, ‘pin’, ‘arrow’可选 mark_point_symbolsize -&gt; int 标记点图形大小，默认为 50 mark_point_textcolor -&gt; str 标记点字体颜色，默认为’#fff’ 代码示例: from pyecharts import Bar bar = Bar(&quot;标记线和标记点示例&quot;) bar.add(&quot;商家A&quot;, attr, v1, mark_point=[&quot;average&quot;]) bar.add(&quot;商家B&quot;, attr, v2, mark_line=[&quot;min&quot;, &quot;max&quot;]) bar.render() 3.3 X 轴和 Y 轴交换bar = Bar(&quot;X 轴和Y轴交换&quot;) bar.add(&quot;商家A&quot;, attr, v1) bar.add(&quot;商家B&quot;, attr, v2, is_convert=True) bar.render(&quot;bar_xy_exchange.html&quot;) 3.4 Bar - datazoomdatazoom 适合所有平面直角坐标系图形，也就是(Line、Bar、Scatter、EffectScatter、Kline) 3.4.1 slide 类型import random attr = [&quot;{}天&quot;.format(i) for i in range(30)] v1 = [random.randint(1, 30) for _ in range(30)] bar = Bar(&quot;Bar - datazoom - slider 示例&quot;) bar.add(&quot;&quot;, attr, v1, is_label_show=True, is_datazoom_show=True) bar.render() 3.4.2 inside 类型attr = [&quot;{}天&quot;.format(i) for i in range(30)] v1 = [random.randint(1, 30) for _ in range(30)] bar = Bar(&quot;Bar - datazoom - inside 示例&quot;) bar.add(&quot;&quot;, attr, v1, is_datazoom_show=True, datazoom_type=&apos;inside&apos;, datazoom_range=[10, 25]) bar.show_config() bar.render() 3.4.3 坐标轴标签旋转当 x 轴或 y 轴由的标签因为过于密集而导致全部显示出来会重叠时, 可采用使 标签旋转的方法. attr = [&quot;{}天&quot;.format(i) for i in range(20)] v1 = [random.randint(1, 20) for _ in range(20)] bar = Bar(&quot;坐标轴标签旋转示例&quot;) bar.add(&quot;&quot;, attr, v1, xaxis_interval=0, xaxis_rotate=30, yaxis_rotate=30) bar.show_config() bar.render() 可通过设置 xaxis_min/xaxis_max/yaxis_min/yaxis_max 来调整 x 轴 和 y 轴上的最大最小值, 针对数值轴有效. 可通过 label_color 设置柱状颜色, 如 [“#eee”, “#000”], 所有图标类型的图例颜色都可以通过 label_color 来修改. 4. Bar3D (3D 柱状图)5. EffectScatter (带有涟漪特效动画的散点图)利用动画特效, 可以将某些想要突出的数据进行视觉突出. EffectScatter.add(name, x_value, y_value, symbol_size=10, **kwargs) name –&gt; str : 图例名称 x_axis –&gt; list : x 坐标轴数据 y_axis –&gt; list : y 坐标轴数据 symbol_size –&gt; int : 标记图形大小. symbol –&gt; str : 标记图形, 有 “rect”, “roundRect”, “triangle”, “diamond”, “pin”, “arrow” 可选. effect_brushtype –&gt; str : 波纹绘制方式, 有 “stroke”, “fill” 可选, 默认为 “stroke” effect_scale –&gt; float : 动画中波纹的最大缩放比例, 默认为 2.5 effect_period –&gt; float : 动画持续时间, 默认为 4s. 普通散点图: from pyecharts import EffectScatter v1 = [10, 20, 30, 40, 50, 60] v2 = [25, 20, 15, 10, 60, 33] es = EffectScatter(&quot;动态散点图示例&quot;) es.add(&quot;effectScatter&quot;, v1, v2) es.render() 各种图形散点示例: es = EffectScatter(&quot;动态散点图各种图形示例&quot;) es.add(&quot;&quot;, [10], [10], symbol_size=20, effect_scale=3.5, effect_period=3, symbol=&quot;pin&quot;) es.add(&quot;&quot;, [20], [20], symbol_size=12, effect_scale=4.5, effect_period=4,symbol=&quot;rect&quot;) es.add(&quot;&quot;, [30], [30], symbol_size=30, effect_scale=5.5, effect_period=5,symbol=&quot;roundRect&quot;) es.add(&quot;&quot;, [40], [40], symbol_size=10, effect_scale=6.5, effect_brushtype=&apos;fill&apos;,symbol=&quot;diamond&quot;) es.add(&quot;&quot;, [50], [50], symbol_size=16, effect_scale=5.5, effect_period=3,symbol=&quot;arrow&quot;) es.add(&quot;&quot;, [60], [60], symbol_size=6, effect_scale=2.5, effect_period=3,symbol=&quot;triangle&quot;) es.render() 6. Funnel (漏斗图)Funnel.add(name, attr, value, **kwargs) name –&gt; str : 图例名称 attr –&gt; list : 属性名称 value –&gt; list : 属性对应的值, 普通示例: from pyecharts import Funnel attr = [&quot;衬衫&quot;, &quot;羊毛衫&quot;, &quot;雪纺衫&quot;, &quot;裤子&quot;, &quot;高跟鞋&quot;, &quot;袜子&quot;] value = [20, 40, 60, 80, 100, 120] funnel = Funnel(&quot;漏斗图示例&quot;) funnel.add(&quot;商品&quot;, attr, value, is_label_show=True, label_pos=&quot;inside&quot;, label_text_color=&quot;#fff&quot;) funnel.render() 示例: funnel = Funnel(&quot;漏斗图示例&quot;, width=600, height=400, title_pos=&apos;center&apos;) funnel.add(&quot;商品&quot;, attr, value, is_label_show=True, label_pos=&quot;outside&quot;, legend_orient=&apos;vertical&apos;, legend_pos=&apos;left&apos;) funnel.show_config() funnel.render() 7. Gauge (仪表盘)Gauge.add(name, attr, value, scale_range=None, angle_range=None, **kwargs) name –&gt; str : 图例名称 attr –&gt; list : 属性名称 value –&gt; list : 属性对应的值 scale_range –&gt; list : 仪表盘数据范围, 默认为 [0,100] angle_range –&gt; list : 仪表盘角度范围, 默认为 [225, -45] 示例一 : from pyecharts import Gauge gauge = Gauge(&quot;仪表盘示例&quot;) gauge.add(&quot;业务指标&quot;, &quot;完成率&quot;, 66.66) gauge.show_config() gauge.render() 示例二 : gauge = Gauge(&quot;仪表盘示例&quot;) gauge.add(&quot;业务指标&quot;, &quot;完成率&quot;, 166.66, angle_range=[180, 0], scale_range=[0, 200], is_legend_show=False) gauge.show_config() gauge.render() 8. Geo (地理坐标系)地理坐标系组件用于地图的绘制, 支持在地理坐标系上绘制散点图, 线集. Geo.add(name, attr, value, type=”scatter”, maptype=”china”, symbol_size=12, border_color=”#111”, geo_normal_color=”#323c48”, geo_emphasis_color=”#2a333d”, **kwargs) name –&gt; str : 图例名称 attr –&gt; list : 属性名称 value –&gt; list : 属性所对应的值 type –&gt; str : 图例类型, 有 “scatter”, “effectscatter”, “heatmap” 可选, 默认为 “scatter” maptype –&gt; str : 地图类型, 目前只支持 “china” symbol_size –&gt; int : 标记图形大小, 默认12 border_color –&gt; str : 地图边界颜色, 默认为 “#111” geo_normal_color –&gt; str : 正常状态下地图区域的颜色, 默认为 “#323C48” geo_emphasis_color –&gt; str : 高亮状态下地图区域的颜色, 默认为 “#2a333d” 8.1 scatter请配合 通用配置项 中的 visualmap 使用. from pyecharts import Geo data = [ (&quot;海门&quot;, 9),(&quot;鄂尔多斯&quot;, 12),(&quot;招远&quot;, 12),(&quot;舟山&quot;, 12),(&quot;齐齐哈尔&quot;, 14),(&quot;盐城&quot;, 15), (&quot;赤峰&quot;, 16),(&quot;青岛&quot;, 18),(&quot;乳山&quot;, 18),(&quot;金昌&quot;, 19),(&quot;泉州&quot;, 21),(&quot;莱西&quot;, 21), (&quot;日照&quot;, 21),(&quot;胶南&quot;, 22),(&quot;南通&quot;, 23),(&quot;拉萨&quot;, 24),(&quot;云浮&quot;, 24),(&quot;梅州&quot;, 25), (&quot;文登&quot;, 25),(&quot;上海&quot;, 25),(&quot;攀枝花&quot;, 25),(&quot;威海&quot;, 25),(&quot;承德&quot;, 25),(&quot;厦门&quot;, 26), (&quot;汕尾&quot;, 26),(&quot;潮州&quot;, 26),(&quot;丹东&quot;, 27),(&quot;太仓&quot;, 27),(&quot;曲靖&quot;, 27),(&quot;烟台&quot;, 28), (&quot;福州&quot;, 29),(&quot;瓦房店&quot;, 30),(&quot;即墨&quot;, 30),(&quot;抚顺&quot;, 31),(&quot;玉溪&quot;, 31),(&quot;张家口&quot;, 31), (&quot;阳泉&quot;, 31),(&quot;莱州&quot;, 32),(&quot;湖州&quot;, 32),(&quot;汕头&quot;, 32),(&quot;昆山&quot;, 33),(&quot;宁波&quot;, 33), (&quot;湛江&quot;, 33),(&quot;揭阳&quot;, 34),(&quot;荣成&quot;, 34),(&quot;连云港&quot;, 35),(&quot;葫芦岛&quot;, 35),(&quot;常熟&quot;, 36), (&quot;东莞&quot;, 36),(&quot;河源&quot;, 36),(&quot;淮安&quot;, 36),(&quot;泰州&quot;, 36),(&quot;南宁&quot;, 37),(&quot;营口&quot;, 37), (&quot;惠州&quot;, 37),(&quot;江阴&quot;, 37),(&quot;蓬莱&quot;, 37),(&quot;韶关&quot;, 38),(&quot;嘉峪关&quot;, 38),(&quot;广州&quot;, 38), (&quot;延安&quot;, 38),(&quot;太原&quot;, 39),(&quot;清远&quot;, 39),(&quot;中山&quot;, 39),(&quot;昆明&quot;, 39),(&quot;寿光&quot;, 40), (&quot;盘锦&quot;, 40),(&quot;长治&quot;, 41),(&quot;深圳&quot;, 41),(&quot;珠海&quot;, 42),(&quot;宿迁&quot;, 43),(&quot;咸阳&quot;, 43), (&quot;铜川&quot;, 44),(&quot;平度&quot;, 44),(&quot;佛山&quot;, 44),(&quot;海口&quot;, 44),(&quot;江门&quot;, 45),(&quot;章丘&quot;, 45), (&quot;肇庆&quot;, 46),(&quot;大连&quot;, 47),(&quot;临汾&quot;, 47),(&quot;吴江&quot;, 47),(&quot;石嘴山&quot;, 49),(&quot;沈阳&quot;, 50), (&quot;苏州&quot;, 50),(&quot;茂名&quot;, 50),(&quot;嘉兴&quot;, 51),(&quot;长春&quot;, 51),(&quot;胶州&quot;, 52),(&quot;银川&quot;, 52), (&quot;张家港&quot;, 52),(&quot;三门峡&quot;, 53),(&quot;锦州&quot;, 54),(&quot;南昌&quot;, 54),(&quot;柳州&quot;, 54),(&quot;三亚&quot;, 54), (&quot;自贡&quot;, 56),(&quot;吉林&quot;, 56),(&quot;阳江&quot;, 57),(&quot;泸州&quot;, 57),(&quot;西宁&quot;, 57),(&quot;宜宾&quot;, 58), (&quot;呼和浩特&quot;, 58),(&quot;成都&quot;, 58),(&quot;大同&quot;, 58),(&quot;镇江&quot;, 59),(&quot;桂林&quot;, 59),(&quot;张家界&quot;, 59), (&quot;宜兴&quot;, 59),(&quot;北海&quot;, 60),(&quot;西安&quot;, 61),(&quot;金坛&quot;, 62),(&quot;东营&quot;, 62),(&quot;牡丹江&quot;, 63), (&quot;遵义&quot;, 63),(&quot;绍兴&quot;, 63),(&quot;扬州&quot;, 64),(&quot;常州&quot;, 64),(&quot;潍坊&quot;, 65),(&quot;重庆&quot;, 66), (&quot;台州&quot;, 67),(&quot;南京&quot;, 67),(&quot;滨州&quot;, 70),(&quot;贵阳&quot;, 71),(&quot;无锡&quot;, 71),(&quot;本溪&quot;, 71), (&quot;克拉玛依&quot;, 72),(&quot;渭南&quot;, 72),(&quot;马鞍山&quot;, 72),(&quot;宝鸡&quot;, 72),(&quot;焦作&quot;, 75),(&quot;句容&quot;, 75), (&quot;北京&quot;, 79),(&quot;徐州&quot;, 79),(&quot;衡水&quot;, 80),(&quot;包头&quot;, 80),(&quot;绵阳&quot;, 80),(&quot;乌鲁木齐&quot;, 84), (&quot;枣庄&quot;, 84),(&quot;杭州&quot;, 84),(&quot;淄博&quot;, 85),(&quot;鞍山&quot;, 86),(&quot;溧阳&quot;, 86),(&quot;库尔勒&quot;, 86), (&quot;安阳&quot;, 90),(&quot;开封&quot;, 90),(&quot;济南&quot;, 92),(&quot;德阳&quot;, 93),(&quot;温州&quot;, 95),(&quot;九江&quot;, 96), (&quot;邯郸&quot;, 98),(&quot;临安&quot;, 99),(&quot;兰州&quot;, 99),(&quot;沧州&quot;, 100),(&quot;临沂&quot;, 103),(&quot;南充&quot;, 104), (&quot;天津&quot;, 105),(&quot;富阳&quot;, 106),(&quot;泰安&quot;, 112),(&quot;诸暨&quot;, 112),(&quot;郑州&quot;, 113),(&quot;哈尔滨&quot;, 114), (&quot;聊城&quot;, 116),(&quot;芜湖&quot;, 117),(&quot;唐山&quot;, 119),(&quot;平顶山&quot;, 119),(&quot;邢台&quot;, 119),(&quot;德州&quot;, 120), (&quot;济宁&quot;, 120),(&quot;荆州&quot;, 127),(&quot;宜昌&quot;, 130),(&quot;义乌&quot;, 132),(&quot;丽水&quot;, 133),(&quot;洛阳&quot;, 134), (&quot;秦皇岛&quot;, 136),(&quot;株洲&quot;, 143),(&quot;石家庄&quot;, 147),(&quot;莱芜&quot;, 148),(&quot;常德&quot;, 152),(&quot;保定&quot;, 153), (&quot;湘潭&quot;, 154),(&quot;金华&quot;, 157),(&quot;岳阳&quot;, 169),(&quot;长沙&quot;, 175),(&quot;衢州&quot;, 177),(&quot;廊坊&quot;, 193), (&quot;菏泽&quot;, 194),(&quot;合肥&quot;, 229),(&quot;武汉&quot;, 273),(&quot;大庆&quot;, 279)] geo = Geo(&quot;全国主要城市空气质量&quot;, &quot;data from pm2.5&quot;, title_color=&quot;#fff&quot;, title_pos=&quot;center&quot;, width=1200, height=600, background_color=&apos;#404a59&apos;) attr, value = geo.cast(data) geo.add(&quot;&quot;, attr, value, visual_range=[0, 200], visual_text_color=&quot;#fff&quot;, symbol_size=15, is_visualmap=True) geo.show_config() geo.render() 8.2 effectScatterfrom pyecharts import Geo data = [(&quot;海门&quot;, 9), (&quot;鄂尔多斯&quot;, 12), (&quot;招远&quot;, 12), (&quot;舟山&quot;, 12), (&quot;齐齐哈尔&quot;, 14), (&quot;盐城&quot;, 15)] geo = Geo(&quot;全国主要城市空气质量&quot;, &quot;data from pm2.5&quot;, title_color=&quot;#fff&quot;, title_pos=&quot;center&quot;, width=1200, height=600, background_color=&apos;#404a59&apos;) attr, value = geo.cast(data) geo.add(&quot;&quot;, attr, value, type=&quot;effectScatter&quot;, is_random=True, effect_scale=5) geo.show_config() geo.render() 8.3 heatmapgeo = Geo(&quot;全国主要城市空气质量&quot;, &quot;data from pm2.5&quot;, title_color=&quot;#fff&quot;, title_pos=&quot;center&quot;, width=1200, height=600, background_color=&apos;#404a59&apos;) attr, value = geo.cast(data) geo.add(&quot;&quot;, attr, value, type=&quot;heatmap&quot;, is_visualmap=True, visual_range=[0, 300], visual_text_color=&apos;#fff&apos;) geo.show_config() geo.render() 9. Graph (关系图)10. HeatMap (热力图)11. Kline (K线图)红涨蓝跌 Kline.add(name, x_axis, y_axis, **kwargs) name –&gt; str : 图例名称 x_axis –&gt; list : x 坐标轴数据 y_axis –&gt; [list] : 包含列表的列表. y 坐标轴数据. 数据中, 每一行是一个 数据项, 每一列属于一个维度. 数据项具体为 [open, close, lowest, highest], 即 [开盘值, 收盘值, 最低值, 最高值]. 示例一 : 普通线 from pyecharts import Kline v1 = [[2320.26, 2320.26, 2287.3, 2362.94], [2300, 2291.3, 2288.26, 2308.38], [2295.35, 2346.5, 2295.35, 2345.92], [2347.22, 2358.98, 2337.35, 2363.8], [2360.75, 2382.48, 2347.89, 2383.76], [2383.43, 2385.42, 2371.23, 2391.82], [2377.41, 2419.02, 2369.57, 2421.15], [2425.92, 2428.15, 2417.58, 2440.38], [2411, 2433.13, 2403.3, 2437.42], [2432.68, 2334.48, 2427.7, 2441.73], [2430.69, 2418.53, 2394.22, 2433.89], [2416.62, 2432.4, 2414.4, 2443.03], [2441.91, 2421.56, 2418.43, 2444.8], [2420.26, 2382.91, 2373.53, 2427.07], [2383.49, 2397.18, 2370.61, 2397.94], [2378.82, 2325.95, 2309.17, 2378.82], [2322.94, 2314.16, 2308.76, 2330.88], [2320.62, 2325.82, 2315.01, 2338.78], [2313.74, 2293.34, 2289.89, 2340.71], [2297.77, 2313.22, 2292.03, 2324.63], [2322.32, 2365.59, 2308.92, 2366.16], [2364.54, 2359.51, 2330.86, 2369.65], [2332.08, 2273.4, 2259.25, 2333.54], [2274.81, 2326.31, 2270.1, 2328.14], [2333.61, 2347.18, 2321.6, 2351.44], [2340.44, 2324.29, 2304.27, 2352.02], [2326.42, 2318.61, 2314.59, 2333.67], [2314.68, 2310.59, 2296.58, 2320.96], [2309.16, 2286.6, 2264.83, 2333.29], [2282.17, 2263.97, 2253.25, 2286.33], [2255.77, 2270.28, 2253.31, 2276.22]] kline = Kline(&quot;K 线图示例&quot;) kline.add(&quot;日K&quot;, [&quot;2017/7/{}&quot;.format(i + 1) for i in range(31)], v1) kline.show_config() kline.render() 示例二 : 带 datazoom 的 kline. kline = Kline(&quot;K 线图示例&quot;) kline.add(&quot;日K&quot;, [&quot;2017/7/{}&quot;.format(i + 1) for i in range(31)], v1, mark_point=[&quot;max&quot;], is_datazoom_show=True) kline.show_config() kline.render() 示例三 : datazoom 添加到 纵坐标轴上. kline = Kline(&quot;K 线图示例&quot;) kline.add(&quot;日K&quot;, [&quot;2017/7/{}&quot;.format(i + 1) for i in range(31)], v1, mark_point=[&quot;max&quot;], is_datazoom_show=True, datazoom_orient=&apos;vertical&apos;) kline.show_config() kline.render() 12. Line (折线图/面积图)折线图是用折现将各个数据点标志连接起来的图表, 用以展现数据的变化趋势. Line.add(name, x_axis, y_axis, is_symbol_show=True, is_smooth=False, is_stack=False, is_step=False, is_fill=False, **kwargs) name –&gt; str : 图例名称 x_axis –&gt; list : x 坐标轴数据 y_axis –&gt; list : Y 坐标轴数据 is_symbol_show –&gt; bool : 是否显示标记图形, 默认为 True is_smooth –&gt; bool : 是否显示平滑曲线, 默认为 False is_stack –&gt; bool : 数据堆叠, 同个类目轴上系列配置相同的 stack 值可以堆叠放置, 默认为 False. is_step –&gt; bool/str : 是否是阶梯线图. 默认为 False. 也支持设置成 “start”, “middle”, “end” 分别配置在当前点, 当前点与下个点的中间, 下个点的拐弯. is_fill –&gt; bool : 是否填充曲线所绘制面积, 默认为 False. mark_point –&gt; list : 标记点, 有 min, max, average 可选 mark_line –&gt; list : 标记线, 有 min, max, average 可选. mark_point_symbol –&gt; str : 标记点图形, 默认为 pin, 有 circle, rect, roundRect, triangle, diamond, pin, arrow 可选. mark_point_symbolsize –&gt; int : 标记点图形大小, 默认为 50 mark_point_textcolor –&gt; str : 标记点字体颜色, 默认为 #fff. area_color –&gt; str : 填充区域颜色. area_opacity –&gt; float : 填充区域透明度 示例一 : from pyecharts import Line attr = [&quot;衬衫&quot;, &quot;羊毛衫&quot;, &quot;雪纺衫&quot;, &quot;裤子&quot;, &quot;高跟鞋&quot;, &quot;袜子&quot;] v1 = [5, 20, 36, 10, 10, 100] v2 = [55, 60, 16, 20, 15, 80] line = Line(&quot;折线图示例&quot;) line.add(&quot;商家A&quot;, attr, v1, mark_point=[&quot;average&quot;]) line.add(&quot;商家B&quot;, attr, v2, is_smooth=True, mark_line=[&quot;max&quot;, &quot;average&quot;]) line.show_config() line.render() 示例二 : 标记点 配置示例. line = Line(&quot;折线图示例&quot;) line.add(&quot;商家A&quot;, attr, v1, mark_point=[&quot;average&quot;, &quot;max&quot;, &quot;min&quot;], mark_point_symbol=&apos;diamond&apos;, mark_point_textcolor=&apos;#40ff27&apos;) line.add(&quot;商家B&quot;, attr, v2, mark_point=[&quot;average&quot;, &quot;max&quot;, &quot;min&quot;], mark_point_symbol=&apos;arrow&apos;, mark_point_symbolsize=40) line.show_config() line.render() 示例三 : 折线图-数据堆叠示例 line = Line(&quot;折线图-数据堆叠示例&quot;) line.add(&quot;商家A&quot;, attr, v1, is_stack=True, is_label_show=True) line.add(&quot;商家B&quot;, attr, v2, is_stack=True, is_label_show=True) line.show_config() line.render() 示例四 : 折线图-阶梯图示例 line = Line(&quot;折线图-面积图示例&quot;) line.add(&quot;商家A&quot;, attr, v1, is_fill=True, line_opacity=0.2, area_opacity=0.4, symbol=None) line.add(&quot;商家B&quot;, attr, v2, is_fill=True, area_color=&apos;#000&apos;, area_opacity=0.3, is_smooth=True) line.show_config() line.render() 示例五 : 折线图-面积图示例 line = Line(&quot;折线图-面积图示例&quot;) line.add(&quot;商家A&quot;, attr, v1, is_fill=True, line_opacity=0.2, area_opacity=0.4, symbol=None) line.add(&quot;商家B&quot;, attr, v2, is_fill=True, area_color=&apos;#000&apos;, area_opacity=0.3, is_smooth=True) line.show_config() line.render() 13. Line3D (3D折线图)14. Liquid (水球图)主要用来突出数据的百分比. Liquid.add(name, data, shape=”circle”, liquid_color=None, is_liquid_animation=True,is_liquid_outline_show=True, **kwargs) name –&gt; str : 图例名称 data –&gt; list : 数据项 shape –&gt; str : 水球外形, 有 circle, rect, roundRect, triangle, diamond, pin, arrow 可选. 默认为 circle. liquid_color –&gt; list : 波浪颜色, 默认颜色列表为 [“#294D99”, “#156ACF”, “#1598ED”, “#45BDFF”] is_liquid_animation –&gt; bool : 是否显示波浪动画, 默认为 True. is_liquid_outline_show –&gt; bool : 是否显示边框, 默认为 True. 示例一 : 有边界, 单波浪 from pyecharts import Liquid liquid = Liquid(&quot;水球图示例&quot;) liquid.add(&quot;Liquid&quot;, [0.6]) liquid.show_config() liquid.render() 示例二 : 无边界, 多波浪 from pyecharts import Liquid liquid = Liquid(&quot;水球图示例&quot;) liquid.add(&quot;Liquid&quot;, [0.6, 0.5, 0.4, 0.3], is_liquid_outline_show=False) liquid.show_config() liquid.render() 15. Map (地图)地图主要用于地理区域数据的可视化. Map.add(name, attr, value, is_roam=True, maptype=”china”, **kwargs) name –&gt; str : 图例名称 attr –&gt; list : 属性名称 value –&gt; list : 属性所对应的值. is_roam –&gt; bool/str : 是否开启鼠标缩放和平移漫游, 默认为 True. 如果只开启缩放或者平移, 可以设置成 “scale” 或者 “move”, 设置为 True ,表示两个都开启. maptype –&gt; str : 地图烈性, 支持 china, world, 安徽、澳门、北京、重庆、福建、福建、甘肃、广东，广西、广州、海南、河北、黑龙江、河南、湖北、湖南、江苏、江西、吉林、辽宁、内蒙古、宁夏、青海、山东、上海、陕西、四川、台湾、天津、香港、新疆、西藏、云南、浙江. 地图提供了(自定义模式)[https://github.com/chenjiandongx/pyecharts/blob/master/document/zh-cn/user-customize-map.md]. 示例一 : 全国地图示例 from pyecharts import Map value = [155, 10, 66, 78] attr = [&quot;福建&quot;, &quot;山东&quot;, &quot;北京&quot;, &quot;上海&quot;] map = Map(&quot;全国地图示例&quot;, width=1200, height=600) map.add(&quot;&quot;, attr, value, maptype=&apos;china&apos;) map.show_config() map.render() 示例二 : Map + VisualMap # 中国地图 from pyecharts import Map value = [155, 10, 66, 78, 33, 80, 190, 53, 49.6] attr = [&quot;福建&quot;, &quot;山东&quot;, &quot;北京&quot;, &quot;上海&quot;, &quot;甘肃&quot;, &quot;新疆&quot;, &quot;河南&quot;, &quot;广西&quot;, &quot;西藏&quot;] map = Map(&quot;Map 结合 VisualMap 示例&quot;, width=1200, height=600) map.add(&quot;&quot;, attr, value, maptype=&apos;china&apos;, is_visualmap=True, visual_text_color=&apos;#000&apos;) map.show_config() map.render() # 广东地图 from pyecharts import Map value = [20, 190, 253, 77, 65] attr = [&apos;汕头市&apos;, &apos;汕尾市&apos;, &apos;揭阳市&apos;, &apos;阳江市&apos;, &apos;肇庆市&apos;] map = Map(&quot;广东地图示例&quot;, width=1200, height=600) map.add(&quot;&quot;, attr, value, maptype=&apos;广东&apos;, is_visualmap=True, visual_text_color=&apos;#000&apos;) map.show_config() map.render() 示例三 : 世界地图示例 value = [95.1, 23.2, 43.3, 66.4, 88.5] attr= [&quot;China&quot;, &quot;Canada&quot;, &quot;Brazil&quot;, &quot;Russia&quot;, &quot;United States&quot;] map = Map(&quot;世界地图示例&quot;, width=1200, height=600) map.add(&quot;&quot;, attr, value, maptype=&quot;world&quot;, is_visualmap=True, visual_text_color=&apos;#000&apos;) map.render() 16. Parallel (平行坐标系)17. Pie (饼图-玫瑰图)饼图用于表现不同类目的数据在总和中的占比. 每个弧度表示数据数量的比例. Pie.add(name, attr, value, radius=None, center=None, rosetype=None, **kwargs) name –&gt; str : 图例名称 attr –&gt; list : 属性名称 value –&gt; list : 属性对应的值. radius –&gt; list : 饼图的半径, 数组的第一项是内半径, 第二项为 外半径(默认为 [0.75]). 默认设置成百分比, 相对于容器高宽中较小的一项的一半. center –&gt; list : 饼图的中心(圆心)坐标, 数组的第一项是横坐标, 第二项是纵坐标, 默认为 [50,50]. 默认设置成百分比, 设置成百分比时第一项是相对于容器宽度, 第二项是相对于容器高度. rosetype –&gt; str : 是否展示位 南丁格尔图, 通过半径区分数据大小, 有 “radius” 和 “area” 两种模式. 默认为 “radius”. radius : 扇区圆心角展现数据的百分比, 半径展现数据的大小 area : 所有扇区圆心角相同, 仅通过半径展现数据大小. 示例一 : 饼图 from pyecharts import Pie attr = [&quot;衬衫&quot;, &quot;羊毛衫&quot;, &quot;雪纺衫&quot;, &quot;裤子&quot;, &quot;高跟鞋&quot;, &quot;袜子&quot;] v1 = [11, 12, 13, 10, 10, 10] pie = Pie(&quot;饼图示例&quot;) pie.add(&quot;&quot;, attr, v1, is_label_show=True) pie.show_config() pie.render() 示例二 : 饼图-圆环图示例 from pyecharts import Pie attr = [&quot;衬衫&quot;, &quot;羊毛衫&quot;, &quot;雪纺衫&quot;, &quot;裤子&quot;, &quot;高跟鞋&quot;, &quot;袜子&quot;] v1 = [11, 12, 13, 10, 10, 10] pie = Pie(&quot;饼图-圆环图示例&quot;, title_pos=&apos;center&apos;) pie.add(&quot;&quot;, attr, v1, radius=[40, 75], label_text_color=None, is_label_show=True, legend_orient=&apos;vertical&apos;, legend_pos=&apos;left&apos;) pie.show_config() pie.render() 示例三 : 饼图-玫瑰图示例 from pyecharts import Pie attr = [&quot;衬衫&quot;, &quot;羊毛衫&quot;, &quot;雪纺衫&quot;, &quot;裤子&quot;, &quot;高跟鞋&quot;, &quot;袜子&quot;] v1 = [11, 12, 13, 10, 10, 10] v2 = [19, 21, 32, 20, 20, 33] pie = Pie(&quot;饼图-玫瑰图示例&quot;, title_pos=&apos;center&apos;, width=900) pie.add(&quot;商品A&quot;, attr, v1, center=[25, 50], is_random=True, radius=[30, 75], rosetype=&apos;radius&apos;) pie.add(&quot;商品B&quot;, attr, v2, center=[75, 50], is_random=True, radius=[30, 75], rosetype=&apos;area&apos;, is_legend_show=False, is_label_show=True) pie.show_config() pie.render() 18. Polar (极坐标系)可用以散点图和折线图. Polar.add(name, data, angle_data=None, radius_data=None, type=”line”, symbol_siza=4, start_angle=90, rotate_step=0, boundary_gap=True, clockwise=True, **kwargs) name –&gt; str : 图例名称 data –&gt; [list] : 包含列表的列表, 数据项, [极径, 极角, [ 数据值]] angle_data –&gt; list : 角度类目数据 radius_data –&gt; list : 半径类目数据 type –&gt; str : 图例类型, 有 line, scatter, effectScatter, barAngle, barRadius 可选, 默认为 line. symbol_size –&gt; int : 标记图形大小, 默认为 4 start_angle –&gt; int : 起始刻度的角度, 默认为 90 度, 即圆形的正上方, 0 度为圆心的正右方. rotate_step –&gt; int : 刻度标签旋转的角度, 在类目轴的类目标签显示不下的时候,可以通过旋转防止标签之间重叠. 旋转的角度从 -90 度 到 90 度, 默认为 0. boundary_gap –&gt; bool : 坐标两边留白策略. 默认为 True, 这是刻度只是作为分割线, 标签和数据点都会在两个刻度之间的带(band) 中间. clockwise –&gt; bool : 刻度增长是否按顺时针, 默认为 True is_stack –&gt; bool : 数据堆叠, 同个类目轴上系列配置相同的 stack 值可以堆叠放置 . axis_range –&gt; list : 坐标轴刻度范围, 默认为 [None, None]. is_angleaxis_show –&gt; bool : 是否显示极坐标系的角度轴, 默认为 True. is_radiusaxis_show –&gt; bool : 是否显示极坐标系的经向轴, 默认为 True. is_splitline_show –&gt; bool : 是否显示分割线, 默认为 True is_axisline_show –&gt; bool : 是否显示坐标轴线, 默认为 True area_opacity –&gt; float : 填充区域透明度 area_color –&gt; str : 填充区域颜色. 可配置 lineStyle 参数 示例一 : 极坐标系 - 散点图示例 # 极坐标系 - 散点 from pyecharts import Polar import random data = [(i, random.randint(1, 100)) for i in range(101)] polar = Polar(&quot;极坐标系-散点图示例&quot;) polar.add(&quot;&quot;, data, boundary_gap=False, type=&apos;scatter&apos;, is_splitline_show=False, area_color=None, is_axisline_show=True) polar.show_config() polar.render() # 极坐标系 - 多重散点 from pyecharts import Polar import random data_1 = [(10, random.randint(1, 100)) for i in range(300)] data_2 = [(11, random.randint(1, 100)) for i in range(300)] polar = Polar(&quot;极坐标系-散点图示例&quot;, width=1200, height=600) polar.add(&quot;&quot;, data_1, type=&apos;scatter&apos;) polar.add(&quot;&quot;, data_2, type=&apos;scatter&apos;) polar.show_config() polar.render() # 极坐标系 - 动态散点图 from pyecharts import Polar import random data = [(i, random.randint(1, 100)) for i in range(10)] polar = Polar(&quot;极坐标系-动态散点图示例&quot;, width=1200, height=600) polar.add(&quot;&quot;, data, type=&apos;effectScatter&apos;, effect_scale=10, effect_period=5) polar.show_config() polar.render() 示例二 : 极坐标系 - 堆叠柱状图示例 - barRadius from pyecharts import Polar radius = [&apos;周一&apos;, &apos;周二&apos;, &apos;周三&apos;, &apos;周四&apos;, &apos;周五&apos;, &apos;周六&apos;, &apos;周日&apos;] polar = Polar(&quot;极坐标系-堆叠柱状图示例&quot;, width=1200, height=600) polar.add(&quot;A&quot;, [1, 2, 3, 4, 3, 5, 1], radius_data=radius, type=&apos;barRadius&apos;, is_stack=True) polar.add(&quot;B&quot;, [2, 4, 6, 1, 2, 3, 1], radius_data=radius, type=&apos;barRadius&apos;, is_stack=True) polar.add(&quot;C&quot;, [1, 2, 3, 4, 1, 2, 5], radius_data=radius, type=&apos;barRadius&apos;, is_stack=True) polar.show_config() polar.render() 示例三 : 极坐标系 - 堆叠柱状图 – &gt; barAngle from pyecharts import Polar radius = [&apos;周一&apos;, &apos;周二&apos;, &apos;周三&apos;, &apos;周四&apos;, &apos;周五&apos;, &apos;周六&apos;, &apos;周日&apos;] polar = Polar(&quot;极坐标系-堆叠柱状图示例&quot;, width=1200, height=600) polar.add(&quot;&quot;, [1, 2, 3, 4, 3, 5, 1], radius_data=radius, type=&apos;barAngle&apos;, is_stack=True) polar.add(&quot;&quot;, [2, 4, 6, 1, 2, 3, 1], radius_data=radius, type=&apos;barAngle&apos;, is_stack=True) polar.add(&quot;&quot;, [1, 2, 3, 4, 1, 2, 5], radius_data=radius, type=&apos;barAngle&apos;, is_stack=True) polar.show_config() polar.render() 19. Radar (雷达图)20. Scatter (散点图)21. Scatter3D (3D散点图)22. WordCloud (词云图)WordCloud.add(name, attr, value, shape=”circle”, word_gap=20, word_size_range=None, rotate_step=45) name –&gt; str : 图例名称 attr –&gt; list : 属性名称 value –&gt; list : 属性所对应的值 shape –&gt; list : 词云图轮廓, 有 cicle, cardioid, diamond, triangle-forward, triangle, pentagon, star 可选. word_gap –&gt; int : 单词间隔, 默认为 20 word_size_range –&gt; list : 单词字体大小范围, 默认为 [12, 60] rotate_step –&gt; int : 旋转单词角度, 默认为 45. 当且仅当 shape 为默认的’circle’时 rotate_step 参数才生效 示例一 : from pyecharts import WordCloud name = [&apos;Sam S Club&apos;, &apos;Macys&apos;, &apos;Amy Schumer&apos;, &apos;Jurassic World&apos;, &apos;Charter Communications&apos;, &apos;Chick Fil A&apos;, &apos;Planet Fitness&apos;, &apos;Pitch Perfect&apos;, &apos;Express&apos;, &apos;Home&apos;, &apos;Johnny Depp&apos;, &apos;Lena Dunham&apos;, &apos;Lewis Hamilton&apos;, &apos;KXAN&apos;, &apos;Mary Ellen Mark&apos;, &apos;Farrah Abraham&apos;, &apos;Rita Ora&apos;, &apos;Serena Williams&apos;, &apos;NCAA baseball tournament&apos;, &apos;Point Break&apos;] value = [10000, 6181, 4386, 4055, 2467, 2244, 1898, 1484, 1112, 965, 847, 582, 555, 550, 462, 366, 360, 282, 273, 265] wordcloud = WordCloud(width=1300, height=620) wordcloud.add(&quot;&quot;, name, value, word_size_range=[20, 100]) wordcloud.show_config() wordcloud.render() 示例二 : wordcloud = WordCloud(width=1300, height=620) wordcloud.add(&quot;&quot;, name, value, word_size_range=[30, 100], shape=&apos;diamond&apos;) wordcloud.show_config() wordcloud.render() 23. 用户自定义23.1 Grib : 并行显示多张图用户可以自定义集合 Line/Bar/Kline/Scatter/EffectScatter/Pie/HeatMap 图表, 将不同类型图表画在多张图上. Grid 类的使用 引入 Grid 类, from pyecharts import Grid 实例化 Grid 类, grid = Grid() 使用 add() 向 grid 中添加图, 至少需要设置 grid_top, grid_bottom, grid_left, grid_right 四个参数中的一个. grid_width 和 grid_height 一般不用设置, 默认即可. add() 参数如下: grid_width –&gt; str/int : grid 组件的宽度, 默认自适应 grid_height –&gt; str/int : grid 组件的高度, 默认自适应 grid_top –&gt; str/int : grid 组件离容器顶部的距离. 默认为 None, 有 top,center,middle 可选, 也可为 百分数或者整数. grid_bottom –&gt; str/int : grid 组件离容器底部的距离. 默认为 None, 有 top,center,middle 可选, 也可为 百分数或者整数. grid_left –&gt; str/int : grid 组件离容器左侧的距离. 默认为 None, 有 top,center,middle 可选, 也可为 百分数或者整数. grid_right –&gt; str/int : grid 组件离容器右侧的距离. 默认为 None, 有 top,center,middle 可选, 也可为 百分数或者整数. 使用 render() 方法渲染成 .html 文件. Grid 类中的其他方法render_embed() : 在 Flask/Django 中可以使用该方法渲染.show_config() : 打印输出所有配置项.chart : chart 属性返回图形示实例. 示例一 : 上下类型, Bar + Line from pyecharts import Bar, Line, Grid attr = [&quot;衬衫&quot;, &quot;羊毛衫&quot;, &quot;雪纺衫&quot;, &quot;裤子&quot;, &quot;高跟鞋&quot;, &quot;袜子&quot;] v1 = [5, 20, 36, 10, 75, 90] v2 = [10, 25, 8, 60, 20, 80] bar = Bar(&quot;柱状图示例&quot;, height=720) bar.add(&quot;商家A&quot;, attr, v1, is_stack=True) bar.add(&quot;商家B&quot;, attr, v2, is_stack=True) line = Line(&quot;折线图示例&quot;, title_top=&quot;50%&quot;) attr = [&apos;周一&apos;, &apos;周二&apos;, &apos;周三&apos;, &apos;周四&apos;, &apos;周五&apos;, &apos;周六&apos;, &apos;周日&apos;] line.add(&quot;最高气温&quot;, attr, [11, 11, 15, 13, 12, 13, 10], mark_point=[&quot;max&quot;, &quot;min&quot;], mark_line=[&quot;average&quot;]) line.add(&quot;最低气温&quot;, attr, [1, -2, 2, 5, 3, 2, 0], mark_point=[&quot;max&quot;, &quot;min&quot;], mark_line=[&quot;average&quot;], legend_top=&quot;50%&quot;) grid = Grid() grid.add(bar, grid_bottom=&quot;60%&quot;) grid.add(line, grid_top=&quot;60%&quot;) bar.show_config() grid.render() 示例二 : 左右类型, Scatter + EffectScatter from pyecharts import Scatter, EffectScatter, Grid v1 = [5, 20, 36, 10, 75, 90] v2 = [10, 25, 8, 60, 20, 80] scatter = Scatter(width=1200) scatter.add(&quot;散点图示例&quot;, v1, v2, legend_pos=&quot;70%&quot;) es = EffectScatter() es.add(&quot;动态散点图示例&quot;, [11, 11, 15, 13, 12, 13, 10], [1, -2, 2, 5, 3, 2, 0], effect_scale=6, legend_pos=&quot;20%&quot;) grid = Grid() grid.add(scatter, grid_left=&quot;60%&quot;) grid.add(es, grid_right=&quot;60%&quot;) grid.render() 示例三 : 上下左右类型, Bar + Line + Scatter + EffectScatter from pyecharts import Bar, Line, Scatter, EffectScatter, Grid attr = [&quot;衬衫&quot;, &quot;羊毛衫&quot;, &quot;雪纺衫&quot;, &quot;裤子&quot;, &quot;高跟鞋&quot;, &quot;袜子&quot;] v1 = [5, 20, 36, 10, 75, 90] v2 = [10, 25, 8, 60, 20, 80] bar = Bar(&quot;柱状图示例&quot;, height=720, width=1200, title_pos=&quot;65%&quot;) bar.add(&quot;商家A&quot;, attr, v1, is_stack=True) bar.add(&quot;商家B&quot;, attr, v2, is_stack=True, legend_pos=&quot;80%&quot;) line = Line(&quot;折线图示例&quot;) attr = [&apos;周一&apos;, &apos;周二&apos;, &apos;周三&apos;, &apos;周四&apos;, &apos;周五&apos;, &apos;周六&apos;, &apos;周日&apos;] line.add(&quot;最高气温&quot;, attr, [11, 11, 15, 13, 12, 13, 10], mark_point=[&quot;max&quot;, &quot;min&quot;], mark_line=[&quot;average&quot;]) line.add(&quot;最低气温&quot;, attr, [1, -2, 2, 5, 3, 2, 0], mark_point=[&quot;max&quot;, &quot;min&quot;], mark_line=[&quot;average&quot;], legend_pos=&quot;20%&quot;) v1 = [5, 20, 36, 10, 75, 90] v2 = [10, 25, 8, 60, 20, 80] scatter = Scatter(&quot;散点图示例&quot;, title_top=&quot;50%&quot;, title_pos=&quot;65%&quot;) scatter.add(&quot;scatter&quot;, v1, v2, legend_top=&quot;50%&quot;, legend_pos=&quot;80%&quot;) es = EffectScatter(&quot;动态散点图示例&quot;, title_top=&quot;50%&quot;) es.add(&quot;es&quot;, [11, 11, 15, 13, 12, 13, 10], [1, -2, 2, 5, 3, 2, 0], effect_scale=6, legend_top=&quot;50%&quot;, legend_pos=&quot;20%&quot;) grid = Grid() grid.add(bar, grid_bottom=&quot;60%&quot;, grid_left=&quot;60%&quot;) grid.add(line, grid_bottom=&quot;60%&quot;, grid_right=&quot;60%&quot;) grid.add(scatter, grid_top=&quot;60%&quot;, grid_left=&quot;60%&quot;) grid.add(es, grid_top=&quot;60%&quot;, grid_right=&quot;60%&quot;) grid.render() 23.2 Overlap : 结合不同类型图表叠加画在同张图上.用户可以自定义结合 Line/Bar/Kline, Scatter/EffectScatter 图表, 将不同类型图表画在一张图上, 利用第一个图表为基础, 之后的数据都将画在第一个图表上. Overlap 使用方法 引入 Overlap 类, from pyecharts import Overlap 实例化 Overlap 类, overlap = Overlap() 使用 add() 向 overlap 添加图 使用 render() 渲染生成 .html 文件 Overlap 类中的其他方法 render_embed() : 在 Flask/Django 中可用该方法渲染. show_config() : 打印输出所有配置项 chart : 返回图形示例. 示例一 : Line + Bar from pyecharts import Bar, Line, Overlap attr = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;, &apos;E&apos;, &apos;F&apos;] v1 = [10, 20, 30, 40, 50, 60] v2 = [38, 28, 58, 48, 78, 68] bar = Bar(&quot;Line - Bar 示例&quot;) bar.add(&quot;bar&quot;, attr, v1) line = Line() line.add(&quot;line&quot;, attr, v2) overlap = Overlap() overlap.add(bar) overlap.add(line) overlap.render() 示例二 : from pyecharts import Scatter, EffectScatter, Overlap v1 = [10, 20, 30, 40, 50, 60] v2 = [30, 30, 30, 30, 30, 30] v3 = [50, 50, 50, 50, 50, 50] v4 = [10, 10, 10, 10, 10, 10] es = EffectScatter(&quot;Scatter - EffectScatter 示例&quot;) es.add(&quot;es&quot;, v1, v2) scatter = Scatter() scatter.add(&quot;scatter&quot;, v1, v3) es_1 = EffectScatter() es_1.add(&quot;es_1&quot;, v1, v4, symbol=&apos;pin&apos;, effect_scale=5) overlap = Overlap() overlap.add(es) overlap.add(scatter) overlap.add(es_1) overlap.render() 示例三 : Kline + Line import random from pyecharts import Line, Kline, Overlap v1 = [[2320.26, 2320.26, 2287.3, 2362.94], [2300, 2291.3, 2288.26, 2308.38], [2295.35, 2346.5, 2295.35, 2345.92], [2347.22, 2358.98, 2337.35, 2363.8], [2360.75, 2382.48, 2347.89, 2383.76], [2383.43, 2385.42, 2371.23, 2391.82], [2377.41, 2419.02, 2369.57, 2421.15], [2425.92, 2428.15, 2417.58, 2440.38], [2411, 2433.13, 2403.3, 2437.42], [2432.68, 2334.48, 2427.7, 2441.73], [2430.69, 2418.53, 2394.22, 2433.89], [2416.62, 2432.4, 2414.4, 2443.03], [2441.91, 2421.56, 2418.43, 2444.8], [2420.26, 2382.91, 2373.53, 2427.07], [2383.49, 2397.18, 2370.61, 2397.94], [2378.82, 2325.95, 2309.17, 2378.82], [2322.94, 2314.16, 2308.76, 2330.88], [2320.62, 2325.82, 2315.01, 2338.78], [2313.74, 2293.34, 2289.89, 2340.71], [2297.77, 2313.22, 2292.03, 2324.63], [2322.32, 2365.59, 2308.92, 2366.16], [2364.54, 2359.51, 2330.86, 2369.65], [2332.08, 2273.4, 2259.25, 2333.54], [2274.81, 2326.31, 2270.1, 2328.14], [2333.61, 2347.18, 2321.6, 2351.44], [2340.44, 2324.29, 2304.27, 2352.02], [2326.42, 2318.61, 2314.59, 2333.67], [2314.68, 2310.59, 2296.58, 2320.96], [2309.16, 2286.6, 2264.83, 2333.29], [2282.17, 2263.97, 2253.25, 2286.33], [2255.77, 2270.28, 2253.31, 2276.22]] attr = [&quot;2017/7/{}&quot;.format(i + 1) for i in range(31)] kline = Kline(&quot;Kline - Line 示例&quot;) kline.add(&quot;日K&quot;, attr, v1) line_1 = Line() line_1.add(&quot;line-1&quot;, attr, [random.randint(2400, 2500) for _ in range(31)]) line_2 = Line() line_2.add(&quot;line-2&quot;, attr, [random.randint(2400, 2500) for _ in range(31)]) overlap = Overlap() overlap.add(kline) overlap.add(line_1) overlap.add(line_2) overlap.render() 23.4 Page : 同一网页按顺序展示多图.Page 类的使用 引入 Page 类, from pyecharts import Page 实例化 Page 类, page = Page() 使用 add() 向 page 实例中添加图片 使用 render() 渲染生成 .html 文件. Page 类中的其他方法 render_embed() : 在 Flask/Django 中可以使用该方法渲染 show_config() : 打印输出所有配置项 chart : chart 属性返回图形实例. 示例 : #coding=utf-8 from __future__ import unicode_literals from pyecharts import Line, Pie, Kline, Radar from pyecharts import Page page = Page() # line attr = [&apos;周一&apos;, &apos;周二&apos;, &apos;周三&apos;, &apos;周四&apos;, &apos;周五&apos;, &apos;周六&apos;, &apos;周日&apos;] line = Line(&quot;折线图示例&quot;) line.add(&quot;最高气温&quot;, attr, [11, 11, 15, 13, 12, 13, 10], mark_point=[&quot;max&quot;, &quot;min&quot;], mark_line=[&quot;average&quot;]) line.add(&quot;最低气温&quot;, attr, [1, -2, 2, 5, 3, 2, 0], mark_point=[&quot;max&quot;, &quot;min&quot;], mark_line=[&quot;average&quot;]) page.add(line) # pie attr = [&quot;衬衫&quot;, &quot;羊毛衫&quot;, &quot;雪纺衫&quot;, &quot;裤子&quot;, &quot;高跟鞋&quot;, &quot;袜子&quot;] v1 = [11, 12, 13, 10, 10, 10] pie = Pie(&quot;饼图-圆环图示例&quot;, title_pos=&apos;center&apos;) pie.add(&quot;&quot;, attr, v1, radius=[40, 75], label_text_color=None, is_label_show=True, legend_orient=&apos;vertical&apos;, legend_pos=&apos;left&apos;) page.add(pie) # kline v1 = [[2320.26, 2320.26, 2287.3, 2362.94], [2300, 2291.3, 2288.26, 2308.38], [2295.35, 2346.5, 2295.35, 2345.92], [2347.22, 2358.98, 2337.35, 2363.8], [2360.75, 2382.48, 2347.89, 2383.76], [2383.43, 2385.42, 2371.23, 2391.82], [2377.41, 2419.02, 2369.57, 2421.15], [2425.92, 2428.15, 2417.58, 2440.38], [2411, 2433.13, 2403.3, 2437.42], [2432.68, 2334.48, 2427.7, 2441.73], [2430.69, 2418.53, 2394.22, 2433.89], [2416.62, 2432.4, 2414.4, 2443.03], [2441.91, 2421.56, 2418.43, 2444.8], [2420.26, 2382.91, 2373.53, 2427.07], [2383.49, 2397.18, 2370.61, 2397.94], [2378.82, 2325.95, 2309.17, 2378.82], [2322.94, 2314.16, 2308.76, 2330.88], [2320.62, 2325.82, 2315.01, 2338.78], [2313.74, 2293.34, 2289.89, 2340.71], [2297.77, 2313.22, 2292.03, 2324.63], [2322.32, 2365.59, 2308.92, 2366.16], [2364.54, 2359.51, 2330.86, 2369.65], [2332.08, 2273.4, 2259.25, 2333.54], [2274.81, 2326.31, 2270.1, 2328.14], [2333.61, 2347.18, 2321.6, 2351.44], [2340.44, 2324.29, 2304.27, 2352.02], [2326.42, 2318.61, 2314.59, 2333.67], [2314.68, 2310.59, 2296.58, 2320.96], [2309.16, 2286.6, 2264.83, 2333.29], [2282.17, 2263.97, 2253.25, 2286.33], [2255.77, 2270.28, 2253.31, 2276.22]] kline = Kline(&quot;K 线图示例&quot;) kline.add(&quot;日K&quot;, [&quot;2017/7/{}&quot;.format(i + 1) for i in range(31)], v1) page.add(kline) # radar schema = [(&quot;销售&quot;, 6500), (&quot;管理&quot;, 16000), (&quot;信息技术&quot;, 30000), (&quot;客服&quot;, 38000), (&quot;研发&quot;, 52000), (&quot;市场&quot;, 25000)] v1 = [[4300, 10000, 28000, 35000, 50000, 19000]] v2 = [[5000, 14000, 28000, 31000, 42000, 21000]] radar = Radar(&quot;雷达图示例&quot;) radar.config(schema) radar.add(&quot;预算分配&quot;, v1, is_splitline=True, is_axisline_show=True) radar.add(&quot;实际开销&quot;, v2, label_color=[&quot;#4e79a7&quot;], is_area_show=False, legend_selectedmode=&apos;single&apos;) page.add(radar) page.render() 23.5 Timeline : 提供时间线轮播多张图Timeline 类的使用 引入 TimeLIne 类, from pyecharts import Timeline 实例化 Timeline 类, timeline = Timeline() 实例化 Timeline 类时接受设置参数. is_auto_play -&gt; bool 是否自动播放，默认为 Flase is_loop_play -&gt; bool 是否循环播放，默认为 True is_rewind_play -&gt; bool 是否方向播放，默认为 Flase is_timeline_show -&gt; bool 是否显示 timeline 组件。默认为 True，如果设置为false，不会显示，但是功能还存在。 timeline_play_interval -&gt; int 播放的速度（跳动的间隔），单位毫秒（ms）。 timeline_symbol -&gt; str 标记的图形。ECharts 提供的标记类型包括 ‘circle’, ‘rect’, ‘roundRect’, ‘triangle’, ‘diamond’, ‘pin’, ‘arrow’ timeline_symbol_size -&gt; int/list 标记的图形大小，可以设置成诸如 10 这样单一的数字，也可以用数组分开表示宽和高，例如 [20, 10] 表示标记宽为 20，高为 10。 timeline_left -&gt; int/str timeline 组件离容器左侧的距离。 left 的值可以是像 20 这样的具体像素值，可以是像 ‘20%’ 这样相对于容器高宽的百分比，也可以是 ‘left’, ‘center’, ‘right’。如果 left 的值为’left’, ‘center’, ‘right’，组件会根据相应的位置自动对齐。 timeline_right -&gt; int/str timeline 组件离容器右侧的距离。同 left timeline_top -&gt; int/str timeline 组件离容器顶侧的距离。同 left timeline_bottom -&gt; int/str timeline 组件离容器底侧的距离。同 left 使用 add() 向 timeline 中添加图. 该方法接受两个参数, 第一个为 图实例 , 第二个为时间线的时间点. 使用 render() 渲染成.html` 文件. Timeline 类中的其他 render_embed() : 在 Flask/Django 中可以使用该方法渲染 show_config() : 打印输出所有配置项 chart : chart 属性返回图形实例. 示例一 : from pyecharts import Bar, Timeline attr = [&quot;衬衫&quot;, &quot;羊毛衫&quot;, &quot;雪纺衫&quot;, &quot;裤子&quot;, &quot;高跟鞋&quot;, &quot;袜子&quot;] bar_1 = Bar(&quot;2012 年销量&quot;, &quot;数据纯属虚构&quot;) bar_1.add(&quot;春季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_1.add(&quot;夏季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_1.add(&quot;秋季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_1.add(&quot;冬季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_2 = Bar(&quot;2013 年销量&quot;, &quot;数据纯属虚构&quot;) bar_2.add(&quot;春季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_2.add(&quot;夏季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_2.add(&quot;秋季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_2.add(&quot;冬季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_3 = Bar(&quot;2014 年销量&quot;, &quot;数据纯属虚构&quot;) bar_3.add(&quot;春季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_3.add(&quot;夏季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_3.add(&quot;秋季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_3.add(&quot;冬季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_4 = Bar(&quot;2015 年销量&quot;, &quot;数据纯属虚构&quot;) bar_4.add(&quot;春季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_4.add(&quot;夏季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_4.add(&quot;秋季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_4.add(&quot;冬季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_5 = Bar(&quot;2016 年销量&quot;, &quot;数据纯属虚构&quot;) bar_5.add(&quot;春季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_5.add(&quot;夏季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_5.add(&quot;秋季&quot;, attr, [randint(10, 100) for _ in range(6)]) bar_5.add(&quot;冬季&quot;, attr, [randint(10, 100) for _ in range(6)], is_legend_show=True) timeline = Timeline(is_auto_play=True, timeline_bottom=0) timeline.add(bar_1, &apos;2012 年&apos;) timeline.add(bar_2, &apos;2013 年&apos;) timeline.add(bar_3, &apos;2014 年&apos;) timeline.add(bar_4, &apos;2015 年&apos;) timeline.add(bar_5, &apos;2016 年&apos;) timeline.render() 示例二 : from pyecharts import Pie, Timeline attr = [&quot;衬衫&quot;, &quot;羊毛衫&quot;, &quot;雪纺衫&quot;, &quot;裤子&quot;, &quot;高跟鞋&quot;, &quot;袜子&quot;] pie_1 = Pie(&quot;2012 年销量比例&quot;, &quot;数据纯属虚构&quot;) pie_1.add(&quot;秋季&quot;, attr, [randint(10, 100) for _ in range(6)], is_label_show=True, radius=[30, 55], rosetype=&apos;radius&apos;) pie_2 = Pie(&quot;2013 年销量比例&quot;, &quot;数据纯属虚构&quot;) pie_2.add(&quot;秋季&quot;, attr, [randint(10, 100) for _ in range(6)], is_label_show=True, radius=[30, 55], rosetype=&apos;radius&apos;) pie_3 = Pie(&quot;2014 年销量比例&quot;, &quot;数据纯属虚构&quot;) pie_3.add(&quot;秋季&quot;, attr, [randint(10, 100) for _ in range(6)], is_label_show=True, radius=[30, 55], rosetype=&apos;radius&apos;) pie_4 = Pie(&quot;2015 年销量比例&quot;, &quot;数据纯属虚构&quot;) pie_4.add(&quot;秋季&quot;, attr, [randint(10, 100) for _ in range(6)], is_label_show=True, radius=[30, 55], rosetype=&apos;radius&apos;) pie_5 = Pie(&quot;2016 年销量比例&quot;, &quot;数据纯属虚构&quot;) pie_5.add(&quot;秋季&quot;, attr, [randint(10, 100) for _ in range(6)], is_label_show=True, radius=[30, 55], rosetype=&apos;radius&apos;) timeline = Timeline(is_auto_play=True, timeline_bottom=0) timeline.add(pie_1, &apos;2012 年&apos;) timeline.add(pie_2, &apos;2013 年&apos;) timeline.add(pie_3, &apos;2014 年&apos;) timeline.add(pie_4, &apos;2015 年&apos;) timeline.add(pie_5, &apos;2016 年&apos;) timeline.show_config() timeline.render() 24. pyecharts 集成 Flask核心原理: 使用 render_template 将 Type.render_embed() 返回的 js 代码, 作为参数传入 template 中, template 需要事先加载 所需要的 js 库. template 代码示例 &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;ECharts&lt;/title&gt; &lt;script src=&quot;http://oog4yfyu0.bkt.clouddn.com/echarts.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;http://oog4yfyu0.bkt.clouddn.com/echarts-gl.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript &quot; src=&quot;http://echarts.baidu.com/gallery/vendors/echarts/map/js/china.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript &quot; src=&quot;http://echarts.baidu.com/gallery/vendors/echarts/map/js/world.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript &quot; src=&quot;http://oog4yfyu0.bkt.clouddn.com/wordcloud.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; {{myechart|safe}} &lt;/body&gt; &lt;/html&gt; flaks 代码示例 from flask import Flask, render_template app = Flask(__name__) @app.route(&quot;/&quot;) def hello(): return render_template(&apos;pyecharts.html&apos;, myechart=scatter3d()) def scatter3d(): from pyecharts import Scatter3D import random data = [[random.randint(0, 100), random.randint(0, 100), random.randint(0, 100)] for _ in range(80)] range_color = [&apos;#313695&apos;, &apos;#4575b4&apos;, &apos;#74add1&apos;, &apos;#abd9e9&apos;, &apos;#e0f3f8&apos;, &apos;#ffffbf&apos;, &apos;#fee090&apos;, &apos;#fdae61&apos;, &apos;#f46d43&apos;, &apos;#d73027&apos;, &apos;#a50026&apos;] scatter3D = Scatter3D(&quot;3D scattering plot demo&quot;, width=1200, height=600) scatter3D.add(&quot;&quot;, data, is_visualmap=True, visual_range_color=range_color) return scatter3D.render_embed()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>PyPi</tag>
        <tag>pyecharts</tag>
        <tag>echarts</tag>
        <tag>JavaScript 图表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 扩展之 -- flask-whooshee]]></title>
    <url>%2F2018%2F03%2F16%2FflaskExt--flask-whooshee%2F</url>
    <content type="text"><![CDATA[flask-whooshee 基于 sqlalchemy 的全文索引 Flask-Whooshee 是一个 基于Whoosh 的高级 flask 集成. 可用于索引和检索 joined queries. 1. 安装$ pip install Flask-Whooshee 2. 初始化与配置2.1 初始化方式 直接初始化, 并绑定到一个 flask 实例 from flask-whooshee import Whooshee app = Flask(__name__) whooshee = Whooshee(app) 使用工厂模式初始化 whooshee = Whooshee() def create_app(): app = Flask(__name__) whooshee.init_app(app) # ... ... return app 2.2 配置可用的配置变量 Option Desc Default WHOOSHEE_DIR 索引存放目录 whooshee WHOOSHEE_MIN_STRING_LEN 可查询的最小字符串 3 WHOOSHEE_WRITER_TIMEOUT How long should whoosh try to acquire write lock 2 WHOOSHEE_MEMORY_STORAGE 使用内存存放索引, 用于测试 False WHOOSHEE_ENABLE_INDEXING Specify wherher or not to actually do operations with the Whoosh index True 3. 使用方法3.1 单表检索简单用法, 如下代码, 将 Entry 表中的 title, content 两个字段作为可全文索引字段. from app import whooshee @whooshee.register_model(&apos;title&apos;, &apos;content&apos;) class Entry(db.Model): id = db.Colume(db.Integer, primary_key=True) title = db.Colume(db.String) content = db.Colume(db.Text) 查询使用: # 查询 Entry 表中, title 或 content 中包含 &quot;chuck norris&quot; 的字段 Entry.query.whooshee_search(&quot;chuck norris&quot;).order_by(Entry.id.desc()).all 3.2 跨表检索需要创建 whooshee 的子类, 实现跨表索引 from flask_sqlalchemy import SQLAlchemy from flask_whooshee import Whooshee, AbstractWhoosheer class User(db.Model): id = db.Colume(db.Integer, primary_key=True) name = db.Colume(db.String) # you can still keep the model whoosheer @whooshee.register_model(&apos;title&apos;, &apos;content&apos;) class Entry(db.Model): id = db.Colume(db.Integer, primary_key=True) title = db.Colume(db.String) content = db.Colume(db.Text) user = db.relationshio(User, backref=db.backref(&quot;entries&quot;)) user_id = db.Colume(db.Integer, db.ForeignKey(&quot;user.id&quot;)) # custom whoosheer class which we will use to update the User and Entry indexes: @whooshee.register_whoosheer class EntryUserWhoosheer(AbstractWhoosheer): # create schema , the unique attribute must be in form of model.__name__.lower() + &apos;_&apos; + &apos;id&apos; (name of model primary key) schema = whoosh.fields.Schema( entry_id = whoosh.fields.NUMERIC(stored=Truem, unique=True), user_id = whoosh.fields.NUMERIC(stored=Truem), username = whoosh.fields.TEXT(), title = whoosh.fields.TEXT(), content = whoosh.fields.TEXT()) # do not forget to list the included models models = [Entry, User] # create insert_* and update_* methods for all models # if you have camel case names like FooBar, just lowercase them: insert_foobar, update_foobar. @classmethod def update_user(cls, writer, user): pass # TODO: update all users entries @classmethod def update_entry(cls, writer, entry): writer.update_document(entry_id=entry.id, user_id=entry.user.id, username=entry.user.name, title=entry.title, content=entry.content) @classmethod def insert_user(cls, writer, user): pass # nothing , user doesn&apos;t have entries yet. @classmethod def insert_entry(cls, writer, entry): writer.add_document(entry_id=entry.id, user_id=entry.user.id, username=entry.user.name, title=entry.title, content=entry.content) @classmethod def delete_user(cls, writer, user): pass # TODO: delete all users entries @classmethod def delete_entry(cls, writer, entry): writer.delete_by_term(&apos;entry_id&apos;, entry.id) # to register all whoosheers in one place, just call the `Whooshee.register_whoosheer()` method like this: whooshee.register_whoosheer(EntryUserWhoosheer) 查询使用: # will find any joined entry &lt;--&gt; query # whose User.name or Entry.title, Entry.content matches &apos;chuck norris&apos; Entry.query.join(User).whooshee_search(&quot;chuck norris&quot;).order_by(Entry.id.desc()).all() The whoosheer that is used for searching is, by default, selected based on the models participating in the query. This set of models is compared against the value of models attribute of each registered whoosheer and the one with an exact match is selected. You can override this behaviour by explicitly passing whoosheer that should be used for searching to the WhoosheeQuery.whooshee_search() method. This is useful if you don’t want to join on all the models that form the search index. # If there exists an entry of a user called ‘chuck norris’, # this entry will be found because the custom whoosheer, # that contains field username, will be used. # But without the whoosheer option, # that entry won’t be found (unless it has ‘chuck&amp;nbsp;norris’ in content or title) # because the model whoosheer will be used. Entry.query.whooshee_search(&apos;chuck norris&apos;, whoosheer=EntryUserWhoosheer).order_by(Entry.id.desc()).all() 3.3 检索结果排序默认情况下, 只有枷锁结果的前 10 个会被根据相关性排序, 可以通过设置 order_by_relevance 参数修改默认值. # 所有结果均根据相关性排序 Entry.query.join(User).whooshee_search(&quot;chuck norris&quot;, order_by_relevance=-1).all() # 所有结果均不排序 Entry.query.join(User).whooshee_search(&quot;chuck norris&quot;, order_by_relevance=0).all() # 修改默认值 10. Entry.query.join(User).whooshee_search(&quot;chuck norris&quot;, order_by_relevance=25).all() 3.4 索引3.4.1 重新索引当索引数据丢失或使用 Flask-Whooshee 索引已存在的数据时, 可以使用 Whooshee.reindex() 方法重新索引数据. from flask_whooshee import Whooshee whooshee = Whooshee(app) whoosheer.reindex() 3.4.2 手动更新索引If your application depends heavily on write operations and there are lots of concurrent search-index updates, you might want opt for a cron job invoking whooshee.reindex() periodically instead of employing the default index auto-updating mechanism. This is especially recommended, if you encouter LockError raised by python-whoosh module and setting WHOOSHEE_WRITER_TIMEOUT to a higher value (default is 2) does not help. To disable index auto updating, set auto_update class property of a Whoosheer to False: @whooshee.register_whoosheer class NewEntryUserWhoosheer(EntryUserWhoosheer): auto_update = False By setting the configuration option WHOOSHEE_ENABLE_INDEXING to False, you can turn of any operations with the Whoosh index (creating, updating and deleting entries). This can be useful e.g. when mass-importing large amounts of entries for testing purposes, but you don’t actually need the whooshee fulltext search for these tests to pass.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Flask 扩展</tag>
        <tag>全文索引</tag>
        <tag>whooshee</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python yaml 解析]]></title>
    <url>%2F2018%2F03%2F16%2Fpython-yml%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[依赖 $ pip install pyyaml 示例文件 : $ cat test.yaml host: ip00: 192.168.1.1 ip01: one: 192.168.1.2 two: 192.168.1.254 soft: apache: 2.2 mysql: 5.2 php: 5.3 解析 &gt; import yaml &gt; s = yaml.load(file(&quot;test.yaml&quot;)) &gt; print s # s 为字典 {&apos;host&apos;: {&apos;ip00&apos;: &apos;192.168.1.1&apos;, &apos;ip01&apos;: {&apos;one&apos;: &apos;192.168.1.2&apos;, &apos;two&apos;: &apos;192.168.1.254&apos;}}, &apos;soft&apos;: {&apos;apache&apos;: 2.2, &apos;mysql&apos;: 5.2, &apos;php&apos;: 5.3}} 写入 &gt; file=&apos;kkk.yaml&apos; &gt; data={&apos;host&apos;: {&apos;ip01&apos;: {&apos;two&apos;: &apos;192.168.1.254&apos;, &apos;one&apos;: &apos;192.168.1.2&apos;}, &apos;ip00&apos;: &apos;192.168.1.1&apos;}, &apos;soft&apos;: {&apos;apache&apos;: 2.2, &apos;php&apos;: 5.3, &apos;mysql&apos;: 5.2}} &gt; f=open(file,&apos;w&apos;) &gt; yaml.dump(data,f) &gt; f.close() yaml 语法1) 基本规则① 基本语法规则 - 大小写敏感, - 使用缩进表示层级关系 - 缩进时, 不允许用 Tab 键, 只允许使用空格. - 缩进的空格数目不重要, 只要相同层级的元素左侧对齐即可. ② 支持的数据结构 - 对象 : 键值对的集合, 又称为字典/映射/哈希 - 数组 : 一组按次序排序的值, 又称为序列/列表 - 纯量 : 单个的, 不可再分的值. ③ 注释 : # 2) 对象 : 一组键值对, 使用冒号结构表示animal: pets hash: {name: Steve, foo: bar} # 将所有键值对写成一个行内对象. 3) 数组 : 一组横线开头的行,- cat - dog - goldfish 数据结构的子成员是一个数组, 则可以在该项下面缩进一个空格. - - cat - dog - goldfish 数组使用行内表示法 : animal: [cat, dog] 4) 复合结构 : 对象 + 数组languages: - ruby - perl - python websites: YAML: yaml.org Ruby: ruby-lang.org Python: python.org Perl: use.perl.org 5) 纯量 : 最基本的, 不可再分的值.字符串 : ① 默认不使用引号表示 ② 字符串中包含空格,或者特殊字符, 需要放在引号之中. str: &apos;内容： 字符串&apos; ③ 单引号和双引号都可以使用, 双引号不会对特殊字符串转义. s1: &apos;内容\n字符串&apos; s2: &quot;内容\n字符串&quot; ④ 单引号之中如果还有单引号, 必须连续使用两个单引号转义. str: &apos;labor&apos;&apos;s day&apos; ⑤ 多行字符串, 从第二行开始, 必须有一个单空格缩进, 换行符会被转换为空格. | : 保留换行符 &gt; : 折叠换行 + : 保留文字块默认的换行, - : 删除字符串末尾的换行. this: | Foo Bar that: &gt; Foo Bar 转换后 : { this: &apos;Foo\nBar\n&apos;, that: &apos;Foo Bar\n&apos; } s1: | Foo s2: |+ Foo s3: |- Foo 转换后 : { s1: &apos;Foo\n&apos;, s2: &apos;Foo\n\n\n&apos;, s3: &apos;Foo&apos; } ⑥ 字符串中插入 HTML 标记. message: | &lt;p style=&quot;color: red&quot;&gt; 段落 &lt;/p&gt; 布尔值 : true, false isBoy: true 整数 : 以 字面量 形式表示 number: 12 浮点数 : 以 字面量 形式表示 number: 12.345 Null : ~ parent: ~ 时间 : ISO8601 格式 iso8601: 2001-12-14t21:59:43.10-05:00 日期 : 复合 iso8601 格式的年、月、日表示。 date: 1976-07-31 强制类型转换 : !!TYPE VAR, 使用两个感叹号，强制转换数据类型。 e: !!str 123 f: !!str true 7) 引用 :&amp; : 锚点, 用来建立锚点,* : 别名, 用来引用锚点&lt;&lt; : 合并到当前数据 示例 : defaults: &amp;defaults adapter: postgres host: localhost development: database: myapp_development &lt;&lt;: *defaults test: database: myapp_test &lt;&lt;: *defaults 等同于如下代码 : defaults: adapter: postgres host: localhost development: database: myapp_development adapter: postgres host: localhost test: database: myapp_test adapter: postgres host: localhost 示例 : - &amp;showell Steve - Clark - Brian - Oren - *showell 转换后为 : [ &apos;Steve&apos;, &apos;Clark&apos;, &apos;Brian&apos;, &apos;Oren&apos;, &apos;Steve&apos; ]]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>PyPi</tag>
        <tag>yaml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[/dev/shm 与 tmpfs]]></title>
    <url>%2F2018%2F03%2F16%2Fdev_shm-%E4%B8%8E-tmpfs%2F</url>
    <content type="text"><![CDATA[1./dev/shm 与 tmpfs/dev/shm/是linux下一个目录，/dev/shm目录不在磁盘上，而是在内存里, 类型为 tmpfs ，因此使用linux /dev/shm/ 的效率非常高，直接写进内存. tmpfs有以下特点： tmpfs 是一个文件系统，而不是块设备。 动态文件系统的大小。 tmpfs 的另一个主要的好处是它闪电般的速度。因为典型的 tmpfs 文件系统会完全驻留在 RAM 中，读写几乎可以是瞬间的。 tmpfs 数据在重新启动之后不会保留，因为虚拟内存本质上就是易失的。 2.linux /dev/shm 默认容量linux下/dev/shm的容量默认最大为内存的一半大小，使用 df -h 命令可以看到。但它并不会真正的占用这块内存，如果/dev/shm/下没有任何文件，它占用的内存实际上就是0字节；如果它最大为1G，里头放有100M文件，那剩余的900M仍然可为其它应用程序所使用，但它所占用的100M内存，则不会被系统回收重新划分. 3.linux /dev/shm 容量(大小)调整linux /dev/shm容量(大小)是可以调整，在有些情况下(如oracle数据库)默认的最大一半内存不够用，并且默认的 inode 数量很低一般都要调高些，这时可以用mount命令来管理它。 mount -o size=1500M -o nr_inodes=1000000 -o noatime,nodiratime -o remount /dev/shm 在2G的机器上，将最大容量调到1.5G，并且inode数量调到1000000，这意味着大致可存入最多一百万个小文件 通过/etc/fstab文件来修改/dev/shm的容量(增加size选项即可),修改后，重新挂载即可. 参考: linux /dev/shm的用途参考: kernel tmpfs 文档]]></content>
      <categories>
        <category>计算机原理与操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[容器网络规范]]></title>
    <url>%2F2018%2F03%2F16%2F%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[类型: 1.原始容器网络, 桥接 –&gt; Nat 和 端口映射 桥接模式 HOST 模式 Container 模式 2.容器网络规范CNM 和 CNI 不是网络实现, 而是网络规范和网络体系. 这两个模型完全插件化的, 用户可以以插件的形式去插入具体的网络实现. 1) Container Networking Model (CNM)主导 : docker 公司, –&gt; 不够灵活, 是 docker 原生网络实现. 实现 : 现已被 Cisco Contiv, Kuryr , Open Virtual Networking(OVN), Project Calico, VMware 和 weave 这些公司和项目支持. 结构解析: Libnetwork 是 CNM 的原生实现, 他为 docker daemon 和 网络驱动程序之间提供了接口. 网路控制器负责将驱动和一个网络进行对接, 每个驱动程序负责管理它所拥有的网络以及为该网络提供的各种服务, 如 IPAM 等. 由多个驱动支撑的多个网络可以同时并存. 网络驱动可以按提供方式划为原生驱动(libnetwork内置的或docker 支持的)或者远程驱动(第三方插件). 原生驱动包括 none,bridge,overlay,MACvlan. 驱动也可以按照适用范围划分为本地(单主机)和全局(多主机) Network Sandbox : 容器内部的网络栈, 包含 interface,路由表,及DNS等配置, 可以看做基于容器网络配置的一个隔离环境(其概念类似 &apos;network namespace&apos;) Endpoint : 网络接口, 一端在网络容器内, 另一端在网络内. 一个 Endpoint 可以加入一个网络, 一个容器可以有多个 Endpoint. Network : 一个 Endpoint 的集合, 该集合内的所有 Endpoint 可以互联互通, (其概念类似于 Linux Bridge, VLAN) CNM 支持标签(lables), lable 是以 key-value对 定义的元数据, 用户可以通过定义lable这样的元数据来自定义 libnetwork 和驱动的行为. 2) Container Networking Interface (CNI)主导 : google k8s 主导 –&gt; 更具通用性, 十分灵活拍. 实现 : 采纳该规范的包括 Mesos, Cloud Foundry, Kubernets, Kurma, rkt. 另外 Contiv Networking , project Calico 和 Weave 这些项目为 CNI 提供插件支持. 结构解析 : CNI 的规范比较小巧, 规定了一个容器runtgime 和网络插件之间简单的契约. 这个契约通过 JSON 的语法定义了CNI插件所需要提供的输入和输出. 一个容器可以被加入到不同插件锁駆动的多个网络之中. 一个网络有自己对应的插件和唯一的名称. CNI 插件需要提供两个指令: 一个用来将网络接口加入到指定网络, 一个用来将其移除. 这两个接口分别在容器被创建和销毁的时候调用. 在使用CNI 接口是容器runtime 首先需要分配一个网络命名空间以及一个容器ID, 然后联通一些CNI配置参数传给网络驱动. 接着网络驱动会将该容器链接到网络并将分配IP地址以及JSON的格式的返回给容器runtime. 目前 CNI 的功能涵盖了IPAM,L2和L3 , 端口映射(L4) 则用容器runtime 自己负责. CNI 也没有规定端口映射的实现. 这样比较简单的设计对于 Mesos 来讲有些问题. 端口映射是其中之一. 另外一个问题是: 当CNI的配置被改变时, 容器的行为在规范中没有定义. 为此 Mesos 在CNI agent 重启的时候, 会使用该容器与CNI关联的配置.]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 进程, 线程 与 进程间通信]]></title>
    <url>%2F2018%2F03%2F16%2FLinux-%E8%BF%9B%E7%A8%8B-%E7%BA%BF%E7%A8%8B-%E4%B8%8E%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[进程如何使用内存.当程序文件运行为进程时, 进程在内存中获得空间. 1) Text : 固定大小 存储指令(instruction), 说明每一步的操作. 2) Global Data : 固定大小 存放全局变量 3) Stack 存放局部变量. 以帧(stack frame) 为单位, 当程序调用函数的时候, stack 向下增长一帧. 帧中存储该函数的参数和局部变量, 以及该函数的返回地址(return address). 此时, 计算机控制权转移到被调用的函数, 该函数处于激活状态(active). 位于栈最下方的帧, 和全局变量一起, 构成了当前的环境(context) 上下文. 激活的函数可以从环境中调用需要的变量. 典型的编程语言都只允许你使用位于 stack 最下方的帧, 而不允许你调用其他的帧(这也符合 stack 先进先出的特征). 当函数又进一步调用另一个函数的时候, 一个新的帧会继续增加到帧的下方, 控制权移交到新的函数当中. 当激活函数返回的时候, 会从栈中弹出(pop, 读取并从占中删除)该帧, 并根据帧中记录的返回地址, 将控制权交给返回地址所指定的指令. 在进程运行的过程中, 通过调用和返回函数, 控制权不断在函数间转移. 进程可以在调用函数的时候, 原函数的帧中保存有在我们离开时的状态, 并为新的函数开辟所需的帧空间. 在调用函数返回时, 该函数的帧所占据的空间随着帧的弹出而清空. 进程再次回到原函数的帧中保存的状态, 并根据返回地址所指向的指令继续执行. 上面的过程不断继续, 栈不断增长或减小, 主函数返回的时候, 栈全部清空, 进程结束. 4) Heap 存放动态变量(dynamic variable). 程序利用 malloc 系统调用, 直接从内存中为 dynamic variable 开辟空间. 当程序总使用 malloc 的时候, 堆(heap)会向上增长, 其增长的部分就成为 malloc 从内存中分配的空间. malloc 开辟的空间会一直存在, 知道我们调用 free系统调用来释放, 或者进程结束. 一个经典的错误的 内存泄露(memory leakage), 就是指我们没有释放不再使用的堆空间, 导致堆不断增长, 而内存不可用空间不断减少. 堆和栈的大小则会随着进程的运行增大或变小. 当栈和堆增长到两者相遇的时候, 再无内存可用. 进程会出现 栈溢出(stack overflow) 的错误, 导致进程终止. 进程附加信息 : task_struct每个进程还要包括一些进程附加信息, 包括 PID,PPID,PGID等, 用来说明程序的身份,进程关系,以及其他统计信息. 这些信息并不保存在进程自己的内存空间中. 内核 为每个进程在内核自己的空间中分配一个变量(task_struct 结构体)以保存上述信息. 内核可以通过查看自己空间中的各个进程的附加信息就能知道进程的概况, 而不用进入到进程自身的空间. 每个进程的附加信息中都有位置专门用于保存接受到的信息. fork &amp;&amp; execfork : 当程序调用 fork 的时候, 实际上就是讲上面的内存空间, 包括 text,global data, heap,stack, 又赋值出来一个, 构成新的进程, 并在内核中为该进程创建新的附加信息(如pid等), 此后, 两个进程分别地继续运行下去, 新的进程和原有的进程有相同的进程状态(相同的变量值, 相同的 instruction), 我们会只能通过进程的附加信息来区分两者. exec : 程序调用 exec 的时候, 进程清空自身内存空间 text, global data,heap,stack. 并根据新的程序文件重建 text,glabal data ,heap,stack (此时 heap 和 stack 大小都为 0), 并开始运行. 多线程多线程就是允许一个进程内存在多个控制权, 以便让多个函数同时处于激活状态, 从而让多个函数的操作同时运行. 即使是单cpu 的计算机,也可以通过不停的在不同线程的指令键切换, 从而造成多线程同事运行的效果. main() 到 func3() 再到 main() 构成一个线程, func1 和 func2 构成另外两个线程. 操作系统一般都有一些系统调用来让你讲一个函数运行成为一个新的线程. 创建一个新的线程时，我们为这个线程建一个新的栈。每个栈对应一个线程。当某个栈执行到全部弹出时，对应线程完成任务，并收工。所以，多线程的进程在内存中有多个栈。多个栈之间以一定的空白区域隔开，以备栈的增长。每个线程可调用自己栈最下方的帧中的参数和变量，并与其它线程共享内存中的Text，heap和global data区域。对应上面的例子，我们的进程空间中需要有3个栈。 多线程同步对于多线程来说, 同步(synchronization) 是指在一定的时间内, 之允许某一个线程来访问某个资源. 可以通过 互斥锁(mutex)/条件变量(condition variable)/读写锁(reader-writer lock)来同步资源. 互斥锁(mutex)互斥锁是一个特殊变量, 有 锁上(lock) 和 打开(ublock) 两个状态. 互斥锁一般被设置成全局变量. 打开的互斥锁可以由某个线程获得, 一旦获得, 这个互斥锁会锁上, 此后只有该线程有权打开. 其他想要获得互斥锁的线程, 会等待知道互斥锁再次打开的时候. (可以将互斥锁想成只能容纳一个人的洗手间,可以从里面将洗手间锁上。其它人只能在互斥锁外面等待那个人出来，才能进去。在外面等候的人并没有排队，谁先看到洗手间空了，就可以首先冲进去。) 条件变量(condition variable)条件变量时另一种常用的变量, 常常被保存为全局变量,并和互斥锁合作. 条件变量特别适用于多个线程等待某个条件的发生。如果不使用条件变量，那么每个线程就需要不断尝试获得互斥锁并检查条件是否发生，这样大大浪费了系统的资源。 如 : 有100个工人，每人负责装修一个房间。当有10个房间装修完成的时候，老板就通知相应的十个工人一起去喝啤酒。 读写锁(reader-writer lock)读写锁与互斥锁非常相似, 有三种状态 : 共享读取锁(shared-read), 互斥写入锁(exclusive-write lock), 打开(unlock). 后两种状态与之前的互斥锁两种状态完全相同. 一个 unlock 的 RW lock 可以被其他线程继续获得 R 锁, 而不必等待该线程释放 R 锁. 但是, 如果此时有其他线程想要获得 W 所, 必须等待所有持有共享读取锁的线程释放到各自的 R 锁. 如果一个锁被一个线程获得 W 锁, 那么其他线程, 无论是想要获取 R 锁还是 W 锁, 都必须等待该线程释放 W 锁. 这样, 多个线程就可以同时读取共享资源, 而具有危险性的写入操作则得到了互斥锁的保护. 同步并发系统，这为程序员编程带来了难度。但是多线程系统可以很好的解决许多IO瓶颈的问题。 Linux 进程间通信.管道(PIPE)可以使用管道将一个进程的输出和另一个进程的输入连接起来，从而利用文件操作API来管理进程间通信。 管道是由内核管理的一个缓冲区(buffer)，相当于我们放入内存中的一个纸条。管道的一端连接一个进程的输出。这个进程会向管道中放入信息。管道的另一端连接一个进程的输入，这个进程取出被放入管道的信息。一个缓冲区不需要很大，它被设计成为环形的数据结构，以便管道可以被循环利用。当管道中没有信息的话，从管道中读取的进程会等待，直到另一端的进程放入信息。当管道被放满信息的时候，尝试放入信息的进程会等待，直到另一端的进程取出信息。当两个进程都终结的时候，管道也自动消失。 从原理上，管道利用fork机制建立，从而让两个进程可以连接到同一个PIPE上。最开始的时候，上面的两个箭头都连接在同一个进程Process 1上(连接在Process 1上的两个箭头)。当fork复制进程的时候，会将这两个连接也复制到新的进程(Process 2)。随后，每个进程关闭自己不需要的一个连接 (两个黑色的箭头被关闭; Process 1关闭从PIPE来的输入连接，Process 2关闭输出到PIPE的连接)，这样，剩下的红色连接就构成了如上图的PIPE。 由于基于fork机制，所以管道只能用于父进程和子进程之间，或者拥有相同祖先的两个子进程之间 (有亲缘关系的进程之间)。为了解决这一问题，Linux提供了FIFO方式连接进程。FIFO又叫做命名管道(named PIPE)。 FIFO (First in, First out)为一种特殊的文件类型，它在文件系统中有对应的路径。当一个进程以读(r)的方式打开该文件，而另一个进程以写(w)的方式打开该文件，那么内核就会在这两个进程之间建立管道，所以FIFO实际上也由内核管理，不与硬盘打交道。之所以叫FIFO，是因为管道本质上是一个先进先出的队列数据结构，最早放入的数据被最先读出来(好像是传送带，一头放货，一头取货)，从而保证信息交流的顺序。FIFO只是借用了文件系统(file system)来为管道命名。写模式的进程向FIFO文件中写入，而读模式的进程从FIFO文件中读出。当删除FIFO文件时，管道连接也随之消失。FIFO的好处在于我们可以通过文件的路径来识别管道，从而让没有亲缘关系的进程之间建立连接。 传统 IPC (interprocess communication) : 特点是允许多进程之间共享资源.消息队列(message queue) 信号量(semaphore) 共享内存(shared memory) 不使用文件操作的API。 对于任何一种IPC来说，你都可以建立多个连接，并使用键值(key)作为识别的方式。我们可以在一个进程中中通过键值来使用的想要那一个连接 (比如多个消息队列，而我们选择使用其中的一个)。键值可以通过某种IPC方式在进程间传递(比如说我们上面说的PIPE，FIFO或者写入文件)，也可以在编程的时候内置于程序中。 消息队列(message queue)与PIPE相类似。它也是建立一个队列，先放入队列的消息被最先取出。不同的是，消息队列允许多个进程放入消息，也允许多个进程取出消息。每个消息可以带有一个整数识别符(message_type)。你可以通过识别符对消息分类 (极端的情况是将每个消息设置一个不同的识别符)。某个进程从队列中取出消息的时候，可以按照先进先出的顺序取出，也可以只取出符合某个识别符的消息(有多个这样的消息时，同样按照先进先出的顺序取出)。消息队列与PIPE的另一个不同在于它并不使用文件API。最后，一个队列不会自动消失，它会一直存在于内核中，直到某个进程删除该队列。 semaphore与mutex类似，用于处理同步问题。我们说mutex像是一个只能容纳一个人的洗手间，那么semaphore就像是一个能容纳N个人的洗手间。其实从意义上来说，semaphore就是一个计数锁(我觉得将semaphore翻译成为信号量非常容易让人混淆semaphore与signal)，它允许被N个进程获得。当有更多的进程尝试获得semaphore的时候，就必须等待有前面的进程释放锁。当N等于1的时候，semaphore与mutex实现的功能就完全相同。许多编程语言也使用semaphore处理多线程同步的问题。一个semaphore会一直存在在内核中，直到某个进程删除它。 共享内存与多线程共享global data和heap类似。一个进程可以将自己内存空间中的一部分拿出来，允许其它进程读写。当使用共享内存的时候，我们要注意同步的问题。我们可以使用semaphore同步，也可以在共享内存中建立mutex或其它的线程同步变量来同步。由于共享内存允许多个进程直接对同一个内存区域直接操作，所以它是效率最高的IPC方式。 互联网通信实际上也是一个进程间通信的问题，只不过这多个进程分布于不同的电脑上。网络连接是通过socket实现的。 参考参考参考参考参考]]></content>
      <categories>
        <category>计算机原理与操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>进程</tag>
        <tag>线程</tag>
        <tag>进程间通信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 内部组件结构 docker daemon, container,runC]]></title>
    <url>%2F2018%2F03%2F16%2Fdocker-%E5%86%85%E9%83%A8%E7%BB%84%E4%BB%B6%E7%BB%93%E6%9E%84-docker-daemon-container-runC%2F</url>
    <content type="text"><![CDATA[Docker, Containerd, RunC :从 Docker 1.11 开始, docker 容器运行已经不是简单地通过 Docker Daemon 来启动, 而是集成了Container, RunC 等多个组件. Docker 服务启动之后, 可以看到系统上启动了 Docker, Docker-container 等进程. 以下介绍 docker(1.11 版本之后每个部分的功能和作用.) OCI 标准Linux基金会于2015年6月成立OCI（Open Container Initiative）组织，旨在围绕容器格式和运行时制定一个开放的工业化标准。该组织一成立便得到了包括谷歌、微软、亚马逊、华为等一系列云计算厂商的支持。而runC就是Docker贡献出来的，按照该开放容器格式标准（OCF, Open Container Format）制定的一种具体实现。 docker 模块结构从Docker 1.11之后，Docker Daemon被分成了多个模块以适应OCI标准。 docker daemon : 独立成单独二进制程序.docker 1.8 之前, 启动会命令: $ docker -d docker 1.8 之后, 启动命令变成了 : $ docker daemon docker 1.11 开始, 启动命令变成了 : $ dockerd containerdcontainerd 是运用 runC（或者任何与 OCI 兼容的程序）来管理容器，通过 gRPC 暴露功能的简易守护进程。相比于 Docker Engine，暴露容器相关的 CRUD 接口使用成熟的 HTTP API，Docker Engine 不仅能暴露容器，还能暴露镜像、数据卷、网络、构建等。 containerd 是容器技术标准化之后的产物, 为了能够兼容 OCI 标准, 将容器运行时及其管理功能从 Docker Daemon 剥离. 理论上, 即使不运行 dockerd 也能直接通过 containerd 来管理容器.(当然, containerd 本身也只是一个守护进程, 容器的实际运行时由 runC 控制.) container(已开源), 其主要职责是镜像管理(镜像, 元信息等), 容器执行(调用最终运行时组件执行). container 向上为 docker daemon 提供了 gRPC 接口, 使得 docker daemon 屏蔽下面的结构变化, 确保原有接口向下兼容. 向下通过 container-shim 结合 runC, 使得引起可以独立升级, 避免之前 docker daemon 升级会导致所有容器不可用的问题.(见上面 docker_mod_arch 图) docker , container , container-shim 之间的关系, 可以通过启动一个 docekr 容器观察之间的管理. ① 启动一个容器: $ docker run -d alpine sleep 1000 ② 查看docker daemon 的pid $ ps aux |grep dockerd # 1480 ③ 查看进程之间的父子关系 $ pstree -l -a -A 1480 dockerd -H fd:// |-docker-containe -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --shim docker-containerd-shim --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --runtime docker-runc | |-docker-containe 2b9251bcc7a4484662c8b69174d92b3183f0f09a59264b412f14341ebb759626 /var/run/docker/libcontainerd/2b9251bcc7a4484662c8b69174d92b3183f0f09a59264b412f14341ebb759626 docker-runc | | |-sleep 1000 | | `-7*[{docker-containe}] | `-9*[{docker-containe}] `-11*[{dockerd}] 当 docker daemon 启动之后, docker 和 docker-container 进程一直存在. 当启动容器之后, docker-container 进程(container 组件)会创建 docker-containerd-shim 进程. 其中 2b9251bcc7a4484662c8b69174d92b3183f0f09a59264b412f14341ebb759626 就是要启动容器的 ID, 最后 docker-containerd-shim 子进程, 液晶是在容器中运行的进程(sleep 1000) 其中 /var/run/docker/libcontainerd/2b9251bcc7a4484662c8b69174d92b3183f0f09a59264b412f14341ebb759626 里面内容有 : /var/run/docker/libcontainerd/2b9251bcc7a4484662c8b69174d92b3183f0f09a59264b412f14341ebb759626 ├── config.json # 容器配置 ├── init-stderr # 标准错误输出 ├── init-stdin # 标准输入 └── init-stdout # 标准输出. RunCunC 是一种只专注于运行容器的轻量级工具。如果你了解 Docker Engine 的早期历史，你就知道它曾经用 LXC 来启动和管理容器；后来它演变为 “libcontainer”。“libcontainer” 是一段与 cgroup 和 namespace 这些 Linux 内核交互的代码，这些内核是容器构建的基石。 简言之，runC 基本上是一种无需进入 Docker Engine，直接控制 libcontainer 的小型命令行工具，是一种管理和运行 OCI 容器的单机二进制. OCI 定义了容器运行时标准, runC 是 Docker 按照 开放容器格式标准(OCF, Open Container Format) 制定的一种具体实现. runC 是从 Docker 的 libcontainer 中迁移而来的, 实现了容器启停,资源隔离等功能. Docker 默认提懂了 docekr-runc 实现, 事实上, 通过 containerd 的疯转, 可以在 Docker daemon 启动的时候指定 runC 的实现. 可以通过在启动 docker daemon 时, 增加 --add-runtime 参数来选择其他的 runC 实现. $ docker daemon --add-runtime &quot;custom=/usr/local/bin/my-runc-replacement&quot; runC 特征 : 1. 支持所有的Linux namespaces，包括user namespaces。目前user namespaces尚未包含。 2. 支持Linux系统上原有的所有安全相关的功能，包括Selinux、 Apparmor、seccomp、cgroups、capability drop、pivot_root、 uid/gid dropping等等。目前已完成上述功能的支持。 3. 支持容器热迁移，通过CRIU技术实现。目前功能已经实现，但是使用起来还会产生问题。 4. 支持Windows 10 平台上的容器运行，由微软的工程师开发中。目前只支持Linux平台。 5. 支持Arm、Power、Sparc硬件架构，将由Arm、Intel、Qualcomm、IBM及整个硬件制造商生态圈提供支持。 6. 计划支持尖端的硬件功能，如DPDK、sr-iov、tpm、secure enclave等等。 7. 生产环境下的高性能适配优化，由Google工程师基于他们在生产环境下的容器部署经验而贡献。 example : 通过 docker 一些命令, 实现不使用 docker daemon 直接运行一个镜像.① 创建容器标准包, 由 container 的 bundle 模块实现, 将 docker 镜像转换成容器标准包 $ mkdir my_container $ cd my_container $ mkdir rootfs $ docker export $(docker create busybox) | tar -C rootfs -xvf - 上述命令, 将 busybox 镜像解压缩到指定的 rootfs 目录中. 如果本地不存在 busybox 进香港, containerd 会通过 distribution 模块去远程仓库拉取. ② 创建配置文件 $ docker-runc spec # 会生成一个 config.json 的配置文件, 该文件和 docker 容器的配置文件类似, 主要包含容器挂载信息, 平台信息, 进程信息等容器启动以来的所有数据. ③ 通过 runc 命令来启动容器 $ apt install runc -y $ runc run busybox docker-proxydocker 的端口转发工具. 实现容器与主机的端口映射. 示例 : $ docker run -itd -p 8008:80008 busybox /bin/sh $ ps aux |grep docker # 注意查看 docker-proxy 的端口对应. root 1498 0.0 0.1 234236 12020 ? Ssl 3月12 4:56 docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --shim docker-containerd-shim --runtime docker-runc root 88902 0.0 0.0 34464 2936 ? Sl 11:21 0:00 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 8008 -container-ip 172.17.0.3 -container-port 8008 root 88906 0.0 0.0 198748 2920 ? Sl 11:21 0:00 docker-containerd-shim 695522643fb8a54ea5d7483ca353c95ed91cba3f2e18ce4b2af286bbc6c3412b /var/run/docker/libcontainerd/695522643fb8a54ea5d7483ca353c95ed91cba3f2e18ce4b2af286bbc6c3412b docker-runc docker-proxy 命令行 $ docker-proxy --help Usage of docker-proxy: -container-ip string container ip -container-port int container port (default -1) -host-ip string host ip -host-port int host port (default -1) -proto string proxy protocol (default &quot;tcp&quot;)]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker daemon</tag>
        <tag>runc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python celery 任务队列]]></title>
    <url>%2F2018%2F03%2F16%2Fpython-celery-%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[一. celery 简介Celery 是一个专注于实时处理和任务调度的分布式任务队列, 同时提供操作和维护分布式系统所需的工具.. 所谓任务就是消息, 消息中的有效载荷中包含要执行任务需要的全部数据. Celery 是一个分布式队列的管理工具, 可以用 Celery 提供的接口快速实现并管理一个分布式的任务队列. Celery 本身不是任务队列, 是管理分布式任务队列的工具. 它封装了操作常见任务队列的各种操作, 我们使用它可以快速进行任务队列的使用与管理. Celery 特性 : 方便查看定时任务的执行情况, 如 是否成功, 当前状态, 执行任务花费的时间等. 使用功能齐备的管理后台或命令行添加,更新,删除任务. 方便把任务和配置管理相关联. 可选 多进程, Eventlet 和 Gevent 三种模型并发执行. 提供错误处理机制. 提供多种任务原语, 方便实现任务分组,拆分,和调用链. 支持多种消息代理和存储后端. Celery 是语言无关的.它提供了python 等常见语言的接口支持. 二. celery 组件1. Celery 扮演生产者和消费者的角色, Celery Beat : 任务调度器. Beat 进程会读取配置文件的内容, 周期性的将配置中到期需要执行的任务发送给任务队列. Celery Worker : 执行任务的消费者, 通常会在多台服务器运行多个消费者, 提高运行效率. Broker : 消息代理, 队列本身. 也称为消息中间件. 接受任务生产者发送过来的任务消息, 存进队列再按序分发给任务消费方(通常是消息队列或者数据库). Producer : 任务生产者. 调用 Celery API , 函数或者装饰器, 而产生任务并交给任务队列处理的都是任务生产者. Result Backend : 任务处理完成之后保存状态信息和结果, 以供查询. Celery架构图 2. 产生任务的方式 : 发布者发布任务(WEB 应用) 任务调度按期发布任务(定时任务) 3. celery 依赖三个库: 这三个库, 都由 Celery 的开发者开发和维护. billiard : 基于 Python2.7 的 multisuprocessing 而改进的库, 主要用来提高性能和稳定性. librabbitmp : C 语言实现的 Python 客户端, kombu : Celery 自带的用来收发消息的库, 提供了符合 Python 语言习惯的, 使用 AMQP 协议的高级借口. 三. 选择消息代理使用于生产环境的消息代理有 RabbitMQ 和 Redis, 官方推荐 RabbitMQ. 四. Celery 序列化在客户端和消费者之间传输数据需要 序列化和反序列化. Celery 支出的序列化方案如下所示: 方案 说明 pickle pickle 是Python 标准库中的一个模块, 支持 Pyuthon 内置的数据结构, 但他是 Python 的专有协议. Celery 官方不推荐. json json 支持多种语言, 可用于跨语言方案. yaml yaml 表达能力更强, 支持的数据类型较 json 多, 但是 python 客户端的性能不如 json msgpack 二进制的类 json 序列化方案, 但比 json 的数据结构更小, 更快. 五. 安装,配置与简单示例Celery 配置参数汇总 配置项 说明 CELERY_DEFAULT_QUEUE 默认队列 CELERY_BROKER_URL Broker 地址 CELERY_RESULT_BACKEND 结果存储地址 CELERY_TASK_SERIALIZER 任务序列化方式 CELERY_RESULT_SERIALIZER 任务执行结果序列化方式 CELERY_TASK_RESULT_EXPIRES 任务过期时间 CELERY_ACCEPT_CONTENT 指定任务接受的内容类型(序列化) 代码示例 : # 安装 $ pip install celery, redis, msgpack # 配置文件 celeryconfig.py CELERY_BROKER_URL = &apos;redis://localhost:6379/1&apos; CELERY_RESULT_BACKEND = &apos;redis://localhost:6379/0&apos; CELERY_TASK_SERIALIZER = &apos;json&apos; CELERY_RESULT_SERIALIZER = &apos;json&apos; CELERY_TASK_RESULT_EXPIRES = 60 * 60 * 24 # 任务过期时间 CELERY_ACCEPT_CONTENT = [&quot;json&quot;] # 指定任务接受的内容类型. # 初始化文件 celery.py from __future__ import absolute_import from celery import Celery app = Celery(&apos;proj&apos;, include=[&quot;proj.tasks&quot;]) app.config_from_object(&quot;proj.celeryconfig&quot;) if __name__ == &quot;__main__&quot;: app.start() # 任务文件 tasks.py from __future__ import absolute_import from proj.celery import app @app.task def add(x, y): return x + y # 启动消费者 $ celery -A proj worker -l info # 在终端中测试 &gt; from proj.tasks import add &gt; r = add.delay(2,4) &gt; r.result 6 &gt; r.status u&quot;SUCCESS&quot; &gt; r.successful() True &gt; r.ready() # 返回布尔值, 任务执行完成, 返回 True, 否则返回 False. &gt; r.wait() # 等待任务完成, 返回任务执行结果. &gt; r.get() # 获取任务执行结果 &gt; r.result # 任务执行结果. &gt; r.state # PENDING, START, SUCCESS &gt; r.status # PENDING, START, SUCCESS # 使用 AsyncResult 方式获取执行结果. # AsyncResult 主要用来存储任务执行信息与执行结果(类似 js 中的 Promise 对象), &gt; from celery.result import AsyncResult &gt; AsyncResult(task_id).get() 4 六. 调用任务的方法 :1. delaytask.delay(args1, args2, kwargs=value_1, kwargs2=value_2) 2. apply_asyncdelay 实际上是 apply_async 的别名, 还可以使用如下方法调用, 但是 apply_async 支持更多的参数: task.apply_async(args=[arg1, arg2], kwargs={key:value, key:value}) 支持的参数 : countdown : 等待一段时间再执行. add.apply_async((2,3), countdown=5) eta : 定义任务的开始时间. add.apply_async((2,3), eta=now+tiedelta(second=10)) expires : 设置超时时间. add.apply_async((2,3), expires=60) retry : 定时如果任务失败后, 是否重试. add.apply_async((2,3), retry=False) retry_policy : 重试策略. max_retries : 最大重试次数, 默认为 3 次. interval_start : 重试等待的时间间隔秒数, 默认为 0 , 表示直接重试不等待. interval_step : 每次重试让重试间隔增加的秒数, 可以是数字或浮点数, 默认为 0.2 interval_max : 重试间隔最大的秒数, 即 通过 interval_step 增大到多少秒之后, 就不在增加了, 可以是数字或者浮点数, 默认为 0.2 . 自定义发布者,交换机,路由键, 队列, 优先级,序列方案和压缩方法: task.apply_async((2,2), compression=&apos;zlib&apos;, serialize=&apos;json&apos;, queue=&apos;priority.high&apos;, routing_key=&apos;web.add&apos;, priority=0, exchange=&apos;web_exchange&apos;) 七. 指定队列 :Celery 默认使用名为 celery 的队列 (可以通过 CELERY_DEFAULT_QUEUE 修改) 来存放任务. 我们可以使用 优先级不同的队列 来确保高优先级的任务优先执行. # 修改配置文件, 保证队列优先级 from kombu import Queue CELERY_QUEUE = ( # 定义任务队列. Queue(&apos;default&apos;, routing_key=&quot;task.#&quot;), # 路由键 以 &quot;task.&quot; 开头的消息都进入 default 队列. Queue(&apos;web_tasks&apos;, routing_key=&quot;web.#&quot;) # 路由键 以 &quot;web.&quot; 开头的消息都进入 web_tasks 队列. ) CELERY_DEFAULT_EXCHANGE = &apos;tasks&apos; # 默认的交换机名字为 tasks CELERY_DEFAULT_EXCHANGE_KEY = &apos;topic&apos; # 默认的交换机类型为 topic CELERY_DEFAULT_ROUTING_KEY = &apos;task.default&apos; # 默认的路由键是 task.default , 这个路由键符合上面的 default 队列. CELERY_ROUTES = { &apos;proj.tasks.add&apos;: { &apos;queue&apos;: &apos;web_tasks&apos;, &apos;routing_key&apos;: &apos;web.add&apos;, } } # 使用指定队列的方式启动消费者进程. $ celery -A proj worker -Q web_tasks -l info # 该 worker 只会执行 web_tasks 中任务, 我们可以合理安排消费者数量, 让 web_tasks 中任务的优先级更高. 阅后即焚模式(transient): from kombu import Queue Queue(&apos;transient&apos;, routing_key=&apos;transient&apos;, delivery_mode=1) 八. 使用任务调度使用 Beat 进程自动生成任务. # 修改配置文件, # 下面的任务指定 tasks.add 任务 每 10s 跑一次, 任务参数为 (16,16). from datetime import timedelta CELERYBEAT_SCHEDULE = { &apos;add&apos;: { &apos;task&apos;: &apos;proj.tasks.add&apos;, &apos;schedule&apos;: timedelta(seconds=10), &apos;args&apos;: (16, 16) } } # crontab 风格 from celery.schedules import crontab CELERYBEAT_SCHEDULE = { &quot;add&quot;: { &quot;task&quot;: &quot;tasks.add&quot;, &quot;schedule&quot;: crontab(hour=&quot;*/3&quot;, minute=12), &quot;args&quot;: (16, 16), } } # 启动 Beat 程序 $ celery beat -A proj # 之后启动 worker 进程. $ celery -A proj worker -l info 或者 $ celery -B -A proj worker -l info 使用自定义调度类还可以实现动态添加任务. 使用 Django 可以通过 Django-celery 实现在管理后台创建,删除,更新任务, 是因为他使用了自定义的 调度类 djcelery.schedulers.DatabaseScheduler . 九. 任务绑定, 记录日志, 重试# 修改 tasks.py 文件. from celery.utils.log import get_task_logger logger = get_task_logger(__name__) @app.task(bind=True) def div(self, x, y): logger.info((&apos;Executing task id {0.id}, args: {0.args!r}&apos; &apos;kwargs: {0.kwargs!r}&apos;).format(self.request)) try: result = x/y except ZeroDivisionError as e: raise self.retry(exc=e, countdown=5, max_retries=3) # 发生 ZeroDivisionError 错误时, 每 5s 重试一次, 最多重试 3 次. return result 当使用 bind=True 参数之后, 函数的参数发生变化, 多出了参数 self, 这这相当于把 div 编程了一个已绑定的方法, 通过 self 可以获得任务的上下文. 十. 信号系统 :信号可以帮助我们了解任务执行情况, 分析任务运行的瓶颈. Celery 支持 7 种信号类型. 任务信号 before_task_publish : 任务发布前 after_task_publish : 任务发布后 task_prerun : 任务执行前 task_postrun : 任务执行后 task_retry : 任务重试时 task_success : 任务成功时 task_failure : 任务失败时 task_revoked : 任务被撤销或终止时 应用信号 Worker 信号 Beat 信号 Eventlet 信号 日志信号 命令信号 不同的信号参数格式不同, 具体格式参见官方文档 代码示例 : # 在执行任务 add 之后, 打印一些信息. @after_task_publish def task_send_handler(sender=None, body=None, **kwargs): print &apos;after_task_publish: task_id: {body[id]}; sender: {sender}&apos;.format(body=body, sender=sender) 十一. 子任务与工作流:可以把任务 通过签名的方法传给其他任务, 成为一个子任务. from celery import signature task = signature(&apos;task.add&apos;, args=(2,2), countdown=10) task task.add(2,2) # 通过签名生成任务 task.apply_async() 还可以通过如下方式生成子任务 : from proj.task import add task = add.subtask((2,2), countdown=10) # 快捷方式 add.s((2,2), countdown-10) task.apply_async() 自任务实现片函数的方式非常有用, 这种方式可以让任务在传递过程中财传入参数. partial = add.s(2) partial.apply_async((4,)) 子任务支持如下 5 种原语,实现工作流. 原语表示由若干指令组成的, 用于完成一定功能的过程. chain : 调用连, 前面的执行结果, 作为参数传给后面的任务, 直到全部完成, 类似管道. from celery import chain res = chain(add.s(2,2), add.s(4), add.s(8))() res.get() 管道式: (add.s(2,2) | add.s(4) | add.s(8))().get() group : 一次创建多个(一组)任务. from celery import group res = group(add.s(i,i) for i in range(10))() res.get() chord : 等待任务全部完成时添加一个回调任务. res = chord((add.s(i,i) for i in range(10)), add.s([&apos;a&apos;]))() res.get() # 执行完前面的循环, 把结果拼成一个列表之后, 再对这个列表 添加 &apos;a&apos;. [0,2,4,6,8,10,12,14,16,18,u&apos;a&apos;] map/starmap : 每个参数都作为任务的参数执行一遍, map 的参数只有一个, starmap 支持多个参数. add.starmap(zip(range(10), range(10))) 相当于: @app.task def temp(): return [add(i,i) for i in range(10)] chunks : 将任务分块. res = add.chunks(zip(range(50), range(50)),10)() res.get() 在生成任务的时候, 应该充分利用 group/chain/chunks 这些原语. 十二. 其他关闭不想要的功能 :@app.task(ignore_result=True) # 关闭任务执行结果. def func(): pass CELERY_DISABLE_RATE_LIMITS=True # 关闭限速. 根据任务状态执行不同操作 :# tasks.py class MyTask(Task): def on_success(self, retval, task_id, args, kwargs): print &apos;task done: {0}&apos;.format(retval) return super(MyTask, self).on_success(retval, task_id, args, kwargs) def on_failure(self, exc, task_id, args, kwargs, einfo): print &apos;task fail, reason: {0}&apos;.format(exc) return super(MyTask, self).on_failure(exc, task_id, args, kwargs, einfo) # 正确函数, 执行 MyTask.on_success() : @app.task(base=MyTask) def add(x, y): return x + y # 错误函数, 执行 MyTask.on_failure() : @app.task #普通函数装饰为 celery task def add(x, y): raise KeyError return x + y 十三. Celery 管理命令任务状态回调 : 参数 说明 PENDING 任务等待中 STARTED 任务已开始 SUCCESS 任务执行成功 FAILURE 任务执行失败 RETRY 任务将被 重试 REVOKED 任务取消 PROGRESS 任务进行中 普通启动命令 :$ celery -A proj worker -l info 使用 daemon 方式 multi :$ celery multi start web -A proj -l info --pidfile=/path/to/celery_%n.pid --logfile=/path/to/celery_%n.log # web 是对项目启动的标识, # %n 是对节点的格式化用法. %n : 只包含主机名 %h : 包含域名的主机 %d : 只包含域名 %i : Prefork 类型的进程索引,如果是主进程, 则为 0. %I : 带分隔符的 Prefork 类型的进程索引. 假设主进程为 worker1, 那么进程池的第一个进程则为 worker1-1 常用 multi 相关命令: $ celery multi show web # 查看 web 启动时的命令 $ celery multi names web # 获取 web 的节点名字 $ celery multi stop web # 停止 web 进程 $ celery multi restart web # 重启 web $ celery multi kill web # 杀掉 web 进程 常用监控和管理命令 : shell : 交互时环境, 内置了 Celery 应用实例和全部已注册的任务, 支持 默认解释器,IPython,BPython . $ celery shell -A proj result : 通过 task_id 在命令行获得任务执行结果 $ celery -A proj result TASK_ID inspect active : 列出当前正在执行的任务 $ celery -A proj inspect active inspect stats : 列出 worker 的统计数据, 常用来查看配置是否正确以及系统的使用情况. $ celery -A proj inspect stats Flower web 监控工具 查看任务历史,任务具体参数,开始时间等信息; 提供图表和统计数据 实现全面的远程控制功能, 包括但不限于 撤销/终止任务, 关闭重启 worker, 查看正在运行任务 提供一个 HTTP API , 方便集成. Flower 的 supervisor 管理配置文件: [program:flower] command=/opt/PyProjects/venv/bin/flower -A celery_worker:celery --broker=&quot;redis://localhost:6379/2&quot; --address=0.0.0.0 --port=5555 directory=/opt/PyProjects/app autostart=true autorestart=true startretries=3 user=derby stdout_logfile=/var/logs/%(program_name)s.log stdout_logfile_maxbytes=50MB stdout_logfile_backups=30 stderr_logfile=/var/logs/%(program_name)s-error.log stderr_logfile_maxbytes=50MB stderr_logfile_backups=3 Celery 自带的事件监控工具显示任务历史等信息.$ celery -A proj event ** 需要把 CELERY_SEND_TASK_SEND_EVENT = True 设置, 才可以获取时间. 使用自动扩展 :$ celery -A proj worker -l info --autoscale=6,3 # 平时保持 3 个进程, 最大时可以达到 6 个. Celery 命令汇总$ celery --help -A APP, --app APP -b BROKER, --broker BROKER --loader LOADER --config CONFIG --workdir WORKDIR --no-color, -C --quiet, -q $ celery &lt;command&gt; --help + Main: | celery worker | celery events | celery beat | celery shell | celery multi | celery amqp + Remote Control: | celery status | celery inspect --help | celery inspect active | celery inspect active_queues | celery inspect clock | celery inspect conf [include_defaults=False] | celery inspect memdump [n_samples=10] | celery inspect memsample | celery inspect objgraph [object_type=Request] [num=200 [max_depth=10]] | celery inspect ping | celery inspect query_task [id1 [id2 [... [idN]]]] | celery inspect registered [attr1 [attr2 [... [attrN]]]] | celery inspect report | celery inspect reserved | celery inspect revoked | celery inspect scheduled | celery inspect stats | celery control --help | celery control add_consumer &lt;queue&gt; [exchange [type [routing_key]]] | celery control autoscale [max [min]] | celery control cancel_consumer &lt;queue&gt; | celery control disable_events | celery control election | celery control enable_events | celery control heartbeat | celery control pool_grow [N=1] | celery control pool_restart | celery control pool_shrink [N=1] | celery control rate_limit &lt;task_name&gt; &lt;rate_limit (e.g., 5/s | 5/m | 5/h)&gt; | celery control revoke [id1 [id2 [... [idN]]]] | celery control shutdown | celery control terminate &lt;signal&gt; [id1 [id2 [... [idN]]]] | celery control time_limit &lt;task_name&gt; &lt;soft_secs&gt; [hard_secs] + Utils: | celery purge | celery list | celery call | celery result | celery migrate | celery graph | celery upgrade + Debugging: | celery report | celery logtool + Extensions: | celery flower 十四. 在 Flask 中使用 CeleryFlask 文档: 基于 Celery 的后台任务在 Flask 中使用 Celery 十五. 参考链接Python Web开发实战]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>PyPi</tag>
        <tag>Celery</tag>
        <tag>任务队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubernetes 学习笔记]]></title>
    <url>%2F2018%2F03%2F16%2Fdocker-kubernetes%2F</url>
    <content type="text"><![CDATA[版本: 基于 Kubernetes v1.6 及以上. 主要功能: 基于容器的应用部署, 维护和滚动升级 负载均衡和服务发现 跨机器和跨地区的集群调度 自动伸缩 无状态服务 和 有状态服务 广泛的 Volume 支持 插件机制保证扩展性. 1. 简介1.1 核心组件: etcd : 保存整个集群的状态; apiserver : 提供资源的操作的唯一入口, 并提供认证,授权,访问控制, API 注册和发现等机制. controller manager : 负责维护集群的状态, 如 故障检测, 自动扩展, 滚动更新; scheduler : 负责资源的调度, 按照都预定的调度策略将 Pod 调度到相应的机器上. kubelet : 负责维护容器的生命周期, 同时也负责 Volume(CVI) 和 网络(CNI) 的管理. Container runtime : 负责镜像管理以及 Pod 和容器的真正运行(CRI) kube-proxy : 负责为 Service 提供 cluster 内部的服务发现和负载均衡 Add-ons 组件: kube-dns : 负责为整个集群提供 DNS 服务. Ingress Controller : 为服务提供外网入口. Heapster : 提供资源监控 Dashboard : 提供 GUI. Federation : 提供跨可用区的集群. Fluentd-elasticsearch : 提供集群日志采集,存储与查询. 1.2 基本概念manifest在 kubernetes 中, 所有对象都使用 manifest (yaml 或 json) 来定义. 编写 yaml 文件时, 可使用 kubectl explain RESOURCR , 获取所有关键字及其用法.Valid resource types include: * buildconfigs (aka &apos;bc&apos;) * builds * clusters (valid only for federation apiservers) * componentstatuses (aka &apos;cs&apos;) * configmaps (aka &apos;cm&apos;) * daemonsets (aka &apos;ds&apos;) * deployments (aka &apos;deploy&apos;) * deploymentconfigs (aka &apos;dc&apos;) * endpoints (aka &apos;ep&apos;) * events (aka &apos;ev&apos;) * horizontalpodautoscalers (aka &apos;hpa&apos;) * imagestreamimages (aka &apos;isimage&apos;) * imagestreams (aka &apos;is&apos;) * imagestreamtags (aka &apos;istag&apos;) * ingresses (aka &apos;ing&apos;) * groups * jobs * limitranges (aka &apos;limits&apos;) * namespaces (aka &apos;ns&apos;) * networkpolicies * nodes (aka &apos;no&apos;) * persistentvolumeclaims (aka &apos;pvc&apos;) * persistentvolumes (aka &apos;pv&apos;) * pods (aka &apos;po&apos;) * podsecuritypolicies (aka &apos;psp&apos;) * podtemplates * policies * projects * replicasets (aka &apos;rs&apos;) * replicationcontrollers (aka &apos;rc&apos;) * resourcequotas (aka &apos;quota&apos;) * rolebindings * routes * secrets * serviceaccounts (aka &apos;sa&apos;) * services (aka &apos;svc&apos;) * statefulsets * users * storageclasses * thirdpartyresources 如下是一个 nginx 服务定义: appVersion: v1 kind: Pod metadata: name: nginx labels: app: nginx spec: containers: - name: nginx images: nginx ports: - containerPort: 80 PodPod 是一组紧密关联的容器集合, 他们共享 IPC, Network, UTC namespace. 是 Kubernetes 调度的基本单位. Pod 的设计理念是支持多个容器在一个 Pod 中共享网络和文件系统, 可以通过进程间通信和文件共享这种简单高效的方式完成服务. NodeNode 是 Pod 真正运行的主机, 可以是物理机, 也可为 虚拟机. 为了管理 Pod, 每个 Node 节点上至少要运行 container runtime(如 docker, rkt), kubelet 和 kube-proxy 服务. NamespaceNamespace 是对一组资源和对象的抽象集合, 如可以用来将系统内部的对象划分为不同的项目组或用户组. 常见的 pods, services , replication controllers 和 deployments 等都是属于某一个 namespace 的 (默认为 default), 而 node/persistenVolumes 等则不属于任何 namespace . VolumePod 的生命周期通常比较短, 主要出现异常, 就会创建一个新的 Pod 来代替他. 此时, 容器中产生的数据, 需要一个位置来保存. Volume 就是为了持久化容器数据为产生的. apiVersion: v1 kind: Pod metadata: name: redis spec: containers: - name: redis image: redis volumeMounts: - name: redis-persistent-storage mountPath: /data/redis volumes: - name: redis-persistent-storage hostPath: path: /data Kubernetes Volume 支持非常多的插件, 可以根据实际需要来选择: emptyDir hostPath gcePersistentDisk awsElasticBlockStore nfs iscsi flocker glusterfs rbd cephfs gitRepo secret persistentVolumeClaim downwardAPI azureFileVolume vsphereVolume ServiceService 是应用服务的抽象, 通过 labels 为应用提供负载均衡和服务发现. 匹配 labels 的 Pod IP 和 端口列表组成 endpoints , 由 kube-proxy 负责将服务 IP 负载均衡到这些 endpoints 上. 每个 Service 都会自动分配一个 cluster IP (仅在集群内部可以访问的虚拟地址) 和 DNS 名, 其他容器可以通过该 地址或 DNS 来访问服务, 而不需要了解后端容器的运行. apiVersion: v1 kind: Service metadata: name: nginx spec: ports: - ports: 8087 # the port that this service should server on name: http targetPort: 80 # the container on each pod to connect to, can be a name(e.g. &apos;www&apos;) or a number (e.g. 80) protocol: TCP selector: app: nginx deploymentLabelLabel 是识别 Kubernetes 对象的标签, 以 key/value 的方式附加到对象上(key &lt; 63 字节, 0 &lt;= value &lt; 253 字节) Label 不提供唯一性, 并且实际上经常是很多对象(如 Pods) 都使用相同的 label 来标识具体的应用. Label 定义好之后, 其他对象可以使用 Label Selector 来选择一组相同 label 的对象(如 ReplicaSet 和 Service 用 label 来选择一组 Pod ). Label Selector 支持一下方式: 等式 : 如 app=nginx 和 evn!=production 集合 : 如 env in (production, qa) 多个 label (他们之间是 AND 关系) : 如 app=nginx, env=test Annotations –&gt; 注释Annotations 是 key/value 形式附加与对象的注释. 不同于 Labels 用于标识和选择对象, Annotations 则是用来记录一些附加信息, 用来辅助应用部署, 安全策略以及调度策略等. 如 deployment 使用 annotations 来记录 rolling update 的状态. 1.3 命令概览命令概览: $ kubectl help Basic Commands (Beginner): create Create a resource by filename or stdin expose Take a replication controller, service, deployment or pod and expose it as a new Kubernetes Service run Run a particular image on the cluster set Set specific features on objects Basic Commands (Intermediate): get Display one or many resources explain Documentation of resources edit Edit a resource on the server delete Delete resources by filenames, stdin, resources and names, or by resources and label selector Deploy Commands: rollout Manage a deployment rollout rolling-update Perform a rolling update of the given ReplicationController scale Set a new size for a Deployment, ReplicaSet, Replication Controller, or Job autoscale Auto-scale a Deployment, ReplicaSet, or ReplicationController Cluster Management Commands: certificate Modify certificate resources. cluster-info Display cluster info top Display Resource (CPU/Memory/Storage) usage cordon Mark node as unschedulable uncordon Mark node as schedulable drain Drain node in preparation for maintenance taint Update the taints on one or more nodes Troubleshooting and Debugging Commands: describe Show details of a specific resource or group of resources logs Print the logs for a container in a pod attach Attach to a running container exec Execute a command in a container port-forward Forward one or more local ports to a pod proxy Run a proxy to the Kubernetes API server cp Copy files and directories to and from containers. Advanced Commands: apply Apply a configuration to a resource by filename or stdin patch Update field(s) of a resource using strategic merge patch replace Replace a resource by filename or stdin convert Convert config files between different API versions Settings Commands: label Update the labels on a resource annotate Update the annotations on a resource completion Output shell completion code for the given shell (bash or zsh) Other Commands: api-versions Print the supported API versions on the server, in the form of &quot;group/version&quot; config Modify kubeconfig files help Help about any command version Print the client and server version information Use &quot;kubectl &lt;command&gt; --help&quot; for more information about a given command. Use &quot;kubectl options&quot; for a list of global command-line options (applies to all commands). 示例: # 创建单个容器, 实际上创建的是一个有 deployment 来管理的 Pod. `kubectl run` 先创建一个 Deployment 资源(replicas=1), 再由 Deployment 来自动创建 Pod . 但是 kubectl run 并不支持所有的功能. $ kubectl run --image=nginx nginx-app --port=80 kubectl run 与如下的操作是等价的: $ vim single_nginx.yaml apiVersion: extensions/v1beta1 kind: Deployment metadata: label: run: nginx-app name: nginx-app namespace: default spec: replicas: 1 selector: matchLabels: run: nginx-app strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 1 type: rollingUpdate template: metadata: labels: run: nginx-app spec: containers: - image: nginx name: nginx-app ports: - containerPort: 80 protocol: TCP dnsPolicy: ClusterFirst restartPolicy: Always $ kubectl create -f single_nginx.yaml $ kubectl expose deployment nginx-app --type=NodePort --port=80 --target=80 # 将 deploy nginx-app 转变为 service $ kubectl describe service nginx-app # kubectl get : 查询资源列表, 类似 docker ps # kubectl describe : 获取资源的详细信息, 类似 docker inspect # kubectl logs : 获取容器日志, 类似 docker logs # kubectl exec : 在容器内部执行命令, 类似 docker exec. $ kubectl exec -it POD_NAME /bin/bash # 进入 pod 内部. 1.4 应用升级与扩展 扩展应用: 修改 Deployment 中的副本的数量(replicas), 可以动态扩展或收缩应用. $ kubectl scal --replicas=3 deployment/nginx-app $ kubectl get deployment 滚动升级 滚动升级(Rolling Update) 通过逐个容器替代升级的方式来实现无中断的服务升级. $ kubectl rolling-update frontend-v1 frontend-v2 --image=image:v2 在滚动升级的过程中, 如果发现失败或配置错误, 可以随时回滚: $ kubectl rolling-update frontend-v1 frontend-v2 --rollback 注意: rolling-update 只针对 ReplicationController, 不能用在策略不是RollingUpdate 的 Deployment 上 (Deployment 可以在 spec 中设置更新策略为 RollingUpdate, 默认就是 RollingUpdate): spec: replicas: 3 selector: matchLabels: run: nginx-app strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 1 type: RollingUpdate 更新应用的话, 可以直接用 kubectl set: $ kubectl set image deployment/nginx-app nginx-app=nginx:1.9.1 滚动升级的过程可以用 rollout 命令查看: $ kubectl rollout status deployment/nginx-app Deployment 回滚: # 显示版本历史 $ kubectl rollout history deployment/nginx-app # 回滚 $ kubectl rollout undo deployment/nginx-app 1.5 资源限制Kubernetes 通过 cgroups 提供容器资源管理功能, 可以限制每个容器的 CPU 和 内存使用. 在 资源运行过程中, 动态修改 资源限制. # 限制 deployment 资源: 限制资源的更新, 将导致 容器重启. $ kubectl set resources deployment nginx-app -c=nginx --limits=cpu=500m,memory=123Mi 在 manifest 中定义: apiVersion: v1 kind: Pod metadata: labels: app: nginx name: nginx spec: containers: - image: nginx name: nginx resources: limits: cpu: &quot;500m&quot; memory: &quot;128Mi&quot; 1.6 健康检查Kubernetes 提供两种探针(Probe, 支持 exec, tcp, http 方式)来探测容器的状态: LivenessProbe : 探测应用是否处于健康状态, 如果不健康则删除重建容器. ReadinessProbe : 探测应用是否启动完成并且处于正常服务状态, 如果不正常则更新容器状态. manifest 示例: resources: limits: cpu: &quot;500m&quot; memory: &quot;128Mi&quot; livenessProbe: httpGet: path: / port: 80 initialDelaySeconds: 15 timeoutSeconds: 1 readinessProbe: httpGet: path: /ping port: 80 initialDelaySeconds: 5 timeoutSeconds: 1 对于已经部署的 deployment, 可以通过 kubectl edit deployment/nginx-app 来动态更新manifest. 1.7 集群联邦(Federation)集群联邦用于跨可用区的 Kubernetes 集群, 需要配合云服务商(如 GCE, AWS) 一起实现. 1.8 Kubernetes 单机版 手动安装 $ yum install ectd kubernetes -y 使用 minikube $ minikube start $ kubectl cluster-info 2. 核心原理Kubernetes 提供了面向应用的容器集群部署和管理系统. Kubernetes 的目标旨在消除编排物理/虚拟计算,网络和存储基础设施的负担, 并使应用程序运行商和开发人员完全将重点放在以容器为中心的原语上进行自助运营. Kubernetes 也提供稳定, 兼容的基础(平台), 用于构建定制化的 workflows 和更高的自动化任务. Kubernetes 具备完善的集群管理能力, 多层次的安全防护和准入机制, 多租户应用支撑能力, 透明的服务注册和服务发现机制, 内建负载均衡器, 故障发现和自我修复能力, 服务滚动升级和在线扩容, 可扩展的资源换自动调度机制, 多粒度的资源配额管理能力. Kubernetes 还提供完善的管理工具, 涵盖开发, 部署测试和运维监控等各个环节. Kubernetes 分层架构 Container Runtime, Network Plugin, Volume Plugin, Image Registry, Cloud Provider, Identify Provider. Nuclens: API and Execution Kubernetes 最核心的功能, 对外提供 API 构建高层的应用, 对内提供插件式应用执行环境. Application Layer: Deployment and Routing 部署(无状态应用, 有状态应用, 批处理任务, 集群应用等) 路由(服务发现, DNS 解析等) Governance Layer: Automation and Policy Enforcement 系统度量 : 如基础设施, 容器和网络的度量 自动化 : 自动扩展, 动态 Provision 策略管理 : RBAC, Quota, PSP, NetworkPolicy 等. Interface Layer: Client Libraries and Tools. kubectl 命令行工具 客户端 SDK 集群联邦 Ecosystem 在接口层之上的庞大容器寄存管理调度的生态系统, 可以划分为两个范围: Kubernetes 外部 : 日志, 监控, 配置管理, CI/CD, Workflow, Faas, OTS应用, ChatOps 等 Kubernetes 内部: CRI, CNI, CVI, 镜像仓库, CloudProvider, 集群自身的配置和管理等. 2.1 设计理念未完成 : 2017年9月29日15:24:20 k8s 系统最核心的两个设计概念: 容错性 + 易扩展性 2.1.1 API 设计原则对于云计算系统, 系统 API 实际上处于系统和设计的统领地位. k8s 集群系统每支持一项新功能, 引入一项新技术, 一定回新引入对应的 API 对象, 支持对该功能的管理操作. 所有 API 应该是声明式的 声明式的操作, 相对于命令式的操作, 对于重复操作的效果是稳定的.这对于容易出现数据丢失或重复的分布式环境来说是很重要的. 声明式操作更容易被用户使用, 可以使系统向用户隐藏实现的细节, 同时, 保留了系统未来持续优化的可能性. 声明式 API 同时隐含了所有的 API 对象都是名词性质的, 如 Service, Volume 这些 API 都是名词, 这些名词描述了用户所期望得到的一个目标分布式对象. API 对象是彼此互不而且可组合的 API 对象尽量实现面向对象设计时的要求, 即 高内聚, 松耦合, 对业务相关的概念有一个合适的分解, 提高分解出来的对象的可重用性. 事实上, k8s 这种分布式系统管理平台, 也是一种业务系统, 只不过它的业务就是调度和管理容器服务. 高层 API 以操作意图为基础设计 高层设计一定是从业务触发, 而不是过早的从技术实现出发. 因此, 针对 k8s 的高层 API 设计, 一定是以 k8s 的业务基础触发, 也就是以系统调度管理容器的操作意图为基础设计. 低层 API 根据高层 API 的控制需要设计 设计实现 低层API 的目的, 是为了被高层API使用, 考虑减少冗余, 提高重用性的目的, 低层API 的设计也要以需求为基础, 尽量抵抗受技术实现影响的诱惑. 尽量避免简单封装, 不要有在外部 API 无法显式知道的内部隐藏的机制. 简单的封装, 实际没有提供新的功能, 反而增加了对所封装API的依赖性. 内部隐藏的机制也是非常不利于系统维护的设计方式, 例如PetSet和ReplicaSet, 本来就是两种Pod集合, 那么K8s就用不同API对象来定义它们, 而不会说只用同一个ReplicaSet, 内部通过特殊的算法再来区分这个ReplicaSet是有状态的还是无状态. API 操作复杂度与对象数量成正比. 这一条主要是从系统性能角度考虑, 要保证整个系统随着系统规模的扩大, 性能不会迅速变慢到无法使用, 那么最低的限定就是API的操作复杂度不能超过O(N), N是对象的数量, 否则系统就不具备水平伸缩性了. API 对象状态不能依赖于网络连接状态. 由于众所周知, 在分布式环境下, 网络连接断开是经常发生的事情, 因此要保证API对象状态能应对网络的不稳定, API对象的状态就不能依赖于网络连接状态. 尽量避免让操作机制依赖于全局状态, 因为在分布式系统中要保证全局状态的同步是非常困难的. 2.1.2 控制机制设计原则 控制逻辑应该只依赖于当前状态 这是为了保证分布式系统的稳定可靠, 对于经常出现局部错误的分布式系统, 如果控制逻辑只依赖当前状态, 那么就非常容易将一个暂时出现故障的系统恢复到正常状态, 因为你只要将该系统重置到某个稳定状态, 就可以自信的知道系统的所有控制逻辑会开始按照正常方式运行. 假设任何错误的可能, 并做容错处理 在一个分布式系统中出现局部和临时错误是大概率事件. 错误可能来自于物理系统故障, 外部系统故障也可能来自于系统自身的代码错误, 依靠自己实现的代码不会出错来保证系统稳定其实也是难以实现的, 因此要设计对任何可能错误的容错处理. 尽量避免复杂状态机, 控制逻辑不要依赖无法监控的内部状态. 因为分布式系统各个子系统都是不能严格通过程序内部保持同步的, 所以如果两个子系统的控制逻辑如果互相有影响, 那么子系统就一定要能互相访问到影响控制逻辑的状态, 否则, 就等同于系统里存在不确定的控制逻辑. 假设任何操作都可能被任何操作对象拒绝, 甚至被错误解析. 由于分布式系统的复杂性以及各子系统的相对独立性, 不同子系统经常来自不同的开发团队, 所以不能奢望任何操作被另一个子系统以正确的方式处理, 要保证出现错误的时候, 操作级别的错误不会影响到系统稳定性. 每个模块都可以在出错后自动恢复. 由于分布式系统中无法保证系统各个模块是始终连接的, 因此每个模块要有自我修复的能力, 保证不会因为连接不到其他模块而自我崩溃. 每个模块都可以在必要时优雅的降级服务. 所谓优雅地降级服务, 是对系统鲁棒性的要求, 即要求在设计实现模块时划分清楚基本功能和高级功能, 保证基本功能不会依赖高级功能, 这样同时就保证了不会因为高级功能出现故障而导致整个模块崩溃. 根据这种理念实现的系统, 也更容易快速地增加新的高级功能, 以为不必担心引入高级功能影响原有的基本功能. 2.1.3 核心技术概念 和 API 对象API 对象是 k8s 集群中的管理操作单元. 每个 API 对象都有 3 大类属性: metadata : 元数据 用来标识 API 对象的, 每个对象至少有 3 个元数据: namespace name uid 各种各样的 labels. spec : 规范 k8s 中所有的配置都是通过 API 对象 spec 去设置的, 也就是用户通过配置系统的理想状态来改变系统. status : 状态 描述了系统实际当前达到的状态. PodPod的设计理念是支持多个容器在一个Pod中共享网络地址和文件系统, 可以通过进程间通信和文件共享这种简单高效的方式组合完成服务. Pod 是 k8s 集群中所有业务类型的基础. 目前 k8s 中的业务主要可以分为: Deployment : 长期伺服型 (long-running) Job : 批处理型 (batch) DaemonSet : 节点后台支撑型 (node-daemon) PetSet : 有状态应用型 (stateful application) Replication Controller, RC : 复制控制器RC是K8s集群中最早的保证Pod高可用的API对象. 通过监控运行中的Pod来保证集群中运行指定数目的Pod副本. RC是K8s较早期的技术概念, 只适用于长期伺服型的业务类型. Replica Set, RS :RS是新一代RC, 提供同样的高可用能力, 区别主要在于RS后来居上, 能支持更多种类的匹配模式. 副本集对象一般不单独使用, 而是作为Deployment的理想状态参数使用. Deployment部署表示用户对K8s集群的一次更新操作. 部署是一个比RS应用模式更广的API对象, 可以是创建一个新的服务, 更新一个新的服务, 也可以是滚动升级一个服务. 滚动升级一个服务, 实际是创建一个新的RS, 然后逐渐将新RS中副本数增加到理想状态, 将旧RS中的副本数减小到0的复合操作；这样一个复合操作用一个RS是不太好描述的, 所以用一个更通用的Deployment来描述. 以K8s的发展方向, 未来对所有长期伺服型的的业务的管理, 都会通过Deployment来管理. ServiceRC、RS和Deployment只是保证了支撑服务的微服务Pod的数量, 但是没有解决如何访问这些服务的问题. 一个Pod只是一个运行服务的实例, 随时可能在一个节点上停止, 在另一个节点以一个新的IP启动一个新的Pod, 因此不能以确定的IP和端口号提供服务. 要稳定地提供服务需要服务发现和负载均衡能力. 服务发现完成的工作, 是针对客户端访问的服务, 找到对应的的后端服务实例. 在K8s集群中, 客户端需要访问的服务就是Service对象. 每个Service会对应一个集群内部有效的虚拟IP, 集群内部通过虚拟IP访问一个服务. 在K8s集群中微服务的负载均衡是由Kube-proxy实现的. Kube-proxy是K8s集群内部的负载均衡器. 它是一个分布式代理服务器, 在K8s的每个节点上都有一个；这一设计体现了它的伸缩性优势, 需要访问服务的节点越多, 提供负载均衡能力的Kube-proxy就越多, 高可用节点也随之增多. 与之相比, 我们平时在服务器端做个反向代理做负载均衡, 还要进一步解决反向代理的负载均衡和高可用问题. JobJob 是 k8s 用来控制批处理型任务的 API 对象. 批处理业务与长期伺服业务的主要区别是批处理业务的运行有头有尾, 而长期伺服业务在用户不停止的情况下永远运行. Job管理的Pod根据用户的设置把任务成功完成就自动退出了. 成功完成的标志根据不同的spec.completions策略而不同： 单Pod型任务有一个Pod成功就标志完成； 定数成功型任务保证有N个任务全部成功； 工作队列型任务根据应用确认的全局成功而标志成功. DaemonSet长期伺服型和批处理型服务的核心在业务应用, 可能有些节点运行多个同类业务的Pod, 有些节点上又没有这类Pod运行； 而后台支撑型服务的核心关注点在K8s集群中的节点（物理机或虚拟机）, 要保证每个节点上都有一个此类Pod运行. 节点可能是所有集群节点也可能是通过nodeSelector选定的一些特定节点. 典型的后台支撑型服务包括, 存储, 日志和监控等在每个节点上支持K8s集群运行的服务. PetSetK8s在1.3版本里发布了Alpha版的PetSet功能. 在云原生应用的体系里, 有下面两组近义词；第一组是无状态（stateless）、牲畜（cattle）、无名（nameless）、可丢弃（disposable）；第二组是有状态（stateful）、宠物（pet）、有名（having name）、不可丢弃（non-disposable）. RC和RS主要是控制提供无状态服务的, 其所控制的Pod的名字是随机设置的, 一个Pod出故障了就被丢弃掉, 在另一个地方重启一个新的Pod, 名字变了、名字和启动在哪儿都不重要, 重要的只是Pod总数； 而PetSet是用来控制有状态服务, PetSet中的每个Pod的名字都是事先确定的, 不能更改. PetSet中Pod的名字的作用是关联与该Pod对应的状态. 对于RC和RS中的Pod, 一般不挂载存储或者挂载共享存储, 保存的是所有Pod共享的状态, Pod像牲畜一样没有分别; 对于PetSet中的Pod, 每个Pod挂载自己独立的存储, 如果一个Pod出现故障, 从其他节点启动一个同样名字的Pod, 要挂载上原来Pod的存储继续以它的状态提供服务. 适合于PetSet的业务包括数据库服务MySQL和PostgreSQL, 集群化管理服务Zookeeper、etcd等有状态服务. PetSet的另一种典型应用场景是作为一种比普通容器更稳定可靠的模拟虚拟机的机制. 传统的虚拟机正是一种有状态的宠物, 运维人员需要不断地维护它, 容器刚开始流行时, 我们用容器来模拟虚拟机使用, 所有状态都保存在容器里, 而这已被证明是非常不安全、不可靠的. 使用PetSet, Pod仍然可以通过漂移到不同节点提供高可用, 而存储也可以通过外挂的存储来提供高可靠性, PetSet做的只是将确定的Pod与确定的存储关联起来保证状态的连续性. PetSet还只在Alpha阶段, 后面的设计如何演变, 我们还要继续观察. FederationK8s在1.3版本里发布了beta版的Federation功能. 在云计算环境中, 服务的作用距离范围从近到远一般可以有：同主机（Host, Node）、跨主机同可用区（Available Zone）、跨可用区同地区（Region）、跨地区同服务商（Cloud Service Provider）、跨云平台. K8s的设计定位是单一集群在同一个地域内, 因为同一个地区的网络性能才能满足K8s的调度和计算存储连接要求. 而联合集群服务就是为提供跨Region跨服务商K8s集群服务而设计的. 每个K8s Federation有自己的分布式存储、API Server和Controller Manager. 用户可以通过Federation的API Server注册该Federation的成员K8s Cluster. 当用户通过Federation的API Server创建、更改API对象时, Federation API Server会在自己所有注册的子K8s Cluster都创建一份对应的API对象. 在提供业务请求服务时, K8s Federation会先在自己的各个子Cluster之间做负载均衡, 而对于发送到某个具体K8s Cluster的业务请求, 会依照这个K8s Cluster独立提供服务时一样的调度模式去做K8s Cluster内部的负载均衡. 而Cluster之间的负载均衡是通过域名服务的负载均衡来实现的. 所有的设计都尽量不影响K8s Cluster现有的工作机制, 这样对于每个子K8s集群来说, 并不需要更外层的有一个K8s Federation, 也就是意味着所有现有的K8s代码和机制不需要因为Federation功能有任何变化. VolumeK8s集群中的存储卷跟Docker的存储卷有些类似, 只不过Docker的存储卷作用范围为一个容器, 而K8s的存储卷的生命周期和作用范围是一个Pod. 每个Pod中声明的存储卷由Pod中的所有容器共享. K8s支持非常多的存储卷类型, 特别的, 支持多种公有云平台的存储, 包括AWS, Google和Azure云；支持多种分布式存储包括GlusterFS和Ceph；也支持较容易使用的主机本地目录hostPath和NFS. K8s还支持使用Persistent Volume Claim即PVC这种逻辑存储, 使用这种存储, 使得存储的使用者可以忽略后台的实际存储技术（例如AWS, Google或GlusterFS和Ceph）, 而将有关存储实际技术的配置交给存储管理员通过Persistent Volume来配置. 总结:k8s 支持的存储类型: 云存储 : AWS, Google, Azure 分布式存储 : GlusterFS, Ceph 本地存储 : hostPath, NFS Persistent Volume Claim : 逻辑存储, 后端可以使用以上任何一种存储. Persistent Volume(PV, 持久存储卷) and Persistent Volume Claim(PVC, 持久存储卷声明) PV和PVC使得K8s集群具备了存储的逻辑抽象能力, 使得在配置Pod的逻辑里可以忽略对实际后台存储技术的配置, 而把这项配置的工作交给PV的配置者, 即集群的管理者. 存储的PV和PVC的这种关系, 跟计算的Node和Pod的关系是非常类似的；PV和Node是资源的提供者, 根据集群的基础设施变化而变化, 由K8s集群管理员配置；而PVC和Pod是资源的使用者, 根据业务服务的需求变化而变化, 有K8s集群的使用者即服务的管理员来配置. NodeK8s集群中的计算能力由Node提供, 最初Node称为服务节点Minion, 后来改名为Node. K8s集群中的Node也就等同于Mesos集群中的Slave节点, 是所有Pod运行所在的工作主机, 可以是物理机也可以是虚拟机. 不论是物理机还是虚拟机, 工作主机的统一特征是上面要运行kubelet管理节点上运行的容器. SecretSecret是用来保存和传递密码、密钥、认证凭证这些敏感信息的对象. 使用Secret的好处是可以避免把敏感信息明文写在配置文件里. 在K8s集群中配置和使用服务不可避免的要用到各种敏感信息实现登录、认证等功能, 例如访问AWS存储的用户名密码. 为了避免将类似的敏感信息明文写在所有需要使用的配置文件中, 可以将这些信息存入一个Secret对象, 而在配置文件中通过Secret对象引用这些敏感信息. 这种方式的好处包括：意图明确, 避免重复, 减少暴漏机会. User Account &amp;&amp; Service Account顾名思义, 用户帐户为人提供账户标识, 而服务账户为计算机进程和K8s集群中运行的Pod提供账户标识. 用户帐户和服务帐户的一个区别是作用范围；用户帐户对应的是人的身份, 人的身份与服务的namespace无关, 所以用户账户是跨namespace的；而服务帐户对应的是一个运行中程序的身份, 与特定namespace是相关的. Namespace名字空间为K8s集群提供虚拟的隔离作用, K8s集群初始有两个名字空间, 分别是默认名字空间default和系统名字空间kube-system, 除此以外, 管理员可以可以创建新的名字空间满足需要. RBAC 访问授权K8s在1.3版本中发布了alpha版的基于角色的访问控制（Role-based Access Control, RBAC）的授权模式. 相对于基于属性的访问控制（Attribute-based Access Control, ABAC）, RBAC主要是引入了角色（Role）和角色绑定（RoleBinding）的抽象概念. 在ABAC中, K8s集群中的访问策略只能跟用户直接关联；而在RBAC中, 访问策略可以跟某个角色关联, 具体的用户在跟一个或多个角色相关联. 显然, RBAC像其他新功能一样, 每次引入新功能, 都会引入新的API对象, 从而引入新的概念抽象, 而这一新的概念抽象一定会使集群服务管理和使用更容易扩展和重用. 2.2 主要概念PodPod 是一组紧密关联的容器集合, 他们共享 IPC, Network, UTC namespace, 是 kubernetes 调度的基本单位. Pod 的设计理念是支持多个容器在一个 Pod 中共享网络和文件系统, 可以通过进程间通信和文件共享这种简单高效的方式组合完成服务. Pod 特征 包含多个共享IPC、Network和UTC namespace的容器, 可直接通过localhost通信 所有Pod内容器都可以访问共享的Volume, 可以访问共享数据 Pod一旦调度后就跟Node绑定, 即使Node挂掉也不会重新调度, 推荐使用Deployments、Daemonsets等控制器来容错 优雅终止：Pod删除的时候先给其内的进程发送SIGTERM, 等待一段时间（grace period）后才强制停止依然还在运行的进程 特权容器（通过SecurityContext配置）具有改变系统配置的权限（在网络插件中大量应用） Pod 定义通过 yaml 或 json 描述 pod 和其内 container 的运行环境以及期望状态. 一个简单的 nginx pod 定义: apiVersion: v1 kind: Pod metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 使用 VolumeVolume 可以为容器提供持久化存储. apiVersion: v1 kind: Pod metadata: name: redis spec: containers: - name: redis image: redis volumeMounts: - name: redis-storage mountPath: /data/redis volumes: - name: redis-storage emptyDir: {} RestartPolicy支持三种 RestartPolicy: 此处重启指 在 Pod 所在 Node上本地重启, 而不会调度到其他 Node 上. Always : 只要退出就重启 OnFailure : 失败退出(exit code 不等于 0)时重启 Never : 只要退出就不再重启. 资源限制Kubernetes 通过 cgroups 提供容器资源管理的功能, 可以限制每个容器的 CPU 和内存使用等. CPU 的单位是 milicpu, 500mcpu=0.5cpu,内存单位包括 E,P,T,G,M,K,Ei,Pi,Ti,Gi,Mi,Ki 等. apiVersion: v1 kind: Pod metadata: labels: app: nginx name: nginx spec: containers: - image: nginx name: nginx resources: limits: cpu: &quot;500m&quot; memory: &quot;128Mi&quot; 健康检查为了确保容器在部署后确实处于正常运行状态, Kubernetes 提供了两种探针(Probe, 支持 exec, tcp 和 http 方式) 来探测容器的状态. LivenessProbe : 探测应用是否处于健康状态, 如果不健康则删除重建该容器. ReadinessProbe : 探测应用是否启动完成并且处于正常服务状态, 如果不正常则更新容器的状态. apiVersion: v1 kind: Pod metadata: labels: app: nginx name: nginx spec: containers: - image: nginx imagePullPolicy: Always name: http resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File resources: limits: cpu: &quot;500m&quot; memory: &quot;128Mi&quot; livenessProbe: httpGet: path: / port: 80 initialDelaySeconds: 15 timeoutSeconds: 1 readinessProbe: httpGet: path: /ping port: 80 initialDelaySeconds: 5 timeoutSeconds: 1 Init ContainerInit Container 在所有容器运行之前执行(run-to-completion), 常用来初始化配置. apiVersion: v1 kind: Pod metadata: name: init-demo spec: containers: - name: nginx image: nginx ports: - containerPort: 80 volumeMounts: - name: workdir mountPath: /usr/share/nginx/html # These containers are run during pod initialization initContainers: - name: install image: busybox command: - wget - &quot;-O&quot; - &quot;/work-dir/index.html&quot; - http://kubernetes.io volumeMounts: - name: workdir mountPath: &quot;/work-dir&quot; dnsPolicy: Default volumes: - name: workdir emptyDir: {} Hooks支持两种 Hook: postStart : 容器启动后执行, 注意由于是异步执行, 它无法保证一定在 ENTRYPOINT 之后执行. preStop : 容器停止前执行, 常用于资源清理. 示例 : apiVersion: v1 kind: Pod metadata: name: lifecycle-demo spec: containers: - name: lifecycle-demo-container image: nginx lifecycle: postStart: exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello from the postStart handler &gt; /usr/share/message&quot;] preStop: exec: command: [&quot;/usr/sbin/nginx&quot;,&quot;-s&quot;,&quot;quit&quot;] 指定 Node通过 nodeSelector , 一个 Pod 可以指定它所想要运行的 Node 节点. 首先, 先给 Node 加上标签: $ kubectl label nodes &lt;your-node-name&gt; disktype=ssd 然后, 指定该 Pod 只运行在 lable 为 disktype=ssd 的 Node 上. apiVersion: v1 kind: Pod metadata: name: nginx labels: env: test spec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent nodeSelector: disktype: ssd 使用 CapabilitiesCapabilities从2.1版开始,Linux内核有了能力(capability)的概念,即它打破了UNIX/LINUX操作系统中超级用户/普通用户的概念,由普通用户也可以做只有超级用户可以完成的工作. capability可以作用在进程上(受限),也可以作用在程序文件上,它与sudo不同,sudo只针对用户/程序/文件的概述,即sudo可以配置某个用户可以执行某个命令,可以更改某个文件,而capability是让某个程序拥有某种能力. 例如: capability让/tmp/testkill程序可以kill掉其它进程,但它不能mount设备节点到目录,也不能重启系统,因为我们只指定了它kill的能力,即使程序有问题也不会超出能力范围. 每个进程有三个和能力有关的位图: inheritable(I),permitted(P)和effective(E), 对应进程描述符 task_struct(include/linux/sched.h) 里面的 cap_effective, cap_inheritable, cap_permitted,所以我们可以查看/proc/PID/status来查看进程的能力. cap_effective : 当一个进程要进行某个特权操作时,操作系统会检查cap_effective的对应位是否有效,而不再是检查进程的有效UID是否为0.例如,如果一个进程要设置系统的时钟,Linux的内核就会检查cap_effective的CAP_SYS_TIME位(第25位)是否有效. cap_permitted : 表示进程能够使用的能力,在cap_permitted中可以包含cap_effective中没有的能力, 这些能力是被进程自己临时放弃的,也可以说cap_effective是cap_permitted的一个子集. cap_inheritable : 表示能够被当前进程执行的程序继承的能力. 默认情况下, 容器都是以非特权容器的方式运行, 比如, 不能在容器中创建虚拟网卡, 配置虚拟网络. Kubernetes 提供了修改 Capabilities 的机制, 可以按需要给容器增加或删除, 如下配置中, 给容器增加了 CAP_NET_ADMIN 并 删除 CAP_KILL . apiVersion: v1 kind: Pod metadata: name: hello-world spec: containers: - name: friendly-container image: &quot;alpine:3.4&quot; command: [&quot;/bin/echo&quot;, &quot;hello&quot;, &quot;world&quot;] securityContext: capabilities: add: - NET_ADMIN drop: - KILL NamespaceNamespace 是对一组资源和对象的抽象集合, 比如可以用来将系统内部的对象划分为不同的项目组或用户组. 常见的 pods, services, replication controller 和 deployments 等都是属于某一个 namespace 的(默认为 default), 而 node , persistentVolumes 等则不属于任何 namespace . Namespace 常用来隔离不同的用户, 比如 Kubernetes 自带的服务一般运行在 kube-system namespace 中. 操作kubectl 可以通过 --namespace 或 -n 选项指定 namespace, 如果不指定, 则默认为 default. 查询$ kubectl get namespace 创建$ cat my-namespace.yaml apiVersion: v1 kind: Namespace metadata: name: new-namespace $ kubectl create -f ./my-namespace.yaml 删除注意: 删除一个 namespace 会自动删除所有属于该 namespace 的资源 $ kubectl delete namespace new-namespace NodeNode 是 Pod 真正运行的主机, 可以是 物理机, 也可以是虚拟机. 为了管理 Pod, 每个 Node 节点上至少要运行 Container runtime(如 docker/rkt), kubelet 和 kube-proxy . Node 管理Node 本质上不是 kubernetes 来创建的, kubernetes 只是管理 Node 上的资源. 默认情况下, kubelet 在启动时会向 master 注册自己, 并创建 Node 资源. 虽然可以通过 Manifest 创建一个 Node 对象, 但 Kubernetes 只是去检查 Node 是否可用, 如果检查失败, 则不会向上调度 Pod. { &quot;kind&quot;: &quot;Node&quot;, &quot;apiVersion&quot;: &quot;v1&quot;, &quot;metadata&quot;: { &quot;name&quot;: &quot;10.240.79.157&quot;, &quot;labels&quot;: { &quot;name&quot;: &quot;my-first-k8s-node&quot; } } } node 可用性检查是由 Node Controller 来完成的, Node Controller 负责: 维护 Node 状态 与 Cloud Provider 同步 Node 给 Node 分配 CIDR 删除带有 NoExecute taint 的 Node 上的 Pod. Node 状态每个 Node 都会包括以下状态信息: 地址: 包括hostname, public IP, private IP 条件(Condition): 包括 OutOfDisk, Ready, MemoryPressure, DiskPressure. 容量(Capacity): Node 上的可用资源, 包括 CPU, 内存和 Pod 总数. 基本信息(Info): 包括内核版本, 容器引擎版本, OS类型等. Taints 和 tolerationsTaints 和 tolerations 用于保证 Pod 不被调度到不合适的 Node 上. Taints 应用 Node 上;tolerations 应用于 Pod 上, tolerations 是可选的. 如, 假设 node1 上应用以下几个 taint: $ kubectl taint nodes node1 key1=value1:NoSchedule $ kubectl taint nodes node1 key1=value1:NoExecute $ kubectl taint nodes node1 key2=value2:NoSchedule Node 维护模式维护模式表示 : Node 不可调度, 但不影响其上正在运行的 Pod, 这种在维护 Node 时是非常有用的. $ kubectl cordon NODE_NAME 服务发现与负载均衡kubernetes 在设计之初就充分考虑了针对容器的服务发现与负载均衡机制, 提供了 Service 资源, 并通过 kube-proxy 配合 cloud provider 来适应不同的场景. 随着 Kubernetes 用户的激增, 用户场景的不断丰富, 又产生了一些新的负载均衡机制, 每个机制都有其特定的应用场景: 1. Service :直接使用 Service 提供 cluster 内部的负载均衡, 并借助 cloud provider 提供的 LB 提供外部访问. Service 是对一组提供相同功能的 Pods 的抽象, 并为他们提供统一的入口. 借助 Service, 应用可以方便的实现服务发现与负载均衡, 并实现应用的零宕机升级. Service 通过标签来选取服务后端, 一般配合 Replication Controller 或者 Deployment 来保证后端容器的正常运行. 这些匹配标签的 Pod IP 和端口列表组成 endpoints, 由 kube-proxy 负责将服务 IP 负载均衡到这些 endpoints. 1.1 Service 类型 ClusterIP : 默认类型, 自动分配一个仅 cluster 内部可以访问的虚拟IP. NodePort : 在 ClusterIP 基础上为 Service 在每台机器上绑定一个端口, 这样就可以通过 &lt;NodeIP&gt;:NodePort 来访问服务. LoadBalancer : 在 NodePort 基础上, 基础 cloud provider 创建一个外部的负载均衡器, 并将请求转发到 &lt;NodeIP&gt;:NodePort . ExternalName : 将服务通过 DNS CNAME 记录方式转达到指定的域名 (通过 spec.externlName 设定). 需要 kube-dns 版本 1.7 以上. 另外, 也可以将已有的服务以 Service 的形式加入到 Kubernetes 集群中, 只需要在创建 Service 的时候不指定 Label selector , 而是在 Service 创建好后手动为其添加 endpoint. 1.2 Service 定义Service 的定义也是通过 yaml 或 json , 示例: 定义 nginx 服务, 并将服务的 80 端口装发到 default namespace 中 lable 为 run=nginx 的 Pod 的 80 端口. apiVersion: v1 kind: Service metadata: labels: run: nginx name: nginx namespace: default spec: ports: - port: 80 protocol: TCP targetPort: 80 selector: run: nginx sessionAffinity: None type: ClusterIP 1.3 查看 service 状态# 查看 service $ kubectl get service nginx # 查看 service 自动创建的 endpoints $ kubectl get endpoints nginx # Service nginx 自动关联 endpoints $ kubectl describe service nginx 1.4 不指定 Selector 的服务在创建 Service 的时候, 也可不指定 Selectors, 用来将 service 转发到 kubernetes 集群外部的服务(而不是 Pod). 目前支持两种方法: 自定义 endpoints 创建同名的 service 和 endpoints , 在 endpoints 中设置外部服务的 IP 和端口. kind: Service apiVersion: v1 metadata: name: my-service spec: ports: - protocol: TCP port: 80 targetPort: 9376 --- kind: Endpoints apiVersion: v1 metadata: name: my-service subsets: - addresses: - ip: 1.2.3.4 ports: - port: 9376 通过 DNS 转发 在 service 定义中指定 externalName, 此时 DNS 服务会给 &lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local 创建一个 CNAME 记录, 其值为 my.database.example.com. 并且, 该服务不会自动分配 ClusterIP, 需要通过 service 的 DNS 来访问(这种服务也称为 Headless Service). kind: Service apiVersion: v1 metadata: name: my-service namespace: default spec: type: ExternalName externalName: my.database.example.com 1.5 Headless 服务Headless 服务即不需要 Cluster IP 的服务, 即在创建服务的时候指定 spec.clusterIP=None, 包括两种类型: 不指定 selector, 但设置 externalName, 即上面的 1.4.2 示例, 通过 CNAME 记录处理. 指定 Selector, 通过 DNS A 记录设置后端 endpoint 列表. 2. Ingress Controller :使用 Service 提供 cluster 内部的负载均衡, 但是通过自定义的 LB 提供外部访问. Service 虽然解决了服务发现和负载均衡的问题, 但他在使用上还是有一些限制, 比如: 只支持 4 层负载均衡, 没有 7 层的功能; 对外访问的时候, NodePort 类型需要在外部搭建额外的负载均衡器, 而 LoadBalancer 要求 kubernetes 必须跑在支持的 cloud provider 上. Ingress Controller 就是为了解决这些限制而引入的新资源, 主要用来将服务暴露在 cluster 外面, 并且可以自定义服务的访问策略. 如想要通过负载均衡器实现不同子域名到不同服务的访问. apiVersion: extensioins/v1beta1 kind: Ingress metadata: name: test spec: rules: - host: foo.bar.com http: paths: - backend: serviceName: s1 servicePort: 80 - host: bar.foo.com http: paths: - backend: serviceName: s2 servicePort: 80 注意Ingress 本身并不会自动创建负载均衡器, cluster 中需要运行一个 ingresses controller 来根据 Ingress 的定义来管理负载均衡器. 目前社区提供了 nginx 和 gce 的参考实现. 3. Service Load Balance :把 load balancer 直接跑在容器中, 实现 Bare Metal 的 Service Load Balancer. 在 Ingress 出现之前, Service Load Balance 是推荐的解决 Service 局限性的方式. Service Load Balance 将 haproxy 跑在容器中, 并监控 service 和 endpoints 的变化, 通过容器 IP 对外提供 4 层和 7 层负载均衡服务. 社区提供的 Service Load Balance 支持四种负载均衡协议: TCP, HTTP, HTTPS, SSL TERMINATION , 并支持 ACL 访问控制. 4. Custom Load Balance :自定义负载均衡, 并替代 kube-proxy, 一般在物理部署 kubernetes 时使用, 方便介入公司已有的外部服务. 基本的思路是监控 kubernetes 中 service 和 endpoints 的变化, 并根据这些变化来配置负载均衡器, 比如 weave flux, nginx plus, kube2haproxy 等. VolumeKubernetes 提供的强大的 Volume 机制和丰富的插件, 解决了容器数据持久化和容器间共享数据的问题. Kubernetes Volume 的生命周期与 Pod 绑定. 容器挂掉后, kubelet 再次重启容器时, Volume 的数据依然还在; 而 Pod 删除时, Volume 才会清理. 数据是否丢失取决于具体的 Volume 类型, 比如 emptyDir 的数据会跌势, 而 PV 的数据则不会. Volume 类型 emptyDir hostPath gcePersistentDisk awsElasticBlockStore nfs iscsi flocker glusterfs rbd cephfs gitRepo secret persistentvolumes downwardAPI azureFileVolume azureDisk vsphereVolume Quobyte PortworxVolume ScaleIO FlexVolume 这些 Volume 并非全部是持久化的, 比如 emptyDir, secret, gitRepo 等, 这些 volumes 会随着 Pod 的消亡而消失. emptyDir当 Pod 设置了 emptyDir 类型 Volume, Pod 被分配到 Node 上时, 会创建 emptyDir , 只要 Pod 运行在 Node 上, emptyDir 都会存在(容器挂掉不会导致 emptyDir 丢失数据), 但是如果 Pod 从 Node 上被删除(Pod被删除或者Pod 发生迁移), emptyDir 会被删除, 并且永远丢失. apiVersion: v1 kind: Pod metadata: name: test-pd spec: containers: - image: gcr.io/google_containers/test-webserver name: test-container volumeMounts: - mountPath: /cache name: cache-volume volumes: - name: cache-volume emptyDir: {} hostPathhostPach 允许挂在 Node 上的文件系统到 Pod 里面, 如果 Pod 需要使用 Node 上的文件, 可以使用 hostPath. apiVersion: v1 kind: Pod metadata: name: test-pd spec: containers: - image: gcr.io/google_containers/test-webserver name: test-container volumeMounts: - mountPath: /test-pd name: test-volume volumes: - name: test-volume hostPath: path: /data NFSNFS 即网络文件系统. Kubernetes 通过简单的配置就可以挂在 NFS 到 Pod 中, 而 NFS 中的数据是可以永久保存的, 同时 NFS 支持同时写操作. volumes: - name: nfs nfs: server: 192.168.1.100 path: &quot;/&quot; gcePersistentDiskgcePersistentDisk 可以挂载 GCE 上的永久磁盘到容器, 需要 Kubernetes 运行在 GCE 的 VM 中. volumes: - name: test-volume gcePersistentDisk: pdName: my-data-disk # this GCE PD must already exist. fsType: ext4 awsElasticBlockStoreawsElasticBlockStore 可以挂载 AWS 上的 EBS 盘到容器, 需要 Kubernetes 运行在 AWS 的 EC2 上. volumes: - name: test-volume awsElasticBlockStore: volumeID: MY_VOLUME_ID fsType: ext4 gitRepogitRepo volume 将 git 代码下拉到指定的容器路径中. volumes: - name: git-volume gitRepo: repository: &quot;git@somewhere:me/my-git-repo.git&quot; revision: &quot;22f1d8406d464b0c0874075539c1f2e96c253775&quot; subPathPod 的多个容器使用同一个 Volume 时, subPath 非常有用. apiVersion: v1 kind: Pod metadata: name: my-lamp-site spec: containers: - name: mysql image: mysql volumeMounts: - mountPath: /var/lib/mysql name: site-data subPath: mysql - name: php image: php volumeMounts: - mountPath: /var/www/html name: site-data subPath: html volumes: - name: site-data persistentVolumeClaim: claimName: my-lamp-site-data FlexVolume如果内置的 Volume 不满足需求, 则可以使用 FlexVolume 实现自己的 Volume 插件. 注意要把 volume plugin 放到 /usr/libexec/kubernetes/kubelet-plugins/volume/exec/&lt;vendor-driver&gt;/&lt;driver&gt;, plugin 要实现 init/attach/detach/mount/umount 等命令, 参考LVM. - name: test flexVolume: driver: &quot;kubernetes.io/lvm&quot; fsType: &quot;ext4&quot; options: volumeID: &quot;vol1&quot; size: &quot;1000m&quot; volumegroup: &quot;kube_vg&quot; Persistent VolumePersistentVolumes(PV) 和 PersistentVolumeClaim(PVC) 提供了方便的持久化卷: PV 提供网络存储资源; PVC 请求存储资源. 因此, 设置持久化的工作流包括配置底层文件系统或者云数据卷, 创建持久性数据卷, 最后创建 claim 来将 Pod 跟数据卷关联起来. PV 和 PVC 可以将 pod 和数据卷解耦, pod 不需要知道确切的文件系统或者支持他的持久化引擎. Volume 生命周期 与 状态Volume 的生命周期包括 5 个阶段: Provisioning : PV 的创建, 可以直接创建 PV (静态方式), 也可以使用 StorageClass 动态创建. Binding : 将 PV 分配给 PVC. Using : Pod 通过 PVC 使用该 Volume. Releasing : Pod 释放 Volume 并删除 PVC. Reclaiming : 回收 PV, 可以保留 PV 以便下次使用, 也可以直接从云存储中删除. 根据以上 5 个阶段, Volume 的状态有以下 4 种: Available: 可用 Bound: 已经分配给 PVC Released: PVC 解绑但尚未执行回收策略. Failed: 发生错误. PVPersistentVolume (PV) 是集群之中的一块网络存储, 跟 Node 一样, 也是集群的资源. PV 跟 Volume(卷) 类似, 不过会有独立于 Pod 的生命周期. # NFS PV apiVersion: v1 kind: PersistentVolume metadata: name: pv0003 spec: capacity: storage: 5Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle nfs: path: /tmp server: 172.17.0.100 PV 的访问方式(accessModes) 有三种: ReadWriteOnce(RWO) : 最基本方式, 可读可写, 但只支持被单个 Pod 挂在. ReadOnlyMany(ROX) : 以只读方式被多个 Pod 挂载. ReadWriteMany(RWX) : 以读写方式被多个 Pod 挂载. 不是每一种存储都支持这三种方式, 像共享方式, 目前支持的还比较少, 比较常用的是 NFS, 在PVC 绑定 PV 是通常根据两个条件来绑定: ① 存储大小; ② 访问模式. PV 的回收策略(persistentVolumeReclaimPolicy), 有三种: Retain : 不清理, 保留 Volume (需要手动清理) Recycle : 删除数据, 即 rm -rf /thevolume/*, 只有NFS和 HostPath支持 Delete : 删除存储资源, 比如删除 AWS EBS 卷. 只有AWS EBS, GCE PD, Azure Disk 和 Cinder支持 StorageClass通过手动方式创建 Volume, 在管理很多 Volume 时不太方便, Kubernetes 提供 StorageClass 来动态创建 PV, 不仅节省管理员时间, 还可以封装不同类型的存储供 PVC 选用. 在使用 PVC 时, 可以通过 DefaultStorageClass Admission Controller 定义默认的 StorageClass, 以供为指定 storageClassName 的 PVC 使用. GCE 示例 kind: StorageClass apiVersion: storage.k8s.io/v1beta1 metadata: name: slow provisioner: kubernetes.io/gce-pd parameters: type: pd-standard zone: us-central1-a Ceph RBD 示例 apiVersion: storage.k8s.io/v1beta1 kind: StorageClass metadata: name: fast provisioner: kubernetes.io/rbd parameters: monitors: 10.16.153.105:6789 adminId: kube adminSecretName: ceph-secret adminSecretNamespace: kube-system pool: kube userId: kube userSecretName: ceph-secret-user Glusterfs 示例 apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: slow provisioner: kubernetes.io/glusterfs parameters: resturl: &quot;http://127.0.0.1:8081&quot; clusterid: &quot;630372ccdc720a92c681fb928f27b53f&quot; restauthenabled: &quot;true&quot; restuser: &quot;admin&quot; secretNamespace: &quot;default&quot; secretName: &quot;heketi-secret&quot; gidMin: &quot;40000&quot; gidMax: &quot;50000&quot; volumetype: &quot;replicate:3&quot; OpenStack Cinder 示例 kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: gold provisioner: kubernetes.io/cinder parameters: type: fast availability: nova PVCPV 是存储资源, 而 PersistentVolumeClaim(PVC) 是对 PV 的请求. PVC跟Pod类似: Pod 消费 Node 资源, PVC 消费 PV 资源; Pod 能够请求 CPU 和内存资源, 而 PVC 请求 特定大小和访问模式的数据卷. 示例: kind: PersistentVolumeClaim apiVersion: v1 metadata: name: myclaim spec: accessModes: - ReadWriteOnce resources: requests: storage: 8Gi storageClassName: slow selector: matchLabels: release: &quot;stable&quot; matchExpressions: - {key: environment, operator: In, values: [dev]} PVC 可以直接挂载到 Pod 中: kind: Pod apiVersion: v1 metadata: name: mypod spec: containers: - name: myfrontend image: dockerfile/nginx volumeMounts: - mountPath: &quot;/var/www/html&quot; name: mypd volumes: - name: mypd persistentVolumeClaim: claimName: myclaim Deployment简述Deployment 为 Pod 和 ReplicaSet 提供了一个声明式定义(declarative)方法, 用来替代以前的 ReplicationController 来方便的管理应用. 典型的使用场景包括: 定义 Deployment 来创建 Pod 和 ReplicaSet 滚动升级和回滚应用 扩容和缩容 暂停和继续 Deployment 使用示例: 定义 nginx deployment apiVersion: extensions/v1beta1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 扩容 $ kubectl scale deployment nginx-deployment --replicas 10 如果集群支持 horizontal pod autoscaling 的话, 可以设置 deployment 为自动扩展: $ kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80 更新镜像 $ kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1 回滚 $ kubectl rollout undo deployment/nginx-deployment Deployment 概念详细解析使用场景Deployment 为 Pod 和 Replica Set (下一代 Replication Controller) 提供声明式更新 : 只需要在 Deployment 中描述目标状态, Deployment Controller 就会将 Pod 和 Replica Set 的实际状态改变到目标状态. 也可以定义一个全新的 Deployment , 也可以创建一个新的替换旧的 Deployment. 典型用例: 使用 Deployment 来创建 ReplicaSet. ReplicaSet 在后台创建 Pod, 检查启动状态, 看是成功还是失败. 通过更新 Deployment 的 PodTemplateSpec 字段来声明 Pod 的新状态. 这会创建一个新的 ReplicaSet , Deployment 会按照控制的速率将 Pod 从旧的 ReplicaSet 移动到新的 ReplicaSet 中. 如果当前状态不稳定, 回滚到之前的 Deployment revision. 每次回滚都会更新 Deployment 的 revision. 扩容 Deployment 以满足更高的负载 暂定 Deployment 来应用 PodTemplateSpec 的多个修复, 然后恢复上线. 根据 Deployment 的状态判断上线是否 hang 住了. 清除旧的不必要的 ReplicaSet. 创建 Deployment# 将 kubectl 的 --record 的 flag 设置为 true , 可以在 annotation 中记录当前命令创建或升级了该资源, 这在将来会很有用. $ kubectl create -f docs/user-guide/nginx-deployment.yaml --record deployment &quot;nginx-deployment&quot; created # 查看 deployment 状态 $ kubectl get deployment # 查看创建 rs 和 pod 资源 $ kubectl get rs # rs 的名称总是 &quot;&lt;Deployment_Name&gt;-&lt;hash_of_pod_template&gt;&quot; $ kubectl get pods --show-labels 更新 DeploymentDeployment 的 rollout 当且仅当 Deployment 的 pod template (.spec.template) 中的 label 更新或镜像更改时被触发. 其他更新, 如扩容 Deployment 不会触发 rollout Deployment 可以保证在升级时只有一定数量的 Pod 是 down的. 默认的, 他会确保至少有比期望的 Pod 数量少一个 Pod 是 up 状态(最多一个不可用). Deployment 同时也可以确保只创建出超过期望数量的一定数量的 Pod. 默认的, 他会确保最多比期望的 Pod 数量多一个的 Pod 是 up 的(虽多一个 surge). 在未来的 Kubernetes 版本中, 将从 1-1 变成 25% - 25%. 在如下的实例中, 会看到, 开始创建一个新的 Pod , 然后删除一些就的 Pod 在创建一个新的 . 当新的Pod 创建出来之前不会杀掉旧的 Pod. 这样就能确保可用的 Pod 数量至少有 2 个, Pod 的总数最多为 4 个. # 让 nginx pod 使用 nginx:1.9.1 的镜像来代替原来的 nginx:1.7.9 的镜像 $ kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1 deployment &quot;nginx-deployment&quot; image updated # 也可以用 edit 来编辑 Deployment $ kubectl edit deployment/nginx-deployment # 查看 rollout 状态 $ kubectl rollout status deployment/nginx-deployment # 查看 deployment 状态 $ kubectl get deployments - UP-TO-DATE : replica 中已到达目标配置的数目 - CURRENT : 当前 Deployment 管理的 replica 数量 - AVAILABLE : 当前可用的 replica 数量 $ kubectl describe deployment # 查看 ReplicaSet 状态 和 Pods 状态 # rs 的更新 Pod 是通过创建一个新的 ReplicaSet 并扩容 3 个 replica , 同时将原来的 ReplicaSet 缩容到 0 个 replica. $ kubectl get rs $ kubectl get pods Rollover(多个 rollout 并行)每当 Deployment controllers 观测到有新的 deployment 被创建时, 如果没有已存在的 ReplicaSet 来创阿金期望个数的 Pode 的话, 就会创建出一个新的 ReplicaSet 来做这件事. 已存在的 ReplicaSet 控制 label 匹配 .spec.selector 当 template 跟 .spec.template 不匹配的 Pod 缩容. 最终, 新的 ReplicaSet 会将扩容出 .spec.replicas 指定数目的 Pod, 旧的 ReplicaSet 会缩容到 0 . 如果你更新了一个的已存在并正在进行中的Deployment, 每次更新 Deployment 都会创建一个新的 ReplicaSet 并扩容它, 同时回滚之前扩容的 ReplicaSet – 将它添加到旧的 ReplicaSet 列表, 开始缩容. 例如, 假如你创建了一个有5个 niginx:1.7.9 replica 的 Deployment, 但是当还只有3个 nginx:1.7.9 的 replica 创建出来的时候你就开始更新含有5个 nginx:1.9.1 replica 的 Deployment . 在这种情况下, Deployment 会立即杀掉已创建的3个 nginx:1.7.9 的 Pod , 并开始创建 nginx:1.9.1 的 Pod . 它不会等到所有的5个 nginx:1.7.9 的 Pod 都创建完成后才开始改变航道. 回退 Deployment默认情况下, kubernetes 会在系统中保留两次的 deployment 的 rollout 历史记录, 一遍可以随时回退, 可以通过修改 revision history limit 来更改保存的 revision 数. 注意 : 只要 Deployment 的 rollout 被触发就会创建一个 revision, 也就是说当且仅当 Deployment 的 Pod template (如 .spec.template) 被更改, 例如更新 template 中的 label 和容器镜像时, 就会创建出一个新的 revision. 其他的更新, 比如扩容 Deployment 不会创建 revision – 因此我们可以方便的手动或自动扩容, 这意味着当你回退到历史 revision 时, 只有 Deployment 的 Pod template 部分才会回退. # 查看 rollout 状态 $ kubectl rollout status deployment nginx-deployment $ kubectl describe deployment 检查 Deployment 升级历史记录# 检查 deployment 的 revision # 如果在创建 deployment 时使用了 --recored 参数, 可以记录命令, 方便查看每次 revision 的变化 $ kubectl rollout history deployment/nginx-deployment # 查看单个 revision 的详细信息 $ kubectl rollout history deployment/nginx-deployment --revision=2 回退到历史版本# 查看相关帮助信息 $ kubectl rollout --help # 回退当前 rollout 到之前的版本 $ kubectl rollout undo deployment/nginx-deployment # 回退到指定版本 $ kubectl rollout undo deployment/nginx-deployment --revision=2 # 查看 deployment 状态 $ kubectl get deployment # deployment 回退到先前的稳定版, deployment controllers 产生一个回退到 revision_2 的 &apos;DeploymentRollback&apos; 的 event. $ kubectl describe deployment 清理 Policy可以通过设置 .spec.revisionHistoryLimit 项来志定 deployment 最多保留多少个 revision 历史记录. 默认会保留所有的 revision, 如果将该项设置为 0, 则 Deployment 不允许回退. Deployment 扩容使用如下命令, 扩容 Deployment $ kubectl scale deployment nginx-deployment --replicas 10 如果集群中启用了 horizontal pod autoscaling, 可以给 Deployment 设置一个 autoscaler , 基于当前 Pod 的 CPU 利用率选择最少和最多的 Pod 数. $ kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80 比例扩容(灰度)RollingUpdate Deployment 支持同时运行一个应用的多个版本. 当 autoscaler 扩容 RollingUpdate Deployment 的时候, 正在中途的 rollout (进行中或者已经暂停), 为了降低风险, Deployment controller将会平衡已存在的活动中的ReplicaSets（有Pod的ReplicaSets）和新加入的replicas. 这被称为比例扩容. 例如, 你正在运行中含有10个replica的Deployment. maxSurge=3, maxUnavailable=2. $ kubectl get deploy NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 10 10 10 10 50s 你更新了一个镜像, 而在集群内部无法解析. $ kubectl set image deploy/nginx-deployment nginx=nginx:sometag deployment &quot;nginx-deployment&quot; image updated 镜像更新启动了一个包含ReplicaSet nginx-deployment-1989198191的新的rollout, 但是它被阻塞了, 因为我们上面提到的maxUnavailable. $ kubectl get rs NAME DESIRED CURRENT READY AGE nginx-deployment-1989198191 5 5 0 9s nginx-deployment-618515232 8 8 8 1m 然后发起了一个新的Deployment扩容请求. autoscaler将Deployment的repllica数目增加到了15个. Deployment controller需要判断在哪里增加这5个新的replica. 如果我们没有谁用比例扩容, 所有的5个replica都会加到一个新的ReplicaSet中. 如果使用比例扩容, 新添加的replica将传播到所有的ReplicaSet中. 大的部分加入replica数最多的ReplicaSet中, 小的部分加入到replica数少的ReplciaSet中. 0个replica的ReplicaSet不会被扩容. 在我们上面的例子中, 3个replica将添加到旧的ReplicaSet中, 2个replica将添加到新的ReplicaSet中. rollout进程最终会将所有的replica移动到新的ReplicaSet中, 假设新的replica成为健康状态. $ kubectl get deploy NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 15 18 7 8 7m $ kubectl get rs NAME DESIRED CURRENT READY AGE nginx-deployment-1989198191 7 7 0 7m nginx-deployment-618515232 11 11 11 7m 暂停和恢复 Deployment可以在触发一次或多次更新前暂停一个 Deployment, 然后再恢复它. 这样就能多次暂停和恢复 Deployment, 在此期间进行一些修复工作, 而不会触发不必要的 rollout. Deployment 暂停前的初始状态将继续他的功能, 而不会对 Deployment 的更新产生任何影响, 主要 Deployment 是暂停的. 注意 : 在恢复 Deployment 之前, 无法回退一个暂停了的 Deployment. # 查看刚创阿金的 Deployment $ kubectl get deploy $ kubectl get rs # 暂停 Deployment $ kubectl rollout pause deployment/nginx-deployment # 更新 Deployment 中的镜像, 新的 rollout 启动了 $ kubectl set image deploy/nginx nginx=nginx:1.9.1 $ kubectl rollout history deploy/nginx $ kubectl get rs # 可以进行任意多次更新, 如更新使用的资源 $ kubectl set resources deployment nginx -c=nginx --limits=cpu=200m,memory=512Mi # 恢复暂停的 Deployment $ kubectl rollout resume deploy nginx # 查看 最新状态 $ kubectl get rs -w $ kubectl get rs Deployment 状态Progressing Deployment可以使用 kubectl rollout status 监控 Deployment 的进度. Kubernetes 将执行过下列任务之一的 Deployment 标记为 progressing 状态. Deployment 正在创建新的 ReplicaSet 过程中 Deployment 正在扩容一个已有的 ReplicaSet. Deployment 正在速溶一个已有的 ReplicaSet. Complete DeploymentKubernetes 将包括以下特定的 Deployment 标记为 complete 状态: Deployment 最小可用. 最小可用意味着 Deployment 的可用 replica 个数等于或者超多 Deployment 策略中的期望个数. 所有与该 Deployment 相关的 replica 都被更新到指定版本, 也即更新完成. 该 Deployment 中没有旧的 Pod 的存在. 可以用 kubectl rollout status 命令查看 Deployment 是否完成, 如果 rollout 成功完成, kubectl rollout status 将返回一个 0 值的 exit code. $ kubectl rollout status deploy/nginx Failed DeploymentDeployment 在尝试部署新的 ReplicaSet 的时候可能卡住, 也不会完成. 这可能是因为以下因素导致的: 无效的引用 不可读的 probe failure 镜像拉去错误 权限不够 范围限制 程序运行时配置错误 探测这种情况的一种方式是, 在 Deployment spec 中指定 .spec.progressDeadlineSeconds. .spec.progressDeadlineSeconds 表示 Deployment controllers 等待多少秒才能确定(通过 Deployment status) Deployment 进程是卡住的. # 设置 progressDeadlineSeconds 使得 controller 在 Deployment 在进度卡住 10 分钟后报告 $ kubectl patch deployment/nginx-deployment -p &apos;{&quot;spec&quot;:{&quot;progressDeadlineSeconds&quot;: 600}}&apos; 当超过截止时间后, Deployment controllers 会在 Deployment 的 status.conditions 中增加一条 DeploymentCondition , 它包含如下属性: Type=Progressing Status=False Reason=ProgressDeadlineExeceeded 注意: kubernetes 除了报告 Reason=ProgressDeadlineExeceeded 状态信息外不会对卡住的 Deployment 做任何操作. 更高层次的协调器可以利用它并采取相应行动, 例如, 回滚 Deployment 到之前的版本. 注意: 在暂停的 Deployment 中, Kubernetes 不会检查指定的 deadline. 可以在 Deployment 的 rollout 途中安全的暂停它, 然后在恢复, 这不会触发超过 deadline 的状态. 操作失败的 Deployment所有对完成的 Deployment 的操作都适用于失败的 Deployment , 可以对他括/缩容, 回退到历史版本, 甚至多次暂停它来应用 Deployment pod template. 清理 Policy设置 Deployment 中的 spec.revisionHistoryLimit 项来指定保留多少旧的 ReplicaSet. 余下的就在后台被当做垃圾收集. 默认所有 revision 历史都会被保留, 未来的版本会改为 2 . 注意: 将 spec.revisionHistoryLimit 设置为 0 , 将导致所有 Deployment 的历史记录都会被清除. 该 Deployment 无法回退. 使用示例金丝雀 Deployment如果想要使用 Deployment 对部分用户或服务器发布 release, 可以创建多个 Deployment , 每个对一个 release. 编写 Deployment SpecDeployment 也需要 apiVersion, kind, metadata, spec 这些配置项. Pod Template .spec.template 是 .spec 中唯一要求的字段. 它是 Pod template , 它跟 Pod 有一模一样的 schema, 除了他是嵌套的, 并且不需要 apiVersion 和 kind 字段. 另外, 为了划分 Pod 的范围, Deployment 中的 pod template 必须制定适当的 label (不要跟其他 controllers 重复了) 和适当的重启策略. .spec.template.spec.restartPolicy 可以设为 Always , 如果不只定的话, 这就是默认设置. Replicas .spec.replicas 可选字段, 指定期望的 Pod 数量, 默认是 1. Selector .spec.selector 可选字段, 用来指定 label selector, 圈定 Deployment 管理的 Pod 范围. 如果被指定, .spec.selector 必须匹配 .spec.template.metadata.labels, 否则, 将被 API 拒绝. 如果没有指定, .spec.selector.matchLabels 默认是 .spec.template.metadata.labels 在 Pod 的 template 跟 .spec.template 不同或者数量超过了 .spec.replicas 规定的数量的情况下, Deployment 会杀掉 label 跟 selector 不同的 Pod. 注意: 不应该再创建其他 label 跟这个 selector 匹配的 pod, 或者通过其他 Deployment, 或者通过其他 Controller, 如 ReplicaSet 和 ReplicationController. 否则 该 Deployment 会把他们都当成自己创建的. 注意: 如果有多个 controllers 使用了重复的 selector, controllers 们可能会相互冲突, 并导致不正确的行为. 策略 .spec.strategy 指定新的 Pod 替换 旧的 Pod 的策略. .spec.strategy.type 可以是 Recreate 或 RollingUpdate. 其中 RollingUpdate 是默认值. .spec.strategy.type=Recreate: 在创建新的 Pod 之前会先杀掉所有已存在的 Pod. .spec.strategy.type=RollingUpdate: Deployment 使用 rolling update 的方式更新 Pod, 可以指定 maxUnavailable 和 maxSurge 来控制 rolling update 进程, 这两个值不能同时为 0. .spec.strategy.rollingupdate.maxUnavailable 可选配置, 用来指定在升级过程中, 不可用 Pod 的最大数量值. 该值可以为一个绝对数值(如 5), 也可以是期望 Pod 数量的百分比(如 10%), 通过计算百分比的绝对值向下取整. 如果 .spec.strategy.rollingupdate.maxSurge 为 0 时, 该值 不能为 0. 默认值为 1. .spec.strategy.rollingupdate.maxSurge 可选配置, 用来指定超过期望的 Pod 数量的最大个数. 该值可以为一个绝对数值(如 5), 也可以是期望 Pod 数量的百分比(如 10%), 通过计算百分比的绝对值向下取整. 如果 .spec.strategy.rollingupdate.maxUnavailable 为 0 时, 该值 不能为 0. 默认值为 1. Progress Deadline Seconds .spec.progressDeadlineSeconds 可选配置, 用来指定在系统报告 Deployment failed progressing – 表现为 resources 的状态中的 type=Progressing, status=False, Reason=ProgressDeadlineExceeded 前可以等待的 Deployment 进行的秒数 .Deployment controllers 会继续重试该 Deployment. 如果设置该参数, 该值必须大于 .spec.minReadySeconds Min Ready Seconds .spec.minReadySeconds 可选配置, 用来指定没有任何容器 crash 的 Pod 并被认为是可用状态的最小秒数, 默认为 0. Rollback To .spec.rollbackTo 可选配置, 用来配置 Deployment 回退的配置. 设置该参数将触发回退操作, 每次回退完成后, 该值就会被清除. .spec.rollbackTo.revision 可选配置, 用来指定回退到的 revision, 默认为 0, 即回退到历史中最老的 revision. Revision History Limit Deployment revision history 存储在他控制的 ReplicaSets 中. .spec.revisionHistoryLimit 可选配置, 用来指定可以保留的旧的 ReplicaSet 数量. 该理想值取决于 Deployment 的频率和稳定性. 如果该值没有设置的话, 默认所有旧的 ReplicaSet 都会被保留, 将资源存储在 etcd 中 每个 Deployment 的该配置都保存在 ReplicaSet 中, 一旦删除旧的 ReplicaSet , 则 Deployment 就再也无法回退到该 revision. 如果设置为 0 , 则 ReplicaSet 无法回退. Paused .spec.paused 是可选配置, boolean 值. 用来指定暂停和恢复 Deployment. Deployment 被创建之后, 默认是 非 paused. Paused 和 没有 Paused 的 Deployment 之间唯一的区别就是, 所有对 Paused Deployment 中的 PodTemplateSpec 的修改都不会触发新的 rollout. SecretSecret 解决了密码, token, 密钥等敏感数据的配置问题, 而无需把这些敏感数据暴露到镜像或 Pod Spec 中. Secret 可以以 Volume 或者环境变量的方式使用. 类型1. Service Account :用来访问 Kubernetes API, 有 Kubernetes 自动创建, 并且会挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount 目录中. $ kubectl run nginx --image nginx $ kubectl get pods $ kubectl exec nginx_POD_ID ls /run/secrets/kubernetes.io/serviceaccount ca.crt namespace token 2. Opaque :base64 编码格式的 secrets, 用来存储密码, 密钥等. 创建Opaque 类型是一个 map 类型, 要求 value 是 base64 编码格式. $ echo -n &apos;admin&apos; | base64 YWRtaW4= $ echo -n &quot;123456&quot; | base64 MTIzNDU2 $ cat secrets.yml apiVersion: v1 kind: Secret metadata: name: mysecret type: Opaque data: password: MTIzNDU2 username: YWRtaW4= # 创建 secrets $ kubectl create -f secrets.yml 如果是从文件创建 secrets, 则可以用更简单的 kubectl 命令: # 创建 tls 的 secret $ kubectl create secret generic helloworld-tls --from-file=key.pem --from-file=cert.pem 使用: 以 Volume 方式: 将 Secret 挂载到 Volume 中. apiVersion: v1 kind: Pod metadata: labels: name: db name: db spec: volumes: - name: secrets secret: secretName: mysecret container: - image: gcr.io/my_project_id/pg:v1 name: db volumeMounts: - name: secrets mountPath: &quot;/etc/secrets&quot; readOnly: true ports: - name: cp containerPort: 5432 hostPort: 5432 以环境变量方式: 将 secret 导出到环境变量中 apiVersion: extensions/v1beta1 kind: Deployment metadata: name: wordpress-deployment spec: replicas: 2 strategy: type: RollingUpdate template: metadata: labels: app: wordpress visualize: &quot;true&quot; spec: container: - name: &quot;wordpress&quot; images: &quot;wordpress&quot; ports: - containerPort: 80 env: - name: WORDPRESS_DB_USER valueFrom: secretKeyRef: name: mysecret key: username - name: WORDPRESS_DB_PASSWORD valueFrom: secretKeyRef: name: mysecret key: password 3. kubernetes.io/dockerconfigjson :用来存储私有 docker Registry 的认证信息. 创建 # 直接用 kubectl 命令来创建用于 docker Registry 认证的 secret $ kubectl create secret docker-registrty myregistrykey --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL # 直接读取 `~/.dockercfg` 内容来创建 $ kubectl create secret docker-registry myregistrykey --from-file=&quot;~/.dockercfg&quot; 使用: 在创建 Pod 时, 通过 imagePullSecrets 来引用myregistrykey apiVersion: v1 kind: Pod metadata: name: foo spec: containers: - name: foo image: janedoe/awesomeapp:v1 imagePullSecrets: - name: myregistrykey StatefulSetStatefulSet 为了解决有状态服务的问题(对应 Deployment 和 ReplicaSets 为无状态服务设计). 1. 应用场景 稳定的持久化存储, 即 Pod 重新调度后还是能访问到相同的持久化数据, 基于 PVC 来实现. 稳定的网络标志, 即 Pod 重新调度后其 PodName 和 HostName 不变, 基于 Headleass Service(没有 Cluster IP 的 Service) 来实现. 有序部署, 有序扩展 即 Pod 是有顺序的, 在部署或者扩展的时候要依据定义的顺序依次进行(即 从 0 到 N-1, 在下一个 Pod 运行之前所有之前的 Pod 必须都是 Running 和 Ready 状态), 基于 init container 实现. 有序收缩, 有序删除(即 从 N-1 到 0) StatefulSet 由一下几个部分组成: 用于定义网络标志(DNS domain)的 Headless Service. 用于创建 PersistnetVolumes 的 volumeClaimTemplates 定于具体应用的 StatefulSet StatefulSet 中每个 Pod 的 DNS 格式为 statefulSetName-{0..N-1}.serviceName.namespace.svc.cluster.local, 其中: serviceName 为 Headless Service的名字 0..N-1 为 Pod 所在的序号, 从 0 开始到 N-1 statefulSetName 为 StatefulSet 的名字 namespace 为服务所在的 namespace, Headless Service 和 StatefulSet 必须在相同的 namespace. .cluster.local 为 Cluster Domain. 2. 示例示例1 : nginx 服务 $ cat web.yml --- apiVersion: v1 kind: Service metadata: name: nginx labels: app: nginx spec: ports: - port: 80 name: web clusterIP: None selector: app: nginx --- apiVersion: apps/v1beta1 kind: StatefulSet metadata: name: web spec: serviceName: &quot;nginx&quot; replicas: 2 template: metadata: labels: app: nginx spec: containers: - name: nginx images: gcr.io/google_containers/nginx-slim:0.8 ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www annotations: volume.alpha.kubernetes.io/storage-class: anything spec: accessModes: [&quot;ReadWriteOnce&quot;] resources: requests: storage: 1Gi $ kubectl create -f web.yml # 查看创建的 headless service 和 statefulset $ kubectl get service nginx $ kubectl get statefulset web # 根据 volumeClaimTemplates 自动创建 PVC (在 GCE 中会自动创建 kubernetes.io/gce-pd 类型的 volume) $ kubectl get pvc # 查看创建的 pod, 他们都是有序的. $ kubectl get pods -l app=nginx # 使用 nslookup 查看 Pod 的 DNS $ kubectl run -t --tty --image busybox dns-test --restart=Never --rm /bin/bash $ nslookup web-0.nginx $ nslookup web-1.nginx # 扩容 $ kubectl scale statefulset web --replicas=5 # 缩容 $ kubectl patch statefulset web -p &apos;{&quot;spec&quot;: {&quot;replicas&quot;: 3}}&apos; # 镜像更新(目前不支持直接更新 image, 需要 patch 来间接实现) $ kubectl patch statefulset web --type=&apos;json&apos; -p=&apos;[{&quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;/spec/template/spec/containers/0/image&quot;, &quot;value&quot;:&quot;gcr.io/google_containers/nginx-slim:0.7&quot;}]&apos; # 删除 StatefulSet 和 Headless Service $ kubectl delete statefulset web $ kubectl delete service nginx # 删除不在使用的 PVC $ kubectl delete pvc www-web-0 www-web-1 示例2 : zookeeper 服务 $ cat zookeeper.yml --- apiVersion: v1 kind: Service metadata: name: zk-headless labels: app: zk-headless spec: ports: - port: 2888 name: server - port: 3888 name: leader-election clusterIP: None selector: app: zk --- apiVersion: v1 kind: ConfigMap metadata: name: zk-config data: ensemble: &quot;zk-0;zk-1;zk-2&quot; jvm.heap: &quot;2G&quot; tick: &quot;2000&quot; init: &quot;10&quot; sync: &quot;5&quot; client.cnxns: &quot;60&quot; snap.retain: &quot;3&quot; purge.interval: &quot;1&quot; --- apiVersion: policy/v1beta1 kind: PodDisruptionBudget metadata: name: zk-budget spec: selector: matchLabels: app: zk minAvailable: 2 --- apiVersion: apps/v1beta1 kind: StatefulSet metadata: name: zk spec: serviceName: zk-headless replicas: 3 template: metadata: labels: app: zk annotations: pod.alpha.kubernetes.io/initialized: &quot;true&quot; scheduler.alpha.kubernetes.io/affinity: &gt; { &quot;podAntiAffinity&quot;: { &quot;requiredDuringSchedulingRequiredDuringExecution&quot;: [{ &quot;labelSelector&quot;: { &quot;matchExpressions&quot;: [{ &quot;key&quot;: &quot;app&quot;, &quot;operator&quot;: &quot;In&quot;, &quot;values&quot;: [&quot;zk-headless&quot;] }] }, &quot;topologyKey&quot;: &quot;kubernetes.io/hostname&quot; }] } } spec: containers: - name: k8szk imagePullPolicy: Always image: gcr.io/google_samples/k8szk:v1 resources: requests: memory: &quot;4Gi&quot; cpu: &quot;1&quot; ports: - containerPort: 2181 name: client - containerPort: 2888 name: server - containerPort: 3888 name: leader-election env: - name : ZK_ENSEMBLE valueFrom: configMapKeyRef: name: zk-config key: ensemble - name : ZK_HEAP_SIZE valueFrom: configMapKeyRef: name: zk-config key: jvm.heap - name : ZK_TICK_TIME valueFrom: configMapKeyRef: name: zk-config key: tick - name : ZK_INIT_LIMIT valueFrom: configMapKeyRef: name: zk-config key: init - name : ZK_SYNC_LIMIT valueFrom: configMapKeyRef: name: zk-config key: tick - name : ZK_MAX_CLIENT_CNXNS valueFrom: configMapKeyRef: name: zk-config key: client.cnxns - name: ZK_SNAP_RETAIN_COUNT valueFrom: configMapKeyRef: name: zk-config key: snap.retain - name: ZK_PURGE_INTERVAL valueFrom: configMapKeyRef: name: zk-config key: purge.interval - name: ZK_CLIENT_PORT value: &quot;2181&quot; - name: ZK_SERVER_PORT value: &quot;2888&quot; - name: ZK_ELECTION_PORT value: &quot;3888&quot; command: - sh - -c - zkGenConfig.sh &amp;&amp; zkServer.sh start-foreground readinessProbe: exec: command: - &quot;zkOk.sh&quot; initialDelaySeconds: 15 timeoutSeconds: 5 livenessProbe: exec: command: - &quot;zkOk.sh&quot; initialDelaySeconds: 15 timeoutSeconds: 5 volumeMounts: - name: datadir mountPath: /var/lib/zookeeper securityContext: runAsUser: 1000 fsGroup: 1000 volumeClaimTemplates: - metadata: name: datadir annotations: volume.alpha.kubernetes.io/storage-class: anything spec: accessModes: [ &quot;ReadWriteOnce&quot; ] resources: requests: storage: 20Gi $ kubectl create -f zookeeper.yml 3. 注意事项 还在beta状态, 需要kubernetes v1.5版本以上才支持 所有Pod的Volume必须使用PersistentVolume或者是管理员事先创建好 为了保证数据安全, 删除StatefulSet时不会删除Volume StatefulSet需要一个Headless Service来定义DNS domain, 需要在StatefulSet之前创建好 目前StatefulSet还没有feature complete, 比如更新操作还需要手动patch DaemonSetDaemonSet 保证在每个 Node 上都运行一个容器副本, 常用来部署一些集群的日志, 监控, 或者其他系统管理应用. 使用场景典型应用包括: 日志收集, 如 fluentd, logstash 等. 系统监控, 如 Prometheus Node Exporter, collectd, New Relic agent, Ganglia gmond 等. 系统程序, 如 kube-proxy, kube-dns, glusterd, ceph. 示例 : 使用 Fluentd 收集日志apiVersion: extensions/v1beta1 kind: DaemonSet metadata: name: fluentd spec: template: metadata: labels: app: logging id: fluentd name: fluentd spec: containers: - name: fluentd-es image: gcr.io/google_containers/fluentd-elasticsearch:1.3 env: - name: FLUENT_ARGS value: -qq volumeMounts: - name: containers mountPath: /var/lib/docker/containers - name: varlog mountPath: /varlog volumes: - hostPath: path: /var/lib/docker/containers name: containers - hostPath: path: /var/log name: varlog 指定 Node 节点DaemonSet 会忽略 Node 的 unschedulable 状态, 有两种方式来指定 Pod 只运行在指定的 Node 节点上: nodeSelector : 只调度到匹配指定 label 的 Node上.# 给 Node 打标签 $ kubectl label nodes node-01 disktype=ssd # 在 daemonset 中指定 nodeSelector 为 disktype=ssd spec: nodeSelector: disktype: ssd nodeAffinity : 功能更丰富的 Node 选择器, 支持集合操作nodeAffinity 支持两种选择条件: requiredDuringSchedulingIgnoredDuringExecution : 代表必须满足条件 preferredDuringSchedulingIgnoredDuringExecution : 优选条件. 示例: 调度 Pod 到包含标签kubernetes.io/e2e-as-name 并且值为 e2e-az1 或 e2e-az2 的 Node, 并且优选带有标签 another-node-label-key=another-node-label-value 的 Node. apiVersion: v1 kind: Pod metadata: name: with-node-affinity spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/e2e-az-name operator: In values: - e2e-az1 - e2e-az2 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: another-node-label-key operator: In values: - another-node-label-value containers: - name: with-node-affinity image: gcr.io/google_containers/pause:2.0 podAffinity : 调度到满足条件的 Pod 所在的 Node 上.podAffinity 基于 Pod 的标签来选择 Node, 仅调度到满足条件 Pod 所在的 Node 上, 支持 podAffinity 和 podAntiAffinity. 示例:如果一个Node 所在的 Zone 中包含至少一个带有 security=s1 标签且运行中的 pod, 那么调度到该 Pod;不调度到’包含至少一个带有 security=s2 标签且运行中的 Pod’ 的 Node 上. apiVersion: v1 kind: Pod metadata: name: with-pod-affinity spec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: security operator: In values: - S1 topologyKey: failure-domain.beta.kubernetes.io/zone podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: security operator: In values: - S2 topologyKey: kubernetes.io/hostname containers: - name: with-pod-affinity image: gcr.io/google_containers/pause:2.0 静态 Pod可以使用静态 Pod 来在每台机器上运行指定的 Pod, 需要 kubelet 在启动的时候指定 manifest 目录: $ kubelet --pod-manifest-path=/etc/kubernetes/manifests 然后将所需要的 Pod 定义文件放到指定的 manifests 目录中. 静态 Pod 不能通过 API Service 来删除, 但可以通过删除 manifests 文件来自动删除对应的 Pod ServiceAccountServiceAccount 是为了方便 Pod 里面的进程调用 Kubernetes API 或 其他外部服务而设计的. 它与 UserAccount 不同: User Account 是为人设计的, 而 ServiceAccount 是为 Pod 中的进程调用 Kubernetes API 而设计的(类似于 AWS AMI ROLE 的概念). UsersAccount 的跨 namespace 的, 而 ServiceAccount 则是仅局限于它所在的 namespace. 每个 namespace 都会自动创建一个 default service account . Token controller 检测 service account 的创建, 并为他们创还能 secret. 开始 ServiceAccount Admission Controller 后: 每个 Pod 在创建后都会自动设置 spec.serviceAccount 为 default, 除非指定了其他 ServiceAccount. 验证 Pod 引用的 ServiceAccount 已经存在, 否则拒绝创建. 如果 Pod 没有指定 ImagePullSecrets , 则把 ServiceAccount 的 ImagePullSecrets 加到 Pod 中. 每个 container 启动后, 都会挂载 ServiceAccount 的 token 和 ca.crt 到 /var/run/secrets/kubernetes.io/serviceaccount/ $ kubectl exec nginx-3137573019-md1u2 ls /var/run/secrets/kubernetes.io/serviceaccount/ 创建 ServiceAccount# 创建 ServiceAccount $ kubectl create serviceaccount jenkins # 查看 serviceAccount 配置信息 $ kubectl get serviceaccounts jenkins -o yaml 授权Service Account 为服务提供了一种方便的认证机制, 但它不关心授权的问题. 可以配合 RBAC 来为 Service Account 鉴权: 配置 --authorization-mode=RBAC 和 --runtime-config=rbac.authorization.k8s.io/v1alpha1 配置 --authorization-rbac-super-user=admin 定义 Role, ClusterRole, RoleBinding 或 ClusterRoleBinding # This role allows to read pods in the namespace &quot;default&quot; kind: Role apiVersion: rbac.authorization.k8s.io/v1alpha1 metadata: namespace: default name: pod-reader rules: - apiGroups: [&quot;&quot;] # The API group &quot;&quot; indicates the core API Group. resources: [&quot;pods&quot;] verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;] nonResourceURLs: [] --- # This role binding allows &quot;default&quot; to read pods in the namespace &quot;default&quot; kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1alpha1 metadata: name: read-pods namespace: default subjects: - kind: ServiceAccount # May be &quot;User&quot;, &quot;Group&quot; or &quot;ServiceAccount&quot; name: default roleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io ReplicationController和ReplicaSetReplicationController (简称 RC) 用来确保容器应用的副本数始终保持在用户定义的副本数, 即如果有容器异常退出, 会自动创建新的 Pod 来替代; 而异常多出来的容器也会自动回收. ReplicationController 的典型应用场景包括确保健康的 Pod 的数量, 弹性伸缩, 滚动升级以及应用多版本发布跟踪等. ReplicaSet (简称 RS) : 新版本 k8s 中建议使用 ReplicaSet 来取代 ReplicationController . ReplicaSet 跟 ReplicationController 没有本质的不同, 只是名字不一样, 并且 ReplicaSet 支持集合式的 selector (ReplicationController 仅支持等式). 虽然 ReplicaSet 可以独立使用, 但建议使用 Deployment 来自动管理 ReplicaSet, 这样就无需担心跟其他机制的不兼容问题(如 ReplicaSet 不支持 rolling-update 但 Deployment 支持), 并且还支持版本记录, 回滚, 暂停升级等高级特性. # Replication Controller 示例 apiVersion: v1 kind: ReplicationController metadata: name: nginx spec: replicas: 3 selector: app: nginx template: metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 # ReplicaSet 示例 apiVersion: extensions/v1beta1 kind: ReplicaSet metadata: name: frontend # these labels can be applied automatically # from the labels in the pod template if not set # labels: # app: guestbook # tier: frontend spec: # this replicas value is default # modify it according to your case replicas: 3 # selector can be applied automatically # from the labels in the pod template if not set, # but we are specifying the selector here to # demonstrate its usage. selector: matchLabels: tier: frontend matchExpressions: - {key: tier, operator: In, values: [frontend]} template: metadata: labels: app: guestbook tier: frontend spec: containers: - name: php-redis image: gcr.io/google_samples/gb-frontend:v3 resources: requests: cpu: 100m memory: 100Mi env: - name: GET_HOSTS_FROM value: dns # If your cluster config does not include a dns service, then to # instead access environment variables to find service host # info, comment out the &apos;value: dns&apos; line above, and uncomment the # line below. # value: env ports: - containerPort: 80 JobJob 负责批处理短暂的一次性任务(short lived one-off tasks). 它保证批处理任务的一个或多个 Pod 成功结束. Kubernetes 支持一下集中 Job: 非并行 Job : 通常创建一个 Pod 直至其成功结束. 固定结束次数的 Job : 设置 .spec.completions 创建多个 Pod, 直到 .spec.completions 个 Pod 成功结束. 带有工作队列的并行 Job : 设置 .spec.Parallelism 但不设置 .spec.completions, 当所有 Pod 结束并且至少一个成功时, Job 就认为是成功的. 根据 .spec.completions 和 .spec.Parallelism 的设置, 可以将 Job 划分为以下几种 pattern : Job 类型 使用示例 行为 completionis Parallelism 一次性 Job 数据库迁移 创建一个 Pod 直至其成功结束 1 1 固定结束次数的 Job 处理工作队列的 Pod 依次创建一个 Pod 运行直至 completions 个 成功结束 2+ 1 固定结束次数的并行 Job 多个 Pod 同时处理工作队列 依次创阿金多个 Pod 运行, 直至 completions 个成功结束 2+ 2+ 并行 Job 多个 Pod 同时处理工作队列 创建一个或多个 Pod 直至有一个成功结束 1 2+ Job ControllerJob Controller 负责根据 Job Spec 创建 Pod, 并持续监控 Pod 的窗台, 直至其成功结束. 如果失败, 则根据 restartPolicy (只支持 OnFailure , Never, 不支持 Always) 决定是否创建新的 Pod 再次重新任务. Job spec spec.template 格式同 Pod RestartPolicy 仅支持 Never 或 OnFailure 单个 Pod 时, 默认 Pod 成功运行后 Job 即结束 .spec.completions 表示 Job 结束需要成功运行的 Pod 个数, 默认为 1 .spec.parallelism 标志并行运行的 Pod 的个数, 默认为 1 spec.activeDeadlineSeconds 标志失败 Pod 的重试最大时间, 超过这个时间不会继续重试. 示例: $ cat job.yaml apiVersion: batch/v1 kind: Job metadata: name: pi spec: template: metadata: name: pi spec: containers: - name: pi image: perl command: [&quot;perl&quot;, &quot;-Mbignum=bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;] restartPolicy: Never $ kubectl create -f ./job.yaml $ pods=$(kubectl get pods --selector=job-name=pi --output=jsonpath={.items..metadata.name}) $ kubectl logs $pods # 固定次数的 Job apiVersion: batch/v1 kind: Job metadata: name: busybox spec: completions: 3 template: metadata: name: busybox spec: containers: - name: busybox image: busybox command: [&quot;echo&quot;, &quot;hello&quot;] restartPolicy: Never Bare Pods所谓 Bare Pods 是指直接用 PodSpec 来创建的 Pod (即不在 ReplicaSets 或者 ReplicationController 的管理之下的 Pods). 这些 Pod 在 Node 重启后不会自动重启, 但 Job 则会创建新的 Pod 继续任务. 所以, 推荐使用 Job 来代替 Bare Pods, 即便是应用只需要一个 Pod. CronJobCronJob 即定时任务, 类似 Linux 系统的 crontab, 在指定的时间周期运行指定的任务. 在 Kubernetes 1.5 , 使用 CronJob 需要开启 batch/v2alpha1 API, 即 --runtime-config=batch/v2alpha1. CronJob Spec .spec.schedule 指定任务运行周期, 格式同 Cron .spec.jobTemplate 执行需要运行的任务, 格式同 Job .spec.startingDeadlineSeconds 指定任务开始的截止期限. .spec.concurrencyPolicy 指定任务的并发策略, 支持 Allow,Forbid,Replace 三个选项. 示例: $ cat cronjob.yaml apiVersion: batch/v2alpha1 kind: CronJob metadata: name: hello spec: schedule: &quot;*/1 * * * *&quot; jobTemplate: spec: template: spec: containers: - name: hello image: busybox args: - /bin/sh - -c - date; echo Hello from the Kubernetes cluster restartPolicy: OnFailure $ kubectl create -f cronjob.yaml # 使用 &apos;kubectl run&apos; 来创建一个 CronJob $ kubectl run hello --schedule=&quot;*/1 * * * *&quot; --restrart=OnFailure --image=busybox -- /bin/sh -c &quot;date ; echo Hello from the k8s cluster&quot; $ kubectl get cronjob $ kubectl get jobs $ pods=$(kubectl get pods --selector=job-name=hello-1202039034 --output=jsonpath={.items..metadata.name} -a) $ kubectl logs $pods # 注意 : 删除 CronJob 的时候, 不会自动删除 job, 这些 job 可以用 &apos;kubectl delete cronjob&apos; 来删除 $ kubectl delete cronjob hello SecurityContextSecurity Context 的目的是限制不可信容器的行为, 保护系统和其他容器不受其影响. Kubernetes 提供了三种配置 Security Context 的方法: Container-level Security Context : 仅应用到指定的容器, 并且不会影响 volume. # 设置容器运行在特权模式 apiVersion: v1 kind: Pod metadata: name: hello-world spec: containers: - name: hello-world-container # The container definition # ... securityContext: privileged: true Pod-level Security Context : 应用到 Pod 内所有容器以及 Volume, (包括 fsGroup 和 selinuxOptions) apiVersion: v1 kind: Pod metadata: name: hello-world spec: containers: # specification of the pod&apos;s containers # ... securityContext: fsGroup: 1234 supplementalGroups: [5678] seLinuxOptions: level: &quot;s0:c123,c456&quot; Pod Security Policies (PSP) : 应用到集群内部所有 Pod 以及 Volume Pod Security Policies (PSP) 是集群级的 Pod 安全策略, 自动为集群内的 Pod 和 Volume 设置 Security Context. 使用 PSP 需要 API Server 开启 extensions/v1beta1/podsecuritypolicy 并且配置 PodSecurityPolicy admission 控制器. 支持的控制项 控制项 说明 privileged 添加特权容器 defaultAddCapabilities 可添加到容器的 Capabilities requiredDropCapalibities 会从容器中删除的 Capabilities volumes 控制容器可以使用哪些 volume hostNetwork host 网络 hostPorts 允许的 host 端口列表 hostPID 使用 host PID namespace hostIPC 使用 host IPC namespace seLinux SELinux Context runAsUser user ID supplementalGroups 允许的补充用户组 fsGroup volume FSGroup readOnlyRootFilesystem 只读根文件系统 示例: 限制容器的 host 端口范围为 8000 - 8080 . apiVersion: extensions/v1beta1 kind: PodSecurityPolicy metadata: name: permissive spec: seLinux: rule: RunAsAny supplementalGroups: rule: RunAsAny runAsUser: rule: RunAsAny fsGroup: rule: RunAsAny hostPorts: - min: 8000 max: 8080 volumes: - &apos;*&apos; Resource QuotaResource Quote (资源配额) 是用来限制用户资源用量的一种机制. 其工作原理如下: 资源配额应用在 Namespace 上, 并且每个 Namespace 最多只能有一个 ResourceQuote 对象. 开启计算资源配额后, 创建容器时必须配置计算资源请求或限制, 也可以用 LimitRange 设置默认值. 用户超额后禁止创建新的资源. 资源配额开启 在 API Server 启动时配置 ResourceQuota adminssion control 在 namespace 中创建 ResourceQuote 对象即可. 资源配额的类型与范围类型 : 计算资源 : 包括 CPU 和 memory CPU : limits.cpu, requests.cpu memory : limits.memory, requests.memory 示例: apiVersion: v1 kind: ResourceQuota metadata: name: compute-resources spec: hard: pods: &quot;4&quot; requests.cpu: &quot;1&quot; requests.memory: 1Gi limits.cpu: &quot;2&quot; limits.memory: 2Gi 存储资源 : 包括存储资源的总量以及指定 storage classs 的总量. requests.storage persistentvolumeclaims .storageclass.storage.k8s.io/requests.storage .storageclass.storage.k8s.io/persistentvolumeclaims 对象数 : 即可创建的对象的个数. pods, replicationcontrollers, ‘configmaps’, ‘secrets’ resourcequotes, persistentvolumeclaims services, services.loadbalancers, ‘servuces.nodeports’ 示例: apiVersion: v1 kind: ResourceQuota metadata: name: object-counts spec: hard: configmaps: &quot;10&quot; persistentvolumeclaims: &quot;4&quot; replicationcontrollers: &quot;20&quot; secrets: &quot;10&quot; services: &quot;10&quot; services.loadbalancers: &quot;2&quot; 范围 : 范围 说明 Terminating podSpec.ActiveDeadlineSeconds &gt;= 0 的 Pod NotTerminating podSpec.ActiveDeadlineSeconds=nil 的 Pod BestEffort 所有容器的 requests 和 limits 都没有设置的 Pod (Best-Effort) NotBestEffort 与BestEffort 相反 LimitRange默认情况下, kubernetes 中所有容器都没有 CPU 和内存限制.LimitRange 用来给 Namespace 增加一个资源限制, 包括最小, 最大 和 默认资源. $ cat limits.yaml apiVersion: v1 kind: LimitRange metadata: name: mylimits spec: limits: - max: cpu: &quot;2&quot; memory: 1Gi min: cpu: 200m memory: 6Mi type: Pod - default: cpu: 300m memory: 200Mi defaultRequest: cpu: 200m memory: 100Mi max: cpu: &quot;2&quot; memory: 1Gi min: cpu: 100m memory: 3Mi type: Container $ kubectl create -f limits.yaml --namespace=limit-example $ kubectl describe limits mylimits --namespace=limit-example Horizontal Pod AutoscalingHorizontal Pod Autoscaling 可以根据 CPU 使用率或应用自定义 metrics 自动扩展 Pod 数量, 支持 replication controller, deployment 和 replica set. 控制管理器每个 30s (可以通过 --horizontal-pod-autoscaler-sync-period 修改) 查询 metrics 资源使用情况. 支持三种 metrics 类型: 预定义 metrics (如 Pod 的 CPU), 以利用率的方式计算 自定义 Pod metrics ,以原始值(raw value) 的方式计算 自定义 object metries 支持两种 metrics 查询方式: Heapster 和自定义的 REST API 支持多 metrics . 示例: # 创建pod和service $ kubectl run php-apache --image=gcr.io/google_containers/hpa-example --requests=cpu=200m --expose --port=80 # 创建autoscaler $ kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10 $ kubectl get hpa # 增加负载 $ kubectl run -i --tty load-generator --image=busybox /bin/sh $ while true; do wget -q -O- http://php-apache.default.svc.cluster.local; done # 过一会就可以看到负载升高了 $ kubectl get hpa # autoscaler将这个deployment扩展为7个pod $ kubectl get deployment php-apache # 删除刚才创建的负载增加pod后会发现负载降低, 并且pod数量也自动降回1个 $ kubectl get hpa $ kubectl get deployment php-apache 自定义 metrics可以参考 k8s.io/metics 开发自定义的metrics API server. 使用方法: 控制管理器开启 --horizontal-pod-autoscaler-use-rest-clients 管理控制器的 --apiserver 指向 API Server Aggregator 在 API Serveri Aggregator 中注册自定义的 metrics API 示例: apiVersion: autoscaling/v2alpha1 kind: HorizontalPodAutoscaler metadata: name: php-apache namespace: default spec: scaleTargetRef: apiVersion: apps/v1beta1 kind: Deployment name: php-apache minReplicas: 1 maxReplicas: 10 metrics: - type: Resource resource: name: cpu targetAverageUtilization: 50 - type: Pods pods: metricName: packets-per-second targetAverageValue: 1k - type: Object object: metricName: requests-per-second target: apiVersion: extensions/v1beta1 kind: Ingress name: main-route targetValue: 10k status: observedGeneration: 1 lastScaleTime: &lt;some-time&gt; currentReplicas: 1 desiredReplicas: 1 currentMetrics: - type: Resource resource: name: cpu currentAverageUtilization: 0 currentAverageValue: 0 Network PolicyNetwork Policy 提供基于策略的网络控制, 用于隔离应用并减少攻击面. 它使用标签选择器模拟传统的分段网络, 并通过策略控制他们之间的流量以及来自外部的流量. 在使用 Network Policy 之前, 需要注意: apiserver 开启 extensions/v1beta1/networkpolicies 网络插件需要支持 Network Policy , 如 Calico, Romana, Weave Net 和 trireme 等 策略 Namespace 隔离 默认情况下, 所有 Pod 之前是全通的. 每个 Namespace 可以配置独立的网络策略, 来隔离 Pod 之间的流量. 比如隔离 namespace 的所有 Pod 之间的流量(包括从外部到该 namespace 中所有 pod 的流量以及 namespace 内部 Pod 相互之间的流量). $ kubectl annotate ns &lt;namespace&gt; 目前 Network Policy 仅支持 Ingress 流量控制 Pod 隔离 通过使用标签选择器, 包括 namespaceSelecrtor 和 podSelector 来控制 Pod 之间的流量. # 允许 default namespace 中带有 role=frontend 标签的 Pod 访问 default namespace 中带有 role=db 标签的 pod 的 6379 端口. # 允许带有 project=myprojects 标签的namespace中所有Pod访问default namespace中带有 role=db 标签Pod的6379端口 apiVersion: extensions/v1beta1 kind: NetworkPolicy metadata: name: test-network-policy namespace: default spec: podSelector: matchLabels: role: db ingress: - from: - namespaceSelector: matchLabels: project: myproject - podSelector: matchLabels: role: frontend ports: - protocol: tcp port: 6379 示例 : 以 calico 为例看一下 Network Policy 的具体用法# 配置 kubectl 使用 CNI 网络插件 $ kubectl --network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin ... # 安装 calico 网络插件 # 注意修改 CIDR, 需要跟 k8s pod-network-cide 一直, 默认为 192.168.0.0/16 $ kubectl apply -f http://docs.projectcalico.org/v2.1/getting-started/kubernetes/installation/hosted/kubeadm/1.6/calico.yaml # 部署 nginx 服务 用于测试, 此时可以通过其他 Pod 访问 nginx 服务. $ kubectl run nginx --image=nginx --replicas=2 $ kubectl expose deployment nginx --port=80 # 开启 default namespace 的 DefaultDeny Network Policy 后, 其他 POd 包括 namespace 外部, 就不能访问 nginx 服务了 $ kubectl annotate ns default # 创建一个带有 &apos;access=true&apos; 的 Pod访问的 网络策略 $ cat nginx-policy.yaml kind: NetworkPolicy apiVersion: extensions/v1beta1 metadata: name: access-nginx spec: podSelector: matchLabels: run: nginx ingress: - from: - podSelector: matchLabels: access: &quot;true&quot; $ kubectl create -f nginx-policy.yaml # 带有 `access=true` 标签的 Pod 可以访问 nginx 服务 $ kubectl run busybox --rm -ti --labels=&quot;access=true&quot; --image=busybox /bin/sh / # wget --spider --timeout=1 nginx # 开启 ngixn 服务的外部访问 $ cat nginx-external-policy.yaml apiVersion: extensions/v1beta1 kind: NetworkPolicy metadata: name: front-end-access namespace: sock-shop spec: podSelector: matchLabels: run: nginx ingress: - ports: - protocol: TCP port: 80 $ kubectl create -f nginx-external-policy.yaml Ingress通常情况下, service 和 pod 的 IP 仅可在集群内部访问. 集群外部的请求需要通过负载均衡转发到 service 的 Node 上暴露的 NodePort 上, 然后再由 kube-proxy 将其转发给相关的 Pod. Ingress 为进入进群的情求提供路由规则的集合. internet | [ Ingress ] –|—–|– [ Services ] Ingress 可以给 service 提供集群外部访问的 URL, 负载均衡, SSL 终止, HTTP 路由等. 为了配置这些 Ingress 规则, 集群管理员需要部署一个 Ingress controller , 它监听 Ingress 和 service 的变化, 并根据规则配置负载均衡并提供访问入口. 格式每个 Ingress 都需要配置 rules, 目前 Kubernetes 仅支持 http 规则. # 示例: 将请求 `/testpath` 转发到服务 `test` 的 80 端口 apiVersion: extensions/v1beta1 kind: Ingress metadata: name: test-ingress spec: rules: - http: paths: - path: /testpath backend: serviceName: test servicePort: 80 # 创建 $ kubectl create test-ingress.yaml # 查看详情 $ kubectl get ing Ingress 类型 单服务 Ingress 单服务 Ingress 即该 Ingress 仅指定一个没有任何规则的后端服务. apiVersion: extensions/v1beta1 kind: Ingress metadata: name: test-ingress spec: backend: serviceName: testsvc servicePort: 80 单个服务还可以通过设置 Service.Type=NodePort 或 Service.Type=LoadBalancer 来对外暴露. 路由到多服务的 Ingress 路由到多服务的 Ingress 即根据请求路径的不同转发到不同的后端服务上.如 : foo.bar.com --&gt; 178.91.123.143 --&gt; /foo s1:80 /bar s2:80 apiVersion: extensions/v1beta1 kind: Ingress metadata: name: test spec: rules: - host: foo.bar.com http: paths: - path: /foo backend: serviceName: s1 servicePort: 80 - path: /bar backend: serviceName: s2 servicePort: 80 虚拟主机 Ingress 虚拟主机 Ingress 即根据名字的不同转发到不同的后端服务上, 而他们共用同一个 IP 地址: foo.bar.com --| |-&gt; foo.bar.com s1:80 | 178.91.123.132 | bar.foo.com --| |-&gt; bar.foo.com s2:80 示例: 基于 Host header 路由请求的 Ingress apiVersion: extensions/v1beta1 kind: Ingress metadata: name: test spec: rules: - host: foo.bar.com http: paths: - backend: serviceName: s1 servicePort: 80 - host: bar.foo.com http: paths: - backend: serviceName: s2 servicePort: 80 没有定义规则的后端服务成为默认后端服务, 可以用来方便的处理 404 页面. TLS Ingress TLS Ingress 通过 Secret 获取 TLS 私钥和证书(名为 tls.crt 和 tls.key), 来执行 TLS 终止. 如果 Ingress 中的 TLS 配置部分指定了不同的主机, 则他们将根据通过 SNI TLS 扩展指定的主机名(如 Ingress Controller 支持 SNI) 在多个相同的端口上进行复用. # 定义一个包含 `tls.crt` 和 `tls.key` 的 secret apiVersion: v1 data: tls.crt: base64 encoded cert tls.key: base64 encoded key kind: Secret metadata: name: testsecret namespace: default type: Opaque # Ingress 中医用 secret apiVersion: extensions/v1beta1 kind: Ingress metadata: name: no-rules-map spec: tls: - secretName: testsecret backend: serviceName: s1 servicePort: 80 **注意** 不同 Ingress Controller 支持的 TLS 功能不尽相同, 可以参阅有关 nginx, GCE 或任何其他 Ingress Controlles 的文档, 以了解 TLS 的支持情况. 更新 Ingress更新 Ingress 有两种方式: kubectl edit ing &lt;ing_name&gt; 在线修改, 保存后即会将其更新到 Kubernetes API Server, 进而触发 Ingress Controller 重新配置负载均衡. kubectl replace -f new-ingress.yaml 来更新(替换) Ingress Controllertraefik ingress 实践案例kubernetes/ingress 示例Kubernetes Ingress Controller使用 NGINX 和 NGINX Plus 的 Ingress Controller 进行 Kubernetes 的负载均衡 ThirdPartyResourcesThirdPartyResources 是一种无需改变代码就可以扩展 Kubernetes API 的机制, 可以用来管理自定义对象. 每个 ThirdPartyResources 都包含以下属性: metadata 跟 kubernetes metadata 一样. kind 自定义的资源类型, 采用 &lt;kind_name&gt;.&lt;domain&gt; 的格式. description 资源描述 version 版本列表 其他 : 其他任何自定义的属性. 示例: 创建一个 /apis/stable.example.com/v1/namespaces/&lt;namespace&gt;/crontabs/..的 API $ cat resource.yaml apiVersion: extensions/v1beta1 kind: ThirdPartyResource metadata: name: cron-tab.stable.example.com description: &quot;A specification of a Pod to run on a cron style schedule&quot; versions: - name: v1 $ kubectl create -f resource.yaml # 创建具体的 CronTab 对象 $ cat my-cronjob.yaml apiVersion: &quot;stable.example.com/v1&quot; kind: CronTab metadata: name: my-new-cron-object cronSpec: &quot;* * * * /5&quot; image: my-awesome-cron-image $ kubectl create -f my-crontab.yaml $ kubectl get crontab ThirdPartyResources 与 RBACThirdPartyResources 不是 namespace-scoped 的资源, 在普通用户使用之前需要绑定 ClusterRole 权限. $ cat cron-rbac.yaml apiVersion: rbac.authorization.k8s.io/v1alpha1 kind: ClusterRole metadata: name: cron-cluster-role rules: - apiGroups: - extensions resources: - thirdpartyresources verbs: - &apos;*&apos; - apiGroups: - stable.example.com resources: - crontabs verbs: - &quot;*&quot; $ kubectl create -f cron-rbac.yaml $ kubectl create clusterrolebinding user1 --clusterrole=cron-cluster-role --user=user1 --user=user2 --group=group1 ConfigMapConfigMap 用于保存配置数据的键值对, 可以用来保存单个属性, 也可以用来保存配置文件. ConfigMap 跟 secret 很类似, 但它可以更方便的处理不包含敏感信息的字符串. 创建可以使用 kubectl create configmap 从文件, 目录或者 key-value 字符串等创建 ConfigMap. 从 key-value 字符串创建 ConfigMap $ kubectl create configmap special-config --from-literal=special.how=very $ kubectl get configmap special-config -o go-template=&apos;{{.data}}&apos; map[special.how:very] 从 环境变量 创建 $ echo -e &quot;a=b\nc=d&quot; | tee config.env $ kubectl create configmap special-config --from-env-file=config.env $ kubectl get configmap special-config -o go-template=&apos;{{.data}}&apos; map[a:b c:d] 从 目录创建 $ mkdir config $ echo a &gt; config/a $ echo b &gt; config/b $ kubectl create configmap special-config --from-file=config/ $ kubectl get configmap special-config -o go-template=&apos;{{.data}}&apos; map[a:a b:b ] 使用ConfigMap 可以通过多种方式在 Pod 中使用. 但是需要注意: ConfigMap 必须在 Pod 引用之前创建; 使用envFrom 时, 将会自动忽略无效的键. 设置环境变量 # 创建 ConfigMap $ kubectl create configmap special-config --from-literal=special.how=very --from-literal=special.type=charm $ kubectl create configmap env-config --from-literal=log_level=INFO # 以环境变量方式引用 apiVersion: v1 kind: Pod metadata: name: test-pod spec: containers: - name: test-container image: gcr.io/google_containers/busybox command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;env&quot; ] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type envFrom: - configMapRef: name: env-config restartPolicy: Never # 当 Pod 运行结束后, 它的输出会包括 SPECIAL_LEVEL_KEY=very SPECIAL_TYPE_KEY=charm log_level=INFO 用作命令行参数 将 ConfigMap 用作命令行参数时, 需要先把 ConfigMap 的数据保存在环境变量zhong, 然后通过 $(VAR_NAME) 的方式引用环境变量. apiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-container image: gcr.io/google_containers/busybox command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo $(SPECIAL_LEVEL_KEY) $(SPECIAL_TYPE_KEY)&quot; ] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type restartPolicy: Never # 当 Pod 结束后输出 very charm 用作 Volume 配置文件 可以直接用 ConfigMap 的数据填充 Volume. apiVersion: v1 kind: Pod metadata: name: vol-test-pod spec: containers: - name: test-container image: gcr.io/google_containers/busybox command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;cat /etc/config/special.how&quot; ] volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: special-config restartPolicy: Never # 当 Pod 结束后输出 very # 可以指定 Volume 路径 apiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-container image: gcr.io/google_containers/busybox command: [ &quot;/bin/sh&quot;,&quot;-c&quot;,&quot;cat /etc/config/keys/special.level&quot; ] volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: special-config items: - key: special.level path: /keys restartPolicy: Never PodPressetPodPresset 用来给指定标签的 Pod 注入额外的信息, 如环境变量, 存储卷等. 这样, Pod 模板就不需要为每个 Pod 都显式设置重复的信息. 开启 PodPresset 开启 API settings.k8s.io/v1alpha1/podpreset 开启准入控制 PodPreset 示例# 增加环境变量和存储卷的 PorPreset kind: PodPreset apiVersion: settings.k8s.io/v1alpha1 metadata: name: allow-database namespace: myns spec: selector: matchLabels: role: frontend env: - name: DB_PORT value: &quot;6379&quot; volumeMounts: - mountPath: /cache name: cache-volume volumes: - name: cache-volume emptyDir: {} # 用户提交 Pod apiVersion: v1 kind: Pod metadata: name: website labels: app: website role: frontend spec: containers: - name: website image: ecorp/website ports: - containerPort: 80 # 经过准入控制 `PodPreset` 后, Pod 会自动增加环境变量和存储卷. apiVersion: v1 kind: Pod metadata: name: website labels: app: website role: frontend annotations: podpreset.admission.kubernetes.io/allow-database: &quot;resource version&quot; spec: containers: - name: website image: ecorp/website volumeMounts: - mountPath: /cache name: cache-volume ports: - containerPort: 80 env: - name: DB_PORT value: &quot;6379&quot; volumes: - name: cache-volume emptyDir: {} 示例# ConfigMap apiVersion: v1 kind: ConfigMap metadata: name: etcd-env-config data: number_of_members: &quot;1&quot; initial_cluster_state: new initial_cluster_token: DUMMY_ETCD_INITIAL_CLUSTER_TOKEN discovery_token: DUMMY_ETCD_DISCOVERY_TOKEN discovery_url: http://etcd_discovery:2379 etcdctl_peers: http://etcd:2379 duplicate_key: FROM_CONFIG_MAP REPLACE_ME: &quot;a value&quot; # PodPreset kind: PodPreset apiVersion: settings.k8s.io/v1alpha1 metadata: name: allow-database namespace: myns spec: selector: matchLabels: role: frontend env: - name: DB_PORT value: 6379 - name: duplicate_key value: FROM_ENV - name: expansion value: $(REPLACE_ME) envFrom: - configMapRef: name: etcd-env-config volumeMounts: - mountPath: /cache name: cache-volume - mountPath: /etc/app/config.json readOnly: true name: secret-volume volumes: - name: cache-volume emptyDir: {} - name: secret-volume secretName: config-details # 用户提交 Pod apiVersion: v1 kind: Pod metadata: name: website labels: app: website role: frontend spec: containers: - name: website image: ecorp/website ports: - containerPort: 80 # 经过准入控制 `PodPreset` 后, Pod 会自动增加 ConfigMap 环境变量 apiVersion: v1 kind: Pod metadata: name: website labels: app: website role: frontend annotations: podpreset.admission.kubernetes.io/allow-database: &quot;resource version&quot; spec: containers: - name: website image: ecorp/website volumeMounts: - mountPath: /cache name: cache-volume - mountPath: /etc/app/config.json readOnly: true name: secret-volume ports: - containerPort: 80 env: - name: DB_PORT value: &quot;6379&quot; - name: duplicate_key value: FROM_ENV - name: expansion value: $(REPLACE_ME) envFrom: - configMapRef: name: etcd-env-config volumes: - name: cache-volume emptyDir: {} - name: secret-volume secretName: config-details 2.3 核心组件Kubernetes 多组件之间的通信原理为: apiserver 负责 etcd 存储的所有操作, 且只有 apiserver 才直接操作 etcd 集群. apiserver 对内(集群中的其他组件)和对外(用户)提供统一的 REST API, 其他组件均通过 apiserver 进行通信. controller manager , scheduler, kube-proxy 和 kubelet 等均通过 apiserver watch API 检测资源变化情况, 并对资源做相应的操作. 所有需要更新资源状态的操作均通过 apiserver 的 REST API 进行. apiserver 也会直接调用 kubectl API (如 logs , exec, attach 等), 默认不校验 kubelet 证书, 但可以通过 --kubelet-certificate-authority 开启, (而 GKE 通过 SSH 隧道保护他们之间的通信). etcd保存了整个集群的状态； Etcd 是 CoreOS 基于 Raft 开发的分布式 key-value 存储, 可用于服务发现, 共享配置以及一致性保障(如数据库选主, 分布式锁等). 1. 主要功能 基本 Key-value 存储 监听机制 key 的过期及续约机制, 用于监控和服务发现. 原子 CAS 和 CAD , 用于分布式锁和 leader 选举. 2. ETCD 基于 Raft 的一致性 选举方法 初始启动时, 节点处于 follower 状态, 并被设定一个 election timeout, 如果在这一时间周期内, 没有收到来自 leader 的 heartbeat , 节点将发起选举 : 将自己切换为 candidate(候选人) 之后, 向集群中其他 follower 节点发送请求, 询问其是否选举自己成为 leader. 当收到来自集群中过半数节点的接受投票后, 节点即成为 leader, 开始接收保存 client 的数据并向其他的 follower 节点同步日志. 如果没有达成一致, 则 candidate 随机选择一个等待间隔 (150ms ~ 300ms) 再次发起投票, 得到集群中半数以上 follower 接受的 candidate 将成为 leader. leader 节点依靠定时向 follower 发送 heartbeat 来保持其地位. 任何时候, 如果其他 follower 在 election timeout 期间都没有收到来自 leader 的 heartbeat, 同样会将自己的状态切换为 candidate 并发起选举. 每成功选举一次, 新 leader 的任期(Term) 都会比之前 leader 的任期大 1. 日志复制 当 leader 接受到客户端的日志(事务请求)后, 先把该日志追加到本地 Log 中, 然后通过 heartbeat 把该 Entry 同步给其他 follower; follower 接受到日志后记录日志, 然后向 leader 发送 ACK; 当 leader 收到大多数 (n/2+1) follower 的 ACK 信息后, 将该日志设置为已提交, 并追加到本地磁盘中, 通知客户端并在下一个 heartbeat 中 leader 将通知所有的 follower 将该日志存储在自己本地磁盘中. 安全性 安全性是用于保证每个节点都执行相同序列的安全机制, 如当 某个 follower 在当前 leader commit log 时变得不可用了, 稍后, 可能该 follower 又被选举为 leader , 这是新 leader 可能会用新的 log 覆盖先前已 commited 的 log, 这就是导致节点指定不同序列. safety 就是用于保证选举出来的 leader 一定包含先前 commited log 的机制. 选举安全性(Election safety) : 每个任期(Term) 只能选举出一个 leader Leader 完整性(Leader Completeness) : 指 Leader 日志的完整性, 当 Log 在任期 Term1 被 Commit 后, 那么以后任期 Term2, Term3 … 等的 Leader 必须包含该 Log; Raft 在选举节点就使用 Term 的判断用于保证完整性: 当请求投票的该 Candidate 的 Term 较大或 Term 相同Index 较大则投票, 否则拒绝该请求. 失效处理 Leader 失效 : 其他没有收到 heartbeat 的节点会发起新的选举, 而当 Leader 恢复后由于步进数小会自动成为 follower, 日志也会被新 leader 的日志覆盖. follower 节点不可用 : follower 节点不可用的情况, 相对容易解决, 因为集群中的日志内容始终是从 leader 节点同步的, 只要这一节点再次加入集群是重新从 leader 节点处复制日志即可. 多个 candidate : 冲突后 candidate 将随机选择一个等待时间(150ms ~ 300ms) 再次发起投票, 得到集群中半数以上 follower 接受的 candidate 将成为 leader. wal 日志 Etcd 实现 raft 的时候, 充分利用了 go 语言 CSP 并发模型和 chan 的魔法. wal 日志是二进制的, 接续出来之后是以上数据结构: type : 只有两种类型: 0 : 表示 Normal; 1 : 表示 COnfChange , 即 Etcd 本身的配置变更同步, 如有新节点加入等. term : 每个 term 代表一个主节点的任期, 每次主节点变更 term 就会变化. index : 该序号严格有序递增的, 代表变更序号. data : 二进制的 data, 将 raft request 对象的 pb 结构整个保存下来. etcd 源码下有个 tools/etcd-dump-log 可以将 wal 日志 dump 成文本查看, 可以协助分析 raft 协议. raft 协议本身不关心应用数据, 即 data 中的部分. 一致性都通过同步 wal 日志来实现, 每个节点将从主节点收到的 data apply 到本地存储, raft 只关心日志的同步状态, 如果本地存储实现的有 bug, 比如没有正确的将 data apply 到本地, 也可能会导致数据不一致. 3. Etcd v2 与 v3Etcd v2 和 v3 本质上是共享同一套 raft 协议代码的两个独立的应用. 接口不一样, 存储不一样, 数据相互隔离. Etcd v2 存储, watch 以及过期机制 Etcd v2 是个纯内存的实现, 并未实时将数据写入到磁盘, 持久化机制很简单: 就是将 store 整个序列化成 json 写入文件. 数据在内存是一个简单的树结构. store 中有一个全局 currentIndex , 每次变更, index 会加 1. 然后每个 event 都会关联到 currentIndex. 当客户端调用 watch 接口(参数中增加 wait 参数时), 如果请求参数中有 waitIndex, 并且 waitIndex 小于等于 currentIndex , 并且和 watch key 匹配的 event 如果有数据, 则直接返回. 如果没有数据或者请求没有带 waitIndex , 则放入 WatchHub 中, 每个 key 会关联一个 watcher 列表, 当有变更操作时, 变更生成的 event 会放入 EventHistory 表中, 同时通知和该 key 相关的 watcher. 注意 EventHistroy 是有长度限制的, 最长1000. 也就是说, 如果你的客户端停了许久, 然后重新watch的时候, 可能和该waitIndex相关的event已经被淘汰了, 这种情况下会丢失变更. 如果通知watch的时候, 出现了阻塞（每个watch的channel有100个缓冲空间）, Etcd 会直接把watcher删除, 也就是会导致wait请求的连接中断, 客户端需要重新连接. Etcd store的每个node中都保存了过期时间, 通过定时机制进行清理. 过期时间只能设置到每个key上, 如果多个key要保证生命周期一致则比较困难. watch只能watch某一个key以及其子节点（通过参数 recursive),不能进行多个watch. 很难通过watch机制来实现完整的数据同步（有丢失变更的风险）, 所以当前的大多数使用方式是通过watch得知变更, 然后通过get重新获取数据, 并不完全依赖于watch的变更event. Etcd v3 存储, watch 以及过期机制 Etcd v3 将watch和store拆开实现. Store Etcd v3 store 分为两部分 : 内存中的索引 : kvindex, 是基于google开源的一个golang的btree实现的. 后端存储 : 按照它的设计, backend可以对接多种存储, 当前使用的boltdb. boltdb是一个单机的支持事务的kv存储, Etcd 的事务是基于boltdb的事务实现的. Etcd 在boltdb中存储的key是reversion, value是 Etcd 自己的key-value组合, 也就是说 Etcd 会在boltdb中把每个版本都保存下, 从而实现了多版本机制. reversion主要由两部分组成, - main rev, 每次事务进行加一 - sub rev, 同一个事务中的每次操作加一. 如上示例, 第一次操作的main rev是3, 第二次是4. 当然这种机制大家想到的第一个问题就是空间问题, 所以 Etcd 提供了命令和设置选项来控制compact, 同时支持put操作的参数来精确控制某个key的历史版本数. 了解了 Etcd 的磁盘存储, 可以看出如果要从boltdb中查询数据, 必须通过 `reversion`, 但客户端都是通过key来查询value, 所以 Etcd 的内存 kvindex 保存的就是key和reversion之前的映射关系, 用来加速查询. 2. watch Etcd v3 的watch机制支持watch某个固定的key, 也支持watch一个范围（可以用于模拟目录的结构的watch）, 所以 watchGroup 包含两种watcher, 一种是 key watchers, 数据结构是每个key对应一组watcher, 另外一种是 range watchers, 数据结构是一个 IntervalTree , 方便通过区间查找到对应的watcher. 同时, 每个 WatchableStore 包含两种 watcherGroup, 一种是synced, 一种是unsynced, 前者表示该group的watcher数据都已经同步完毕, 在等待新的变更, 后者表示该group的watcher数据同步落后于当前最新变更, 还在追赶. 当 Etcd 收到客户端的watch请求, 如果请求携带了revision参数, 则比较请求的revision和store当前的revision, 如果大于当前revision, 则放入synced组中, 否则放入unsynced组. 同时 Etcd 会启动一个后台的goroutine持续同步unsynced的watcher, 然后将其迁移到synced组. 也就是这种机制下, Etcd v3 支持从任意版本开始watch, 没有v2的1000条历史event表限制的问题（当然这是指没有compact的情况下）. 另外我们前面提到的, Etcd v2在通知客户端时, 如果网络不好或者客户端读取比较慢, 发生了阻塞, 则会直接关闭当前连接, 客户端需要重新发起请求. Etcd v3为了解决这个问题, 专门维护了一个推送时阻塞的watcher队列, 在另外的goroutine里进行重试. Etcd v3 对过期机制也做了改进, 过期时间设置在lease上, 然后key和lease关联. 这样可以实现多个key关联同一个lease id, 方便设置统一的过期时间, 以及实现批量续约. 4. etcd 周边工具 Confd : 基于 etcd 的kv 存储, 实现配置变更的机制和工具. Confd 通过 watch 机制监听 Etcd 的变更, 然后将数据同步到自己的一个本地存储, 用户可以通过配置定义自己关注那些 key 的变更, 同事提供一个配置文件模板. Confd 一旦发现数据变更就是用最新数据渲染模板生成配置文件, 如果新旧配置文件有变化, 则进行替换, 同时触发用户提供的 reload 脚本, 让应用程序重新加载配置. Metad 服务注册的实现模式一般分两种: 调度系统代为注册 : 应用程序启动后需要一种机制让应用程序知道”我是谁”, 然后发现自己所在的集群以及自己的配置. 应用程序自己注册; Metad 使用 调用系统代为注册的机制. 客户端请求 Metad 的一个固定的 /self , 有 Metad 告知应用程序其所属的元信息(通过保存一个 ip 到元信息路径的映射关系实现), 简化了客户端的服务发现和配置变更逻辑. Metad 后端支持 Etcd v3 , 提供简单好用的 http rest 接口. 他会把 Etcd 的数据通过 watch 机制同步到本地内存中, 相当于一个 Etcd 代理. 也可以吧 Metad 当做 Etcd 代理来使用, 适用于不方便使用 Etcd v3 的 rpc 接口或向降低 Etcd 压力的场景. apiserver提供了资源操作的唯一入口, 并提供认证、授权、访问控制、API注册和发现等机制； 功能: 提供集群管理的 REST API 接口, 包括认证授权, 数据校验以及集群状态变更等; 提供其他模块之间的数据交互和通信的枢纽(其他模块通过 API Servier 查询或修改数据, 只有 API Servier 才能直接操作 Etcd) REST APIkube-apiserver 支持同时提供 https (端口 6443) 和 http (端口 8080) API, 其中 http API 是非安全接口, 不做任何认证授权机制. 两个接口提供的 REST API 格式相同. 实际使用中, 通常使用 kubectl 来访问 apiserver, 也可以通过 Kubernetes 各个语言的 client 库来访问 apiserver. 在使用 kubectl 时, 打开调试日志, 可以看到每个 API 的调用格式: $ kubectl --v=8 get pods OpenAPI 和 Swagger 通过 /swaggerapi 可以查看 Swagger API, /swagger.json 查看 OpenAPI.开启 --enable-swagger-ui=true后, 还可以通过 /swagger-ui 访问 Swagger UI. 访问控制Kubernetes API 的每个请求都会经过多阶段的访问控制之后, 才会被接受, 这包括认证, 授权以及准入控制等. 认证 开启 TLS 时, 所有的请求都需要首先认证. Kubernetes 支持多种认证机制, 并支持同时开启多个认证插件(只要有一个认证通过即可). 如果认证成功, 则用户的 username 会传入授权模块做进一步授权认证; 如果认证失败, 返回 HTTP 401. Kubernetes 不直接管理用户, 不能创建 user 对象, 也不存储 username. kubernetes 认证插件 授权 认证之后的请求就到了 授权模块. Kubernetes 支持多种授权机制, 并支持同事开启多个授权插件(只要一个验证通过即可). 如果授权成功, 则用户的请求会发送到准入控制模块做进一步请求认证, 授权失败则返回 HTTP 403. kubernetes 授权插件 准入控制(Admission Control) 准入控制用来对请求做进一步的验证或添加默认参数. 不同于授权和认证只关心请求的用户和操作, 准入控制还处理请求的内容, 并且仅对创建, 更新, 删除, 链接(如代理)等有效, 对 读 操作无效. 准入控制支持同时开启多个插件, 他们依次调用, 只有全部插件都通过的请求才可以放过进入系统. kubernetes 准入控制插件 启动 apiserver 示例$ kube-apiserver --feature-gates=AllAlpha=true --runtime-config=api/all=true \ --requestheader-allowed-names=front-proxy-client \ --client-ca-file=/etc/kubernetes/pki/ca.crt \ --allow-privileged=true \ --experimental-bootstrap-token-auth=true \ --storage-backend=etcd3 \ --requestheader-username-headers=X-Remote-User \ --requestheader-extra-headers-prefix=X-Remote-Extra- \ --service-account-key-file=/etc/kubernetes/pki/sa.pub \ --tls-cert-file=/etc/kubernetes/pki/apiserver.crt \ --tls-private-key-file=/etc/kubernetes/pki/apiserver.key \ --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt \ --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt \ --insecure-port=8080 \ --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,ResourceQuota,DefaultTolerationSeconds \ --requestheader-group-headers=X-Remote-Group \ --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key \ --secure-port=6443 \ --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname \ --service-cluster-ip-range=10.96.0.0/12 \ --authorization-mode=RBAC \ --advertise-address=192.168.0.20 --etcd-servers=http://127.0.0.1:2379 kube-apiserver 工作原理 kube-schedulerkube-scheduler 负责分配调度 Pod 到集群内的节点上, 它监听 kube-apiserver , 查询还未分配 Node 的 Pod, 然后根据调度策略为这些 Pod 分配节点(更新 Pod 的 NodeName 字段). 调度器需要考虑的因素, 影响调度的 因素: 公平调度 资源高效利用 QoS affinity 和 anti-affinity 数据本地化(data locality) 内部负载干扰(inter-workload interference) deadlines 指定 Node 节点调度有三种方式指定 Pod 只运行在指定的 Node 节点上: nodeSelector : 只调度到匹配指定 label 的 Node 上. 给 Node 打标签 $ kubectl label nodes node-01 disktype=ssd 在 daemonset 中指定 nodeSelector 为 disktype=ssd spec: nodeSelector: disktype: ssd nodeAffinity : 功能更丰富的 Node 选择器, 如支持集合操作 nodeAffinity 目前支持两种: requiredDuringSchedulingIgnoredDuringExecution : 必须满足条件 preferredDuringSchedulingIgnoredDuringExecution : 优选条件 示例: 调度到包含标签 kubernetes.io/e2e-az-name 并且值为 e2e-az1 或 e2e-az2 的 Node上, 并且优选还带有标签 another-node-label-key=another-node-label-value 的 Node. apiVersion: v1 kind: Pod metadata: name: with-node-affinity spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/e2e-az-name operator: In values: - e2e-az1 - e2e-az2 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: another-node-label-key operator: In values: - another-node-label-value containers: - name: with-node-affinity image: gcr.io/google_containers/pause:2.0 podAffinity : 调度到满足条件的 Pod 所在的 Node 上. podAffinity 基于 Pod 的标签来选择 Node, 仅调度到满足条件 Pod 所在的 Node 上. 支持 podAffinity 和 podAntiAffinity. 示例: 如果一个“Node所在Zone中包含至少一个带有security=S1标签且运行中的Pod”，那么可以调度到该Node; 不调度到“包含至少一个带有security=S2标签且运行中Pod”的Node上. apiVersion: v1 kind: Pod metadata: name: with-pod-affinity spec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: security operator: In values: - S1 topologyKey: failure-domain.beta.kubernetes.io/zone podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: security operator: In values: - S2 topologyKey: kubernetes.io/hostname containers: - name: with-pod-affinity image: gcr.io/google_containers/pause:2.0 Taints 和 tolerationsTaints 和 tolerations 用于保证 Pod 不被调度到不合适的 Node 上, 其中 Taints 应用于 Node 上. 类型: NoSchedule : 新的 Pod 不调度到该 Node 上, 不影响正在运行的 Pod PreferNoSchedule : soft 版的 NoSchedule, 尽量不调度到该 Node 上. NoExecute : 新的 Pod 不调度到该 Node , 并删除(evict) 已在运行的 Pod, Pod 可以增加一个时间tolerationSeconds. 当 Pod 的 Tolerations 匹配 Node 的所有 Taints 的时候, 可以调度到该 Node 上;当 Pod 是已经运行的时候, 也不会删除(evicted).对于 NoExecute, 如果 Pod 增阿基了一个 tolerationSeconds , 则会在该时间之后才删除 Pod. 示例: 在 Node1 上应用以下一个 taint: $ kubectl taint nodes node1 key1=value1:NoSchedule $ kubectl taint nodes node1 key2=value2:NoExecute $ kubectl taint nodes node1 key2=value2:NoSchedule tolerations 应用于 Pod 上. # 如下 Pod 由于没有 tolerate `key2=value2:NoSchedule` 无法调度到 node1 上 tolerations: - key: &quot;key1&quot; operator: &quot;Equal&quot; value: &quot;value1&quot; effect: &quot;NoSchedule&quot; - key: &quot;key1&quot; operator: &quot;Equal&quot; value: &quot;value1&quot; effect: &quot;NoExecute&quot; # 正在运行且带有 `tolerationSeconds` 的 Pod 会在 600s 后被删除 tolerations: - key: &quot;key1&quot; operator: &quot;Equal&quot; value: &quot;value1&quot; effect: &quot;NoSchedule&quot; - key: &quot;key1&quot; operator: &quot;Equal&quot; value: &quot;value1&quot; effect: &quot;NoExecute&quot; tolerationSeconds: 600 - key: &quot;key2&quot; operator: &quot;Equal&quot; value: &quot;value2&quot; effect: &quot;NoSchedule&quot; DaemonSet 创建的 Pod 会自动加上对 node.alpha.kubernetes.io/unreachable 和 node.alpha.kubernetes.io/notReady 的 NoExecute toleration, 以避免被删除. 多调度器如果默认的调度器不满足要求, 还可以部署自定义的调度器, 并且在整个集群中还可以同时运行多个调度器. 通过 podSpec.schedulerName 来选择使用哪一个调度器(默认使用内置调度器). apiVersion: v1 kind: Pod metadata: name: nginx labels: app: nginx spec: # 选择使用自定义调度器my-scheduler schedulerName: my-scheduler containers: - name: nginx image: nginx:1.10 调度器扩展kube-scheduler 还支持使用 --policy-config-file 指定一个调度策略文件来自定义调度策略. { &quot;kind&quot; : &quot;Policy&quot;, &quot;apiVersion&quot; : &quot;v1&quot;, &quot;predicates&quot; : [ {&quot;name&quot; : &quot;PodFitsHostPorts&quot;}, {&quot;name&quot; : &quot;PodFitsResources&quot;}, {&quot;name&quot; : &quot;NoDiskConflict&quot;}, {&quot;name&quot; : &quot;MatchNodeSelector&quot;}, {&quot;name&quot; : &quot;HostName&quot;} ], &quot;priorities&quot; : [ {&quot;name&quot; : &quot;LeastRequestedPriority&quot;, &quot;weight&quot; : 1}, {&quot;name&quot; : &quot;BalancedResourceAllocation&quot;, &quot;weight&quot; : 1}, {&quot;name&quot; : &quot;ServiceSpreadingPriority&quot;, &quot;weight&quot; : 1}, {&quot;name&quot; : &quot;EqualPriority&quot;, &quot;weight&quot; : 1} ], &quot;extenders&quot;:[ { &quot;urlPrefix&quot;: &quot;http://127.0.0.1:12346/scheduler&quot;, &quot;apiVersion&quot;: &quot;v1beta1&quot;, &quot;filterVerb&quot;: &quot;filter&quot;, &quot;prioritizeVerb&quot;: &quot;prioritize&quot;, &quot;weight&quot;: 5, &quot;enableHttps&quot;: false, &quot;nodeCacheCapable&quot;: false } ] } 其他影响调度的因素 如果 Node Condition 处于 MemoryPressure , 则所有 BestEffort 的新 Pod (未指定 resources limits 和 request) 不会调度到该 Node 上. 如果 Node Condition 处于 DiskPressure, 则所有新 Pod 都不会调度到该 Node 上. 为保证Critical Pods 的正常运行, 当他们处于异常状态时, 会自动重新调度. Critical Pods 是指: annotation 包括 scheduler.alpha.kubernetes.io/critical-pod=&#39;&#39; tolerations 包括 [{&quot;key&quot;: &quot;CriticalAddoneOnly&quot;, &quot;operator&quot;: &quot;Exists&quot;}] 启动 kube-scheduler 示例$ kube-scheduler --address=127.0.0.1 --leader-elect=true --kubeconfig=/etc/kubernetes/scheduler.conf kube-scheduler 工作原理For given pod: +---------------------------------------------+ | Schedulable nodes: | | | | +--------+ +--------+ +--------+ | | | node 1 | | node 2 | | node 3 | | | +--------+ +--------+ +--------+ | | | +-------------------+-------------------------+ | | v +-------------------+-------------------------+ Pred. filters: node 3 doesn&apos;t have enough resource +-------------------+-------------------------+ | | v +-------------------+-------------------------+ | remaining nodes: | | +--------+ +--------+ | | | node 1 | | node 2 | | | +--------+ +--------+ | | | +-------------------+-------------------------+ | | v +-------------------+-------------------------+ Priority function: node 1: p=2 node 2: p=5 +-------------------+-------------------------+ | | v select max{node priority} = node 2 kube-scheduler 调度分为两个阶段: predicate 和 priority predicate 过滤不符合条件的节点 predicate 策略: PodFitsPorts : 同PodFitsHostPorts PodFitsHostPorts : 检查是否有Host Ports冲突 PodFitsResources : 检查Node的资源是否充足, 包括允许的Pod数量、CPU、内存、GPU个数以及其他的OpaqueIntResources HostName : 检查pod.Spec.NodeName是否与候选节点一致 MatchNodeSelector : 检查候选节点的pod.Spec.NodeSelector是否匹配 NoVolumeZoneConflict : 检查volume zone是否冲突 MaxEBSVolumeCount : 检查AWS EBS Volume数量是否过多（默认不超过39） MaxGCEPDVolumeCount : 检查GCE PD Volume数量是否过多（默认不超过16） MaxAzureDiskVolumeCount : 检查Azure Disk Volume数量是否过多（默认不超过16） MatchInterPodAffinity : 检查是否匹配Pod的亲和性要求 NoDiskConflict : 检查是否存在Volume冲突, 仅限于GCE PD、AWS EBS、Ceph RBD以及ISCSI GeneralPredicates : 分为noncriticalPredicates和EssentialPredicates. noncriticalPredicates中包含PodFitsResources, EssentialPredicates中包含PodFitsHost, PodFitsHostPorts和PodSelectorMatches. PodToleratesNodeTaints : 检查Pod是否容忍Node Taints CheckNodeMemoryPressure : 检查Pod是否可以调度到MemoryPressure的节点上 CheckNodeDiskPressure : 检查Pod是否可以调度到DiskPressure的节点上 NoVolumeNodeConflict : 检查节点是否满足Pod所引用的Volume的条件 priority 优先级排序, 选择优先级最高的节点. priority 策略: SelectorSpreadPriority : 优先减少节点上属于同一个Service或Replication Controller的Pod数量 InterPodAffinityPriority : 优先将Pod调度到相同的拓扑上（如同一个节点、Rack、Zone等） LeastRequestedPriority : 优先调度到请求资源少的节点上 BalancedResourceAllocation : 优先平衡各节点的资源使用 NodePreferAvoidPodsPriority : alpha.kubernetes.io/preferAvoidPods字段判断,权重为10000, 避免其他优先级策略的影响 NodeAffinityPriority : 优先调度到匹配NodeAffinity的节点上 TaintTolerationPriority : 优先调度到匹配TaintToleration的节点上 ServiceSpreadingPriority : 尽量将同一个service的Pod分布到不同节点上, 已经被SelectorSpreadPriority替代[默认未使用] EqualPriority : 将所有节点的优先级设置为1[默认未使用] ImageLocalityPriority : 尽量将使用大镜像的容器调度到已经下拉了该镜像的节点上[默认未使用] MostRequestedPriority : 尽量调度到已经使用过的Node上, 特别适用于cluster-autoscaler[默认未使用] controller manager 负责维护集群的状态, 比如故障检测、自动扩展、滚动更新等；Controller Managher 由 kube-controller-manager 和 cloud-controller-manager 组成, 是 kubernetes 的大脑, 它通过 apiserver 监控整个集群的状态, 并确保集群处于预期的工作状态. kube-controller-manager 由一系列控制器组成. 控制器: 必须启动的控制器 EndpointController ReplicationController PodGCController ResourceQuotaController NamespaceController ServiceAccountController GarbageCollectorController DaemonSetController JobController DeploymentController ReplicaSetController HPAController DisruptionController StatefulSetController CronJobController CSRSigningController CSRApprovingController TTLController 默认启动的可选控制器, 可通过选项设置是否开启 TokenController NodeController ServiceController RouteController PVBinderController AttachDetachController 默认禁止的可选控制器, 可通过选项设置是否开启 BootstrapSignerController TokenCleanerController cloud-controller-manager 是 Kubernetes 启动 Cloud Provider 的时候才需要, 用来配合云服务提供商的控制, 也包括一系列的控制器. 控制器: CloudNodeController RouteController ServiceController kube-controller-manager 启动示例$ kube-controller-manager --enable-dynamic-provisioning=true \ --feature-gates=AllAlpha=true \ --horizontal-pod-autoscaler-sync-period=10s \ --horizontal-pod-autoscaler-use-rest-clients=true \ --node-monitor-grace-period=10s \ --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt \ --address=127.0.0.1 \ --leader-elect=true \ --use-service-account-credentials=true \ --controllers=*,bootstrapsigner,tokencleaner \ --kubeconfig=/etc/kubernetes/controller-manager.conf \ --insecure-experimental-approve-all-kubelet-csrs-for-group=system:bootstrappers \ --root-ca-file=/etc/kubernetes/pki/ca.crt \ --service-account-private-key-file=/etc/kubernetes/pki/sa.key \ --cluster-signing-key-file=/etc/kubernetes/pki/ca.key 如何保证高可用 在启动时设置 --leader-elect=true 后, controller manager 会使用多节点选主的方式选择主节点. 只有主节点才会调用 StartControllers() 启动所有控制器, 而其他从节点则仅执行选主算法. 多节点选主的实现方法见leaderelection.go, 它实现了两种资源锁(Endpoint 和 ConfigMap, kube-controller-manager 和 cloud-controller-manager 都使用 Endpoint 锁), 通过更新资源的 Annotation (control-plane.alpha.kubernetes.io/leader) , 来确认主从关系. 如何保证高性能 从 kubernetes 1.7 开始, 所有需要监控资源变化情况的调用均推荐使用 Informer. Informar 提供了基于事件通知的只读缓存机制, 可以注册资源变化的回调函数, 并可以极大减少 API 的调用. kubelet 负责维护容器的生命周期, 同时也负责Volume（CVI）和网络（CNI）的管理；每个节点上都运行一个 kubelet 服务进程, 默认监听 10250 端口, 接受并执行 master 发来的指令, 管理 Pod 和 Pod 中的容器. 每个 kubelet 进程会在 API Server 上注册节点自身信息, 定期向 master 节点汇报节点的资源使用情况, 并通过 cAdvisor 监控节点和容器的资源. 节点管理 主要是节点自注册和节点状态更新: kubectl 可以通过设置启动参数 --register-node 来确定是否向 API Server 注册自己. 如果 Kubelet 没有选择自注册模式, 则需要用户自己配置 Node 资源信息, 同时需要告知 kubelet 集群上的 API Server 的位置 kubelet 在启动时通过 API Server 注册节点信息, 并定时向 API Server 发送节点新消息, API Server 在接收到新消息后, 将信息写入 etcd. Pod 管理 获取 Pod 清单 kubelet 以 PodSpec 的方式工作. PodSpec 是描述一个 Pod 的 YAML 或 JSON 对象. kubelet 采用一组通过各种机制提供的 podSpecs (主要通过 apiserver), 并确保这些 podSpecs 中描述的 Pod 正常健康运行. 向 kubelet 提供节点上需要运行的 Pod 清单的方法: 文件 启动参数 --config 指定的配置目录下的文件(默认 /etc/kubernetes/manifests/ ). 该文件默认每 20s 重新检查一次. HTTP endpoint(URL) 启动参数 --manifest-url 设置, 默认每 20s 检查一次这个断点. API Server 通过 API Server 监听 Etcd 目录, 同步 Pod 清单. HTTP Server kubectl 侦听 HTTP 请求, 并响应简单的 API 以提交新的 Pod 清单. 通过 API Server 获取 Pod 清单及创建 Pod 的过程 Kubelet 通过 API Server Client (kubelet 启动时创建) 使用 Watch 加 List 的方式监听 /registry/nodes/$当前节点名 和 /registry/pods 目录, 将获取的信息同步到本地缓存中. Kubelet 监听 etcd , 所有针对 Pod 的操作都将会被 kubelet 监听到. 如果发现新的绑定到本节点的 Pod, 则按照 Pod 清单的要求创建该 Pod. 如果发现本地的 Pod 被修改, 则 Kubelet 会做出相应的修改.比如 删除某个Pod 中的某个容器时, 则会通过 Docker Client 删除该容器. kubelet 读取监听到的信息, 如果是创建和修改 Pod 任务, 则执行如下处理: 为 该 Pod 创建一个数据目录; 从 API Server 读取该 Pod 清单; 为该 Pod 挂载外部卷 下载 Pod 用到的 Secret; 检查已经在节点上运行的 Pod, 如果该 Pod 没有容器或 Pause 容器没有启动, 则先停止Pod 里所有容器的进程. 如果在 Pod 中有需要删除的容器, 则删除这些容器. 用kubernetes/pause 镜像为每个 Pod 创建一个容器. Pause 容器用于接管 Pod 所有其他容器的网络. 每创建一个新的 Pod, Kubelet 都会先创建一个 Pause 容器, 然后创建其他的容器. 为 Pod 中的每个容器做如下处理: 为容器计算一个 hash 值, 然后用容器的名字去 Docker 查询对应容器的 hash 值. 若查找到容器, 且两者 hash 值不同, 则停止 Docker 中容器的进程, 并停止与之关联的 Pause 容器的进程; 若两者相同, 则不作任何处理. 如果容器被终止了, 且容器没有指定 restartPolicy , 则不作任何处理; 调用 Docker Client 下载容器镜像, 调用 Docker Client 运行容器. Static Pod 所有以非 API Server 方式创建的 Pod 都叫 Static Pod. Kubelet 将 Static Pod 的状态汇报给 API Server, API Server 为该 Static Pod 创建一个 Mirror Pod 和其相匹配. Mirror Pod 的状态将真实反映 Static Pod 的状态. 当 Static Pod 被删除时, 与之相对应的 Mirror Pod 也会被删除. 容器健康检查 Pod 通过两类探针检查容器的健康状态: LivenessProbe 用于判断容器是否健康, 告诉 Kubelet 一个容器什么时候处于不健康的状态. 如果 LivenessProbe 探测到容器不健康, 则 Kubelet 将删除该容器, 并根据容器的重启策略做相应的处理. 如果一个容器不包含LivenessProbe 探针, 那么 Kubelet 认为该容器的 LivenessProbe 探针返回的值永远是 Success. Kubelet 定期调用容器中的 LivenessProbe 探针来诊断容器的健康状况. LivenessProbe 包含如下三种实现方式: ExecAction : 在容器内部执行一个命令, 如果该命令的退出码状态为 0 , 则表明容器健康. TCPSocketAction : 通过容器的 IP 地址和端口号执行 TCP 检查, 如果端口能被方位, 则表明容器健康. HTTPGetAction : 通过容器的 IP 地址, 端口号, 及路径调用 HTTP GET 方法, 如果响应的状态码大于等于 200 且小于 400, 则认为容器状态健康. ReadinessProbe 用于判断容器是否启动完成且准备接受请求. 如果 ReadinessProbe 探针探测到失败, 则 Pod 的状态将被修改. Endpoint Controller 将从 Service 的 Endpoint 中删除包含该容器所在的 Pod 的 IP 地址的 Endpoint 条目. cAdvisor 资源监控 Kubernetes 集群中, 应用程序的执行情况可以在不同的级别上检测到, 这些级别包括: 容器 pod service 整个集群 Heapster 项目为 Kubernetes 提供一个基本的监控平台, 他是集群级别的监控是时间数据集成器. Heapster 以 Pod 的方式运行在集群中, Heapster 通过kubelet 发现所有运行在集群中的节点, 并查看来自这些节点的资源使用情况. Heapster 通过带着关联标签的 Pod 分组这些信息, 这些数据将被推到一个可配置的后端, 用于存储和可视化展示. 支持的的后端包括 InfluxDB 和 Google Cloud Monitoring. cAdvisor 是一个开源的分析容器资源使用率和性能特性的代理工具, 已集成到 Kubernetes 代码中. cAdvisor 自动查找所有在其所在节点上的容器, 自动采集 CPU, 内存 , 文件系统 和 网络使用的统计信息. cAdvisor 通过他所在节点机的 Root 容器, 采集并分析该节点机的全面使用情况. cAdvisor 通过其所在节点机的 4194 端口暴露一个简单的 UI. 容器运行时(Container Runtime) 容器运行时是 Kubernetes 最重要的组件之一, 负责真正管理镜像和容器的生命周期. Kubelet 通过 Container Runtime Interface (CRI) 与容器运行时交互, 以管理镜像和容器. CRI Container Runtime Interface (CRI) 是 kubelet 1.5/1.6 中主要负责的一块项目, 他重新定义了 kubelet container runtime API, 将原来完全面向 Pod 级别的 API 拆分成 面向Sandbox 和 Container 的 API, 并分离镜像管理和容器引擎到不同的服务. Docker Docker runtime 的核心代码在 kubelet 内部, 是最稳定和特定支持最好的 Runtime. Hyper Hyper 是一个基于 Hypervisor 的容器运行时, 为 kubernetes 带来了强隔离, 适用于多租户和运行不可信容器的场景. Hyper 在 Kubernetes 的集成项目为 frakti, 目前已支持 Kubernetes v1.6+ Rkt Rkt 是另一个继承在 kubelet 内部的容器运行时. Runc cri-containerd : 还在开发中, cri-o : 以支持 Kubernetes v1.6 启动 kubelet 示例$ kubelet --kubeconfig=/etc/kubernetes/kubelet.conf \ --require-kubeconfig=true \ --pod-manifest-path=/etc/kubernetes/manifests \ --allow-privileged=true \ --network-plugin=cni \ --cni-conf-dir=/etc/cni/net.d \ --cni-bin-dir=/opt/cni/bin \ --cluster-dns=10.96.0.10 \ --cluster-domain=cluster.local \ --authorization-mode=Webhook \ --client-ca-file=/etc/kubernetes/pki/ca.crt \ --feature-gates=AllAlpha=true kubelet 工作原理 kubelet 内部组件: kubelet API 认证API : 10250 cAdvisor API : 4194 只读 API : 10255 健康检查 API : 10248 syncLoop 从 API 或者 manifest 目录接受 Pod 更新, 发送到 podWorkers 处理, 大量使用 channel 处理异步请求. 辅助的 manager 如 cAdvisor , PLEG, Volume Manager 等, 处理 syncLoop 以外的其他工作. CRI 容器执行引擎接口, 负责与 container runtime shim 通信. 容器引擎插件 如 dockershim, rkt 等. 网络插件 目前支持 CNI 和 kubenet. kube-proxy 负责为Service提供cluster内部的服务发现和负载均衡；每台机器上都运行一个 kube-proxy 服务, 他监听 API Server 中的 service 和 endpoint 的变化情况, 并通过 iptables 等来为服务配置负载均衡(仅支持 TCP 和 UDP). 不支持 HTTP 路由, 并且也没有健康检查机制, 这些可以通过自定义 Ingress Controller 的方法来解决. kube-proxy 运行方式 : 直接运行在 物理机上 以 static pod 方式运行 以 daemonset 方式运行 kube-proxy 当前支持一下几种实现: userspace : 在用户空间监听一个端口, 所有服务通过 iptables 转发到这个端口, 然后在其内部负载均衡到实际的 Pod. 效率低, 有明显的 性能瓶颈. iptables : 目前推荐方案, 完全以 iptables 规则的方式来实现 service 负载均衡. 在服务多的时候, 产生太多的 iptables 规则, 大规模下也有性能问题. winuserspace : 同 userspace , 但仅工作在 windows 上. ipvs 方案: 正在讨论中, 尚未实现, 大规模情况下可以大幅提高性能. 启动示例: $ kube-proxy –kubeconfig=/var/lib/kube-proxy/kubeconfig.conf kube DNS : 为集群提供命名服务, 作为 addon 的方式部署 支持的 DNS 格式: Service A record : 生成 my-svc.my-namespace.svc.cluster.local. 解析 IP 分为两种情况: 普通 Service 解析为 Cluster IP Headless Service 解析为指定的 Pod IP 列表 SRV record : 生成 _my-port-name._my-port-protocol.my-svc.my-namespace.svc.cluster.local Pod A record : pod-ip-address.my-namespace.pod.cluster.local hostname 和 subdomain : hostname.custom-subdomain.default.svc.cluster.local apiVersion: v1 kind: Pod metadata: name: busybox2 labels: name: busybox spec: hostname: busybox-2 subdomain: default-subdomain containers: - image: busybox command: - sleep - &quot;3600&quot; name: busybox 组件及启动示例kube-dns 由三个容器组成: kube-dns : DNS 服务的核心组件, 主要有 KubeDNS 和 SkyDNS 组成. KubeDNS 负责监听 Service 和 Endpoint 的变化情况, 并将相关的信息更新到 SkyDNS 中. SkyDNS 负责 DNS 解析, 监听在 10053 端口(TCP/UDP), 同时也监听在 10055 端口提供 metrics. kube-dns 还监听 8081 端口, 以供健康检查使用. dnsmasq-nanny : 负责启动 dnsmasq , 并在配置发生变化是重启 dnsmasq dnsmasq 的 upstream 为 SkyDNS, 即集群内部的 DNS 解析有 SkyDNS 负责. sidecar : 复则健康检查和提供 DNS metrics (监听 10054 端口) 启动示例: # kube-dns container $ kube-dns --domain=cluster.local. --dns-port=10053 --config-dir=/kube-dns-config --v=2 # dnsmasq container $ dnsmasq-nanny -v=2 -logtostderr -configDir=/etc/k8s/dns/dnsmasq-nanny -restartDnsmasq=true -- -k --cache-size=1000 --log-facility=- --server=127.0.0.1#10053 # sidecar container $ sidecar --v=2 --logtostderr --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local.,5,A --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local.,5,A Federation在云计算环境中，服务的作用距离范围从近到远一般可以有：同主机（Host，Node）、跨主机同可用区（Available Zone）、跨可用区同地区（Region）、跨地区同服务商（Cloud Service Provider）、跨云平台。 K8s的设计定位是单一集群在同一个地域内，因为同一个地区的网络性能才能满足K8s的调度和计算存储连接要求。而集群联邦（Federation）就是为提供跨Region跨服务商K8s集群服务而设计的。 每个Federation有自己的分布式存储、API Server 和 Controller Manager。用户可以通过Federation的API Server注册该Federation的成员K8s Cluster。 当用户通过Federation的API Server创建、更改API对象时，Federation API Server会在自己所有注册的子K8s Cluster都创建一份对应的API对象。在提供业务请求服务时，K8s Federation会先在自己的各个子Cluster之间做负载均衡，而对于发送到某个具体K8s Cluster的业务请求，会依照这个K8s Cluster独立提供服务时一样的调度模式去做K8s Cluster内部的负载均衡。而Cluster之间的负载均衡是通过域名服务的负载均衡来实现的。 所有的设计都尽量不影响K8s Cluster现有的工作机制，这样对于每个子K8s集群来说，并不需要更外层的有一个K8s Federation，也就是意味着所有现有的K8s代码和机制不需要因为Federation功能有任何变化。 组件: federation-apiserver : 类似kube-apiserver，但提供的是跨集群的REST API federation-controller-manager : 类似kube-controller-manager，但提供多集群状态的同步机制 kubefed : Federation管理命令行工具 部署方法# 下载 kubefed 和 kubectl $ curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/kubernetes-client-linux-amd64.tar.gz $ tar -xzvf kubernetes-client-linux-amd64.tar.gz # 初始化主集群 # 选择一个已部署好的 Kubernetes 集群作为主集群, 作为集群联邦的控制平面, 并配置好本地的 kubeconfig, 然后运行 kubefed inti 来初始化集群 $ kubefed init fellowship \ --host-cluster-context=rivendell \ # 部署集群的kubeconfig配置名称 --dns-provider=&quot;google-clouddns&quot; \ # DNS服务提供商，还支持aws-route53或coredns --dns-zone-name=&quot;example.com.&quot; \ # 域名后缀，必须以.结束 --apiserver-enable-basic-auth=true \ # 开启basic认证 --apiserver-enable-token-auth=true \ # 开启token认证 --apiserver-arg-overrides=&quot;--anonymous-auth=false,--v=4&quot; # federation API server自定义参数 $ kubectl config use-context fellowship hyperkubekubeadmkubectl参考资料kubernetes handbook]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>容器编排</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Buffer Cache 区别]]></title>
    <url>%2F2018%2F03%2F15%2FBuffer-Cache-%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[buffer 是磁盘缓存, 缓存的是连续的blockcache 文件缓存, 缓存的是组成文件的非连续的block, 示例:某个磁盘中的 block 编号 1 - 10, buffer 缓存: 依据磁盘的局部性原理, 其缓存的是 从 编号5-10 的block; cache 缓存: 某个文件存放该磁盘上, 并且占据所有编号为奇数的block.]]></content>
      <categories>
        <category>计算机原理与操作系统</category>
      </categories>
      <tags>
        <tag>buffer</tag>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用redis生成分布式锁]]></title>
    <url>%2F2018%2F03%2F15%2F%E5%88%A9%E7%94%A8redis%E7%94%9F%E6%88%90%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[使用 redis 命令 set(self, name, value, ex=None, px=None, nx=False, xx=False) 生成分布式锁.使用 setnx(key, value) + expire(key, sec) 生成分布式锁.指令与原理: set(self, name, value, ex=None, px=None, nx=False, xx=False) –&gt; 推荐, 更加原子性 ex : 设置过期时间, 单位 秒 px : 设置过期时间, 单位 毫秒 nx : nx=True, 当 name 不存在时, 设置其值为 value. xx : xx=True, 当 name 存在时, 设置其值为 value. setnx(key, value) + expire(key, sec) 当 key 存在时, 忽略 set key 值, 并返回 False; 当 key 不存在时, set key 值, 并返回 True 示例代码: import redis def redis_conn(host=&quot;127.0.0.1&quot;, port=6379, db=0): return redis.StrictRedis(host=host, port=port, db=db) myredis = redis_conn() # 设置锁, 并获取锁. def redis_lock(key, value): k = str(key).lower().strip() while True: if dredis.set(k, value, ex=3600, nx=True): break else: time.sleep(5) # 释放锁 def redis_unlock(key): uuid_key = str(key).lower().strip() pipe = dredis.pipeline() pipe.get(uuid_key) pipe.delete(uuid_key) res = pipe.execute() return res[0]]]></content>
      <categories>
        <category>Middleware</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis 汇总]]></title>
    <url>%2F2018%2F03%2F15%2Fredis-%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[1. Redis 介绍1.1 使用场景Redis是远程字典服务器 的缩写, 适用于如下场景: 数据库 缓存 队列系统 1.2 Redis所支持的数据类型 字符串类型 当存储的字符串类型是整数形式时, 可以对其进行递增操作, 比如：set age 1, incr age, 返回递增后的值, 递增操作是原子操作. 散列类型 列表类型 集合类型 有序集合类型 2. 安装配置与优化2.1 源码编译安装# 安装依赖, 编译工具 $ yum groupinstall &quot;Development Tools&quot; -y # 编译安装 $ wget http://usl/redis-stable.tgz $ tar xf redis-stable.tgz $ cd redis-stable $ make PREFIX=/usr/loca/redis $ make install PREFIX=/usr/local/redis # 配置启动 $ mkdir /usr/local/redis/{logs,data,conf} $ cp *.conf /usr/local/redis/conf/ $ sed -i &apos;s/^daemonize no/daemonize yes/g&apos; /usr/local/redis/conf/redis.conf $ cat &gt;/etc/profile.d/redis.sh &lt;&lt;EOF #!/bin/bash # export PATH=$PATH:/usr/local/redis/bin EOF $ source /etc/profile.d/redis.sh # 启动测试 $ redis-server /usr/local/redis/conf/redis.conf $ redis-cli -p REDIS_PORT &gt; info make install命令执行完成后, 会在/usr/local/redis 目录下生成 6 个可执行文件, 分别是redis-server、redis-cli、redis-benchmark、redis-check-aof 、redis-check-dump, 它们的作用如下： redis-server : Redis服务器的daemon启动程序 redis-cli ：Redis命令行操作工具. 也可以用telnet根据其纯文本协议来操作 redis-benchmark : Redis性能测试工具, 测试Redis在当前系统下的读写性能 redis-check-aof : 数据修复,AOF文件修复工具 redis-check-dump : 检查导出工具,RDB文件检查工具 redis-sentinel : sentinel 服务器 ,哨兵 2.2 redis 配置参数2.2.1 redis.conf 配置文件参数daemonize ：是否以后台daemon方式运行 pidfile ：pid文件位置 port ：监听的端口号 timeout ：请求超时时间 loglevel ：log信息级别 logfile ：log文件位置 databases ：开启数据库的数量 save * * ：保存快照的频率, 第一个*表示多长时间, 第二个*表示执行多少次写操作. 在一定时间内执行一定数量的写操作时, 自动保存快照. 可设置多个条件. rdbcompression ：是否使用压缩 dbfilename ：数据快照文件名(只是文件名, 不包括目录) dir：数据快照的保存目录(这个是目录) -- 持久化存储保存位置. appendonly ：是否开启appendonlylog, 开启的话每次写操作会记一条log, 这会提高数据抗风险能力, 但影响效率. appendfsync ：appendonlylog如何同步到磁盘(三个选项, 分别是每次写都强制调用fsync、每秒启用一次fsync、不调用fsync等待系统自己同步) 2.2.2 命令行 config 配置还可以在 redis 运行中通过 CONFIG SET 命令在不重新启动redis的情况下,动态修改部分 redis 配置. redis&gt; CONFIG SET loglevel warning redis&gt; CONFIG GET loglevel 支持的配置修改项: save rdbcompression rdbchekcsum dbfilename masterauth slave-server-stale-data sleva-read-only maxmemory maxmemory-policy maxmemory-samples appendonly appendfsync auto-aof-rewrite-percentage auto-aof-rewrite-min-size lua-time-limit slowlog-log-slower-than slowlog-max-len hash-max-ziplist-entries hash-max-ziplist-value list-max-ziplist-entries list-max-ziplist-value set-max-intset-entries zset-max-ziplist-entries zset-max-ziplist-value 使用 config 命令配置 redis server 时, 应当同时手动修改配置文件, 保证 redis-server 的配置与配置文件中一致, 否则容易采坑. 2.2.3 系统优化参数修改系统配置文件, 执行命令 $ echo vm.overcommit_memory=1 &gt;&gt; /etc/sysctl.conf $ sysctl vm.overcommit_memory=1 或执行echo vm.overcommit_memory=1 &gt;&gt;/proc/sys/vm/overcommit_memory 使用数字含义： 0, 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存, 内存申请允许；否则, 内存申请失败, 并把错误返回给应用进程. 1, 表示内核允许分配所有的物理内存, 而不管当前的内存状态如何. 2, 表示内核允许分配超过所有物理内存和交换空间总和的内存 2.3 启动与关闭2.3.1 启动 前台启动 # 以开发模式启动redis-server,并指定端口,默认为6379 $ redis-server [--port=6380] 后台启动 $ vim redis.conf daemonize yes $ redis-server /etc/redis.conf 当配置文件后跟参数时, 参数会覆盖配置文件中的该选项. 此种启动方式应当仅限于测试, 生产勿用. $ redis-server /etc/redis.conf --loglevel warning 检测是否启动成功 $ redis-cli info 2.3.2 关闭# redis 会先断开所有客户端连接,然后根据配置执行持久化,最后完成退出. $ redis-cli shutdown # redis 可以妥善处理 SIGTERM 信号, 效果与发送 shutdown 命令一样. $ kill redis_PID 3. redis 命令3.1 redis 执行命令方式方式一 : 将命令作为 redis-cli 的参数执行 $ redis-cli -h HOST -p PORT CMD 或 $ echo &quot;REDIS_CMD&quot; | redis-cli -h HOST -p PORT 方式二 : 交互式模式 $ redis-cli -h HOST -p PORT &gt; CMD 3.2 命令返回值 状态回复 : 直接显示状态信息 redis&gt; PING PONG 错误回复 : 当出现命令不存在或命令格式有错误等情况时 Redis 会返回错误回复(error reply). 错误回复以error开头, 并在后面跟上错误信息. 整数回复 : 整数回复(integer reply)以(integer)开头, 并在后面跟上整数数据 # 递增键值返回以整数形式返回递增后的键值. redis&gt; INCR foo # 返回数据库中键的数量 redis&gt; DBSIZE 字符串回复 : 当请求一个字符串类型键的键值或一个其他类型键中的某个元素时就会得到一个字符串回复. 字符串回复以双引号包裹 redis&gt; GET foo 多行字符回复 : 多行字符串回复中的每行字符串都以一个序号开头. # 返回符合指定规则的键名. redis&gt; KEYS * 4. redis 多数据库redis 是一个字典结构的存储服务器,实际上一个redis实例提供了多个用来存储数据的字典,可以加将每个字典理解成一个独立的数据库. 每个数据库对外都是以一个从0开始的递增数字命名,redis 默认支持16个数据库. 客户端与redis建立链接之后,自动连接 0号 数据库,不过可以随时使用 SELECT 命令更换数据库, 但这种数据库更像是一种命名空间,而不适宜存储不同应用程序的数据 ,可以启动多个redis实例,存储数据. 但是可以用 数据库0 存储应用A的线上数据, 数据库1 存储应用A的测试数据. redis&gt; SELECT 1 OK redis[1]&gt; GET foo 注意: 这种数据库更像是一种命名空间,而不适宜存储不同应用程序的数据. redis 不支持自定义数据库的名字,每个数据库都以编号命名. 开发者必须自己记录那些数据库存储了那些数据 redis 不支持为每个数据库设置不同的访问密码, redis 多个数据库之间并不是完全隔离的. 如 FLASHALL 会清空一个redis实例中所有数据库中的数据. 5. redis 数据类型:所有 redis 命令都是原子操作. Redis中每个键都属于一个明确的数据类型,如通过HSET建立的键是散列类型,通过SET建立的键是字符串类型. 使用一种数据类型的命令操作另一种数据类型的键会提示错误. 5.0 基础命令5.0.1. 获取符合规则的键名列表 : KEYS patternredis&gt; KEYS glob_pattern ? : 匹配一个字符 * : 匹配任意个字符,包括0个 [] : 匹配括号内的任一字符, &quot;-&quot; 表示范围,[0-9] \x : 转义 5.0.2. 判断一个键是否存在# 有返回1, 没有返回0 redis&gt; EXISTS key 5.0.3. 删除键# 可以删除多个keys, 返回删除的键的个数. redis&gt; DEL key [key ...] # 一次删除多个键 : 删除所有以 &quot;user:*&quot; 开头的键. $ redis-cli KEYS &apos;user:*&apos; | xargs redis-cli DEL 或 # 性能更好. $ redis-cli DEL `redis-cli KEYS &quot;user:*&quot;` 5.0.4. 获得键值的数据类型:# 返回 string(字符串),hash(散列),list(列表),set(集合),zset(有序集合) redis&gt; TYPE key # 向指定的列表类型键中增加一个元素,如果键不存在则创建它. &gt; LPUSH key value 5.0.5. 键命名规范:对象类型:对象ID:对象属性 如 : post:articleID:page.view -- 文章访问量 5.0.6. 过期时间 设置过期时间 返回值 : 1 表示甚至成功 ; 0 表示键不存在或设置失败. 对键多次使用 EXPIRE 会重新设置键的过期时间. # seconds 表示过期时间,必须为整数. &gt; EXPIRE key seconds # 设置过期时间,时间单位是毫秒 &gt; PEXPIRE key milliseconds PEXPIRE key 10000 == EXPIRE key 1 # 第二个参数表示键的过期时间.使用UNIX时间戳. 表示到 UNIX_TIME 时过期. &gt; EXPIREAT key UNIX_TIME # 同上,但单位为毫秒. &gt; PEXPIREAT key UNIX_TIME_MS 查看过期时间 返回值 : 剩余时间,单位秒 ; 当键不存在时,返回 -2 ; 没有为键设置过期时间 ,返回 -1 . # 查看一个键还有多久时间会被删除, &gt; TTL key # 以毫秒为单位返回键的剩余时间. &gt; PTTL key 取消过期时间设置 注意 : 使用 SET 或 GETSET 命令为键赋值也会同时清除键的过期时间. 其他只对键值进行操作的命令(如 INCR,LPUSH,HSET,ZREN) 均不会影响键的过期时间. # 取消键的过期时间设置,即将键恢复成永不过期. &gt; PERSIST key 实现缓存. 实际开发中会发现很难为缓存键设置合理的过期时间, 为此可以限制 Redis 能够使用的最大内存,并让Redis按照一定的规则淘汰不需要的缓存键,这种方式在只将Redis用作缓存系统时非常实用. $ vim redis.conf # 限制Redis最大可用内存大小,单位字节. maxmemory = 12345 # 在超出maxmemory大小时,指定策略删除不需要的键,直到Redis占用的内存小于指定内存. maxmemory-policy = volatile-lru maxmemory-policy 策略 : LRU (Least Recently Used),最近最少使用 volatile-lru : 使用LRU算法删除一个键(只对设置了过期时间的键) allkeys-lru : 使用LRU算法删除一个键 volatile-random : 随机删除一个键(只对设置了过期时间的键) allkeys-random : 随机删除一个键 volatile-ttl : 删除过期时间最近的一个键 noeviction : 不删除键,只返回错误. volatile : 易变的,不稳定的, 5.1 字符串类型 :最基本的数据类型, 能存储任何形式的字符串,包括二进制数据. 可以存储 用户邮箱/JSON化的对象/图片等. 字符串类型是其他4种数据类型的基础,其他数据类型和字符串的差别从某种角度来说只是组织字符串的形式不同. 如 列表类型是以列表的形式组织字符产,集合是以集合的形式组织字符串. 单个字符串类型键允许存储的数据的最大容量是512MB. 5.1.1 赋值与取值 :&gt; SET key value &gt; GET key # 为程序设置分布式锁时, 非常有用. &gt; set(key, value, ex=None, px=None, nx=False, xx=False) ex : 设置过期时间, 单位 秒 px : 设置过期时间, 单位 毫秒 nx : nx=True, 当 key 不存在时, 设置其值为 value. xx : xx=True, 当 key 存在时, 设置其值为 value 5.1.2 递增数字:当存储的字符串类型是整数形式时, 可以对其进行递增操作, # 让当前键值递增,并返回递增后的值 &gt; INCR key # 对 key 进行 100 次递增操作 $ redis-cli -r 100 incr key 用途 : 文章访问量统计 生成自增ID 存储文章数据 5.1.3 增加指定的整数 :# 指定当前 key 增加 increment 个数 &gt; INCRBY key increment # 指定 bar 增加 2 redis&gt; INCRBY bar 2 5.1.4 减少指定的整数 :# 让键值递减 &gt; DECR key # 指定减少个数 &gt; DECRBY key decrement 5.1.5 增加指定浮点数:# 指定增加一个双精度浮点数. &gt; INCRBYFLOAT key increment 5.1.6 向尾部追加值 :# 向键值的末尾追加value, 如果键不存在则将该键的值设置为 value, 返回值是追加后字符串的总长度. &gt; APPEND key value 5.1.7 获取字符串长度 :# 返回键值的长度,如果键不存在则返回0 . &gt; STRLEN key 5.1.8 同时获取/设置多个键值&gt; MGET key [key ...] &gt; MSET key value [key value ...] 5.1.9 位操作 :一个字节由8个二进制位组成, Redis提供了 4 个命令可以直接对二进制位进行操作. 位操作符可以非常紧凑的存储布尔值,并且 GETBIT 和 SETBIT 的时间复杂度是O(1)的,性能很高. GETBIT# 获取一个字符串类型键指定位置的二进制位的值. # 如果需要获取的二进制位的索引超出了键值的二进制位的长度,则默认位值是 0 . &gt; GETBIT key offset # bar 的3个字母,的ASCII码为 98,97,114 ,转换为二进制后分别为 : 1100010,1100001,1110010 存储结构为 011000100110000101110010 . redis&gt; SET foo bar OK &gt; GETBIT foo 0 (integer) 0 &gt; GETBIT foo 6 (integet) 1 SETBIT# 设置字符串类型键指定位置的二进制位的值, 返回值是该位置的旧值. # 如果设置的位值超过了键值的二进制位的长度,SETBIT命令会自动将中间的二进制位设置为0 # 如果设置一个不存在的键的指定二进制位的值会自动将其前面的位赋值为 0 . &gt; SETBIT key offset value BITCOUNT# 获得字符串类型键中值是 1 的二进制位个数. start 和 end 限制统计的字节范围. &gt; BITCOUNT key [start] [end] BITOP# 可以对多个字符串类型键进行位运算,并将结果存储在 destkey 参数指定的键中, BITOP的支持的运算操作有 AND,OR,XOR,NOT . &gt; BITOP operation destkey key [key ...] #示例 : 对 bar 和 aar 进行OR运算; &gt; SET foo1 bar &gt; SET foo2 aar &gt; BITOP OR res foo1 foo2 (integer)3 &gt; GET res &quot;car&quot; BITPOS# 可以获取指定键的第一位值是0 或 1 的位置. start end 指定起始字节 , 但返回的偏移量任然从开头算起. # redis_version &gt; 2.8.7 &gt; BITPOS key [0|1] [start] [end] &gt; SET foo bar &gt; BITPOS foo 1 (integer)1 BITFIELD# Perform arbitrary bitfield integer operations on strings. VER &gt; 3.2.0 &gt; BITFIELD key [GET type offset] [SET type offset value] [INCRBY type offset increment] [OVERFLOW WRAP|SAT|FAIL] 5.2 hash 散列类型 :1 个散列类型最多能容纳 2**32 - 1 个元素. hash 的键值也是一种字典结构,其存储了字段(field)和字段值得映射,但字段值只能是字符串,不支持其他类型.散列值类型不能嵌套其他的数据类型. ( Redis 的其他数据类型同样不支持数据类型嵌套. ) 适合存储对象 : 使用对象类别和ID构成键名,使用字段表示对象的属性,而字段值则存储属性值. 对象类别:ID:字段属性 – 字段值 例如 : 存储ID为2的汽车对象, CAR:2:color -- 白色 CAR:2:name -- 奥迪 CAr:2:price -- 900k 5.2.1 赋值与取值 : HSET, HMSET, HGET, HMGET, HGETALL# 设置 key 中指定 filed 的值 &gt; HSET key field value HSET 不区分插入和更新操作. 即修改数据时不用事先判断字段是否存在来决定是插入还是更新操作. 1. 当执行的是 插入 操作时,HSET返回 1 ; 2. 当执行的是 更新 操作时,HSET返回 0 ; 3. 当键本身 不存在 时,HSET会自动创建它. # 获取 key 中指定 field 的值. &gt; HGET key field # 设置一个 key 中的多个 field &gt; HMSET key field value [field value ...] &gt; HMSET car:3 name baoma color black price 900k # 获取一个 key 中的多个 field &gt; HMGET key field [field ...] &gt; HMGET car:3 name color price # 获取键中所有字段和字段值. &gt; HGETALL key &gt; HGETALL car:3 5.2.2 判断字段是否存在# 存在返回 1 ,不存在返回 0 ; &gt; HEXISTS key field &gt; HEXISTS car:3 name 5.2.3 当字段不存在时赋值 :# 如果字段已存在,则不执行任何操作. 且HSETNX是原子操作,不必担心竞态条件. &gt; HSETNX key field value 5.2.4 增加数字 :# 使字段增加指定的整数 . # 如果键不存在,则 HINCRBY 命令会自动建立该键,并默认新建字段的值为&apos;0&apos; . # 命令返回值为增值后的字段值. &gt; HINCRBY key field increment 5.2.5 删除字段 :# 可以删除一个或多个字段,返回值为被删除的字段的个数. &gt; HDEL key field [field ...] 5.2.6 获取所有 字段名(field) 或 字段值 :# 获取字段名字 &gt; HKEYS key # 获取字段值. &gt; HVALS key 5.2.7 获得字段数量&gt; HLEN key 5.3 列表类型 : – 队列 , 1 个列表类型最多能容纳 2**32 - 1 个元素.存储一个有序的字符串列表, 常用操作时向列表两端添加元素,或者后的列表的某一个片段. 列表类型内部是使用双向链表(double linked list)实现的 ,所以向列表两端增加元素的时间复杂度是 O(1) ,获取越接近两端的元素速度越快. 但代价是通过索引访问元素比较慢. 使用场景: 记录新鲜事儿, 最新记录 top 10 记录日志等 5.3.1 向列表两端增加元素.# 向列表左端增加元素,返回增加元素后列表的长度, &gt; LPUSH key value [value ...] # 向列表右端增加元素,返回增加元素后列表的长度. &gt; RPUSH key value [value ...] 5.3.2 从列表两端弹出数据# 从列表左边弹出一个元素,返回被移除的元素值. &gt; LPOP key # 从列表右边弹出一个元素,返回被移除的元素值. &gt; RPOP key ** 模拟 栈 : 后进先出 LPUSH -- LPOP ROUSH -- RPOP ** 模拟 队列 : 先进先出 LPUSH -- RPOP RPUSH -- LPOP 5.3.3 获取列表中元素的个数# LLEN时间复杂度为 O(1) ,使用redis会直接读取现成的值,而不需要遍历一遍数据表来完成统计. &gt; LLEN key 5.3.4 获得列表片段# 起始索引值为 0 .并且 LRANGE 返回的值包含最右边的元素. 支持负索引. &gt; LRANGE key start stop 1. 如果 strat &gt; stop ,则返回空列表 2. 如果 start &gt; LLEN(key) ,返回列表最右边的元素. 5.3.5 删除列表中指定的值# 删除列表中前 count 个值为 value 的元素, 返回值为实际删除的元素个数. &gt; LREM key count value 1. 当 count &gt; 0 ,LREM 从列表 左边 开始删除前 count 个值为 value 的元素 2. 当 count &lt; 0 ,LREM 从列表 右边 开始删除前 |count| 个值为 value 的元素. 3. 当 count = 0 ,LREM 删除 所有值 为 value 的元素. 5.3.6 获取/设置指定索引的元素值# 返回指定索引的元素. 索引从 0 开始. # 当index 为负数时,从右边开始计算索引,最右边的元素索引为 -1 . &gt; LINDEX key index # 将索引为 index 的元素, 赋值为 value. &gt; LSET key index value 5.3.7 只保留列表指定片段# 删除指定范围之外的所有元素. &gt; LTRIM key start end 5.3.8 向列表中插入元素# LINSERT首先会在列表中从左向右查找职位 pivot 的元素,然后 BEFORE|AFTER 插入 value . # LINSERT 返回值为插入后列表的元素个数. &gt; LINSERT key [ BEFORE | AFTER ] pivot value 5.3.9 将元素弓一个列表转到另一个列表.把列表类型作为队列使用时,RPOPLPUSH命令可以很直观的在多个队列中传递数据. 当 source 和 destination 相同时, RPOPLPUSH 会不断将对尾的元素转移到队首,借助这个特性,可以实现一个网站监控系统: 使用一个队列存储需要监控的网址,然后监控程序不断的使用 RPOPLPUSH 命令循环去除一个网址来检测可用性. 另外,在检测过程中,可以不断的向队列中增加新的元素, 而且整个系统容易扩展,允许多个客户端同时处理队列. # 从 source RPOP 一个元素, LPUSH 到 destination ,并返回改变的元素值. # 整个操作过程是原子的. &gt; RPOPLPUSH source destination 5.4 集合类型集合中的每个元素都是不同的, 且没有顺序 . 一个集合类型最多可以存储 2**32-1 个字符串. 集合类型在Redis内部是通过使用值为空的 散列表(hash table)实现的, 故操作的时间复杂度是O(1)的. 多个集合类型键之间可以进行并集/交集/差集运算. 5.4.1 增加/删除元素# 向集合中增加一个或多个元素,如果键不存在则会自动创建. 如果元素已经存在,则会忽略. # 命令返回值为加入的元素的个数. &gt; SADD key member [member ...] # 从集合中删除一个或多个元素,并返回删除成功的元素的个数. &gt; SREM key member [member ...] 5.4.2 获取集合中所有的元素# 返回集合中的所有元素. &gt; SMEMBERS key 5.4.3 判断元素是否在集合中# 判断一个元素是否在集合中是一个事件复杂度为O(1)的操作,无论集合中有多少元素. # 当值存在是返回 1 ,当值不存在是返回 0 . &gt; SISMEMBER key member 5.4.4 集合间运算集合运算 # 差集运算. # 集合A 与 集合B 的差集表示 A - B, 代表所有属于A 且 不属于B的元素构成的集合. &gt; SDIFF key [key ...] # 先计算 setA - setB ,再计算结果与 setC 的差集. &gt; SDIFF setA setB setC # 交集运算. # 集合A 和 集合B 的交集表示 A ∩ B,代表所有属于A 且 属于B的元素构成的集合. &gt; SINTER key [key ...] # 并集计算. # 集合A 和 集合B 的并集表示 A ∪ B, 代表所有属于A 或 属于B的元素构成的集合. &gt; SUNION key [key ...] 进行集合运算,并将结果存储. 常用于需要多次运算的场合. # SDIFF操作之后,将结果存储在 destination 中 &gt; SDIFFSTORE destination key [key ...] # SINTER操作之后,将结果存储在 destination 中 &gt; SINTERSTORE destination key [key ...] # SUNION操作之后,将结果存储在 destination 中 &gt; SUNIONSTORE destination key [key ...] 5.4.5 获取元素的个数&gt; SCARD key 5.4.6 随机获取集合中的元素# 用来随机集合中获取 count 个元素. &gt; SRANDMEMBER key [count] 当 count &gt; 0 , SRANDMEMBER 会随机从集合里获得count个不重复的元素. 当 count 的值大于集合中全部的元素的个数时,返回集合中的全部元素. 当 count &lt; 0 , SRANDMEMBER 随机从集合中获取 |count| 个元素.这些元素有可能相同. 5.4.7 从集合中弹出一个元素# 从集合中随机弹出一个元素. &gt; SPOP key 5.5 有序集合类型 : sorted set有序集合是在集合的基础上,为集合中的每个元素都关联了一个分数,这使得我们不仅可以完成插入/删除和判断元素是否存在等集合类型操作 ,还可以获得分数最高(或最低)的前N个元素、获得指定分数范围内的元素等与分数有关的操作. 虽然集合中每个元素都是不同的, 但是它们的分数却可以相同. 有序集合使用散列表和跳跃表实现,所以即使读取列表中间部分的数据也很快(时间发咋读O(log(N)))有序集合可以调整集合中某个元素的位置(通过修改这个元素的分数).有序集合比列表类型更耗费内存. 有序集合算得上是 Redis的5种数据类型中最高级的类型了,可以与列表类型和集合类型对照理解. 5.5.1 增加元素# 向有序集合中添加一个元素和该元素的分数,如果该元素已经存在,则会用新的分数替换原有的分数. # 命令返回值 : 新加入到集合中的元素的个数. # 分数可以为双精度浮点数. &gt; ZADD key score member [score member] # +inf 正无穷 &gt; ZADD testboard +inf haha # -inf 负无穷 &gt; ZADD testboard -inf hehe 5.5.2 获得元素的分数&gt; ZSCORE key member 5.5.3 获得排名在某个范围的元素列表# 按元素分数从小到大顺序返回 索引 从start 到 stop 之间的所有元素(包含两端的元素). # 索引从 0 开始, 负数代表从后向前查找. # [WITHSCORES] 表示在获得 元素 值的同时,展示元素的分数. &gt; ZRANGE key start stop [WITHSCORES] 时间复杂度 : O(log n+m) , n 为有序集合的基数, m为返回的元素的个数. 当两个元素分数相同时,Redis按照字典书序来进行排序. &gt; ZREVRANGE key start stop [WITHSCORES] # 元素从大到小排序. 5.5.4 获得指定分数范围的元素按照元素分数从小到大的顺序返回分数在min 和 max之间(包含min,max)的元素. 如果希望分数范围不包含端点值,可以在分数前加上 “(“ 符号,可以单独加. min ,max 支持 +inf 和 -inf . &gt; ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] LIMIT offset count : 在获得的元素列表的基础上,向后偏移 offset 个元素,并只获取钱 count 个元素. &gt; ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] # 元素从大到小. 5.5.5 增加某个元素的分数# 增加一个元素的分数,返回值是更改后的分数. increment 支持负数. &gt; ZINCRBY key increment member 5.5.6 获得集合中元素的数量&gt; ZCARD key 5.5.7 获得指定分数范围内的元素的个数&gt; ZCOUNT key min max 5.5.8 删除一个或多个元素&gt; ZREM key member [member ...] 5.5.9 按照排名范围删除元素.# 按照元素分数从小到大的顺序(即索引0表示最小的值)删除处在指定排名范围内的所有元素, 并返回删除的元素数量. &gt; ZREMRANGEBYRANK key start stop 5.5.10 按照分数范围删除元素# 删除指定分数范围内的所有元素,min max 的特定和 ZRANGEBUSCORE 命令中的一样. 返回值是删除的元素数量. &gt; ZREMRANGEBYSCORE key min max 5.5.11 获得元素的排名# 安装元素分数从小到大的顺序获得指定的元素的排名(从0开始,即分数最小的元素排名为0) &gt; ZRANK key member # 分数最大的元素排名为0 &gt; ZREVRANK key member 5.5.12 计算有序集合的交集计算多个有序集合的交集,并将结果存储在 destination 键中(同样以有序集合类型存储), 返回值为 destination 键中元素的个数. &gt; ZINTERSTORE destination numkeys key [key...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX ] destination 键中元素的分数是由 AGGREGATE 参数决定的. - 当 AGGREGATE 是 SUM 时(默认值), destination键中元素的分数是每个参与计算的集合中该元素分数的和. - 当 AGGREGATE 是 MIN 时, destination键中元素的分数是每个参与计算的集合中该元素分数的最小值. - 当AGGREGATE是MAX时, destination键中元素的分数是每个参与计算的集合中该元素分数的最大值. ZINTERSTORE命令还能够通过WEIGHTS参数设置每个集合的权重, 每个集合在参与计算时元素的分数会被乘上该集合的权重 6. redis 事务 transction数据库原理中很重要的一个概念是事务, 简单来说就是把一系列动作看做一个整体, 如果其中一个出了问题, 应该把状态恢复到执行该整体之前的状态. 在 Redis 中, MULTI、EXEC、DISCARD、WATCH 这四个指令是事务处理的基础. - MULTI : 用来 组装 一个事务； - EXEC : 用来 执行 一个事务； - DISCARD : 用来 取消 一个事务； - WATCH : 用来 监视 一些key, 一旦这些key在事务执行之前被改变, 则取消事务的执行. 用 MULTI 组装事务时, 每一个命令都会进入到内存队列中缓存起来, 如果出现 QUEUED 则表示我们这个命令成功插入了缓存队列, 在将来执行 EXEC 时, 这些被 QUEUED 的命令都会被组装成一个事务来执行. 对于事务的执行来说, 如果 redis 开启了 AOF 持久化的话, 那么一旦事务被成功执行, 事务中的命令就会通过 write 命令一次性写到磁盘中去, 如果在向磁盘中写的过程中恰好出现断电、硬件故障等问题, 那么就可能出现只有部分命令进行了 AOF 持久化, 这时 AOF 文件就会出现不完整的情况, 这时, 我们可以使用 redis-check-aof 工具来修复这一问题, 这个工具会将 AOF 文件中不完整的信息移除, 确保 AOF 文件完整可用. 然后我们来说说 WATCH 这个指令, 它可以帮我们实现类似于“乐观锁”的效果, 即CAS(check and set). WATCH本身的作用是“监视key是否被改动过”, 而且支持同时监视多个key, 只要还没真正触发事务, WATCH都会尽职尽责的监视, 一旦发现某个key被修改了, 在执行EXEC时就会返回nil, 表示事务无法触发. 6.1 MULTI &amp; EXEC事务同命令一样是Redis的最小执行单位, 一个事务要么都执行,要么都不执行.事务的原理是先将属于一个事务的命令发送给Redis,然后再让Redis一次执行这些命令. &gt; MULTI &gt; CMD_1 # 返回值,QUEUED &gt; CMD_2 # 返回值,QUEUED &gt; EXEC # 返回这些命令的返回值组成的列表. 如果在发送 EXEC 命令前,客户端断开链接,则Redis会清空事务队列. Redis的事务还能保证一个事务内的命令一次执行而不被其他命令插入. 错误处理 : 语法错误 : 只要有一个命令有语法错误,执行EXEC命令之后Redis就会直接返回错误,连语法争取的命令也不会执行. redis 2.6.5 之前的版本会忽略有语法错误的命令,而执行事务中其他语法正确的命令. 运行错误 : 指在命令执行时出现的错误,比如使用散列类型的命令操作集合类型的键,这种错误在实际执行之前是无法发现的,所以事务里的这样的命令是会被执行的. 如果事务里的一条命令出现了运行错误,事务里的其他命令依然会继续执行(包括出错之后的命令). Redis的事务没有回滚功能,为此开发者必须自己将数据库复原回事务执行前的状态. Redis不支持回滚功能,也使得Redis 在事务上可以保值简洁和快速. 6.2 WATCH &amp; UNWATCHWatch 命令 : 用于监控一个或多个键, 一旦其中有一个键被修改(或删除), 之后的事务就不会执行. 监控将一直持续到 EXEC命令结束. 事务中的命令是在EXEC之后才执行的,所以在MULTI命令之后可以修改WATCH监控的键值. 示例 : redis&gt; SET key 1 redis&gt; WATCH key redis&gt; SET key 2 redis&gt; MULTI redis&gt; SET key 3 redis&gt; EXEC (nil) redis&gt; GET key &quot;2&quot; 该例子中,在执行WATCH命令后, 事务执行只玩修改了 key 的值(SET key 2),所以最后事务中的命令 SET key 3 没有执行,EXEC返回空结果. WATCH 命令的作用只是当被监控的键值被修改后阻止之后的一个事务执行,而不能保证其他客户端不修改这一键值,所以我们需要在EXEC执行失败后重新执行整个函数. 执行EXEC命令后会取消对所有键的监控,如果不想执行事务中的命令也可以使用 UNWATCH 命令来取消监控. 7. 排序 有序集合的集合操作 有序集合的常见的使用场景是大数据排序. ZINTERSTORE ZUNIONSTORE MULTI ZINTERSTORE tempKey ZRANGE tempKey DEL tempKey EXEC SORT命令 : 可以对列表类型,集合类型和有序集合类型键进行排序, 并且可以完成与关系数据库中的联结查询类似的任务. BY 参数 GTE 参数 STORE 参数 性能优化 : SORT 是Redis中最强大最复杂的命令之一,如果使用不好很容易成为性能瓶颈. SORT 的时间复杂度是 O(n+mlog(m)) , n 为排序的列表(或集合或有序集合)中元素的个数. 注意: 尽可能减少待排序键中元素的数量,使 n 尽可能小. 使用 LIMIT 参数,只获取需要的数据, 是 m 尽可能小. 如果要排序的数据数量很大,尽可能使用 STORE 参数将结果缓存. 8. 消息通知8.1 任务队列 : 传递任务的队列与任务队列进行交互的实体有两类 : 生产者 : producer, 生产者会将需要处理的任务放在任务队列中, 消费者 : comsumer, 消费这不断地从任务队列中读入任务信息并执行. 任务队列的优点 : 松耦合 : 生产者和消费者无需知道彼此的实现细节,只需要约定好任务的描述格式. 易于扩展 : 消费者可以有多个,而且可以分布在不同的服务器中,借此可以降低单台服务器的负载. 使用 Redis 实现任务队列 生产者 : LPUSH 消费者 : RPOP BRPOP : 当列表中没有元素时, BRPOP 命令会一直阻塞住链接, 直到有新元素加入. BRPOP 接受连个参数,第一个是键名, 第二个是超时时间; 当超过了超时时间任然没有获得新元素的话,就返回 nil. 0 表示不显示等待时间,即 如果没有新元素加入,就会一直阻塞下去. 当获得一个元素后, BRPOP 命令返回两个值, 第一个是键名,第二个是超时时间(单位s). BRPOP key [key ...] timeout BLPOOP : 从队列左边获取元素. 8.2 优先级队列8.3 ‘发布/订阅’ 模式 : pulish/subscribe ,可以实现进程间的消息传递.8.3.1 基础订阅模式 : 发布者 : 可以向指定的频道发布消息, 所有订阅此频道的订阅者都会收到此消息. 订阅者 : 可以订阅一个或若干个频道(channel). 发布者不会 : 发出的消息不会**持久化. &gt; PUBLISH channel message # 返回值表示接受到这条消息的订阅者数量. 订阅者 : 处于订阅状态下的客户端, 不能使用 SUBSCRIBE,UNSUBSCRIBE,PUNSUBSCRIBE 这四个属于’发布/订阅’模式的命令之外的命令, 否则会报错. &gt; SUBSCRIBE channel [channel ...] 进入订阅状态后客户端可能收到 3 种类型的回复,每种类型的回复都包含 3 个值, 第一个值是消息的类型, 依据消息了类型的不同,第二,第三个值的含义也不同. 消息类型 : subscribe : 表示订阅成功的返回消息, 第二个值是订阅成功的频道名称,第三个值是当前客户端订阅的频道数量. message : 表示收到的消息. 第二个值是产生消息的频道名称,第三个消息是消息的内容. unsubscribe : 表示成功取消订阅某个频道. 第二个值是对应的频道名称,第三个值是当前客户端订阅的频道数量, 当此值为 0 时,客户端会推出订阅状态. UNSUBSCRIBE : 取消订阅指定的频道. 没有指定频道的情况下,将退订所有频道. &gt; UNSUBSCRIBE [channel [channel ...]] 8.3.2 按照规则订阅.PSUBSCRIBE : 订阅指定的规则, 规则支持 glob 风格的通配符. 使用 PSUBSCRIBE 可以重复订阅一个频道. PSUBSCRIBE channel.? channel.?* 则 当 channel.2 发布消息后,该客户端会收到两条消息. &gt; PSUBSCRIBE channel.?* 1) &quot;pmessage&quot; # 表示通过 PSUBSCRIBE 命令订阅 2) &quot;channel.?*&quot; # 订阅时使用的通配符 3) &quot;channel.1&quot; # 实际收到消息的频道的名称 4) &quot;hi!&quot; # 消息的内容. PUNSBUSCRIBE [pattern [pattern ...]] : 退订指定的规则. 如果没有指定会退订所有规则. 使用 PUNSUBSCRIBE 命令只能退订通过 PSUBSCRIBE命令订阅的规则, 不会影响直接通过 SUBSCRIBE 命令订阅的频道； 同样 UNSUBSCRIBE 命令也不会影响通过PSUBSCRIBE命令订阅的规则. 使用 PUNSUBSCRIBE 命令退订某个规则时不会将其中的通配符展开, 而是进行严格的字符串匹配, 所以PUNSUBSCRIBE * 无法退订 channel.* 规则, 而是必须使用 PUNSUBSCRIBE channel.* 才能退订. 9. 管道往返时延 : 网络传输中,往返消息的总耗时. 在执行多条命令时,每条命令都需要等待上一条命令执行完(即受到Redis返回的结果)才能执行, 即使命令并不需要上一条命令的执行结果. Redis 的底层通信协议对管道(pipelining)提供了支持. 通过管道可以一次性发送多条命令并在执行完后一次性将结果返回, 当一组命令中每条命令都不依赖于之前命令的执行结果时就可以将这组命令一起通过管道发出. 管道通过减少客户端与 Redis 的通信次数来实现降低往返时延累计值的目的 Redis 通过监听一个 TCP 端口或者 Unix socket 的方式来接收来自客户端的连接, 当一个连接建立后, Redis 内部会进行以下一些操作： 客户端 socket 会被设置为非阻塞模式, 因为 Redis 在网络事件处理上采用的是非阻塞多路复用模型. 为这个 socket 设置 TCP_NODELAY 属性, 禁用 Nagle 算法. Nagle 算法实际就是当需要发送的数据攒到一定程度时才真正进行发包, 通过这种方式来减少 header 数据占比的问题. 不过在高互动的环境下是不必要的, 一般来说, 在客户端/服务器模型中会禁用. 创建一个可读的文件事件用于监听这个客户端 socket 的数据发送 Redis 管道技术可以在服务端未响应时, 客户端可以继续向服务端发送请求, 并最终一次性读取所有服务端的响应. 管道技术最显著的优势是提高了 redis 服务的性能. 10. 内存优化10.1. redisObject 对象redis 存储的所有值对象, 在内部定义为 redisObeject 结构体, 内部结构如下图: Redis 存储的数据都使用 redisObject 来封装, 包括 string, hash, list, set, zset 在内的所有数据类型. 理解 redisObject 对内存优化非常有帮助, 下面介绍每个字段 1. type 字段 表示当前对象使用的数据类型, redis 主要支持 5 种数据类型 : string,hash,list,set,zset . 可以使用 type {key} 命令查看对象所属类型, type 返回的是值对象类型, 键都是 string 类型. 2. encoding 字段 表示 redis 内部编码类型, encoding 在 redis 内存不使用, 代表当前对象内部使用哪种数据结构实现. 同一个对象采用不同的编码实现内存占用存在明显差异, 具体实现细节见 之后的编码部分. 3. lru 字段 记录对象最后一次被访问的时间, 当配置了 maxmemory 和 maxmemory-policy=volatile-lru | allkeys-lru 时, 用于辅助 LRU 算法删除键数据. 使用 objectidletime {key} 命令在不更新 lru 字段情况下查看当前键的空闲时间. **开发提示：可以使用scan + object idletime 命令批量查询哪些键长时间未被访问, 找出长时间不访问的键进行清理降低内存占用** 4. refcount 字段 记录当前对象被引用的次数, 用于通过引用次数回收内存, 当 refcount=0 时, 可以安全回收当前对象空间. 使用 objectrefcount {key} 获取当前对象引用. 当对象为整数且范围在 0-9999 时, redis 可以使用共享对象的方式来节省内存. 5. *ptr 字段 与对象的数据内容有关, 如果是整数直接存储数据, 否则表示指向数据的指针. Redis 在 3.0 之后对值对象是字符串且长度 &lt;= 39 字节的数据, 内部编码为 embstr 类型, 字符串 sds 和 redisObject 一起分配, 从而只要一次内存操作. **高并发写入场景中, 在条件允许的情况下建议字符串长度控制在39字节以内, 减少创建redisObject内存分配次数从而提高性能. ** 10.2. 缩减键值对象降低 Redis 内存使用最直接的方式就是缩减键和值的长度. - key 长度 : 如在设计键时, 在完整描述业务情况下, 键值越短越好. - value 长度 : 值对象缩减比较复杂, 常见需求是把业务对象序列化成二进制数组放入 redis. - 首先, 应该在业务上精简业务对象, 去掉不必要的属性避免存储无效数据. - 其次, 在序列化工具选择上, 应该选择更高效的序列化工具来降低字节数组大小. ![常见 java 序列化工具空间压缩对比](http://i2.itc.cn/20170216/3084_8e427aa5_bf49_c714_45f8_692fccf2cd6b_1.png) - 值对象除了存储二进制数据之外, 通常还会使用通用格式存储数据 比如 JSON, xml 等作为字符串存储在 redis 中. 这种方式的有点是方便调试和跨语言, 但是同样的数据相比字节数组所需的空间更大, 在内存紧张的情况下, 可使用通用压缩算法压缩 json,xml 后再存入 redis, 从而降低内存使用率, 例如 使用 GZIP 压缩后的 json 可以降低 60% 的空间. **当频繁压缩解压json等文本数据时, 开发人员需要考虑压缩速度和计算开销成本, 这里推荐使用google的Snappy压缩工具, 在特定的压缩率情况下效率远远高于GZIP等传统压缩工具, 且支持所有主流语言环境. ** 10.3. 共享对象池对象共享池指 redis 内存维护 0-9999 的整数对象池, 创建大量的整数类型 redisObject 存在内存开销, 每个 redisObject 内部结构至少占 16字节, 甚至超过了证书自身空间开销. 除了整数值对象, 其他类型如 list,hash,set,zset 内部元素也可以使用整数对象池, 因此开发中, 在满足需求的前提下, 尽量使用整数对象以节省内存. 整数对象池在Redis中通过变量 REDIS_SHARED_INTEGERS 定义, 不能通过配置修改. 可以通过object refcount 命令查看对象引用数验证是否启用整数对象池技术, redis&gt; set foo 100 redis&gt; object refcount foo (integer) 2 redis&gt; set bar 100 redis&gt; object refcount bar (integer) 3 ![共享对象池图示](http://i0.itc.cn/20170216/3084_ffd40aaf_b79c_0c62_9751_650a6b0ccc53_1.png) **当设置maxmemory并启用LRU相关淘汰策略如:volatile-lru, allkeys-lru时, Redis禁止使用共享对象池, 即 共享对象池与maxmemory+LRU策略冲突 ** LRU算法需要获取对象最后被访问时间, 以便淘汰最长未访问数据, 每个对象最后访问时间存储在redisObject对象的lru字段. 对象共享意味着多个引用共享同一个redisObject, 这时lru字段也会被共享, 导致无法获取每个对象的最后访问时间. 如果没有设置maxmemory, 直到内存被用尽Redis也不会触发内存回收, 所以共享对象池可以正常工作. 10.4. 字符串优化0. 在 redis 内部, 所有的键都是字符串类型, 值对象数据除了整数之外都使用字符串存储. 1. 字符串结构 Redis 自己实现了字符串结构, 内部简单动态字符串(Simple dynamic string), SDS. ![SDS 结构图](http://i2.itc.cn/20170216/3084_54bb9bb0_a89d_8e7e_2edb_11fcfc6ee5f1_1.png) SDS 特点 - O(1) 的时间复杂度获取 : 字符串长度,已用长度, 未用长度 - 可用于保存字节数组, 支持安全的二进制数据存储 - 内部实现空间预分配机制, 降低内存再分配次数. - 惰性删除机制, 字符串缩减后的空间不释放, 作为预分配空间保留. 2. 预分配机制. 因为 字符串SDS 存在预分配jizhi,日常开发中要小心预分配带来的内存浪费. 空间预分配规则 : - 第一次创建len属性等于数据实际大小, free等于0, 不做预分配. - 修改后如果已有free空间不够且数据小于1M, 每次预分配一倍容量. 如原有len=60byte, free=0, 再追加60byte, 预分配120byte, 总占用空间:60byte+60byte+120byte+1byte. - 修改后如果已有free空间不够且数据大于1MB, 每次预分配1MB数据. 如原有len=30MB, free=0, 当再追加100byte ,预分配1MB, 总占用空间:1MB+100byte+1MB+1byte. ** 尽量减少字符串频繁修改操作如append, setrange, 改为直接使用set修改字符串, 降低预分配带来的内存浪费和内存碎片化 ** 3. 字符串重构 : 不一定吧每份数据作为字符串整体存储, 像 json 这样的数据可以使用 hash 结构, 使用二级结构存储也能帮助我们节省内存. 同时可以使用hmget,hmset命令支持字段的部分读取修改, 而不用每次整体存取. 10.5. 编码优化10.5.1. 编码Redis对外提供了string,list,hash,set,zet等类型, 但是Redis内部针对不同类型存在编码的概念, 所谓编码就是具体使用哪种底层数据结构来实现. 编码不同将直接影响数据的内存占用和读写效率. 使用object encoding {key}命令获取编码类型. Redis 为每种数据类型都提供了两种内部编码方式, 查看key 的内部编码方式: &gt; OBJECT ENCODING key 数据类型与编码方式 数据类型 内部编码方式 OBJECT_ENCODING命令结果 数据结构 字符串类型 REDIS_ENCODING_RAM &apos;raw&apos; 动态字符串编码 REDIS_ENCODING_INT &apos;int&apos; 整数编码 REDIS_ENCODING_EMBSTR &apos;embstr&apos; 优化内存分配的字符串编码 散列类型 REDIS_ENCODING_HT &apos;hashtable&apos; 散列表编码 REDIS_ENCODING_ZIPLIST &apos;ziplist&apos; 压缩列表编码 列表类型 REDIS_ENCODING_LINKEDLIST &apos;linkedlist&apos; 双向链表编码 REDIS_ENCODING_ZIPLIST &apos;ziplist&apos; 压缩列表编码 REDIS_ENCODING_QUICKLIST &apos;quicklist&apos; 3.2 版本新的列表编码 集合类型 REDIS_ENCODING_HT &apos;hashtable&apos; 散列表编码 REDIS_ENCODING_INTSET &apos;intset&apos; 整数集合编码 有序集合类型 REDIS_ENCODING_SKIPLIST &apos;skiplist&apos; 跳跃表编码 REDIS_ENCODING_ZIPLIST &apos;ziplist&apos; 压缩列表编码 10.5.2. type 和 encoding 对应关系 类型 编码方式 数据结构 转换条件 string raw 动态字符串编码 string embstr 优化内存分配的字符串编码 string int 整数编码 hash hashtable 散列表编码 满足任意条件 : ① value 最大空间(字节) &gt; hash-max-ziplist-value ; ② field 个数 &gt; hash-max-ziplist-entries hash ziplist 压缩列表编码 满足所有条件 : ① value 最大空间(字节) &lt;= hash-max-ziplist-value ; ② field 个数 &lt;= hash-max-ziplist-entries list linkedlist 双向链表编码 满足任意条件 : ① value 最大空间(字节) &gt; list-max-ziplist-value ; ② 链表长度 &gt; list-max-ziplist-entries list ziplist 压缩列表编码 满足所有条件 : ① value 最大空间(字节) &lt;= list-max-ziplist-value ; ② 链表长度 &lt;= list-max-ziplist-entries list quicklist 3.2 版本新的列表编码 废弃 list-max-ziplist-entries 配置, 新配置 : ① list-max-ziplist-size 表示最大压缩空间或长度, 最大空间使用 [-5-1]范围配置, 默认 -2 表示 8KB , 正整数表示最大压缩长度;② list-compress-depth 表示最大压缩深度, 默认 0 不压缩 ; set hashtable 散列表编码 满足任意条件 : ① 元素必须为非整数类型 ; ② 集合长度 &gt; hash-max-ziplist-entries set intset 整数集合编码 满足所有条件 : ① 元素必须为整数 ; ② 集合长度 &lt;= hash-max-ziplist-entries zset skiplist 跳跃列表编码 满足任意条件 : ① value最大空间(字节) &gt; zset-max-ziplist-value ; ② 有序集合长度 &gt; zset-max-ziplist-entries zset ziplist 压缩列表编码 满足所有条件 : ① value最大空间(字节) &lt;= zset-max-ziplist-value ; ② 有序集合长度 &lt;= zset-max-ziplist-entries 10.5.3. 控制编码类型编码类型转换在 redis 写入数据时 自动完成, 这个转换过程不可逆.转换规则只能从小内存编码向大内存编码转换. 转换示例 : redis&gt; lpush list:1 a b c d (integer) 4 //存储4个元素 redis&gt; object encoding list:1 &quot;ziplist&quot; //采用ziplist压缩列表编码 redis&gt; config set list-max-ziplist-entries 4 OK //设置列表类型ziplist编码最大允许4个元素 redis&gt; lpush list:1 e (integer) 5 //写入第5个元素e redis&gt; object encoding list:1 &quot;linkedlist&quot; //编码类型转换为链表 redis&gt; rpop list:1 &quot;a&quot; //弹出元素a redis&gt; llen list:1 (integer) 4 // 列表此时有4个元素 redis&gt; object encoding list:1 &quot;linkedlist&quot; //编码类型依然为链表, 未做编码回退, 因为回退非常消耗 cpu, 得不偿失. 转换规则 见 10.5.2 表 : 可以使用 config set 命令设置编码相关参数来满足使用压缩编码的条件. 对于采用非压缩编码类型的数据, 如 hashtable, linkedlist 等, 设置参数后即使数据满足压缩编码的条件, redis 也不会做转换, 需要重启 redis 重新加载数据才能完成转换. 10.5.4. ziplist 编码主要为节约内存, 因此所有数据都采用线性连续的内存结构. 应用最广泛, 可以作为 hash, list, zset 类型的底层数据结构实现. 字段含义 : zlbytes : 记录整个压缩列表所占字节长度, 方便重新调整 ziplist 空间, 类型是 int-32, 长度为 4 字节. zltail : 记录距离尾节点的偏移量, 方便尾节点弹出操作, 类型 int-32, 长度 4 字节. zllen : 记录压缩链表节点数量, 当长度超过 216-2 时需要遍历整个列表获取长度, 一般很少见, 类型 int-16 , 长度为 2 字节. entry-1 : 记录具体的节点, 长度根据实际存储的数据而定. entry prev_entry_butes_length : 记录前一个节点所占空间, 用于快速定位上一个节点, 可实现列表反向迭代. encoding : 表示当前节点的编码和长度, 前两位表示编码类型: 字符串/整数, 其余位表示数据长度. contents : 保存节点值, 针对实际数据长度做内存占用优化. entry-2 : entry prev_entry_butes_length : encoding : contents : zlend : ziplist 数据结构特点 : 内部表现为数据紧凑排列的一块连续内存数组. 可以模拟双向链表结构, 以 O(1) 时间复杂度入队和出队, 新增删除操作设计内存重新分配或释放, 加大了操作的复杂性. 读写操作设计复杂的指针移动, 最坏的时间复杂度为 O(n2) 适合存储小对象和长度有限的数据. 注意: ziplist压缩编码的性能表现跟值长度和元素个数密切相关. 这对性能要求较高的场景使用 ziplist , 建议 长度不要超过 1000, 每个元素大小控制在 512 字节以内. 命令平均消耗时间使用 info Commandstats 命令获取, 包含每个命令调用次数, 总耗时, 平均耗时, 单位 微秒 redis&gt; info Commandstats 10.5.5. intset 编码intset 是集合(set)类型编码的一种, 内部表现为存储有序, 不重复的整数集.当集合只包含 整数, 且 长度不超过 set-max-intset-entries 配置时, 被启用. 127.0.0.1:6379&gt; sadd set:test 3 4 2 6 8 9 2 (integer) 6 127.0.0.1:6379&gt; OBJECT encoding set:test &quot;intset&quot; 127.0.0.1:6379&gt; SMEMBERS set:test 1) &quot;2&quot; 2) &quot;3&quot; 3) &quot;4&quot; 4) &quot;6&quot; 5) &quot;8&quot; 6) &quot;9&quot; 127.0.0.1:6379&gt; CONFIG SET set-max-intset-entries 6 OK 127.0.0.1:6379&gt; sadd set:test 5 (integer) 1 127.0.0.1:6379&gt; SMEMBERS set:test 1) &quot;6&quot; 2) &quot;3&quot; 3) &quot;8&quot; 4) &quot;4&quot; 5) &quot;9&quot; 6) &quot;2&quot; 7) &quot;5&quot; 127.0.0.1:6379&gt; OBJECT encoding set:test &quot;hashtable&quot; 127.0.0.1:6379&gt; SMEMBERS set:test 1) &quot;6&quot; 2) &quot;3&quot; 3) &quot;8&quot; 4) &quot;4&quot; 5) &quot;9&quot; 6) &quot;2&quot; 7) &quot;5&quot; intset 对写入证书进行排序, 通过 O(log(n)) 时间复杂度实现查找和去重操作 字段含义 : encoding : 整数表示类型, 格局集合内最长整数值确定类型, 证书类型划分三种 : int-16, int-32, int-64 . length : 表示集合元素个数. contents : 整数数组, 按从小到大顺序保存. intset 保存的整数类型根据长度划分, 当保存的证书超出当前类型时, 将会触发自动升级操作, 且升级后不能做回退. 升级操作会导致重新申请内存空间, 把原有数据安装转换类型后拷贝到新数组. 使用intset编码的集合时, 尽量保持整数范围一致, 如都在int-16范围内. 防止个别大整数触发集合升级操作, 产生内存浪费. 10.6. 控制 key 的数量当使用 redis 存储大量数据时, 通常会存在大量键, 过多的键同样会消耗大量内存. Redis本质是一个数据结构服务器, 它为我们提供多种数据结构, 如hash, list, set, zset 等结构. 10.7 系统优化10.7.1. 内存10.7.1.1 vm.overcommit_memoryLinux 操作系统对大部分申请内存的请求都恢复 yes, 以便能运行更多的程序, 应为申请内存之后, 并不会马上使用内存, 这种技术叫做overcommit. vm.overcommit_memory 用来设置内存分配策略, 他有三个可选值: 0 : 表示内核将检查是否有足够的可用内存. 如果有足够的可用内存, 内存申请通过, 否则内存申请失败, 并把错误返回给应用进程. 1 : 表示内核允许超量使用内存直到用完为止. 2 : 表示内存绝不过量的使用内存(“never overcommit”), 即系统整个内存地址空间不能超过 swap + 50% RAM 的值, 50% 是 overcommit_ratio 的默认值, 此参数同样支持修改. 报错信息: # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add &apos;vm.overcommit_memory = 1&apos; to /etc/sysctl.conf and then reboot or run the command &apos;sysctl vm.overcommit_memory=1&apos; for this to take effect. 报错中的 Background save 代表的是 bgsave 和 bgrewritaof, 如果当前内存不足, 操作系统应该如何处理 fork. 如果vm.overcommit_memory=0, 代表如果没有可用内存, 就申请内存失败, 对应到 redis 就是 fork 执行失败, Redis 报错 Cannot allocate memory. 推荐配置: vm.overcommit_memory = 1 配置方法: # 查看当前配置 $ cat /proc/sys/vm/overcommit_memory # 设置 $ echo &quot;vm.overcommit_memory&quot; &gt;&gt; /etc/sysctl.conf $ sysctl vm.overcommit_memory=1 最佳实践: Redis 设置合理的 maxmemory, 保证机器有 20% ~ 30% 的闲置内存. 集中化管理 aof 重写 和 rdb 的 bgsave. 设置 vm.overcommit_memory=1, 防止极端情况下, 会造成 forl 失败. 10.7.1.2 swappinessswap 对于操作系统来说比较重要, 当物理内存不足时, 可以 swap out 一部分内存页, 以解燃眉之急. 但是, swap 空间由硬盘提供, 对于需要高并发, 高吞吐的应用来说, 磁盘 IO 通常会成为系统瓶颈. 在 Linux 中, 并不是要等到所有物理内存都使用完才会使用 swap, 系统参数 swappiness 会决定操作系统使用 swap 的倾向程度. swappiness 的取值范围是 0 ~ 100, swappiness 的值越大, 说明操作系统可能使用 swap 的概率越高. swappiness 值越低, 表示操作系统更加倾向于使用武力内存. swap 的默认值为 60. swappiness 策略 0 Linux 3.5 及以上: 宁愿 OOM , 也不用 swap; Linux 3.4 及以下 : 宁愿 swap 也不要 OOM 1 Linux 3.5 及以上 : 宁愿 swap 也不要 OOM. 60 默认值 100 操作系统主动使用 swap 设置方法: echo VALUE &gt; /proc/sys/vm/swappiness echo &quot;vm.swappiness=VALUE&quot; &gt;&gt; /etc/sysctl.conf 查看 redis 进程 swap 使用情况: cat /proc/REDIS_ID/smaps | grep Swap 最佳实践: 如果 Linux &gt; 3.5 , vm.swappiness=1 ; 否则 vm.swappiness=0, 从而实现如下两个目标: - 物理内存充足时, redis 足够快 - 物理内存不足时, 避免 redis 死掉. - 如果 redis 为高可用, 死掉比阻塞好. 10.7.1.3 Transparent Huge PagesLinux kernel 在 2.6.38 内核增加了 Transparent Huge Pages(THP) 特性, 支持大内存页(2M)分配, 默认开启. 当开启时可以降低 fork 子进程的速度, 但 fork 之后, 每个内存页从原来 4KB 变为 2MB, 会大幅着呢个件重写期间父进程内存消耗. 同时每次写命令引起的复制内存页单位放大了 512倍, 会拖慢写操作的执行时间, 导致大量写操作慢查询. 因此, redis 建议禁止THP 特性: $ echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled $ echo &quot;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&quot; &gt;&gt; /etc/rc.local 注意有些发行版将 THP 放在 /sys/kernel/mm/redhat_transparent_hugepage/enabled 中: $ echo never &gt; /sys/kernel/mm/redhat_transparent_hugepage/enabled 10.7.1.4 OOM killerOOM killer 会在可用内存不足时, 选择性的杀掉用户进程. OOM killer 进程会为每个用户进程设置一个权值, 这个权值越高, 被杀掉的概率越高, 反之, 越低. 每个进程的权值存放在 /proc/PID/oom_score 中, 这个值收到 /proc/PID/oom_adj 的控制, oom_adj 在不同的 Linux 版本中最小值不同, 可以参考 Linux源码中 oom.h (从 -15 到 -17). 当 oom_adj 设置为最小时, 该进程将不会被 OOM killer 杀掉. 对于 redis 所在的服务器来说, 可以将所有 Redis 的 oom_adj 设置为最低值或者稍小的值, 降低被 OOM killer 杀掉的概率. $ echo VALUE &gt; /proc/POD/oom_adj 提示: oom_adj 参数只起到辅助作用, 合理的规划内存更为重要; 在高可用的情况下, 被杀掉比僵死更好, 因此不要过多依赖 oom_adj 配置. 10.7.2. 系统优化10.7.2.1 使用 NTP我们知道像Redis Sentinel和Redis Cluster这两种需要多个Redis实例的类型, 可能会涉及多台服务器. 虽然Redis并没有对多个服务器的时钟有严格的要求, 但是假如多个Redis实例所在的服务器时钟不一致, 对于一些异常情况的日志排查是非常困难的, 10.7.2.2 ulimit在 Linux 中, 可以通过 ulimit 查看和设置系统的当前用户进程的资源数. 其中 open files 参数, 是单个用户同时打开的最大文件个数. Redis 允许同时有多个客户端通过网络进行连接, 可以通过设置 maxclients 来限制最大客户端连接数. 对 Linux 操作系统来说这些网络连接都是文件句柄. ulimit open files 的限制优先级比 maxclients 大. redis 建议把 open files 至少设置成 10032 , 因为 maxclients 的默认值是 10000, 这些用来处理客户端连接, 除此之外, Redis 内部会使用最多 32 个文件描述符, 所以 10032 = 10000 + 32. 10.7.3. 网络10.7.3.1 TCP backlogRedis 默认的 tcp-backlog 为 511, 可以通过修改配置 tcp-backlog 进行调整. 如果 Linux 的 tcp-backlog 小于 redis 设置的 tcp-backlog, 那么启动时会报错: # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. 修改 TCP backlog : $ cat /proc/sys/net/core/somaxconn $ echo 511 &gt; /proc/sys/net/core/somaxconn 11. python与redis$ pip install redis # 创建链接: import redis r = redis.StrictRedis(host=&apos;127.0.0.1&apos;,port=&apos;6379&apos;,db=0) r.set(&apos;foo&apos;,&apos;bar&apos;) r.get(&apos;foo&apos;) # 字典 HMSET/HGETALL HMSET : 将字典作为参数存储 HGETALL : 返回值为字典. # 管道和事务 * 事务 pipe = r.pipeline() pipe.set(&apos;foo&apos;, &apos;bar&apos;) pipe.get(&apos;foo&apos;) result = pipe.execute() print result # [True, &apos;bar&apos;] * 管道 : 管道的使用方式和事务相同, 只不过需要在创建时加上参数transaction=False： pipe = r.pipeline(transaction=False) * 链式调用 : 事务和管道还支持链式调用： result = r.pipeline().set(&apos;foo&apos;, &apos;bar&apos;).get(&apos;foo&apos;).execute() # [True, &apos;bar&apos;] 12. redis 与 lua : Lua 语法简介12.1. 数据类型 :lua 是一个动态类型语言,一个变量可以存储类型的值.Lua 常用数据类型: 空(nil) 空类型只包含一个值,即nil . nil表示空, 没有赋值的变量或标的字段都是 nil.布尔(boolean) 布尔类型包含 True 和 False 两个值.数字(number) 整数合浮点数是都是使用数字类型存储.字符串(string) 字符串类型可以存储字符串,且与Redis的键值一样都是二进制安全的.字符串可以使用单引号或双引号表示,两个符号是相同的. 字符串可以包含转义字符,如 ‘\n’,’\r’ 等.表(table) 表类型是Lua 语言中唯一的数据结构,既可以当数组,又可以当字典,十分灵活.函数(function) 函数是Lua中的一等值(first-class value),可以存储在变量中,作为函数的参数或返回结果. 12.2. 变量:Lua 变量分为全局变量和局部变量. 全局变量无需声明就可以直接使用,默认值是 nil . &gt; print(b) a = 1 –为全局变量a赋值a = nil – 删除全局变量的方法是将其复制为 nil . 全局变量没有声明与未声明之分,只有非 nil 和 nil 的区别.print(b) –无需声明即可使用, 默认值是nil 在Redis脚本中不能使用全局变量,只允许使用局部变量,以防止脚本之间相互影响. 声明局部变量的方式为 “local 变量名” : local c –声明一个局部变量c, 默认值是nil local d = 1 –声明一个局部变量d并赋值为1 local e, f –可以同时声明多个局部变量 * 局部变量的作用域为从声明开始到所在层的语句块的结尾. 声明一个存储函数的局部变量的方法为 : local say_hi = function () print ‘hi’ end 变量名必须是非数字开头,只能包含字母,数字和下划线,区分大小写. 变量名不能与Lua的保留关键字相同, 保留关键字如下: and break do else elseif end false for function if in local nil not or repeat return then true until while 12.3. 注释 :单行 : 以 – 开始,到行尾结束.多行 : 以 –[[ 开始 ,到 ]] 结束. 12.4. 赋值 :多重赋值 : local a, b = 1, 2 – a的值是1, b的值是2 local c, d = 1, 2, 3 – c的值是1, d的值是2, 3被舍弃了 local e, f = 1 – e的值是1, f的值是nil 在执行多重赋值时,Lua会先计算所有表达式的值,比如: local a = {1, 2, 3} local i = 1 i, a[i] = i + 1, 5 – i = 2 ; a = {5,2,3} , lua 索引从 1 开始. lua 中的函数也可以返回多个值 12.5. 操作符12.5.1. 数学操作符 :常见的+、-、*、/、%(取模)、-(一元操作符, 取负)和幂运算符号^. 数学操作符的操作数如果是字符串,则会自动转换为数字. print(&apos;1&apos; + 1) -- 2 print(&apos;10&apos; * 2) -- 20 12.5.2. 比较操作符 :比较操作符的结果一定是布尔类型 ;比较操作符,不会对两边的操作数进行自动类型转换. == : 比较两个操作数的类型和值是否相等 ~= : 与 == 结果相反 &lt;,&gt;,&lt;=,&gt;= : 大于,小于,小于等于,大于等于. 12.5.3. 逻辑操作符 :只要操作数不是 nil 或 false ,逻辑操作符都认为操作数是真. 特别注意 0 或 空字符串也被当做真. Lua 逻辑操作符支持短路, 也就是说对于 false and foo() , lua 不会调用foo函数, or类似. not : 根据操作数的真和假返回false 和 true and : a and b, 如果a 是真,则返回 b , 否则返回 a . or : a or b , 如果a 是假,则返回 a , 否则返回 b . 12.5.4. 连接操作符. “…” 用来连接两个字符串.连接操作符会自动把数字类型的转换成字符串类型. 12.5.5. 取长度操作符. 是lua5.1 新增的操作符, “#” ,用来获取字符串或表的长度.&gt; print(#&apos;hello&apos;) -- 5 12.5.6. 运算符的优先级:^ not # -(一元) * / % + - .. &lt; &gt; &lt;= &gt;= ~= == and or 12.6. if 语句语法 : if 条件表达式 then 语句块 elseif 条件表达式 then 语句块 else 语句块 end 注意 : Lua 中只有 nil 和 false 才是假, 其余值,包括0 和空字符串,都被认为是真值. 在 Redis 的EXISTS命令返回值 1 和 0 分别表示存在或不存在,但无论如何,两个值在Lua 中都是真值. Lua 每个语句都可以 ; 结尾 ,但是一般来说编写 Lua 是会省略 ; , Lua 并不强制要求缩进,所有语句也可以写在一行中, 但为了增强可读性,建议在注意缩进. &gt; a = 1 b = 2 if a then b = 3 else b = 4 end 12.7. 循环语句 while 循环 while 条件表达式 do 语句块 end repeat 循环 repeat 语句块 until 条件表达式 for 循环 形式一 : for 变量=初值,终值,步长 do -- 步长可省略,默认为 1 语句块 end # 计算 1 ~ 100 之和 local sum = 0 for i = 1 ,100 do sum = sum + 1 end // for 循环中的 i 是**局部变量**, 作用域为 for 循环体内. 虽然没有使用 local 声明,但它不是全局变量. 形式二 : for 变量1 ,变量2, ... , 变量N in 迭代器 do 语句块 end 在编写Redis脚本时,我们常用通用形式的for 语句遍历表的值. 12.8. 表类型表是Lua中唯一的数据结构,可以理解为关联数组,任何类型的值(除了空类型)都可以作为表的索引. a = {} --将变量a赋值为一个空表 a[&apos;field&apos;] = &apos;value&apos; --将field字段赋值value print(a.field) --打印内容为&apos;value&apos;, a.field是a[&apos;field&apos;]的语法糖. people = { --也可以这样定义 name = &apos;Bob&apos;, age = 29 } 当索引为整数的时候表和传统的数组一样, 例如： a = {} a[1] = ‘Bob’ a[2] = ‘Jeff’ 可以写成下面这样： a = {‘Bob’, ‘Jeff’} print(a[1]) –打印的内容为’Bob’ 可以使用通用形式的for语句遍历数组,例如: for index,value in ipairs(a) do -- index 迭代数组a 的索引 ; value 迭代数组a 的值. print(index) print(value) end ** ipairs 是Lua 内置的函数,实现类似迭代器的功能. 数字形式的for语句 for i=1,#a do print(i) print(a[i]) end pair : 迭代器,用来遍历非数组的表值 person = { name = &apos;bob&apos;, age = 29 } for index,value in pairs(person) do print(index) print(value) end pairs 与 ipairs 的区别在于前者会办理所有值不为 nil 的索引, 而后者只会从索引 1 开始递增遍历到最后一个值不为 nil 的整数索引. 12.9. 函数函数的一般格式: function(参数列表) 函数体 end 示例: local function square(...) local argv = {...} for i = 1,#argv do argv[i] = argv[i] * argv[i] end return unpack(argv) -- unpack 函数用来返回 表 中的元素. 相当于return argv[1], argv[2], argv[3] end a,b,c = square(1,2,3) print(a) -- 1 print(b) -- 4 print(c) -- 9 可以将函数赋值给一个局部变量, 比如: local square = function(num) return num*num end // 因为在赋值前声明了局部变量 square, 所以可以在函数内部引用自身(实现递归). 函数参数 : 如果实参的个数小于形参的个数,则没有匹配到的形参的值为 nil . 相对应的,如果实参的个数大于形参的个数,则多出的实参会被忽略. 如果希望捕获多出的参数(即实现可变参数个数),可以让最后一个形参为 ‘…’ . 12.10. return &amp; break在 Lua 中 return 和 break (用于跳出循环) 语句必须是语句块中的最后一条语句, 简单的说在这两条语句之后只能是 end,else 或 until 三者之一. 如果希望在语句块中间使用这两条语句,可以人为的使用 do 和 end 将其包围 . 12.11. 标准库Lua 的标准库中提供了很多使用的函数, 比如 ipairs,pairs,tonumber,tostring,unpack 都属于标准库中的Base库. Redis 支持大部分Lua标准库,如下所示: 库名 说明 Base 一些基础函数 String 用于字符串操作的函数 Table 用于表操作的函数 Math 数学计算函数 Debug 调试函数 12.11.1 String库 : 可以通过字符串类型的变量以面向对象的形式访问, 如 string.len(string_var) 可以写成 string_var:len()获取字符串长度 : string.len(string) 作用与操作符 “#” 类似 &gt; print(string.len(&apos;hello&apos;)) -- 5 &gt; print(#&apos;hello&apos;) -- 5 转换大小写 string.upper(string) string.lower(string) 获取子字符串 string.sub(string start[,end ]) -- end 默认为 -1. string.sub() 可以获取一个字符串从索引 start 开始到 end 结束的子字符串,索引从1 开始. 索引也可以是负数, -1 代表最后一个元素 . &gt; print(string.sub(&apos;hello&apos;,1)) -- hello &gt; print(string.sub(&apos;hello&apos;,2)) -- ello &gt; print(string.sub(&apos;hello&apos;,2,-2)) -- ell 12.11.2 Table库 : 其中大部分函数都需要表的形式是数组形式.将数组转换为字符串 table.concat(table [,sep [,i [,j]]]) - sep : 以 sep 指定的参数分割, 默认为空. - i , j : 用来限制要转换的表元素的索引范围. 默认分别为 1 和 表的长度. 不支持负索引. &gt; print(table.concat({1,2,3})) --123 &gt; print(table.concat({1,2,3},&apos;,&apos;,2)) --2,3 &gt; print(table.concat({1,2,3},&apos;,&apos;,2,2)) --2 向数组中插入元素 : # 在指定索引位置 pos 插入元素 value, 并将后面的元素顺序后移. 默认 pos 值是数组长度加 1 , 即在数组尾部插入. table.insert(table ,[pos,] value) &gt; a = {1,2,4} &gt; table.insert(a,3,3) # {1,2,3,4} &gt; table.insert(a,5) # {1,2,3,4,5} &gt; print(table.concat(a,&apos;,&apos;)) 1,2,3,4,5 从数组中弹出一个元素 # 从指定的索引删除一个元素,并将后面的元素前移,返回删除元素值. 默认 pos 的值是数组的长度,即从数组尾部弹出一个元素. table.remove(table,[,pos]) &gt; table.remove(a) --{1,2,3,4} &gt; table.remove(a,1) --{2,3,4} &gt; print(table.caoncat(a,&apos;,&apos;)) 2,3,4 12.11.3 Math库 : 提供常用的数学运算函数, 如果参数是字符串会自动尝试转换成数字.math.abs(x) # 绝对值 math.sin(x) # 三角函数sin math.cos(x) # 三角函数cos math.tan(x) # 三角函数tan math.ceil(x) # 进一取整, 1.2 取整后是 2 math.floor(x) # 向下取整, 1.8 取整后是 1 math.max(x,...) # 获得参数中的最大的值 math.min(x,...) # 获取参数中的最小的值 math.pow(x,y) # 获取 xy 的值 math.sqrt(x) # 获取 x 的平方根 math.random([m,[,n]]) # 生成随机数,没有参数 返回 [0,1]的实数, 参数 m 返回范围在 [1,m] 的整数, 同时提供 m n 返回范围在 [m,n] 的整数. math.randomseed(x) # 设置随机数种子, 同一种子生成的随机数相同. 12.12. 其他库Redis 还通过 cjson库 和 cmsgpack库 提供了对 JSON 和 MessagePack的支持. Redis自动加载了这两个库,在脚本中可以分别通过 cjson 和 cmsgpack 两个全局变量来访问对应的库. local people = { name = &apos;bob&apos;, age = 29 } -- 使用 cjson 序列化成字符串 local json_people_str = cjson.encode(people) -- 使用 cmsgpack 序列化成字符串 local msgpack_people_str = cmsgpack.pack(people) -- 使用 cjson 将序列化后的字符串还原成表 local json_people_obj = cjson.decode(people) print(json_people_obj.name) -- 使用 cmshpack 将序列化后的字符串还原成表 local msgpack_people_obj = cmsgpack.unpack(people) print(msgpack_people_obj.name) 12.13. Redis 与 Lua 在脚本中调用redis命令： redis.call(&apos;set&apos;, &apos;foo&apos;, &apos;bar&apos;) local value = redis.call(&apos;get&apos;, &apos;foo&apos;) -- value的值为bar 脚本相关命令 redis&gt; EVAL 脚本内容 key参数数量 [key...] [arg...] 13. 持久化13.1. RDB方式 : 存数据. 快照式. 根据指定的规则“定时”将内存中的数据存储在硬盘上RDB 方式的持久化是通过快照(snapshotting)完成的, 当符合一定条件时Redis会自动将内存中的所有数据生成一份副本并存储在硬盘上, 这个过程即为快照. 13.1.1 实现方式及原理: Redis 在进行数据持久化的过程中, 会先将数据写入到一个临时文件中, 待持久化过程都结束了, 才会用这个临时文件替换上次持久化好的文件. 正是这种特性, 让我们可以随时来进行备份, 因为快照文件总是完整可用的. 对于 RDB 方式, redis 会单独创建 (fork) 一个子进程来进行持久化, 而主进程是不会进行任何IO操作的, 这样就确保了redis 极高的性能. 如果需要进行大规模数据的恢复, 且对于数据恢复的完整性不是非常敏感, 那 RDB 方式要比 AOF 方式更加的高效. 虽然 RDB 有不少优点, 但它的缺点也是不容忽视的. 如果你对数据的完整性非常敏感, 那么 RDB 方式就不太适合你, 因为即使你每 5 分钟都持久化一次, 当 redis 故障时, 仍然会有近 5 分钟的数据丢失. 在执行 fork 的时候操作系统(类 Unix 操作系统)会使用写时复制(copy-on-write)策略, 即fork函数发生的一刻父子进程共享同一内存数据, 当父进程要更改其中某片数据时(如执行一个写命令), 操作系统会将该片数据复制一份以保证子进程的数据不受影响, 所以新的RDB文件存储的是执行 fork 一刻的内存数据. 另外需要注意的是, 当进行快照的过程中, 如果写入操作较多, 造成 fork 前后数据差异较大, 是会使得内存使用量显著超过实际数据大小的, 因为内存中不仅保存了当前的数据库数据, 而且还保存着 fork 时刻的内存数据. 进行内存用量估算时很容易忽略这一问题, 造成内存用量超限. 任何时候 RDB 文件都是完整的. 这使得我们可以通过定时备份 RDB 文件来实现 Redis 数据库备份. RDB 文件是经过压缩(可以配置rdbcompression参数以禁用压缩节省CPU占用) 的二进制格式, 所以占用的空间会小于内存中的数据大小, 更加利于传输. Redis启动后会读取RDB快照文件, 将数据从硬盘载入到内存. 根据数据量大小与结构和服务器性能不同, 这个时间也不同. 通常将一个记录1000万个字符串类型键、大小为1 GB 的快照文件载入到内存中需要花费20～30秒. 通过RDB方式实现持久化, 一旦Redis异常退出, 就会丢失最后一次快照以后更改的所有数据. 这就需要开发者根据具体的应用场合, 通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能够接受的范围. 快照过程: Redis使用fork函数复制一份当前进程(父进程)的副本(子进程)； 父进程继续接收并处理客户端发来的命令, 而子进程开始将内存中的数据写入硬盘中的临时文件； 当子进程写入完所有数据后会用该临时文件替换旧的 RDB 文件, 至此一次快照操作完成. 13.1.2 Redis对数据进行快照情况/场景: 根据配置规则进行自动快照 : redis.conf 时间窗口 M 和 改动键的个数 N : 每当时间 M 内被改动的键的个数大于 N 时,即自动快照. save 900 1 save 300 10 save 60 10000 同时可以存在多个条件, 条件之间是或的关系. 时间单位是 秒 . 用户指定 SAVA 或 BGSAVE 命令 当进行服务重启、手动迁移以及备份时我们也会需要手动执行快照操作. SAVE : 当执行SAVE命令时, Redis同步地进行快照操作, 在快照执行的过程中会阻塞所有来自客户端的请求. 当数据库中的数据比较多时, 这一过程会导致 Redis 较长时间不响应, 所以要尽量避免在生产环境中使用这一命令. BGSAVE : 需要手动执行快照时推荐使用 BGSAVE 命令. BGSAVE 命令可以在后台异步地进行快照操作, 快照的同时服务器还可以继续响应来自客户端的请求. 执行 BGSAVE后Redis会立即返回 OK 表示开始执行快照操作, 如果想知道快照是否完成, 可以通过 LASTSAVE命令获取最近一次成功执行快照的时间, 返回结果是一个Unix时间戳. 执行 FLUSHALL 命令 当执行 FLUSHALL 命令时, Redis 会清除数据库中的所有数据. 需要注意的是, 不论清空数据库的过程是否触发了自动快照条件, 只要自动快照条件不为空, Redis就会执行一次快照操作. 当没有定义自动快照条件时, 执行FLUSHALL则不会进行快照. 执行复制(replication) 时. 当设置了主从模式时, Redis 会在复制初始化时进行自动快照. 当使用复制操作时, 即使没有定义自动快照条件, 并且没有手动执行过快照操作, 也会生成RDB快照文件. 13.1.3 快照保存 :Redis默认会将快照文件存储在Redis 当前进程的工作目录中的dump.rdb文件中, 也可以通过修改如下 redis.conf 中的参数, 指定快照文件的保存位置: dir : 指定快照文件的 存放路径; dbfilename : 指定 rdb 文件名. 13.1.4 关闭 RDB :redis &gt; CONFIG SET save &quot;&quot; 13.2. AOF方式 : 存操作. 在每次执行命令后将命令本身记录下来, Append Only File.13.2.1. 原理只允许追加不允许改写的文件. AOF 方式是将执行过的写指令记录下来, 在数据恢复时按照从前到后的顺序再将指令都执行一遍, 就这么简单. AOF可以将Redis执行的每一条写命令追加到硬盘文件中, 这一过程显然会降低Redis 的性能, 但是大部分情况下这个影响是可以接受的, 另外使用较快的硬盘可以提高AOF的性能. 原理 : 以纯文本方式实现. AOF文件的内容正是 Redis 客户端向 Redis 发送的原始通信协议的内容. 在启动时Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中, 载入的速度相较RDB会慢一些. AOF 重写的内部运行原理 : 在重写即将开始之际, redis 会创建(fork)一个重写子进程, 这个子进程会首先读取现有的 AOF 文件, 并将其包含的指令进行分析压缩并写入到一个临时文件中. 与此同时, 主工作进程会将新接收到的写指令一边累积到内存缓冲区中, 一边继续写入到原有的 AOF 文件中, 这样做是保证原有的 AOF 文件的可用性, 避免在重写过程中出现意外. 当重写子进程完成重写工作后, 它会给父进程发一个信号, 父进程收到信号后就会将内存中缓存的写指令追加到新 AOF 文件中. 当追加结束后, redis 就会用新 AOF 文件来代替旧 AOF 文件, 之后再有新的写指令, 就都会追加到新的 AOF 文件中了. 重写机制 因为采用了追加方式, 如果不做任何处理的话, AOF 文件会变得越来越大, 为此, redis 提供了 AOF 文件重写(rewrite)机制, 即当 AOF 文件的大小超过所设定的阈值时, redis 就会启动 AOF 文件的内容压缩, 只保留可以恢复数据的最小指令集. 举个例子或许更形象, 假如我们调用了 100 次INCR指令, 在 AOF 文件中就要存储 100 条指令, 但这明显是很低效的, 完全可以把这 100 条指令合并成一条 SET 指令, 这就是重写机制的原理. 在进行 AOF 重写时, 仍然是采用先写临时文件, 全部完成后再替换的流程, 所以断电、磁盘满等问题都不会影响 AOF 文件的可用性. 在同样数据规模的情况下, AOF 文件要比 RDB 文件的体积大. 而且, AOF 方式的恢复速度也要慢于 RDB 方式. 重写机制相关配置: 自动重写 AOF 文件 : 取消redis命令执行中的冗余. # 当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写, 如果之前没有重写过, 则以启动时的AOF文件大小为依据 auto-aof-rewrite-percentage 100 # 限制了允许重写的最小AOF文件大小, 通常在AOF文件很小的情况下即使其中有很多冗余的命令我们也并不太关心 auto-aof-rewrite-min-size 64mb 重写的过程只和内存中的数据有关, 和之前的 AOF文件无关, 手动执行AOF文件重写 : # redis 会生成一个全新的 AOF 文件, 其中便包括了可以恢复现有数据的最少的命令集. &gt; BGREWRITEAOF 同步磁盘缓存到硬盘频率 : # 每秒执行一次同步操作. appendfsync everysec # 表示每次执行写入都会执行同步, 这是最安全也是最慢的方式. appendfsync always # 表示不主动进行同步操作, 而是完全交由操作系统来做(即每30秒一次), 这是最快但最不安全的方式. appendfsync no 13.2.2. 配置开启AOF : 默认 AOF 没有开启. 编辑 redis.conf appendonly yes 文件保存位置 : dir : 设置路径 appendfilename appendonly.aof : 设置文件名称. 默认的 AOF 持久化策略是每秒钟 fsync 一次(fsync 是指把缓存中的写指令记录到磁盘中), 因为在这种情况下, redis 仍然可以保持很好的处理性能, 即使 redis 故障, 也只会丢失最近 1 秒钟的数据. 如果在追加日志时, 恰好遇到磁盘空间满、inode 满或断电等情况导致日志写入不完整, 也没有关系, redis 提供了 redis-check-aof 工具, 可以用来进行日志修复. 13.2.3. 修复 AOF 文件.如果运气比较差, AOF 文件出现了被写坏的情况, 也不必过分担忧, redis 并不会贸然加载这个有问题的 AOF 文件, 而是报错退出. 可以通过以下步骤来修复出错的文件: 备份被写坏的 AOF 文件; 运行 redis-check-aof –fix 进行修复; 用 diff -u 来看下两个文件的差异, 确认问题点; 重启 redis, 加载修复后的 AOF 文件. 13.3. AOF + RDBRedis 允许同时开启 AOF 和 RDB, 既保证了数据安全又使得进行备份等操作十分容易. 此时重新启动Redis后Redis会使用AOF文件来恢复数据, 因为AOF方式的持久化可能丢失的数据更少. 13.4. 备份与恢复13.4.1. 备份 :对于RDB和AOF, 都是直接拷贝文件即可, 可以设定crontab进行定时备份 . 13.4.2. 恢复 :13.4.2.1. RDB将备份文件拷到 data 目录,并给 redis-server 访问权限, 并重启 redis-server 13.4.2.2. AOF重启时加载AOF文件恢复数据. 13.4.2.3. RDB + AOF 只需要将aof文件放入data目录, 启动redis-server, 查看是否恢复, 如无法恢复则应该将aof关闭后重启, redis就会从rdb进行恢复了, 随后调用命令BGREWRITEAOF进行AOF文件写入, 在info的aof_rewrite_in_progress为0后一个新的aof文件就生成了, 此时再将配置文件的 aof 打开, 再次重启redis-server就可以恢复了. 注意: 先不要将dump.rdb放入data目录, 否则会因为aof文件万一不可用, 则 rdb 也不会被恢复进内存, 此时如果有新的请求进来后则原先的 rdb 文件被重写. 14. 集群14.1. 复制复制场景下数据库分为两中角色, 主数据库(master), 可以进行读写操作, 当写操作导致数据变化时会自动将数据同步给从数据库. 从数据库(slave), 一般是只读的, 并接受主数据库同步过来的数据. 一个主数据库可以拥有多个从数据库, 而一个从数据库只能拥有一个主数据库, redis 是支持主从同步的, 而且也支持一主多从以及多级从结构. 主从结构, 一是为了纯粹的冗余备份, 二是为了提升读性能, 比如很消耗性能的 SORT 就可以由从服务器来承担. 在具体的实践中, 可能还需要考虑到具体的法律法规原因, 单纯的主从结构没有办法应对多机房跨国可能带来的数据存储问题, 这里需要特别注意一下 redis 的主从同步是异步进行的, 这意味着主从同步不会影响主逻辑, 也不会降低 redis 的处理性能. 主从架构中, 可以考虑关闭主服务器的数据持久化功能, 只让从服务器进行持久化, 这样可以提高主服务器的处理性能. 在主从架构中, 从服务器通常被设置为只读模式, 这样可以避免从服务器的数据被误修改. 但是从服务器仍然可以接受 CONFIG 等指令, 所以还是不应该将从服务器直接暴露到不安全的网络环境中. 如果必须如此, 那可以考虑给重要指令进行重命名, 来避免命令被外人误执行. 14.1.1 配置 : 配置文件配置方式 –&gt; 推荐生产环境 从数据库的配置文件中添加 : slaveof master_ip master_port 主数据库无需配置 . 命令行形式 : $ redis-server --port 6380 --slaveof 127.0.0.1 6379 在运行时设置 : redis&gt; SLAVEOF 127.0.0.1 6379 SLAVEOF NO ONE : # 使当前数据库停止接收其他数据库的同步并转换成为主数据库. redis&gt; SLAVEOF NO ONE 查看主从状态 redis SALV&gt; INFO replication role:master connected_slaves:1 slave0:ip=127.0.0.1,port=6380,state=online,offset=1,lag=1 master_repl_offset:1 redis MAST&gt; INFO replication role:slave master_host:127.0.0.1 master_port:6379 14.1.2 原理及过程 复制初始化 当一个从数据库启动后, 会向主数据库发送 SYNC 命令. 同时主数据库接收到SYNC命令后会开始在后台保存快照(即RDB持久化的过程), 并将保存快照期间接收到的命令缓存起来. 即使有多个从服务器同时发来 SYNC 指令, 主服务器也只会执行一次BGSAVE, 然后把持久化好的 RDB 文件发给多个下游. 当快照完成后, Redis会将快照文件和所有缓存的命令发送给从数据库. 从数据库收到后, 会载入快照文件并执行收到的缓存的命令. 复制同步阶段. 异步. 主数据库每当收到写命令时就会将命令同步给从数据库, 从而保证主从数据库数据一致. 在同步的过程中从数据库并不会阻塞, 而是可以继续处理客户端发来的命令. 默认情况下, 从数据库会用同步前的数据对命令进行响应. 可以配置 slave-serve-stale-data no 来使从数据库在同步完成前对所有命令(除了INFO和SLAVEOF)都回复错误：”SYNC with master in progress. “ 断线重连 : redis_version &lt; 2.6 重新进行 复制初始化(即主数据库重新保存快照并传送给从数据库), 即使从数据库可能仅有几条命令没有收到, 主数据库也必须要将数据库里的所有数据重新传送给从数据库. redis_version &gt; 2.8 断线重连能够支持 有条件的增量数据传输 , 当从数据库重新连接上主数据库后, 主数据库只需要将断线期间执行的命令传送给从数据库, 从而大大提高Redis复制的实用性. 14.1.3 乐观复制策略Redis采用了乐观复制(optimistic replication)的复制策略, 容忍在一定时间内主从数据库的内容是不同的, 但是两者的数据会最终同步. 限制只有当数据至少同步给指定数量的从数据库时, 主数据库才是可写的： # 只有当3个或3个以上的从数据库连接到主数据库时, 主数据库才是可写的, 否则会返回错误. min-slaves-to-write 3 # 允许从数据库最长失去连接的时间, 如果从数据库最后与主数据库联系(即发送 REPLCONF ACK命令)的时间小于这个值, 则认为从数据库还在保持与主数据库的连接. min-slaves-max-lag 10 14.1.4 图结构(级联结构)从数据库也可以有从数据库. 14.1.5 从数据库持久化 :持久化是相对耗时的. 为了提高性能, 可以通过复制功能建立一个(或若干个)从数据库, 并在从数据库中启用持久化, 同时在主数据库禁用持久化. 当主数据库崩溃时,恢复步骤 : 在从数据库中使用 SLAVEOF NO ONE 命令将从数据库提升成主数据库继续服务 ; 启动之前崩溃的主数据库, 然后使用SLAVEOF命令将其设置成新的主数据库的从数据库, 即可将数据同步回来 . 当开启复制且主数据库关闭持久化功能时, 一定不要使用Supervisor 以及类似的进程管理工具令主数据库崩溃后自动重启. 同样当主数据库所在的服务器因故关闭时, 也要避免直接重新启动. 这是因为当主数据库重新启动后, 因为没有开启持久化功能, 所以数据库中所有数据都被清空, 这时从数据库依然会从主数据库中接收数据, 使得所有从数据库也被清空, 导致从数据库的持久化失去意义. 14.1.6 无硬盘复制 : redis &gt; 2.8.18Redis引入了无硬盘复制选项, 开启该选项时, Redis在与从数据库进行复制初始化时将不会将快照内容存储到硬盘上, 而是直接通过网络发送给从数据库, 避免了硬盘的性能瓶颈. 目前无硬盘复制的功能还在试验阶段, 可以在配置文件中使用如下配置来开启该功能： repl-diskless-sync yes 14.1.7 增量复制 基础 : 从数据库会存储主数据库的运行ID(run id). 每个Redis 运行实例均会拥有一个唯一的运行ID, 每当实例重启后, 就会自动生成一个新的运行ID. 在复制同步阶段, 主数据库每将一个命令传送给从数据库时, 都会同时把该命令存放到一个积压队列(backlog)中, 并记录下当前积压队列中存放的命令的偏移量范围. 同时, 从数据库接收到主数据库传来的命令时, 会记录下该命令的偏移量. 过程 : 当主从连接准备就绪后, 从数据库会发送一条 SYNC 命令来告诉主数据库可以开始把所有数据同步过来了. 而 2.8 版之后, 不再发送 SYNC命令, 取而代之的是发送 PSYNC, 格式为PSYNC主数据库的运行ID 断开前最新的命令偏移量. 主数据库收到 PSYNC命令后, 会执行以下判断来决定此次重连是否可以执行增量复制. a. 首先主数据库会判断从数据库传送来的运行ID是否和自己的运行ID相同. 这一步骤的意义在于确保从数据库之前确实是和自己同步的, 以免从数据库拿到错误的数据(比如主数据库在断线期间重启过, 会造成数据的不一致). b. 然后判断从数据库最后同步成功的命令偏移量是否在积压队列中, 如果在则可以执行增量复制, 并将积压队列中相应的命令发送给从数据库. c. 如果此次重连不满足增量复制的条件, 主数据库会进行一次全部同步 大部分情况下, 增量复制的过程对开发者来说是完全透明的, 开发者不需要关心增量复制的具体细节. 2.8 版本的主数据库也可以正常地和旧版本的从数据库同步(通过接收SYNC 命令), 同样 2.8 版本的从数据库也可以与旧版本的主数据库同步(通过发送 SYNC命令). 唯一需要开发者设置的就是积压队列的大小了. 积压队列 1 .repl-backlog-size : 积压队列的大小,积压队列越大,允许主从断线的时间越长. 积压队列在本质上是一个固定长度的循环队列, **默认情况下积压队列的大小为 1 MB**, 可以通过配置文件的repl-backlog-size选项来调整. 很容易理解的是, 积压队列越大, 其允许的主从数据库断线的时间就越长. 根据主从数据库之间的网络状态, 设置一个合理的积压队列很重要. 因为**积压队列存储的内容是命令本身**, 如 `SET foo bar`, 所以估算积压队列的大小只需要**估计主从数据库断线的时间中主数据库可能执行的命令的大小即可**. repl-backlog-ttl : 当主从连接断开之后,经过多久可以释放积压队列的内存空间,默认1h. 与积压队列相关的另一个配置选项是repl-backlog-ttl, 即当所有从数据库与主数据库断开连接后, 经过多久时间可以释放积压队列的内存空间. 默认时间是1小时. 14.2. 哨兵 :14.2.0. 作用 监控主数据库和从数据库是否正常运行 主数据库出现故障时,自动主从切换. 需要客户端也能实现自动的主从切换, 或者在 redis 集群前端配置负载均衡或者自动切换. 14.2.1. 配置过程一个哨兵可以监控多个集群, 一个集群也可以配置多个哨兵进行监控. 配置哨兵监控一个系统时,只需要配置其监控主数据库即可,哨兵会自动发现所有复制该主数据库的从数据库. quorum : 表示最低通过票数. 执行故障恢复(切换)前,至少需要几个哨兵点同意. # 基本配置 $ vim /etc/redis/sentinel.conf # sentinel monitor master_name ip redis-port quorum + sentinel monitor mymaster 127.0.0.1 6379 1 # mymaster : 表示要监控的主数据库的名字 # 127.0.0.1 6379 : 表示主数据库的地址和端口号, # 启动 $ redis-server /etc/redis/sentinel.conf --sentinel 14641:X 28 Sep 14:59:14.771 # Sentinel runid is 22c9d5b569313d6140806a12ccdc9792df3299c7 14641:X 28 Sep 14:59:14.771 # +monitor master mymaster 127.0.0.1 6379 quorum 1 14641:X 28 Sep 14:59:14.772 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6379 14641:X 28 Sep 14:59:14.774 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6379 14.2.2. 其他配置 一个哨兵节点可以同时监控多个Redis主从系统, 只需要提供多个sentinel monitor配置即可. 同时,多个哨兵节点也可以同时监控同一个 Redis 主从系统, 从而形成网状结构. # 一个哨兵监控多个集群 sentinel monitor mymaster 127.0.0.1 6379 2 sentinel monitor othermaster 192.168.1.3 6380 4 配置文件中还可以定义其他监控相关的参数, 每个配置选项都包含主数据库的名字使得监控不同主数据库时可以使用不同的配置参数. 例如 sentinel down-after-milliseconds mymaster 60000 sentinel down-after-milliseconds othermaster 10000 其他配置. sentinel failover-timeout mymaster 180000 sentinel parallel-syncs mymaster 1 14.3. 集群14.4. 分区分区是分割数据到多个 Redis 实例的处理过程, 因此每个实例只保存 key 的一个子集. 分区主要用于扩充容量, 而不是提高redis 的可用性. 通过利用多台计算机内存的和值, 允许我们构造更大的数据库 通过多核和多台计算机, 允许我们扩展计算能力 通过多台计算机和网络适配器, 允许我们扩展网络带宽 分区实际上把数据进行了隔离, 如果原本应该在同一分区的数据被放在了不同分区, 或者原本没有太多关系的数据因为新的业务产生了关系, 就会遇到一些问题： 涉及多个 key 的操作通常是不被支持的. 举例来说, 当两个 set 映射到不同的 redis 实例上时, 你就不能对这两个 set 执行交集操作 涉及多个 key 的 redis 事务不能使用 当使用分区时, 数据处理较为复杂, 比如你需要处理多个 rdb/aof 文件, 并且从多个实例和主机备份持久化文件 增加或删除容量也比较复杂. redis 集群大多数支持在运行时增加, 删除节点的透明数据平衡的能力, 但是类似于客户端分区、代理等其他系统则不支持这项特性. 然而, 一种叫做 presharding 的技术对此是有帮助的. Redis 有两种类型分区. 假设有 4 个 Redis实例 R0, R1, R2, R3, 和类似 user:1, user:2 这样的表示用户的多个 key, 对既定的 key 有多种不同方式来选择这个 key 存放在哪个实例中. 也就是说, 有不同的系统来映射某个 key 到某个 Redis 服务. 范围分区 最简单的分区方式是按范围分区, 就是映射一定范围的对象到特定的 Redis 实例. 比如, ID 从 0 到 10000 的用户会保存到实例 R0, ID 从 10001 到 20000 的用户会保存到 R1, 以此类推. 这种方式的不足之处是要有一个区间范围到实例的映射表, 同时还需要各种对象的映射表, 通常对 Redis 来说并非是好的方法. 哈希分区 另外一种分区方法是 hash 分区. 这对任何 key 都适用, 也无需是 object_name: 这种形式, 只需要确定统一的哈希函数, 然后通过取模确定应该保存在哪个分区即可. 15. 管理15.1. 安全Redis 安全问题 : redis 是一个弱安全的组件,只有一个简单的明文密码. 使用redis单独用户和组进行安全部署, 并且在OS层面禁止此用户ssh登陆, 这就从根本上防止了root用户启停redis带来的风险. 修改默认端口, 降低网络简单扫描危害. 修改绑定地址, 如果是本地访问要求绑定本地回环. 要求设置密码, 并对配置文件访问权限进行控制, 因为密码在其中是明文. 设置密码: $ config set requirepass [PASSWD] 认证密码 : redis-cli &gt; auth PASSWD HA环境下主从均要求设置密码. 建议在网络防火墙层面进行保护, 杜绝任何部署在外网直接可以访问的redis的出现. 危险命令重命名. redis 的危险命令有: flushdb flushall config keys 在服务端, 通常需要禁用以上命令来使服务器更加安全. 具体做法为, 修改服务器的配置文件 redis.conf, 在 SECURITY 这一区块中, 添加如下命令: $ vim redis.conf # 以下方式, 二选一. # 保留这些命令, 但是修改为复杂的, 不易猜测的其他字符, 以便需要的时候使用. rename-command FLUSHALL joYAPNXRPmcarcR4ZDgC81TbdkSmLAzRPmcarcR rename-command FLUSHDB qf69aZbLAX3cf3ednHM3SOlbpH71yEXLAX3cf3e rename-command CONFIG FRaqbC8wSA1XvpFVjCRGryWtIIZS2TRvpFVjCRG rename-command KEYS eIiGXix4A2DreBBsQwY6YHkidcDjoYA2DreBBsQ # 完全禁用这些命令. rename-command FLUSHALL &quot;&quot; rename-command FLUSHDB &quot;&quot; rename-command CONFIG &quot;&quot; rename-command KEYS &quot;&quot; 15.2. 通信协议15.3. 管理工具16. 监控16.1 redis-cli info 内存使用 info memory ** 如果 Redis 使用的内存超出了可用的物理内存大小, 那么 Redis 很可能系统会被 OOM Killer 杀掉. 为使用内存量设定阈值, 并设定相应的报警机制. used_memory used_memory_peak 持久化 info Persistence rdb_last_save_time : 进行监控, 了解你最近一次 dump 数据操作的时间, rdb_changes_since_last_save : 进行监控来知道如果这时候出现故障, 你会丢失多少数据. 主从复制 info replication master_link_status : 进行监控, 如果这个值是 up, 那么说明同步正常, 如果是 down, fork 性能 info stats 当 Redis 持久化数据到磁盘上时, 它会进行一次 fork 操作, 通过 fork 对内存的 copy on write 机制最廉价的实现内存镜像. 但是虽然内存是 copy on write 的, 但是虚拟内存表是在 fork 的瞬间就需要分配, 所以 fork 会造成主线程短时间的卡顿(停止所有读写操作), 这个卡顿时间和当前 Redis 的内存使用量有关. 通常 GB 量级的 Redis 进行 fork 操作的时间在毫秒级. latest_fork_usec : 监控最近一次fork操作使用时间. 16.2 慢日志Redis 的慢查询日志功能用于记录执行时间超过给定时长的命令请求, 用户可以通过这个功能产生的日志来监视和优化查询速度. Redis 提供了 SLOWLOG 指令来获取最近的慢日志, Redis 的慢日志是直接存在内存中的, 所以它的慢日志开销并不大, 在实际应用中, 我们通过 crontab 任务执行 SLOWLOG 命令来获取慢日志, 然后将慢日志存到文件中, 并用 Kibana 生成实时的性能图表来实现性能监控. Redis 的慢日志记录的时间, 仅仅包括 Redis 自身对一条命令的执行时间, 不包括 IO 的时间, 比如接收客户端数据和发送客户端数据这些时间. Redis 的慢日志和其它数据库的慢日志有一点不同, 其它数据库偶尔出现 100ms 的慢日志可能都比较正常, 因为一般数据库都是多线程并发执行, 某个线程执行某个命令的性能可能并不能代表整体性能, 但是对 Redis 来说, 它是单线程的, 一旦出现慢日志, 可能就需要马上得到重视, 最好去查一下具体是什么原因了. 配置 # 选项指定执行时间超过多少微秒(1 秒等于 1,000,000 微秒)的命令请求会被记录到日志上. 设置的单位是微妙, 默认是10000微妙, 也就是10ms slowlog-log-slower-than # 选项指定服务器最多保存多少条慢查询日志. 服务器使用先进先出的方式保存多条慢查询日志： 当服务器储存的慢查询日志数量等于 slowlog-max-len 选项的值时, 服务器在添加一条新的慢查询日志之前, 会先将最旧的一条慢查询日志删除. slowlog-max-len slowlog 格式详解 &gt; SLOWLOG GET 10 1) 1) (integer) 4 # 日志的唯一标识符(uid) 2) (integer) 1378781447 # 命令执行时的 UNIX 时间戳 3) (integer) 13 # 命令执行的时长, 以微秒计算 4) 1) &quot;SET&quot; # 命令以及命令参数 2) &quot;database&quot; 3) &quot;Redis&quot; 结果为查询ID、发生时间、运行时长 和 原命令, 默认10毫秒, 默认只保留最后的128条. 单线程的模型下, 一个请求占掉10毫秒是件大事情, 注意设置和显示的单位为 微秒, 注意这个时间是不包含网络延迟的. 获取慢查询日志 &gt; slowlog get &gt; slowlog get 10 # 获取前10条 &gt; slowlog get -10 # 获取后10条 获取慢查询日志条数 &gt; slowlog len 清空慢查询 &gt; slowlog reset 16.3 监控服务 sentinel : 哨兵 是 Redis 自带的工具, 它可以对 Redis 主从复制进行监控, 并实现主挂掉之后的自动故障转移. 在转移的过程中, 它还可以被配置去执行一个用户自定义的脚本, 在脚本中我们就能够实现报警通知等功能. Redis Live Redis Live 是一个更通用的 Redis 监控方案, 它的原理是定时在 Redis 上执行 MONITOR 命令, 来获取当前 Redis 当前正在执行的命令, 并通过统计分析, 生成web页面的可视化分析报表 Redis Faina 其原理和 Redis Live 类似, 都是对通过 MONITOR 来做的. 16.4 数据分布 : redis 数据集分析 Redis-sampler Redis-sampler 是 Redis 作者开发的工具, 它通过采样的方法, 能够让你了解到当前 Redis 中的数据的大致类型, 数据及分布状况. redis-audit Redis-audit 是一个脚本, 通过它, 我们可以知道每一类 key 对内存的使用量. 它可以提供的数据有：某一类 key 值的访问频率如何, 有多少值设置了过期时间, 某一类 key 值使用内存的大小, 这很方便让我们能排查哪些 key 不常用或者压根不用. redis-rdb-tools 跟 Redis-audit 功能类似, 不同的是它是通过对 rdb 文件进行分析来取得统计数据的. 17. 其他管理类遍历数据库中的键 : &gt; keys * # 生产环境已禁止,当数据库很大时,会阻塞数据库. &gt; SCAN cursor [MATCH pattern] [COUNT count] # 以渐进的方式,分多次遍历啊整个数据库,并返回匹配给定模式的键. &gt; SSCAN key cursor [MATCH pattern] [COUNT count] # 代替可能会阻塞服务器的 SMEMBERS 命令,遍历集合包含的各个元素. &gt; HSCAN key cursor [MATCH pattern] [COUNT count] # 代替肯能会阻塞服务器的 HGETALL 命令,遍历散列包含的各个键值对. &gt; ZSCAN key cursor [MATCH pattern] [COUNT count] # 代替可能会则色服务器的 ZRANGE 命令,遍历有序集合包含的各个元素. redis-cli 扫描 $ redis-cli --scan --pattern &apos;PATTERN&apos; 管理类 &gt; exists key &gt; del key1 &gt; type key1 &gt; randomkey # 随机返回一个 key &gt; rename OLDKEY NEWKEY &gt; renamenx OLDKEY NEWKEY # 超时时间 &gt; expire key second &gt; persist key # 消除设置的超时时间 &gt; expireat # 采用绝对超时. &gt; ttl key # 返回key 的剩余过期时间. &gt; pexpire key ms # 毫秒为时间单位 &gt; pttl key # 以毫秒返回生命周期. &gt; setnx key value # 仅当 key 不存在时,才set ,存在返回 0 ; nx , not exist . # 用来选举 master 或 做分布式锁, 所有 client 不断尝试使用 setnx key value 抢注 master, 成功的那位不断使用 expire 刷新他的过期时间. &gt; set key value nx|xx # nx : 仅在不存在 key 时 ,进行设置操作. # xx : 尽在存在 key 时, 进行设置操作. &gt; setget key value # 原子的设置key的值,并返回 key 的旧值. 配合 setnx 可以实现分布式锁. 开发设计规范 : key 设计 object-type:id:field.conn # 用 &quot;:&quot; 分割域, 用 &quot;.&quot; 做单词间的链接. ① 把表名转换为 key 前缀, ② 第二段放置用于区分 key 的字段, ③ 第三段放置主键 ④ 第四段写要存储的列名. 性能测试: $ redis-benchmark -q -r 100000 -n 100000 -c 50 $ redis-benchmark -t SET -c 100 -n 10000000 -r 10000000 -d 256 # 开100条线程(默认50), SET 1千万次(key在0-1千万间随机), key长21字节, value长256字节的数据. -r指的是使用随机key的范围. 数据库 : &gt; select db_index # 选择数据库 &gt; flushdb # 删除当前数据库中的所有 key, &gt; flushall # 删除所有的数据库. 执行 lua 脚本 $ redis-cli --eval name.lua PARAMETER 数据迁移 : 1. 将 key 从当前数据库移动到指定数据库 &gt; move key db_index 探测服务延迟 : $ redis-cli --latency # 显示的单位是milliseconds, 作为参考, 千兆网一跳一般延迟为0.16ms左右 查看统计信息 : redis:6379&gt; info 在cli下执行info. redis:6379&gt; info Replication 只看其中一部分. redis:6379&gt; config resetstat 重新统计 查看客户端 : &gt; client list # 列出所有连接 &gt; client kill 127.0.0.1:43501 # 杀死某个连接 查看日志 : 默认位于 redis/log 下 redis.log # redis 主日志 sentinel.log # sentinel 监控日志. 多实例配置 : taskset $ taskset -p REDIS_PID # 显示进行运行的 cpu, 结果 为 f $ taskset -p REDIS_PID -c 3 # 指定进程运行在某个特定 cpu 上, REDIS_PID 只会运行在 第4个 CPU 上. $ taskset -c 1 ./redis-server ./redis-6379.conf # 进程启动时,指定 cpu. 配置文件参数设置技巧 : Include 如果是多实例的话可以将公共的设置放在一个conf文件中, 然后引用即可： include /redis/conf/redis-common.conf 并发延迟检查 1. 检查 cpu 情况 $ mpstat -P ALL 1 2. 检查网络情况 : 可以在系统不繁忙或者临时下线前检测客户端和server或者proxy 的带宽： 1) 在 10.230.48.65 上使用 iperf -s 命令将 Iperf 启动为 server 模式: $ iperf –s 2) 启动客户端, 向IP为10.230.48.65的主机发出TCP测试, 并每2秒返回一次测试结果, 以Mbytes/sec为单位显示测试结果： $ iperf -c 10.230.48.65 -f M -i 2 3. 检查系统情况 : 探测服务延迟 监控正在请求执行的命令 获取慢查询 4. 检查连接数 $ redis-cli info Stats | grep total_connections_received # 如果该值不断升高, 则需要升级应用,改用连接池方式进行,因为频繁的关闭和创建连接,对redis 开销很大. 5. 检查持久化 RDB的时间： latest_fork_usec:936 上次导出rdb快照,持久化花费, 微秒. 检查是否有人使用了SAVE. 6. 检查命令执行情况 &gt; INFO commandstats 查看命令执行了多少次, 执行命令所耗费的毫秒数(每个命令的总时间和平均时间) 内存检查 1. 系统内存查看 2. 系统swap内存查看 3. info 查看内存 &gt; info memory used_memory:859192 # 数据结构的空间 used_memory_rss:7634944 # 实占空间 mem_fragmentation_ratio:8.89 # 前2者的比例, 1.N为佳,如果此值过大,说明redis的内存的碎片化严重,可以导出再导入一次. 4. dump.rdb 文件生成内存报告(rdb-tools) $ rdb -c memory ./dump.rdb &gt; redis_memory_report.csv $ sort -t, -k4nr redis_memory_report.csv 5. query 在线分析: redis-faina , redis 版本 &gt; 2.4 $ cd /opt/test $ git clone https://github.com/Instagram/redis-faina.git $ cd redis-faina/ $ redis-cli -p 6379 MONITOR | head -n 100 | ./redis-faina.py --redis-version=2.4 $ redis-cli MONITOR | head -n 5000 | ./redis-faina.py 6. 内存抽样分析 $ /redis/script/redis-sampler.rb 127.0.0.1 6379 0 10000 $ /redis/script/redis-audit.rb 127.0.0.1 6379 0 10000 7. 统计生产上比较大的 key $ redis-cli --bigkeys # 对redis中的key进行采样, 寻找较大的keys. 是用的是scan方式, 不用担心会阻塞redis很长时间不能处理其他的请求. 执行的结果可以用于分析redis的内存的只用状态, 每种类型key的平均大小. 8. rss 增加,内存碎片增加 可以选择时间进行redis服务器的重新启动, 并且注意在rss突然降低观察是否swap被使用, 以确定并非是因为swap而导致的rss降低. 测试方法 : 1. 模拟 oom $ redis-cli debug oom # redis 直接退出 2. 模拟宕机 $ redis-cli debug segfault 3. 模拟 hang $ redis-cli debug sleep 30 4. 快速产生测试数据 &gt; debug populate 1000 &gt; dbsize 5. 模拟 RDB load 情形 &gt; debug reload # save当前的rdb文件, 并清空当前数据库, 重新加载rdb, 加载与启动时加载类似, 加载过程中只能服务部分只读请求(比如info、ping等)： rdbSave(); emptyDb(); rdbLoad(); 6. 模拟 AOF 加载情形 &gt; debug loadaof # 清空当前数据库,重新从aof文件里加载数据库 emptyDb(); loadAppendOnlyFile();]]></content>
      <categories>
        <category>Middleware</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法复杂度速查表]]></title>
    <url>%2F2018%2F03%2F15%2F%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6%E9%80%9F%E6%9F%A5%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[数据结构, 排序算法, 图操作, 堆操作, Big-O 算法复杂度速查表. 参考链接 图例 数据结构操作 数组排序算法 图操作复杂度 堆操作复杂度 Big-O 复杂度图表]]></content>
  </entry>
  <entry>
    <title><![CDATA[创业的本质]]></title>
    <url>%2F2018%2F03%2F15%2F%E6%9D%82%E8%AE%B0-%E5%88%9B%E4%B8%9A%E7%9A%84%E6%9C%AC%E8%B4%A8%2F</url>
    <content type="text"><![CDATA[我从没有听到过他们的一丝抱怨，我看到的永远是他们冲在一线解决客户问题的身影。这种乐观的心态，这种对荣辱毫不计较的精神，才是真正的创业者精神。 对创业初心的坚持，就是对使命的坚持。使命一定是解决了他人的问题，而不是解决了自己的问题。解决他人的问题就是「利他」，商业的本质不是交换，而是「利他」。一定是在利他的基础上，才能产生交换的需求。这就是为什么多数成功公司的企业文化里，都会强调「利他」的原因。需要有对应的企业文化，来催生对应的组织机制，以完成相应的商业目标，这是一环扣一环的。很多管理者从书上借鉴了一些做法，但并没有理解这其中的深层次联系。如果理解了企业的根本是客户价值，客户价值的本质是利他，从而鼓励所有员工成为「利他」的人，企业文化才不会流于形式和口号，才能真正成为基业长青的基石。 解决他人的问题就是「利他」，商业的本质不是交换，而是「利他」。一定是在利他的基础上，才能产生交换的需求。 我会狂妄的宣称要去颠覆世界，现在看来，世界根本不需要被颠覆，也很难在短时间内颠覆一个行业或一个市场。世界需要的是变得更美好，这是创业公司应该追求的。 Make the world a batter place. 不要用战术上的勤奋，掩盖战略上的懒惰。 创业不是一将功成万骨枯，创业是一个团队的成功。 来源]]></content>
      <categories>
        <category>杂记</category>
      </categories>
      <tags>
        <tag>创业</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fpm 制作 rpm 包]]></title>
    <url>%2F2018%2F03%2F15%2FOS-Linux-fpm-%E6%89%93%E5%8C%85%2F</url>
    <content type="text"><![CDATA[使用 fpm 打包 rpm 包. 一. 使用 fpm 打包 rpm 包 支持的 源类型包 ① dir : 将目录打包成所需要的类型, 可用于源码编译安装软件包 ② rpm : 对 rpm 包进行转换 ③ gem : 对 rubygem 包进行转换 ④ python : 将 python 模块打包成响应的类型 支持的 目标类型包 ① rpm : 转换为 rpm 包 ② deb : 转换为 deb 包 ③ solaris : 转换为 solaris 包 ④ puppet : 转换为 puppet 模块 FPM 安装 及 使用帮助 : FPM 基于 ruby , 需要首先安装 ruby 环境. ruby &gt; 1.8.5 $ yum install ruby rubygems ruby-devel gcc make libffi-devel -y $ yum install rpm-build -y # fpm 依赖 rpmbuild $ gem sources list $ gem sources --remove https://rubygems.org/ $ gem sources --add https://ruby.taobao.org $ gem install fpm # for centos7 $ gem install json -v 1.8.3 # for centos6 $ gem install fpm -v 1.3.3 # for centos6 $ fpm --help -s 指定源类型 -t 指定目标类型，即想要制作为什么包 -n 指定包的名字 -v 指定包的版本号 -C 指定打包的相对路径 Change directory to here before searching forfiles -d 指定依赖于哪些包 -f 第二次打包时目录下如果有同名安装包存在，则覆盖它 -p 输出的安装包的目录，不想放在当前目录下就需要指定 --post-install 软件包安装完成之后所要运行的脚本；同--after-install --pre-install 软件包安装完成之前所要运行的脚本；同--before-install --post-uninstall 软件包卸载完成之后所要运行的脚本；同--after-remove --pre-uninstall 软件包卸载完成之前所要运行的脚本；同--before-remove --description 示例: 定制 nginx rpm 包 $ yum -y install pcre-devel openssl-devel libzip $ useradd nginx -M -s /sbin/nologin $ tar xf nginx_1.10.tar.gz $ cd nginx_1.10 $ ./configure --prefix=/opt/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_stub_status_module $ make &amp;&amp; make install $ echo &quot;nginx-1.10.2&quot; &gt; /opt/nginx/version $ vim /tmp/nginx_rpm.sh #!/bin/bash useradd nginx -M -s /sbin/nologin $ fpm -s dir -t rpm -n nginx -v 1.10.2 -d &apos;pcre-devel,openssl-devel,libzip&apos; --post-install /tmp/nginx_rpm.sh -f /opt/nginx # 注意此处的 绝对路径. $ rpm -qpl nginx-1.6.2-1.x86_64.rpm # 查看软件包内容. 二. 有用的命令.$ yum provides *bin/prove provides Find what package provides the given value resolvedep Determine which package provides the given dependency $ tar -tvf new.tgz # 查看包的内容, 不解压包. $ make install DESTDIR=/tmp/installdir/ $ getent passwd root # 查看手否存在用户root root:x:0:0:root:/root:/bin/bash $ rpm -qp --scripts tengine-2.1.0-1.el6.x86_64.rpm # 查看 rpm 保存的脚本信息]]></content>
      <categories>
        <category>计算机原理与操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>rpm</tag>
        <tag>fpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AWS-S3]]></title>
    <url>%2F2018%2F03%2F15%2FAWS-S3%2F</url>
    <content type="text"><![CDATA[AWS 的数据存储服务 S3使用 S3 创建公司内部的文件服务器, 保存员工私人/共享文件, 并以类似 Dropbox 的方式双向同步. S3 介绍S3 是 AWS 最早发布的诸多服务之一, 用作可信存储. 可信 : 在指定年度内, 为对象提供 99.999999999% 的持久性和 高达 99.99% 的可用性. S3 提供如下特性 : 跨区域复制 : 只需要简单的配置，存储于S3中的数据会自动复制到选定的不同区域中。当你的数据对象的收集分散在不同的区域，而处理集中在某些区域时非常有用。 事件通知 : 当数据对象上传到 Amazon S3 中或从中删除的时候会发送事件通知。事件通知可使用 SQS 或 SNS 进行传送，也可以直接发送到 AWS Lambda 进行处理。 版本控制 : 数据对象可以启用版本控制，这样你就可以很方便地进行回滚。对于应用开发者来说，这是个特别有用的特性。 加密 S3的访问本身是支持 SSL（HTTPS）的，保证传输的安全，对于数据本身，你可以通过Server side encryption（AES256）来加密存储在S3的数据。 访问管理 通过 IAM/VPC 可以控制S3的访问粒度，你甚至可以控制一个bucket（S3对数据的管理单元，一个bucket类似于一组数据的根目录）里面的每个folder，甚至每个文件的访问权限。 可编程 可以使用 AWS SDK 进行客户端或者服务端的开发。 成本监控和控制 S3 有几项管理和控制成本的功能，包括管理成本分配的添加存储桶标签和接收账单警报的 Amazon Cloud Watch 集成。 灵活的存储选项 S3 Standard， Standard–Infrequent Access 选项可用于非频繁访问数据，存储的价格大概是 Standard 的 2/5。 Glacier : 用于存储冷数据（如N年前的Log），价格在 Standard 的 1/4，缺点是需要几个小时来恢复数据。 S3 操作方式consoleAWS CLI创建 bucket aws s3api create-bucket --bucket &lt;name&gt; 删除 bucket aws s3api delete-bucket --bucket &lt;name&gt; 像使用一般文件系统一样操作 S3 aws s3 ls aws s3 cp aws s3 rm 本地文件 与 S3 上文件同步 : aws s3 sync ./local_dir s3://my_bucket/my_dir AWS SDK使用的一般流程 : ① 创建 AWS Connection (需要 access key) ② 使用 connection 创建 S3 对象 ③ 使用 S3 API 进行各种操作. 使用 S3 的典型场景存储用户上传的文件, 如照片,视频等静态内容单做一个 k-v 存储, 承担简单的数据库服务功能数据备份静态网站的托管 : 可以对一个 bucket 使能 Web Hosting.参考]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>S3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AWS-IAM权限控制]]></title>
    <url>%2F2018%2F03%2F15%2FAWS-IAM%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[AWS 的认证与权限管理服务 IAM 与 权限访问控制机制IAM , Identity and Access Management 基本概念ARN, Amazon Resource Name :在 AWS 里, 创建的任何资源都有其全局唯一的 ARN, 是访问控制可以到达的最小粒度. users, 用户groups, 组将用户添加到一个群组中, 可以自动获得这个群组的所有权限. roles, 角色没有任何访问凭证(密码或密钥), 他一般被赋予某个资源(包括用户), 那时起临时具有某些权限. 角色的密钥是动态创建的, 更新和失效都无需特别处理. permissions, 权限,权限可以赋给 用户,组, roles, 权限通过 policy document 描述, policy, 是描述权限的一段 JSON 文本. 示例如下{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;*&quot;, &quot;Resource&quot;: &quot;*&quot; } ] } 用户或者群组只有添加了相关的 policy才会有响应的权限. policy 是 IAM 的核心内容. 是 JSON 格式来描述, 主要包含 Statement, 也就是 policy 拥有的权限的陈诉. 一言以蔽之: 谁在什么条件下能对哪些资源的哪些操作进行处理。 policy 的 PARCE 原则 : Principal : 谁 – 单独创建的 policy 是不需要指明 Principal 的, 当该 policy 被赋给用户,组或者 roles 时, principal 自动创建. Action : 那些操作 Resource : 那些资源 Condition : 什么条件 Effect : 如何处理 (Allow/Deny) 示例 { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;s3:Get*&quot;, &quot;s3:List*&quot; ], &quot;Resource&quot;: &quot;*&quot; } ] } 在这个policy里，Principal和Condition都没有出现。如果对资源的访问没有任何附加条件，是不需要Condition的；而这条policy的使用者是用户相关的principal（users, groups, roles），当其被添加到某个用户身上时，自然获得了principal的属性，所以这里不必指明，也不能指明。 Resource policy，它们不能单独创建，只能依附在某个资源之上（所以也叫inline policy），这时候，需要指明Principal。 示例如下 : { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: &quot;*&quot;, &quot;Action&quot;: &quot;s3:GetObject&quot;, &quot;Resource&quot;: &quot;arn:aws:s3:::corp-fs-web-bucket/*&quot; } ] } 当我希望对一个S3 bucket使能Web hosting时，这个bucket里面的对象自然是要允许外界访问的，所以需要如下的inline policy： Condition 示例 &quot;Condition&quot;: { &quot;IPAddress&quot;: {&quot;aws:SourceIP&quot;: [&quot;10.0.0.0/8&quot;, &quot;4.4.4.4/32&quot;]}, &quot;StringEquals&quot;: {&quot;ec2:ResourceTag/department&quot;: &quot;dev&quot;} } &quot;Condition&quot;: { &quot;StringLike&quot;: { &quot;s3:prefix&quot;: [ &quot;tyrchen/*&quot; ] } } ** 在一条Condition下并列的若干个条件间是and的关系，这里IPAddress和StringEquals这两个条件必须同时成立； ** 在某个条件内部则是or的关系，这里10.0.0.0/8和4.4.4.4/32任意一个源IP都可以访问。 Policy 执行规则 : 默认情况下，一切资源的一切行为的访问都是Deny 如果在policy里显式Deny，则最终的结果是Deny 否则，如果在policy里是Allow，则最终结果是Allow 否则，最终结果是Deny]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>IAM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lua学习笔记]]></title>
    <url>%2F2018%2F03%2F15%2FLua%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Lua 是一种高性能, 解释型, 面向对象的语句, 广泛用于各种项目的内嵌语言, 如 redis, nginx, scrapy, 愤怒的小鸟, 魔兽世界等等. 本文主要介绍 Lua 的语法. 1. 数据类型lua 是一个动态类型语言,一个变量可以存储类型的值.Lua 常用数据类型: 空(nil): 空类型只包含一个值,即nil . nil表示空, 没有赋值的变量或标的字段都是 nil. 布尔(boolean): 布尔类型包含 True 和 False 两个值. 数字(number): 整数合浮点数是都是使用数字类型存储. 字符串(string): 字符串类型可以存储字符串,且与Redis的键值一样都是二进制安全的.字符串可以使用单引号或双引号表示,两个符号是相同的. 字符串可以包含转义字符,如 ‘\n’,’\r’ 等. 表(table): 表类型是Lua 语言中唯一的数据结构,既可以当数组,又可以当字典,十分灵活. 函数(function): 函数是Lua中的一等值(first-class value),可以存储在变量中,作为函数的参数或返回结果. 2. 变量Lua 变量分为全局变量和局部变量. 全局变量无需声明就可以直接使用,默认值是 nil . &gt; print(b) a = 1 -- 为全局变量a赋值 a = nil -- 删除全局变量的方法是将其复制为 nil . 全局变量没有声明与未声明之分,只有非 nil 和 nil 的区别. print(b) -- 无需声明即可使用，默认值是nil 声明局部变量的方式为 “local 变量名” : local c --声明一个局部变量c，默认值是nil local d = 1 --声明一个局部变量d并赋值为1 local e, f --可以同时声明多个局部变量 * 局部变量的作用域为从声明开始到所在层的语句块的结尾. 声明一个存储函数的局部变量的方法为 : local say_hi = function () print &apos;hi&apos; end 变量名必须是非数字开头,只能包含字母,数字和下划线,区分大小写. 变量名不能与Lua的保留关键字相同, 保留关键字如下: and break do else elseif end false for function if in local nil not or repeat return then true until while 3. 注释 单行: -- 开始, 到行尾结束. 多行: --[[ ... ]] . 4. 赋值多重赋值 : local a, b = 1, 2 -- a的值是1，b的值是2 local c, d = 1, 2, 3 -- c的值是1，d的值是2，3被舍弃了 local e, f = 1 -- e的值是1，f的值是nil 在执行多重赋值时,Lua会先计算所有表达式的值,比如: local a = {1, 2, 3} local i = 1 i, a[i] = i + 1, 5 -- i = 2 ; a = {5,2,3} , lua 索引从 1 开始. lua 中的函数也可以返回多个值 5. 操作符5.1 数学操作符 :常见的+、-、*、/、%（取模）、-（一元操作符，取负）和幂运算符号^。 数学操作符的操作数如果是字符串,则会自动转换为数字. print(&apos;1&apos; + 1) -- 2 print(&apos;10&apos; * 2) -- 20 5.2 比较操作符 : == : 比较两个操作数的类型和值是否相等 ~= : 与 == 结果相反 &lt;,&gt;,&lt;=,&gt;= : 大于,小于,小于等于,大于等于. 比较操作符的结果一定是布尔类型 ; 比较操作符,不会对两边的操作数进行自动类型转换. 5.3 逻辑操作符 : not : 根据操作数的真和假返回false 和 true and : a and b, 如果a 是真,则返回 b , 否则返回 a . or : a or b , 如果a 是假,则返回 a , 否则返回 b . 只要操作数不是 nil 或 false ,逻辑操作符都认为操作数是真. 特别注意 0 或 空字符串也被当做真. Lua 逻辑操作符支持短路，也就是说对于 false and foo() ，lua 不会调用foo函数，or 类似。 5.4 连接操作符.... 用来连接两个字符串. 连接操作符会自动把数字类型的抓换成字符串类型. 5.5 取长度操作符.是lua5.1 新增的操作符, # ,用来获取字符串或表的长度. &gt; print(#&apos;hello&apos;) -- 5 5.6 运算符的优先级:^ not # -(一元) * / % + - .. &lt; &gt; &lt;= &gt;= ~= == and or 6. if 语句语法 : if 条件表达式 then 语句块 elseif 条件表达式 then 语句块 else 语句块 end 注意 : Lua 中只有 nil 和 false 才是假, 其余值,包括0 和空字符串,都被认为是真值. Lua 每个语句都可以 ; 结尾 ,但是一般来说编写 Lua 是会省略 ; , Lua 并不强制要求缩进,所有语句也可以写在一行中, 但为了增强可读性,建议在注意缩进. &gt; a = 1 b = 2 if a then b = 3 else b = 4 end 7. 循环语句7.1 while 循环while 条件表达式 do 语句块 end 7.2 repeat 循环repeat 语句块 until 条件表达式 7.3 for 循环形式一 :for 循环中的 i 是局部变量, 作用域为 for 循环体内. 虽然没有使用 local 声明,但它不是全局变量. for 变量=初值,终值,步长 do -- 步长可省略,默认为 1 语句块 end 示例 # 计算 1 ~ 100 之和 local sum = 0 for i = 1 ,100 do sum = sum + 1 end 形式二 :for 变量1 ,变量2, ... , 变量N in 迭代器 do 语句块 end 8. 表类型表是Lua中唯一的数据结构,可以理解为关联数组, 任何类型的值(除了空类型)都可以作为表的索引. a = {} --将变量a赋值为一个空表 a[&apos;field&apos;] = &apos;value&apos; --将field字段赋值value print(a.field) --打印内容为&apos;value&apos;，a.field是a[&apos;field&apos;]的语法糖。 people = { --也可以这样定义 name = &apos;tom&apos;, age = 29 } 当索引为整数的时候表和传统的数组一样，例如： a = {} a[1] = &apos;Tom&apos; a[2] = &apos;Jeff&apos; 可以写成下面这样： a = {&apos;Tom&apos;, &apos;Jeff&apos;} print(a[1]) --打印的内容为&apos;Tom&apos; 可以使用通用形式的for语句遍历数组,例如: for index,value in ipairs(a) do -- index 迭代数组a 的索引 ; value 迭代数组a 的值. print(index) print(value) end -- ipairs 是Lua 内置的函数,实现类似迭代器的功能. 数字形式的for语句 for i=1,#a do print(i) print(a[i]) end pair : 迭代器,用来遍历非数组的表值. person = { name = &apos;Tom&apos;, age = 29 } for index,value in pairs(person) do print(index) print(value) end pairs 与 ipairs 的区别在于前者会遍历所有值不为 nil 的索引, 而后者只会从索引 1 开始递增遍历到最后一个值不为 nil 的整数索引. 9. 函数一般形式: function(参数列表) 函数体 end 可以将函数赋值给一个局部变量, 比如: local square = function(num) return num*num end ** 因为在赋值前声明了局部变量 square, 所以可以在函数内部引用自身(实现递归). 函数参数 : 如果实参的个数小于形参的个数,则没有匹配到的形参的值为 nil . 相对应的,如果实参的个数大于形参的个数,则多出的实参会被忽略. 如果希望捕获多出的参数(即实现可变参数个数),可以让最后一个形参为 ... . local function square(...) local argv = {...} for i = 1,#argv do argv[i] = argv[i] * argv[i] end return unpack(argv) -- unpack 函数用来返回 表 中的元素. 相当于return argv[1], argv[2], argv[3] end a,b,c = square(1,2,3) print(a) -- 1 print(b) -- 4 print(c) -- 9 在 Lua 中, return 和 break (用于跳出循环) 语句必须是语句块中的最后一条语句, 简单的说在这两条语句之后只能是 end,else 或 until 三者之一. 如果希望在语句块中间使用这两条语句,可以认为的使用 do 和 end 将其包围. 10. 标准库 http://www.lua.org/manual/5.1/manual.html#5Lua 的标准库中提供了很多使用的函数, 比如 ipairs,pairs,tonumber,tostring,unpack 都属于标准库中的Base库. Redis 支持大部分Lua标准库,如下所示: 库名 说明 Base 一些基础函数 String 用于字符串操作的函数 Table 用于表操作的函数 Math 数学计算函数 Debug 调试函数 10.1 String库 : 可以通过字符串类型的变量以面向对象的形式访问, 如 string.len(string_var) 可以写成 string_var:len() 获取字符串长度 : string.len(string) 作用与操作符 “#” 类似 &gt; print(string.len(&apos;hello&apos;)) -- 5 &gt; print(#&apos;hello&apos;) -- 5 转换大小写 string.upper(string) string.lower(string) 获取子字符串 string.sub() 可以获取一个字符串从索引 start 开始到 end 结束的子字符串,索引从1 开始. 索引也可以是负数, -1 代表最后一个元素 . string.sub(string start[,end ]) -- end 默认为 -1. &gt; print(string.sub(&apos;hello&apos;,1)) -- hello &gt; print(string.sub(&apos;hello&apos;,2)) -- ello &gt; print(string.sub(&apos;hello&apos;,2,-2)) -- ell 10.2 Table库 : 其中大部分函数都需要表的形式是数组形式. 将数组转换为字符串 table.concat(table [,sep [,i [,j]]]) # sep : 以 sep 指定的参数分割, 默认为空. # i , j : 用来限制要转换的表元素的索引范围. 默认分别为 1 和 表的长度. 不支持负索引. print(table.concat({1,2,3})) –123print(table.concat({1,2,3},’,’,2)) –2,3print(table.concat({1,2,3},’,’,2,2)) –2 向数组中插入元素 table.insert(table ,[pos,] value) # 在指定索引位置 pos 插入元素 value, 并将后面的元素顺序后移. 默认 pos 值是数组长度加 1 , 即在数组尾部插入. &gt; a = {1,2,4} &gt; table.insert(a,3,3) # {1,2,3,4} &gt; table.insert(a,5) # {1,2,3,4,5} &gt; print(table.concat(a,&apos;,&apos;)) 1,2,3,4,5 从数组中弹出一个元素 table.remove(table,[,pos]) # 从指定的索引删除一个元素,并将后面的元素前移,返回删除元素值. 默认 pos 的值是数组的长度,即从数组尾部弹出一个元素. &gt; table.remove(a) --{1,2,3,4} &gt; table.remove(a,1) --{2,3,4} &gt; print(table.caoncat(a,&apos;,&apos;)) 2,3,4 10.3 Math库 : 提供常用的数学运算函数, 如果参数是字符串会自动尝试转换成数字.math.abs(x) # 绝对值 math.sin(x) # 三角函数sin math.cos(x) # 三角函数cos math.tan(x) # 三角函数tan math.ceil(x) # 进一取整, 1.2 取整后是 2 math.floor(x) # 向下取整, 1.8 取整后是 1 math.max(x,...) # 获得参数中的最大的值 math.min(x,...) # 获取参数中的最小的值 math.pow(x,y) # 获取 xy 的值 math.sqrt(x) # 获取 x 的平方根 math.random([m,[,n]]) # 生成随机数,没有参数 返回 [0,1]的实数, 参数 m 返回范围在 [1,m] 的整数, 同时提供 m n 返回范围在 [m,n] 的整数. math.randomseed(x) # 设置随机数种子, 同一种子生成的随机数相同. 11. 其他库Redis 还通过 cjson库 和 cmsgpack库 提供了对 JSON 和 MessagePack的支持. Redis自动加载了这两个库,在脚本中可以分别通过 cjson 和 cmsgpack 两个全局变量来访问对应的库. local people = { name = &apos;Tom&apos;, age = 29 } -- 使用 cjson 序列化成字符串 local json_people_str = cjson.encode(people) -- 使用 cmsgpack 序列化成字符串 local msgpack_people_str = cmsgpack.pack(people) -- 使用 cjson 将序列化后的字符串还原成表 local json_people_obj = cjson.decode(people) print(json_people_obj.name) -- 使用 cmshpack 将序列化后的字符串还原成表 local msgpack_people_obj = cmsgpack.unpack(people) print(msgpack_people_obj.name)]]></content>
      <categories>
        <category>Lua</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
        <tag>redis</tag>
        <tag>lua</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy-命令行工具]]></title>
    <url>%2F2018%2F03%2F15%2FScrapy-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[Scrapy 命令行工具使用汇总.命令行工具 1. Configuration settingsScrapy will look for configuration parameters in ini-style scrapy.cfg files in standard locations: /etc/scrapy.cfg or c:\scrapy\scrapy.cfg –&gt; system-wide ~/.config/scrapy/cfg and ~/.scrapy.cfg –&gt; user-wide scrapy.cfg inside a scrapy project’s root. –&gt; project-wite priority: project-wide &gt; user-wide &gt; system-wide 2. environment variables:SCRAPY_SETTING_MODULE SCRAPY_PROJECT SCRAPY_PYTHON_SHELL 3. scrapy command line# creating projects # by default project_dir == myproject $ scrapy startproject myproject [project_dir] # some cmd must be run from inside a Scrapy project $ cd project_dir # scrapy help $ scrapy -h # scrapy subcmd help $ scrapy SUB_CMD --help 3.1 Global commands : work without an active Scrapy project startprojects # Create a new Scrapy project named &apos;project_name&apos;, under the &apos;project_dir&apos; # if &apos;project_dir&apos; wasn&apos;t specified , it will be the same with the &apos;project_name&apos; $ scrapy startproject &lt;project_name&gt; [project_dir] genspider Create a new spider in the current folder or in the current project’s spiders folder, if called from inside a project. This is just a shortcut for creating spiders. You can just create the spider source code files yourself, instead of using this command. The name parameter is set as the spider’s name. while domain is used to generate the allowed_domains and start_urls spider’s attributes. # create spider &apos;name&apos; using `template` $ scrapy genspider [-t template] &lt;name&gt; &lt;domain&gt; # list all available templates: $ scrapy genspider -l basic # default crawl csvfeed xmlfeed settings get the value of a Scrapy setting. $ scrapy settings [options] $ scrapy settings --get BOT_NAME $ scrapy settings --get DOWNLOAD_DELAY runspider run a spider self-contained in a Python file, without having to create a project. $ scrapy runspider myspider.py shell Starts the Scrapy shell for the given URL or empty if no URL is given. Also support UNIX-style local file path, both relative path or absolute path. $ scrapy shell [url] --spider=SPIDER -c code : evaluate the code in the shell print the result and exit. -no-redirect : Examples: $ scrapy shell http://www.example.com/some/page.html [ ... scrapy shell starts ... ] $ scrapy shell --nolog http://www.example.com/ -c &apos;(response.status, response.url)&apos; (200, &apos;http://www.example.com/&apos;) # shell follows HTTP redirects by default $ scrapy shell --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c &apos;(response.status, response.url)&apos; (200, &apos;http://example.com/&apos;) # you can disable this with --no-redirect # (only for the URL passed as command line argument) $ scrapy shell --no-redirect --nolog http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F -c &apos;(response.status, response.url)&apos; (302, &apos;http://httpbin.org/redirect-to?url=http%3A%2F%2Fexample.com%2F&apos;) fetch Downloads the given URL using the Scrapy downloader and write the contents to the output. $ scrapy fetch &lt;url&gt; --spider=SPIDER : bypass spider autodetection and force use of specific spider --headers : print response HTTP headers --no-redirect : no follow HTTP 3xx redirects view Open the given URL in a brower, as your Scrapy spider would ‘see’ it. $ scrapy view &lt;url&gt; --spider=SPIDER : --no-redirect : version prints the Scrapy version. $ scrapy version [-v] -v : also prints Python, Twisted and Platform info. 3.2 Project-only Commands: work from inside a Scrapy project crawl Start crawling using a spider $ scrapy crawl &lt;spider_name&gt; check check spider contracts $ scrapy check [-l] &lt;spider_name&gt; list list all available spiders in the current project. $ scrapy list edit Edit the given spider using the system default editor. $ scrapy edit &lt;spider_name&gt; parse Fetchs the given URL and parses it with the spider that handler it , using the method pased with the --callcheck option, or parse if not given. $ scrapy parse &lt;url&gt; [options] --spider=SPIDER --a NAME=VALUE : set spider argument (may be repeated) --callback, -c : spider method to use as callback fot parsing the response. --pipeline: process items through pipelines --rules, -r : use &apos;CrawlSpider&apos; rules to discover the callback to use for parsing the response. --noitems : don&apos;t show scraped items --nolinks : don&apos;t show extracted links --nocolour : avoid using pygments to colorize the output. --depth, -d : depth level for which the requests should be followed recursively, default 1. --verbose, -v : display informatioin fot each depth level. bench run a quick benchmark test. $ scrapy bench]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy]]></title>
    <url>%2F2018%2F03%2F15%2FScrapy%2F</url>
    <content type="text"><![CDATA[一. Scrapy 架构组件 P13 组件 描述 类型 ENGINE 引擎, SCHEDULER 调度器, DOWNLOADER 下载器, SPIDER 爬虫, MIDDLEWARE 中间件, ITEM PIPELINE 数据管道, 框架中的数据流 P14 对象 描述 REQUEST Scrapy 中的 HTTP 请求对象 RESPONSE Scrapy 中的 HTTP 响应对象 ITEM 从页面中爬去的一项数据 Request(url[, callback, method=&#39;GET&#39;, headers, body, cookies, meta, encoding=&#39;utf-8&#39;, priority=0, dont_filter=False, errback]) Response 对象 HtmlResponse TextResponse XmlResponse 二. Spiderstart_urls.parse / start_requests.callback --&gt; REQUEST --&gt; DOWNLOADER --&gt; RESPONSE --&gt; Selector/SelectorList[xpath/css][extract/re/extract_first/re_first] 三. Selector 提取数据 构造 Selector html = &quot; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Hello world!&lt;/h1&gt; &lt;p&gt;This is a line.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt;&quot; # 使用文本字符串构造 from scrapy.selector import Selector selector = Selector(text=html) # 使用 Response 对象构造 from scrapy.http import HtmlResponse response = HtmlResponse(url=&quot;http://www.example.com&quot;, body=body, encoding=&apos;utf-8&apos;) selector = Selector(response=response) RESPONSE 内置 selector : 在第一次访问一个 Response 对象的 selector 属性时, Response 对象内部会以自身为参数, 自动创建 Selector 对象, 并将该 Selector 对象缓存, 以便下次使用. class TextResponse(Response): def __init__(self, *args, **kwargs): ... self._cached_selector = None ... @property def selector(self): from scrapy.selector import Selector if self._cached_selector is None: self._cached_selector = Selector(self) return self._cached_selector ... def xpath(self, query, **kwargs): return self.selector.xpath(query, **kwargs) def css(self, query): return self.selector.css(query) 选中数据 XPATH/CSS 提取数据 extract()/re()/extract_first()/re_first() 四. Item 封装数据Scrapy 提供一下两个类, 用户可以使用它们自定义数据类(如书籍信息), 封装爬取到的数据. Item 基类 : 自定义数据类的基类, 支持字典接口(访问 自定义数据类 中的字段与访问字典类似, 支持 get() 方法). Field 类 : 用来描述自定义数据类包含哪些字段(如name, price 等). 1. 自定义数据类, 只需继承 Item, 并创建一系列 Field 对象的类属性即可, 类似于 ORM 创建的 Model.from scrapy import Item, Field class BookItem(Item): name = Field() price = Field() class ForeignBookItem(BookItem): &quot;&quot;&quot; 扩展 BookItem 类 &quot;&quot;&quot; translator = Field() 2. Field 元数据class BookItem(Item): name = Field(a=123, b=[1,2,3]) price = Field(a=lambda x: x+2) # Field 是 Python 字典的子类, 可以通过键获取 Field 对象中的元数据. b = BookItem(name=100, price=101) b[&apos;name&apos;] # 100 b[&apos;price&apos;] # 101 b.fields # {&apos;name&apos;: {&apos;a&apos;: 123, &apos;b&apos;: [1, 2, 3]}, &apos;price&apos;: {&apos;a&apos;: &lt;function __main__.&lt;lambda&gt;&gt;}} 代码示例class BookItem(Item): ... # 当 authors 是一个列表而不是一个字符串时, 串行化为一个字符串. authors = Field(serializer=lambda x: &quot;|&quot;.join(x)) ... 以上例子中, 元数据键 serializer 时 CSVItemExportr 规定好的, 他会用该键获取元数据, 即一个串行化函数对象, 并使用这个串行化函数将 authors 字符串行化成一个字符串, 具体代码参考 scrapy/exporters.py 文件. 五. Item Pipeline 处理数据在 Scrapy 中, Item Pipeline 是处理数据的组件, 一个 Item Pipeline 就是一个包含特定接口的类, 通常只负责一种功能的数据处理, 在一个项目中可以同时启动多个 Item Pipeline, 他们按指定次序级联起来, 形成一条数据处理流水线. Item Pipeline 典型应用 数据请求 验证数据有效性 过滤重复数据 将数据存入数据库. 1. 编写 pipelineclass PriceConverterPipeline(object): # 英镑兑换人民币汇率 exchange_rate = 8.5309 def process_item(self, item, spider): # 提取 item 的 price 字段(如 £ 53.74), 去掉 £ 符号, 转换为 float 类型, 乘以汇率 price = float(item[&quot;price&quot;][1:]) * self.exchange_rate # 保留两位小数赋值, item[&quot;price&quot;] = &quot;¥ %.2f&quot; % price return item 一个 Item Pipeline 不需要继承特定基类, 只需要实现某些特定的方法. process_item(self, item, spider) : 该方法必须实现. 该方法用来处理每一项由 Spider 爬取到的数据, 其中 item 为爬取到的一项数据, Spider 为爬取此项数据的 Spider 对象. process_item 是 Item Pipeline 的核心, process_item 返回的一项数据, 会传递给下一级 Item Pipeline(如果有) 继续处理. 如果 process_item 在处理某项 item 时抛出 DropItem(scrapy.exceptions.DropItem) 异常, 该项 item 便会被抛弃, 不会传递到下一级 Item Pipeline, 也不会导出到文件. 通常, 在检测到无效数据, 或者希望过滤的数据时, 抛出该异常. open_spider(self, spider) Spider 打开时(处理数据前), 回调该方法, 通常该方法用于在 开始处理数据之前完成某些初始化的工作, 如连接数据库. close_spider(self, spider) Spider 关闭时(处理数据后), 回调该方法, 通常该方法用于在 处理完所有数据之后完成某些清理工作, 如关闭数据库链接. from_crawler(cls, crawler) 创建 Item Pipeline 对象时回调该类方法. 通常, 在该方法中通过 crawler.settings 读取配置, 根据配置创建 Item Pipeline 对象. 如果一个 Item Pipeline 定义了 from_crawler 方法, Scrapy 就会调用该方法来创建 Item Pipeline 对象. 该方法的两个参数: cls : Item Pipeline 类的对象, crawler : crawler 是 Scrapy 中的一个核心对象, 可以通过 crawler.settings 属性访问配置文件. 2. 启用 Item Pipeline.$ cat settings.py ITEM_PIPELINES = { &apos;example.pipelines.PriceConverterPipeline&apos;: 300, } ITEM_PIPELINES 是一个字典, 其中每一项 Item Pipeline 类的导入路径, 值是一个 0~1000 的数字, 同时启用多个 Item Pipeline 时, Scrapy 根据这些数值决定各 Item Pipeline 处理数据的先后次序, 数值小的优先级高. 3. 代码示例3.1 Item Pipeline : 过滤重复数据class DuplicatesPipeline(object): def __init__(self): self.book_set = set() def process_item(self, item, spider): name = item[&quot;name&quot;] if name in self.book_set: raise DropItem(&quot;Duplicate book found: %s&quot; % item) self.book_set.add(name) return item 3.2 Item Pipeline : 将数据存储 MongoDB# pipelines.py class MongoDBPipeline(object): @classmethod def from_crawler(cls, crawler): &quot;&quot;&quot; 使用 settings.py 配置文件, 配置 MongoDB 数据库, 而不是硬编码 如果一个 Item Pipeline 定义了 from_crawler 方法, Scrapy 就会调用该方法来创建 Item Pipeline 对象. &quot;&quot;&quot; cls.DB_URI = crawler.settings.get(&quot;MONGO_DB_URI&quot;, &quot;mongodb://localhost:27017/&quot;) cls.DB_NAME = crawler.settings.get(&quot;MONGO_DB_NBAME&quot;, &quot;scrapy_data&quot;) return cls() def open_spider(self, spider): &quot;&quot;&quot;在开始处理数据之前, 链接数据库&quot;&quot;&quot; self.client = pymongo.MongoClient(self.DB_URI) self.db = self.client[self.DB_NAME] def close_spider(self, spider): &quot;&quot;&quot;数据处理完成之后, 关闭数据库链接&quot;&quot;&quot; self.client.close() def process_item(self, item, spider): &quot;&quot;&quot;将 item 数据 写入 MongoDB&quot;&quot;&quot; collection = self.db[spider.name] post = dict(item) if isinstance(item, Item) else item collection.insert_one(post) return item # settings.py MONGO_DB_URI = &quot;mongodb://192.168.1.1:27017/&quot; MONGO_DB_NBAME = &quot;my_scrapy_data&quot; ITEM_PIPELINES = { &quot;toscrapt_book.pipelines.MongoDBPipeline&quot;: 403, } 3.3 Item Pipeline : 将数据存储 Mysql版本一 : # pipelines.py class MySQLPipeline(object): def open_spider(self, spider): db = spider.settings.get(&quot;MYSQL_DB_NAME&quot;, &quot;scrapy_data&quot;) host = spider.settings.get(&quot;MYSQL_HOST&quot;, &quot;locahost&quot;) port = spider.settings.get(&quot;MYSQL_PORT&quot;, &quot;3306&quot;) user = spider.settings.get(&quot;MYSQL_USER&quot;, &quot;root&quot;) password = spider.settings.get(&quot;MYSQL_PASSWORD&quot;, &quot;123456&quot;) self.db_conn = MySQLdb.connect(host=host, port=port, db=db, user=user, passwd=password, charset=&quot;utf-8&quot;) self.db_cur = self.db_conn.cursor() def closer_spider(self, spider): self.db_conn.commit() self.db_conn.close() def procecss_item(self, item, spider): self.insert_db(item) return item def insert_db(self, item): values = ( item[&quot;name&quot;], item[&quot;price&quot;], item[&quot;rating&quot;], item[&quot;number&quot;] ) sql = &quot;INSERT INTO books VALUES (%s, %s, %s, %s, )&quot; self.db_cur.execute(sql, values) # settings.py MYSQL_DB_NAME = &quot;scrapy_data&quot; MYSQL_HOST = &quot;locahost&quot; MYSQL_PORT = &quot;3306&quot; MYSQL_USER = &quot;root&quot; MYSQL_PASSWORD = &quot;123456&quot; ITEM_PIPELINES = { &quot;toscrapt_book.pipelines.MySQLPipeline&quot;: 403, } 版本二: Scrapy 框架本身使用 Twisted 编写, Twisted 是一个事件驱动型的异步网络框架, 鼓励用户编写异步代码, Twisted 中提供了以异步方式多线程访问数据库的模块 adbapi, 使用该模块可以显著提高程序访问数据库的效率. # pipelines.py from twisted.enterprise import adbapi class MySQLAsyncPipeline(object): def open_spider(self, spider): db = spider.settings.get(&quot;MYSQL_DB_NAME&quot;, &quot;scrapy_data&quot;) host = spider.settings.get(&quot;MYSQL_HOST&quot;, &quot;locahost&quot;) port = spider.settings.get(&quot;MYSQL_PORT&quot;, &quot;3306&quot;) user = spider.settings.get(&quot;MYSQL_USER&quot;, &quot;root&quot;) password = spider.settings.get(&quot;MYSQL_PASSWORD&quot;, &quot;123456&quot;) # adbapi.ConnectionPool 可以创建一个数据库连接池对象, 其中包含多个链接对象, 每个链接对象在单独的线程中工作. # adbapi 只提供异步访问数据库的框架, 其内部依然使用 MySQLdb, sqlite3 这样的库访问数据库. self.dbpool = adbapi.ConnectionPool(&quot;MySQLdb&quot;, host=host, database=db, user=user, password=password, charset=&quot;utf-8&quot;) def close_spider(self, spider): self.dbpool.close() def process_item(self, item, spider): # 以异步方式调用 insert_db 方法, 执行完 insert_db 方法之后, 链接对象自动调用 commit 方法. self.dbpool.runInteraction(self.insert_db, item) return item def insert_db(self, tx, item): # tx 是一个 Transaction 对象, 其接口与 Cursor 对象类似, 可以调用 execute 执行 SQL 语句. values = ( item[&quot;name&quot;], item[&quot;price&quot;], item[&quot;rating&quot;], item[&quot;number&quot;] ) sql = &quot;INSERT INTO books VALUES (%s, %s, %s, %s, )&quot; tx.execute(sql, values) # settings.py MYSQL_DB_NAME = &quot;scrapy_data&quot; MYSQL_HOST = &quot;locahost&quot; MYSQL_PORT = &quot;3306&quot; MYSQL_USER = &quot;root&quot; MYSQL_PASSWORD = &quot;123456&quot; ITEM_PIPELINES = { &quot;toscrapt_book.pipelines.MySQLAsyncPipeline&quot;: 403, } 3.4 Item Pipeline : 将数据存储 Redis# pipelines.py import redis from scrapy import Item class RedisPipeline(object): def open_spider(self, spider): db_host = spider.settings.get(&quot;REDIS_HOST&quot;, &quot;localhost&quot;) db_port = spider.settings.get(&quot;REDIS_PORT&quot;, &quot;6379&quot;) db_index = spider.settings.get(&quot;REDIS_DB_INDEX&quot;, 0) self.db_conn = redis.StrictRedis(host=db_host, port=db_port, db=db_index) self.item_i = 0 def close_spider(self, spider): self.db_conn.connection_pool.disconnect() def process_item(self, item, spider): self.insert_db(item) return item def insert_db(self, item): if isinstance(item, Item): item = dict(item) self.item_i += 1 self.db_conn.hmset(&quot;book:%s&quot; % self.item_i, item) # settings.py &quot;REDIS_HOST&quot; = &quot;localhost&quot; &quot;REDIS_PORT&quot; = 6379 &quot;REDIS_DB_INDEX&quot; = 0 ITEM_PIPELINES = { &quot;toscrapt_book.pipelines.RedisPipeline&quot;: 403, } 六. LinkExtractor 提取链接提取页面中的链接, 有两种方法: selector : 提取少量链接时, 或提取规则比较简单. LinkExtractor : 专门用于提取链接的类 LinkExtractor. 1. 使用示例:# url from selector # next_url = response.css(&quot;ul.pager li.next a::attr(href)&quot;).extract_first() # if next_url: # next_url = response.urljoin(next_url) # yield scrapy.Request(next_url, callback=self.parse) # url from LinkeExtractor le = LinkExtractor(restrict_css=&quot;ul.pager li.next&quot;) links = le.extract_links(response) # 返回一个列表, 其中每一个元素都是一个 Link 对象, Link 对象的 url 属性便是链接页面的 绝对 url 地址. if links: next_url = links[0].url yield scrapy.Request(next_url, callback=self.parse) 2. 链接提取规则:LinkExtractor 构造器的所有参数都有默认值, 如果构造对象时, 不传递任何参数(使用默认值), 则提取页面中的所有链接. allow : 接受一个正则表达式或一个正则表达式列表, 提取绝对 url 与 正则表达式匹配的链接, 如果该参数为空(默认), 则提取全部链接. &gt;&gt;&gt; pattern = &apos;/intro/.+\.html$&apos; &gt;&gt;&gt; le = LinkExtractor(allow=pattern) &gt;&gt;&gt; links = le.extract_links(response) deny : 接受一个正则表达式或一个正则表达式列表, 与 allow 相反, 排除绝对 url 与正则表示匹配的链接. &gt;&gt;&gt; pattern = &apos;^http://example.com&apos; &gt;&gt;&gt; le = LinkExtractor(deny=pattern) &gt;&gt;&gt; links = le.extract_links(response) allow_domains : 接受一个域名或一个域名列表, 提取到指定域的链接. &gt;&gt;&gt; domains = [&quot;github.com&quot;, &quot;stackoverflow.com&quot;] &gt;&gt;&gt; le = LinkExtractor(allow_domains=domains) &gt;&gt;&gt; links = le.extract_links(response) deny_domains : 接受一个域名或一个域名列表, 与 allow_domains 相反, 排除到指定域的链接. &gt;&gt;&gt; domains = [&quot;github.com&quot;, &quot;stackoverflow.com&quot;] &gt;&gt;&gt; le = LinkExtractor(deny_domains=domains) &gt;&gt;&gt; links = le.extract_links(response) restrict_xpaths : 接受一个 Xpath 表达式或一个 Xpath 表达式列表, 提取 XPath 表达式选中区域下的的链接. &gt;&gt;&gt; le = LinkExtractor(restrict_xpaths=&quot;//div[@id=&apos;top&apos;]&quot;) &gt;&gt;&gt; links = le.extract_links(response) restrict_css : 接受一个 CSS 选择器或一个 CSS 选择器列表, 提取 CSS 选择器选中区域下的的链接. &gt;&gt;&gt; le = LinkExtractor(restrict_css=&quot;div#bottom&quot;) &gt;&gt;&gt; links = le.extract_links(response) tags : 接受一个标签(字符串)或一个标签列表, 提取指定标签内的链接, 默认为 [&quot;a&quot;, &quot;area&quot;] attrs : 接受一个属性(字符串)或一个属性列表, 提取指定属性内的链接, 默认为 [&quot;href&quot;] # &lt;script type=&quot;text/javascript&quot; src=&quot;/js/app.js&quot; /&gt; &gt;&gt;&gt; le = LinkExtractor(tags=&quot;script&quot;, attrs=&quot;src&quot;) &gt;&gt;&gt; links = le.extract_links(response) process_value : 接受一个形如 func(value) 的回调函数. 如果传递了该参数, LinkExtractor 将调用该回调函数对提取的每一个链接(如 a 的 href) 进行处理, 回调函数正常情况下应该返回一个字符串(处理结果), 想要抛弃所处理的连接时, 返回 None. # &lt;a href=&quot;javascript:goToPage(&apos;/doc.html&apos;); return false&quot;&gt;文档&lt;/a&gt; &gt;&gt;&gt; import re &gt;&gt;&gt; def process(value): m = re.search(&quot;javascript:goToPage\(&apos;(.*?)&apos;&quot;, value) # 如果匹配, 就提取其中 url 并返回, 不匹配则返回原值. if m: value = m.group() return value &gt;&gt;&gt; le = LinkExtractor(process_value=process) &gt;&gt;&gt; links = le.extract_links(response) 七. Exporter 导出数据在 Scrapy 中, 负责导出数据的组件被称为 Exporter(导出器), Scrapy 内部实现了多个 Exporter , 每个 Exporter 实现一种数据格式的导出. 支持的数据导出格式如下(括号内为对应的 Exporter): JSON (JsonItemExporter) JSON lines (JsonLinesItemExporter) CSV (CsvItemExporter) XML (XmlItemExporter) Pickle (PickleItemExporter) Marshal (MarshalItemExporter) Scrapy 爬虫会议 -t 参数中的数据格式字符串(如 csv, json, xml) 为键, 在配置字典 FEED_EXPORTERS 中搜索 Exporter, FEED_EXPORTERS 的内容由以下两个字典的内容合并而成: 默认配置文件中的 FEED_EXPORTERS_BASE, 为 Scrapy 内部支持的导出数据格式, 位于 scrapy.settings.default_settings 用户配置文件中的 FEED_EXPORTERS, 为用户自定义的导出数据格式, 在配置文件 settings.py 中. FEED_EXPORTERS = {&quot;excel&quot;: &quot;my_propject.my_exporters.ExcelItemExporter&quot;} 1. 导出数据方式: 命令行参数 $ scrapy crawl CRAWLER -t FORMAT -o /path/to/save.file $ scrapy crawl books -t csv -o books.data $ scrapy crawl books -t xml -o books.data $ scrapy crawl books -t json -o books.data $ scrapy craw books -o books.csv # Scrapy 可以通过文件后缀名, 推断出文件格式, 从而省去 -t 参数. 如 `-o books.json` -o /path/to/file 支持变量: 如 scrapy crawl books -o &#39;export_data/%(name)s/%(time)s.csv&#39; %(name)s : Spider 的名字 %(time)s : 文件创建时间 通过配置文件指定. 常用选项如下: FEED_URL : 导出文件路径 FEED_URL = &apos;export_data/%(name)s/%(csv)s.data&apos; FEED_FORMAT : 导出数据格式 FEED_FORMAT = &apos;csv&apos; FEED_EXPORT_ENCODING : 导出文件编码, 默认 json 使用数字编码, 其他使用 utf-8 编码 FEED_EXPORT_ENCODING = &quot;gbk&quot; FEED_EXPORT_FIELDS : 导出数据包含的字段(默认情况下, 导出所有字段), 并指定导出顺序. FEED_EXPORT_FIELDS = [&quot;name&quot;, &quot;author&quot;, &quot;price&quot;] FEED_EXPORTERS : 用户自定义的 Exporter 字典, 添加新的导出数据格式时使用. FEED_EXPORTERS = {&quot;excel&quot;: &quot;my_project.my_exporters.ExcelItemExporter&quot;} 2. 自定义数据导出格式import six from scrapy.utils.serialize import ScrapyJSONEncoder import xlwt class BaseItemExporter(object): def __init__(self, **kwargs): self._configure(kwargs) def _configure(self, options, dont_fail=False): self.encoding = options.pop(&quot;encoding&quot;, None) self.fields_to_export = options.pop(&quot;field_to_export&quot;, None) self.export_empty_fields = options.pop(&quot;export_empty_fields&quot;, False) if not dont_fail and options: raise TypeError(&quot;Unexpected options: %s&quot; % &apos;,&apos;.join(options.keys())) def export_item(self, item): &quot;&quot;&quot; 负责导出爬去到的每一项数据, 参数 item 为一项爬取到的数据, 每个子类必须实现该方法. :param item: :return: &quot;&quot;&quot; raise NotImplementedError def serialize_field(self, field, name, value): serializer = field.get(&quot;serializer&quot;, lambda x: x) return serializer(value) def start_exporting(self): &quot;&quot;&quot; 在导出开始时被调用, 可在该方法中执行某些初始化操作. :return: &quot;&quot;&quot; pass def finish_exporting(self): &quot;&quot;&quot; 在导出完成时被调用, 可在该方法中执行某些清理工作. :return: &quot;&quot;&quot; pass def _get_serialized_field(self, item, default_value=None, include_empty=None): &quot;&quot;&quot; Return the fields to export as an iterable of tuples (name, serialized_value) :param item: :param default_value: :param include_empty: :return: &quot;&quot;&quot; if include_empty is None: include_empty = self.export_empty_fields if self.fields_to_export is None: if include_empty and not isinstance(item, dict): field_iter = six.iterkeys(item.fields) else: field_iter = six.iterkeys(item) else: if include_empty: field_iter = self.fields_to_export else: field_iter = (x for x in self.fields_to_export if x in item) for field_name in field_iter: if field_name in item: field = {} if isinstance(item, dict) else item.fields[field_name] value = self.serialize_field(field, field_name, item[field_name]) else: value = default_value yield field_name, value # json class JsonItemExporter(BaseItemExporter): def __init__(self, file, **kwargs): self._configure(kwargs, dont_fail=True) self.file = file kwargs.setdefault(&quot;ensure_ascii&quot;, not self.encoding) self.encoder = ScrapyJSONEncoder(**kwargs) self.first_item = True def start_exporting(self): &quot;&quot;&quot; 保证最终导出结果是一个 json 列表. :return: &quot;&quot;&quot; self.file.write(b&quot;[\n&quot;) def finish_exporting(self): &quot;&quot;&quot; 保证最终导出结果是一个 json 列表. :return: &quot;&quot;&quot; self.file.write(b&quot;\n]&quot;) def export_item(self, item): &quot;&quot;&quot; 调用 self.encoder.encode 将每一项数据转换成 json 串. :param item: :return: &quot;&quot;&quot; if self.first_item: self.first_item = False else: self.file.write(b&quot;,\n&quot;) itemdict = dict(self._get_serialized_field(item)) data = self.encoder.encode(itemdict) self.file.write(to_bytes(data, self.encoding)) # 自定义 excel 导出格式. class ExcelItemExporter(BaseItemExporter): def __init__(self, file, **kwargs): self._configure(kwargs) self.file = file self.wbook = xlwt.Workbook() self.wsheet = self.wbook.add_sheet(&quot;scrapy&quot;) self.row = 0 def finish_exporting(self): self.wbook.save(self.file) def export_item(self, item): fields = self._get_serialized_field(item) # 获取所有字段的迭代器. for col, v in enumerate(x for _, x in fields): self.wsheet.write(self.row, col, v) self.row += 1 $ vim settings.py # my_exporters.py 与 settings.py 位于同级目录下. FEED_EXPORTERS = {&quot;excel&quot;: &quot;example.my_exporters.ExcelItemExporter&quot;} 八. 下载文件(FilesPipeline)和图片(ImagesPipeline)FilesPipeline 和 ImagesPipeline 可以看做两个特殊的下载器, 用户使用时, 只需要铜鼓 item 的一个特殊字段将要下载文件或图片的 URL 传递给他们, 他们会自动将文件或图片下载到本地, 并将下载结果信息存入 item 的另一个特殊字段, 以便用户在导出文件中查阅. 1. FilesPipeline 使用方法 在 settings.py 中启用 FilesPipeline, 通常将其置于其他 Item Pipelines 之前 ITEM_PIPELINES = {&quot;scrapy.pipelines.files.FilesPipeline&quot;: 1} 在 settings.py 中使用 FILES_STORE 指定文件下载目录. FILES_STORE = &quot;/path/to/my/download&quot; 下载文件 在 Spider 解析一个包含文件下载链接的也面试, 将所有需要下载文件的 url 地址收集到一个列表, 赋给 item 的 file_urls 字段(item[&quot;file_urls&quot;]). FilesPipeline 在处理每一项 item 时, 会读取 item[&#39;file_urls&#39;], 对其中每一个 url 进行下载. class DownloadBookSpider(scrapy.Spider): ... def parse(response): item = {} item[&quot;file_urls&quot;] = [] for url in response.xpath(&quot;//a/@href&quot;).extract(): download_url = response.urljoin(url) item[&quot;file_urls&quot;].append(download_url) yield item 当 FilesPipeline 下载完 item[&quot;file_urls&quot;] 中的所有文件后, 会将各文件的下载结果信息收集到另一个列表, 赋给 item[&quot;files&quot;] 字段, 下载信息结果包含以下内容: Path : 文件下载到本地的路径, 相对于 FILES_STORE 的相对路径. Checksum : 文件的校验和 url : 文件的 url 地址. 示例代码# items.py import scrapy class MatplotlibFileItem(scrapy.Item): file_urls = scrapy.Field() files = scrapy.Field() # spiders/matplotlib.py import scrapy from scrapy.linkextractors import LinkExtractor from ..items import MatplotlibFileItem class MatplotlibSpider(scrapy.Spider): name = &apos;matplotlib&apos; allowed_domains = [&apos;matplotlib.org&apos;] start_urls = [&apos;https://matplotlib.org/examples/index.html&apos;] def parse(self, response): # 爬取所有 二级 页面地址 le = LinkExtractor(restrict_css=&quot;div.toctree-wrapper.compound&quot;, deny=&quot;/index.html$&quot;) links = le.extract_links(response) for link in links: yield scrapy.Request(link.url, callback=self.parse_page) def parse_page(self, response): href = response.css(&quot;a.reference.external::attr(href)&quot;).extract_first() url = response.urljoin(href) example = MatplotlibFileItem() example[&quot;file_urls&quot;] = [url] yield example # pipelines.py : 重写 FilesPipeline 的 file_path 代码, 以自定义保存路径. from scrapy.pipelines.files import FilesPipeline from urlparse import urlparse from os.path import basename, dirname, join class MyFilesPipeline(FilesPipeline): def file_path(self, request, response=None, info=None): path = urlparse(request.url).path return join(basename(dirname(path)), basename(path)) # settings.py ITEM_PIPELINES = { # &quot;scrapy.pipelines.files.FilesPipeline&quot;: 1, &apos;matplotlib_file.pipelines.MyFilesPipeline&apos;: 1, } FILES_STORE = &quot;example_src&quot; # 文件下载路径 # 运行: $ scrapy crawl matplotlib -o examp.json 2. ImagesPipeline图片本身也是文件, ImagesPipeline 是 FilesPipeline 的子类, 使用上和 FilesPipeline 大同小异, 只是在所使用的 item 字段和配置选项上略有差别. Desc FilesPipeline ImagesPipeline 导入路径 scrapy.pipelines.files.FilesPipeline scrapy.pipelines.images.ImagesPipeline Item 字段 file_urls, files image_urls, images 下载目录 FILES_STORE IMAGES_STORE 2.1 生成缩略图在 settings.py 中设置 IMAGES_THUMBS, 他是一个字典, 每一项的值是缩略图的尺寸. IMAGES_THUMBS = { &quot;small&quot;: (50, 50), &quot;big&quot;: (270, 270) } 开启该功能后, 下载一张图片时, 会在本地出现 3 张图片, 其存储路径如下: [IMAGES_STORE]/full/name.jpg [IMAGES_STORE]/thumbs/small/name.jpg [IMAGES_STORE]/thumbs/big/name.jpg 2.2 过滤尺寸过小的图片在 settings.py 中设置 IMAGES_MIN_WIDTH 和 IMAGES_MIN_HEIGHT IMAGES_MIN_WIDTH = 110 IMAGES_MIN_HEIGHT = 110 示例代码# settings.py ITEM_PIPELINES = { &quot;scrapy.pipelines.images.ImagesPipeline&quot;: 1, # &apos;so_img.pipelines.SoImgPipeline&apos;: 300, } IMAGES_STORE = &apos;download_images&apos; # spider import json import scrapy class ImagesSpider(scrapy.Spider): IMG_TYPE = &quot;wallpaper&quot; IMG_START = 0 BASE_URL = &quot;http://image.so.com/zj?ch=%s&amp;sn=%s&amp;listtype=new&amp;temp=1&quot; name = &apos;wallpaper&apos; # allowed_domains = [&apos;image.so.com&apos;] start_urls = [BASE_URL % (IMG_TYPE, IMG_START)] MAX_DOWNLOAD_NUM = 100 start_index = 0 def parse(self, response): infos = json.loads(response.body.decode(&quot;utf-8&quot;)) yield {&quot;image_urls&quot;: [info[&quot;qhimg_url&quot;] for info in infos[&quot;list&quot;]]} # 如果 count 字段大于 0, 并且下载数量不足 MAX_DOWNLOAD_NUM, 继续获取下一页信息. self.start_index += infos[&quot;count&quot;] if infos[&quot;count&quot;] &gt; 0 and self.start_index &lt; self.MAX_DOWNLOAD_NUM: yield scrapy.Request(self.BASE_URL % (self.IMG_TYPE, self.start_index)) # 爬取图片 $ scrapy crawl wallpaper 九. 模拟登陆Scrapy 提供一个 FormRequest 类(Request 的子类), 专门用于构造含有表单数据的请求, FormRequest 的构造器方法有一个 formdata 参数, 接受字典形式的表单数据. 直接构造 FormRequest $ scrapy shell http://example.webscraping.com/places/default/user/login &gt;&gt;&gt; sel = response.xpath(&apos;//div[@style]/input&apos;) &gt;&gt;&gt; sel [&lt;Selector xpath=&apos;//div[@style]/input&apos; data=u&apos;&lt;input name=&quot;_next&quot; type=&quot;hidden&quot; value=&apos;&gt;, &lt;Selector xpath=&apos;//div[@style]/input&apos; data=u&apos;&lt;input name=&quot;_formkey&quot; type=&quot;hidden&quot; val&apos;&gt;, &lt;Selector xpath=&apos;//div[@style]/input&apos; data=u&apos;&lt;input name=&quot;_formname&quot; type=&quot;hidden&quot; va&apos;&gt;] &gt;&gt;&gt; fd = dict(zip(sel.xpath(&apos;./@name&apos;).extract(), sel.xpath(&apos;./@value&apos;).extract())) &gt;&gt;&gt; fd {u&apos;_formkey&apos;: u&apos;9c751a58-3dc2-489f-bf7b-93c31fa00c7f&apos;, u&apos;_formname&apos;: u&apos;login&apos;, u&apos;_next&apos;: u&apos;/places/default/index&apos;} &gt;&gt;&gt; fd[&apos;email&apos;] = &quot;liushuo@webscraping.com&quot; &gt;&gt;&gt; fd[&apos;password&apos;] = &quot;12345678&quot; &gt;&gt;&gt; fd {u&apos;_formkey&apos;: u&apos;9c751a58-3dc2-489f-bf7b-93c31fa00c7f&apos;, u&apos;_formname&apos;: u&apos;login&apos;, u&apos;_next&apos;: u&apos;/places/default/index&apos;, &apos;email&apos;: &apos;liushuo@webscraping.com&apos;, &apos;password&apos;: &apos;12345678&apos;} &gt;&gt;&gt; from scrapy.http import FormRequest &gt;&gt;&gt; request = FormRequest(&quot;http://example.webscraping.com/places/default/user/login&quot;, formdata=fd) &gt;&gt;&gt; fetch(request) &gt;&gt;&gt; response.url &apos;http://example.webscraping.com/places/default/index&apos; &gt;&gt;&gt; &quot;Welcome&quot; in response.text True 调用 FormRequest 的 from_response 方法 调用时, 只需传入一个 Response 对象作为第一个参数, 该方法会解析 Response 对象所包含的页面中的 元素, 帮助用户创建 FormRequest 对象, 并将隐藏 中的信息自动填入表单数据. $ scrapy shell http://example.webscraping.com/places/default/user/login &gt;&gt;&gt; fd = {&quot;email&quot;: &quot;liushuo@webscraping.com&quot;, &quot;password&quot;: &quot;12345678&quot;} &gt;&gt;&gt; from scrapy.http import FormRequest &gt;&gt;&gt; req = FormRequest.from_response(response, fd) &gt;&gt;&gt; fetch(req) &gt;&gt;&gt; response.url &apos;http://example.webscraping.com/places/default/index&apos; 1. 实现登录 Spiderclass LoginSpider(scrapy.Spider): name = &quot;login&quot; allowed_domains = [&quot;example.webscraping.com&quot;] start_urls = [&quot;http://example.webscraping.com/places/default/user/profile&quot;] login_url = &quot;http://example.webscraping.com/places/default/user/login&quot; def parse(self, response): keys = response.css(&quot;table label::text&quot;).re(&quot;(.+):&quot;) values = response.css(&quot;table td.w2p_fw::text&quot;).extract() yield dict(zip(keys, values)) def start_requests(self): yield scrapy.Request(self.login_url, callback=self.login) def login(self, response): fd = {&quot;email&quot;: &quot;liushuo@webscraping.com&quot;, &quot;password&quot;: &quot;12345678&quot;} yield scrapy.http.FormRequest.from_response(response, formdata=fd, callback=self.parse_login) def parse_login(self, response): # 如果 if 判断成功, 调用基类的 start_request() 方法, 继续爬取 start_urls 中的页面. if &quot;Welcome&quot; in response.text: yield from super().start_requests() # Python 3 语法 2. 识别验证码 OCR 识别: tesseract-ocr pytesseract 可以识别的验证码比较简单, 对于某些复杂的验证码, pytesseract 识别率很低, 或无法识别. 基本安装与使用 # 安装 $ yum install tesseract -y $ pip install pillow $ pip install pytesseract # 使用 &gt;&gt;&gt; from PIL import Image &gt;&gt;&gt; import pytesseract &gt;&gt;&gt; img = Image.open(&quot;code.png&quot;) &gt;&gt;&gt; img = img.convert(&quot;L&quot;) # 为提高图像识别率, 把图片转换成黑白图. &gt;&gt;&gt; pytesseract.image_to_string(img) 代码示例: import json from PIL import Image from io import BytesIO import pytesseract class CaptchaLoginSpider(scrapy.Spider): name = &quot;login_captcha&quot; start_urls = [&quot;http://xxx.com&quot;] login_url = &quot;http://xxx.com/login&quot; user = &quot;tom@example.com&quot; password = &quot;123456&quot; def parse(self, response): pass def start_requests(self): yield scrapy.Request(self.login_url, callback=self.login, dont_filter=True) def login(self, response): &quot;&quot;&quot; 该方法即是登录页面的解析方法, 又是下载验证码图片的响应处理函数. :param response: :return: &quot;&quot;&quot; # 如果 response.meta[&quot;login_response&quot;] 存在, 当前 response 为验证码图片的响应, # 否则, 当前 response 为登录页面的响应. login_response = response.meta.get(&quot;login_response&quot;) if not login_response: # 此时 response 为 登录页面的响应, 从中提取验证码图片的 url, 下载验证码图片 captchaUrl = response.css(&quot;label.field.prepend-icon img::attr(src)&quot;).extract_first() captchaUrl = response.urljoin(captchaUrl) yield scrapy.Request(captchaUrl, callback=self.login, meta={&quot;login_response&quot;: response}, dont_filter=True) else: # 此时, response 为验证码图片的响应, response.body 为图片二进制数据, # login_response 为登录页面的响应, 用其构造表单请求并发送. formdata = { &quot;email&quot;: self.user, &quot;password&quot;: self.password, &quot;code&quot;: self.get_captcha_by_ocr(response.body) } yield scrapy.http.FormRequest.from_response(login_response, callback=self.parse_login, formdata=formdata, dont_click=True) def parse_login(self, response): info = json.loads(response.text) if info[&quot;error&quot;] == &quot;0&quot;: scrapy.log.logger.info(&quot;登录成功!&quot;) return super().start_requests() scrapy.log.logger.info(&quot;登录失败!&quot;) return self.start_requests() def get_captha_by_ocr(self, data): img = Image.open(BytesIO(data)) img = img.convert(&quot;L&quot;) captcha = pytesseract.image_to_string(img) img.close() return captcha 网络平台识别 阿里云市场提供很多验证码识别平台, 他们提供了 HTTP 服务接口, 用户通过 HTTP 请求将验证码图片发送给平台, 平台识别后将结果通过 HTTP 响应返回. 人工识别 在 Scrapy 下载完验证码图片后, 调用 Image.show 方法将图片显示出来, 然后调用 Python 内置的 Input 函数, 等待用户肉眼识别后输入识别结果. def get_captha_by_user(self, data): img = Image.open(BytesIO(data)) img.show() captha = input(&quot;请输入验证码: &quot;) img.close() return captha 3. Cookie 登录 &amp;&amp; CookiesMiddleware在使用浏览器登录网站后, 包含用户身份信息的 Cookie 会被浏览器保存到本地, 如果 Scrapy 爬虫能直接使用浏览器的 Cookie 发送 HTTP 请求, 就可以绕过提交表单登录的步骤. 3.1 browsercookie第三方 Python 库 browsercookie 便可以获取 Chrome 和 Firefox 浏览器中的 Cookie. $ pip install browsercookie &gt;&gt;&gt; import browsercookie &gt;&gt;&gt; chrome_cookiejar = browsercookie.chrome() &gt;&gt;&gt; firefox_cookiejar = browsercookie.firefox() &gt;&gt;&gt; type(chrome_cookiejar) http.cookiejar.CookieJar &gt;&gt;&gt; for cookie in chrome_cookiejar: # 对 http.cookiejar.CookieJar 对象进行迭代, 可以访问其中的每个 Cookie 对象. print cookie 3.2 CookiesMiddlewareimport six import logging from collections import defaultdict from scrapy.exceptions import NotConfigured from scrapy.http import Response from scrapy.http.cookies import CookieJar from scrapy.utils.python import to_native_str logger = logging.getLogger(__name__) class CookieMiddleware(object): &quot;&quot;&quot; This middleware enables working with sites that need cookies. &quot;&quot;&quot; def __init__(self, debug=False): &quot;&quot;&quot; jars 中的每一项值, 都是一个 scrapy.http.cookies.CookisJar 对象, CookieMiddleware 可以让 Scrapy 爬虫同时使用多个不同的 CookieJar, 即多个不同的账号. Request(url, meta={&quot;cookiejar&quot;: &quot;account_1&quot;}} :param debug: &quot;&quot;&quot; self.jars = defaultdict(CookieJar) self.debug = debug @classmethod def from_crawler(cls, crawler): &quot;&quot;&quot; 从配置文件读取 COOKIES_ENABLED, 决定是否启用该中间件. :param crawler: :return: &quot;&quot;&quot; if not crawler.settings.getbool(&quot;COOKIES_ENABLED&quot;): raise NotConfigured return cls(crawler.settings.getbool(&quot;COOKIES_DEBUG&quot;)) def process_request(self, request, spider): &quot;&quot;&quot; 处理每一个待发送到额 Request 对象, 尝试从 request.meta[&quot;cookiejar&quot;] 获取用户指定使用的 Cookiejar, 如果用户未指定, 就是用默认的 CookieJar(self.jars[None]). 调用 self._get_request_cookies 方法获取发送请求 request 应携带的 Cookie 信息, 填写到 HTTP 请求头. :param request: :param spider: :return: &quot;&quot;&quot; if request.meta.get(&quot;dont_merge_cookies&quot;, False): request cookiejarkey = request.meta.get(&quot;cookiejar&quot;) jar = self.jar[cookiejarkey] cookies = self._get_request_cookies(jar, request) for cookie in cookies: jar.set_cookie_if_ok(cookie, request) # set Cookie header request.headers.pop(&quot;Cookie&quot;, None) jar.add_cookie_header(request) self._debug_cookie(request, spider) def process_response(self, request, response, spider): &quot;&quot;&quot; 处理每一个 response 对象, 依然通过 request.meta[&quot;cookiejar&quot;] 获取用户指定使用的 cookiejar, 调用 extract_cookies 方法将 HTTP 响应头部中的 Cookie 信息保存到 CookieJar 对象中. :param request: :param response: :param spider: :return: &quot;&quot;&quot; if request.meta.get(&quot;dont_merge_cookies&quot;, False): return response # extract cookies from Set-Cookie and drop invalid/expired cookies. cookiejarkey = request.meta.get(&quot;cookiejar&quot;) jar = self.jars[cookiejarkey] jar.extract_cookies(response, request) self._debug_set_cookie(response, request) return response def _debug_cookie(self, request, spider): if self.debug: cl = [to_native_str(c, errors=&quot;replace&quot;) for c in request.headers.getlist(&quot;Cookie&quot;)] if cl: cookies = &quot;\n&quot;.join(&quot;Cookie: {}\n&quot;.format(c) for c in cl) msg = &quot;Sending cookies to:{}\n&quot;.format(request, cookies) logger.debug(msg, extra={&quot;spider&quot;: spider}) def _debug_set_cookie(self, response, spider): if self.debug: cl = [to_native_str(c, errors=&quot;replace&quot;) for c in response.headers.getlist(&quot;Set-Cookie&quot;)] if cl: cookies = &quot;\n&quot;.join(&quot;Set-Cookie: {}\n&quot;.format(c) for c in cl) msg = &quot;Received cookies from:{}\n&quot;.format(response, cookies) logger.debug(msg, extra={&quot;spider&quot;: spider}) def _format_cookie(self, cookie): # build cookie string cookie_str = &quot;%s=%s&quot; % (cookie[&quot;name&quot;], cookie[&quot;value&quot;]) if cookie.get(&quot;path&quot;, None): cookie_str += &quot;;Path=%s&quot; % cookie[&quot;path&quot;] if cookie.get(&quot;domain&quot;, None): cookie_str += &quot;;Domain=%s&quot; % cookie[&quot;domain&quot;] return cookie_str def _get_request_cookies(self, jar, request): if isinstance(request.cookies, dict): cookie_list = [{&quot;name&quot;: k, &quot;value&quot;: v} for k, v in six.iteritems(request.cookies)] else: cookie_list = request.cookies cookies = [self._format_cookie(x) for x in cookie_list] headers = {&quot;Set-Cookie&quot;: cookies} response = Response(request.url, headers=headers) return jar.make_cookies(response, request) 3.3 实现 BrowserCookieMiddleware利用 browsercookie 对 CookieMiddleware 进行改良. import browsercookie from scrapy.downloadermiddlewares.cookies import CookiesMiddleware class BrowserCookiesMiddleware(CookiesMiddleware): def __init__(self, debug=False): super().__init__(debug) self.load_browser_cookies() def load_browser_cookies(self): # for chrome jar = self.jars[&quot;chrome&quot;] chrome_cookies = browsercookie.chrome() for cookie in chrome_cookies: jar.set_cookie(cookie) # for firefox jar = self.jars[&quot;firefox&quot;] firefox_cookies = browsercookie.firefox() for cookie in firefox_cookies: jar.set_cookie(cookie) 使用示例: # settings.py USER_AGENT = &quot;Mozilla/5.0 (X11; CrOS i686 3912.101.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.116 Safari/537.36&quot; DOWNLAODER_MIDDLEWARES = { &quot;scrapy.downloademiddleware.cookies.CookiesMiddleware&quot;: None, &quot;browser_cookie.middlewares.BrowserCookiesMiddleware&quot;: 701 } $ scrapy shell &gt;&gt;&gt; from scrapy import Request &gt;&gt;&gt; url = &quot;https://www.zhihu.com/settings/profile&quot; &gt;&gt;&gt; fetch(Request(url, meta={&quot;cookiejar&quot;: &apos;chrome&apos;})) &gt;&gt;&gt; view(response) 十. 爬取动态页面: Splash 渲染引擎Splash 是 Scrapy 官方推荐的 javascript 渲染引擎, 他是用 Webkit 开发的轻量级无界面浏览器, 提供基于 http 接口的 javascript 渲染服务, 支持如下功能: 为用户返回经过渲染的 HTML 页面或页面截图 并发渲染多个页面 关闭图片加载, 加速渲染 在页面中执行用户自定义的 javascript 代码. 指定用户自定义的渲染脚本(lua), 功能类似于 PhantomJS. 1. 安装# 安装 docker $ yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-selinux docker-engine-selinux docker-engine -y $ yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo $ yum install -y yum-utils device-mapper-persistent-data lvm2 $ yum install docker-ce $ systemctl start docker # 获取镜像 $ docker pull scrapinghub/splash # 运行 splash 服务 $ docker run -p 8051:8051 -p 8050:8050 scrapinghub/splash 2. render.html : 提供 javascript 渲染服务 服务端点 render.html 请求地址 http://localhost:8051/render.html 请求方式 GET/POST 返回类型 html 参数列表: 参数 是否必选 类型 描述 url 必选 string 需要渲染的页面 url timeout 可选 float 渲染页面超时时间 proxy 可选 string 代理服务器地址 wait 可选 float 等待页面渲染的时间 images 可选 integer 是否下载图片, 默认为 1 js_source 可选 string 用自定义的 javascript 代码, 在页面渲染前执行 示例: 使用 request 库调用 render.html 渲染页面. &gt;&gt;&gt; import requests &gt;&gt;&gt; from scrapy.selector import Selector &gt;&gt;&gt; splash_url = &quot;http://localhost:8050/render.html&quot; &gt;&gt;&gt; args = {&quot;url&quot;: &quot;http://quotes.toscrape.com/js&quot;, &quot;timeout&quot;:5,&quot;image&quot;:0} &gt;&gt;&gt; response = requests.get(splash_url, params=args) &gt;&gt;&gt; sel = Selector(response) &gt;&gt;&gt; sel.css(&quot;div.quote span.text::text&quot;).extract() 3. execute : 指定用户自定义的 lua 脚本, 利用该断点可在页面中执行 javascript 代码.在爬去某些页面时, 希望在页面中执行一些用户自定义的 javascript 代码, 例如, 用 javascript 模拟点击页面中的按钮, 或调用页面中的 javascript 函数与服务器交互, 利用 Splash 的 execute 端点可以实现这样的功能. 服务端点 execute 请求地址 http://localhost:8051/execute 请求方式 POST 返回类型 自定义 参数 : 参数 是否必选 类型 描述 lua_source 必选 string 用户自定义的 Lua 脚本 timeout 可选 float 渲染页面超时时间 proxy 可选 string 代理服务器地址 可以将 execute 端点的服务看做一个可用 lua 语言编程的浏览器, 功能类似于 PhantomJS. 使用时需传递一个用户自定义的 Lua 脚本给 Spalsh, 该 Lua 脚本中包含用户想要模拟的浏览器行为. 如 打开某 url 地址的页面 等待页面加载完成 执行 javascript 代码 获取 HTTP 响应头部 获取 Cookie 用户定义的 lua 脚本必须包含一个 main 函数作为程序入口, main 函数被调用时传入一个 splash 对象(lua中的对象), 用户可以调用该对象上的方法操作 Splash. main 函数的返回值可以使 字符串, 也可以是 lua 中的表(类似 python 字典), 表会被编码成 json 串. Splash 对象常用属性和方法 splash.args属性 用户传入参数的表, 通过该属性可以访问用户传入的参数, 如 splash.args.url splash.js_enabled 用于开启/禁止 javascript 渲染, 默认为 True splash.images_enabled 用于开启/禁止 图片加载, 默认为 True splash:go() splash:go(url, baseurl=nil, headers=nil, http_method=&quot;GET&quot;, body=nil, formdata=nil) 类似于在浏览器中打开某 url 地址的页面, 页面所需资源会被加载, 并进行 javascript 渲染, 可以通过参数指定 HTTP 请求头部, 请求方法, 表单数据等. splash:wait() splash:wait(time, cancel_on_redirect=false, cancel_on_error=true) 等待页面渲染, time 参数为等待的秒数. splash:evaljs() splash:evaljs(snippet) 在当前页面下, 执行一段 javascript 代码, 并返回最后一句表达式的值. splash:runjs() splash:runjs(snippet) 在当前页面下, 执行一段 javascript 代码, 与 evaljs 相比, 该函数只执行代码, 不返回值. splash:url() 获取当前页面的 url splash:html() 获取当前页面的 html 文本. splash:get_cookits() 获取全部 cookie 信息. 示例代码: requests 库调用 execute 端点服务 &gt;&gt;&gt; import json &gt;&gt;&gt; lua_script = &quot;&quot;&quot; ...: function main(splash) ...: splash:go(&apos;http://example.com&apos;) ...: splash:wait(0.5) ...: local title = splash:evaljs(&quot;document.title&quot;) ...: return {title=title} ...: end &quot;&quot;&quot; &gt;&gt;&gt; splash_url = &quot;http://localhost:8050/execute&quot; &gt;&gt;&gt; headers = {&quot;content-type&quot;: &quot;application/json&quot;} &gt;&gt;&gt; data = json.dumps({&quot;lua_source&quot;: lua_script}) &gt;&gt;&gt; response = requests.post(splash_url, headers=headers, data=data) &gt;&gt;&gt; response.content &gt;&gt;&gt; &apos;{&quot;title&quot;: &quot;Example Domain&quot;}&apos; &gt;&gt;&gt; response.json() &gt;&gt;&gt; {u&apos;title&apos;: u&apos;Example Domain&apos;} 4. scrapy-splash 安装 $ pip install scrapy-splash 配置 $ cat settings.py # Splash 服务器地址 SPLASH_URL = &quot;http://localhost:8050&quot; # 开启 Splash 的两个下载中间件并调整 HttpCompressionMiddleware 的次序 DOWNLOADER_MIDDLEWARES = { &quot;scrapy_splash.SplashCookiesMiddleware&quot;: 723, &quot;scrapy_splash.SplashMiddleware&quot;: 725, &quot;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&quot;: 810, } # 设置去重过滤器 DUPEFILTER_CLASS = &quot;scrapy_splash.SplashAwareDupeFilter&quot; # 用来支持 cache_args (可选) SPIDER_MIDDLEWARES = { &quot;scrapy_splash.SplashDeduplicateArgsMiddleware&quot;: 100, } 使用 Scrapy_splash 调用 Splash 服务非常简单. scrapy_Splash 中定义了一个 SplashRequest 类, 用户只需使用 scrapy_splash.SplashRequest (替代 scrapy.Request) 提交请求即可. SplashRequest 构造器方法参数 url : 待爬去页面的 url headers : 请求 headers, 同 scrapy.Request. cookies : 请求 cookie, 同 scrapy.Request. args : 传递给 Splash 的参数(除 url), 如 wait, timeout, images, js_source 等 cache_args : 如果 args 中的某些参数每次调用都重复传递, 并且数据量巨大, 此时可以把该参数名填入 cache_args 列表中, 让 Splash 服务器缓存该参数. 如 SplashRequest(url, args={&quot;js_source&quot;: js, &quot;wait&quot;: 0.5}, cache_args=[&quot;js_source&quot;]) endpoint : Splash 服务端点, 默认为 render.html, 即 javascript 渲染服务. 该参数可以设置为 render.json, render.har, render.png, render.jpeg, execute 等. 详细参考文档. splash_url : Splash 服务器地址, 默认为 None, 即使用配置文件中的 SPLASH_URL 地址. 5. 代码示例 quote 名人名言爬取 import scrapy from scrapy_splash import SplashRequest class QuotesSpider(scrapy.Spider): name = &apos;quotes&apos; allowed_domains = [&apos;quotes.toscrape.com&apos;] start_urls = [&apos;http://quotes.toscrape.com/js&apos;] splash_base_args = {&quot;images&quot;: 0, &quot;timeout&quot;: 3} def start_requests(self): for url in self.start_urls: yield SplashRequest(url, args=self.splash_base_args) def parse(self, response): for sel in response.css(&quot;div.quote&quot;): quote = sel.css(&quot;span.text::text&quot;).extract_first() author = sel.css(&quot;small.author::text&quot;).extract_first() yield {&quot;quote&quot;: quote, &quot;author&quot;: author} href = response.css(&quot;li.next &gt; a::attr(href)&quot;).extract_first() if href: url = response.urljoin(href) yield SplashRequest(url, args=self.splash_base_args) jd 图书 爬取 import scrapy from scrapy import Request from scrapy_splash import SplashRequest lua_script = &quot;&quot;&quot; function main(splash) splash:go(splash.args.url) splash:wait(2) splash:runjs(&quot;document.getElementsByClassName(&apos;page&apos;)[0].scrollIntoView(true)&quot;) splash:wait(2) return splash:html() end &quot;&quot;&quot; class JdBookSpider(scrapy.Spider): name = &apos;jd_book&apos; allowed_domains = [&apos;search.jd.com&apos;] base_url = &quot;https://search.jd.com/Search?keyword=python&amp;enc=utf-8&amp;book=y&amp;wq=python&quot; def start_requests(self): # 请求第一个页面, 无需渲染 js yield Request(self.base_url, callback=self.parse_url, dont_filter=True) def parse_url(self, response): # 获取商品总数, 计算出总页数. total = int(response.css(&quot;span#J_resCount::text&quot;).re_first(&quot;(\d+)\D?&quot;)) pageNum = total // 60 + (1 if total % 60 else 0) # 构造每一页的 url, 向 Splash 端点发送请求 for i in xrange(pageNum): url = &quot;%s&amp;page=%s&quot; % (self.base_url, 2*i + 1) headers = {&quot;refer&quot;: self.base_url} yield SplashRequest(url, endpoint=&quot;execute&quot;, headers=headers, args={&quot;lua_source&quot;: lua_script}, cache_args=[&quot;lua_source&quot;]) def parse(self, response): # 获取单个页面中每本书的名字和价格 for sel in response.css(&quot;ul.gl-warp.clearfix &gt; li.gl-item&quot;): yield { &quot;name&quot;: sel.css(&quot;div.p-name&quot;).xpath(&quot;string(.//em)&quot;).extract_first(), &quot;price&quot;: sel.css(&quot;div.p-price i::text&quot;).extract_first() } $ vim settings.py USER_AGENT = u&apos;Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36&apos; 十一. HTTP 代理Scrapy 内部提供了一个下载中间件HttpProxyMiddleware, 专门用于给 Scrapy 设置代理, 他默认是启动的, 他会在系统环境变量中搜索当前系统代理(名称格式为xxx_proxy的环境变量), 作为 Scrapy 爬虫使用的带来. $ export http_proxy=&quot;http://192.168.1.1:8000&quot; $ export https_proxy=&quot;http://192.168.1.1:8001&quot; # 包含用户名和密码 $ export https_proxy=&quot;http://username:password@192.168.1.1:8001&quot; $ curl http(s)://httpbin.org/ip # 返回一个包含请求源 ip 地址信息的额 json 字符串. Scrapy 中为一个请求设置代理的本质就是将代理服务器的 url 填写到 request.meta[&quot;proxy&quot;]. class HttpProxyMiddleware(object): ... def _set_proxy(self, request, scheme): creds, proxy = self.proxies[scheme] request.meta[&quot;proxy&quot;] = proxy if creds: # 如果需要认证, 传递包含用户账号和密码的身份验证信息 request.headers[&quot;Proxy-Authorization&quot;] = b&quot;Basic&quot; + creds # 手动实现 $ scrapy shell &gt;&gt;&gt; from scrapy import Request &gt;&gt;&gt; import base64 &gt;&gt;&gt; req = Request(&quot;http://httpbin.org/ip&quot;, meta={&quot;proxy&quot;: &quot;http://192.168.1.1:8000&quot;}) &gt;&gt;&gt; user = &quot;tom&quot; &gt;&gt;&gt; password = &quot;tom123&quot; &gt;&gt;&gt; user_passwd = (&quot;%s:%s&quot; % (user, password)).encode(&quot;utf8&quot;) &gt;&gt;&gt; req.headers[&quot;Proxy-Authorization&quot;] = b&quot;Basic&quot; + base64.b64encode(user_passwd) &gt;&gt;&gt; fetch(req) 1. 抓取免费代理:代理网站: http://proxy-list.org https://free-proxy-list.net http://www.xicidaili.com http://www.proxy360.cn http://www.kuaidaili.com 获取西祠代理代码 # settings.py USER_AGENT = &quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)&quot; # spider.py import json import scrapy from scrapy import Request class XiciSpider(scrapy.Spider): name = &apos;xici&apos; allowed_domains = [&apos;www.xicidaili.com&apos;] # start_urls = [&apos;http://www.xicidaili.com/nn/&apos;] base_url = &quot;http://www.xicidaili.com/nn/%s&quot; check_url = &quot;%s://httpbin.org/ip&quot; def start_requests(self): for i in xrange(1, 5): yield Request(self.base_url % i) def parse(self, response): for sel in response.xpath(&quot;//table[@id=&apos;ip_list&apos;]/tr[position()&gt;1]&quot;): ip = sel.css(&apos;td:nth-child(2)::text&apos;).extract_first() port = sel.css(&apos;td:nth-child(3)::text&apos;).extract_first() scheme = sel.css(&apos;td:nth-child(6)::text&apos;).extract_first().lower() url = self.check_url % scheme proxy = &quot;%s://%s:%s&quot; % (scheme, ip, port) meta = { &quot;proxy&quot;: proxy, &quot;dont_retry&quot;: True, &quot;download_timeout&quot;: 10, &quot;_proxy_scheme&quot;: scheme, &quot;_proxy_ip&quot;: ip } yield Request(url, callback=self.check_available, meta=meta, dont_filter=True) def check_available(self, response): proxy_ip = response.meta[&quot;_proxy_ip&quot;] if proxy_ip == json.loads(response.text)[&quot;origin&quot;]: yield { &quot;proxy_scheme&quot;: response.meta[&quot;_proxy_scheme&quot;], &quot;proxy&quot;: response.meta[&quot;proxy&quot;] } 2. 基于 HttpProxyMiddleware 实现随机代理# middlewares.py class RandomHttpProxyMiddleware(HttpProxyMiddleware): def __init__(self, auth_encoding=&quot;latin-1&quot;, proxy_list_file=None): if not proxy_list_file: raise NotConfigured self.auth_encoding = auth_encoding # 用两个列表维护 HTTP 和 HTTPS 代理, {&quot;http&quot;: [...], &quot;https&quot;: [...]} self.proxies = defaultdict(list) with open(proxy_list_file) as f: proxy_list = json.load(f) for proxy in proxy_list: scheme = proxy[&quot;proxy_scheme&quot;] url = proxy[&quot;proxy&quot;] self.proxies[scheme].append(self._get_proxy(url, scheme)) @classmethod def from_crawler(cls, crawler): auth_encoding = crawler.settings.get(&quot;HTTPPROXY_AUTH_ENCODING&quot;, &quot;latin-1&quot;) proxy_list_file = crawler.settings.get(&quot;HTTPPROXY_PROXY_LIST_FILE&quot;) return cls(auth_encoding, proxy_list_file) def _set_proxy(self, request, scheme): creds, proxy = random.choice(self.proxies[scheme]) request.meta[&quot;proxy&quot;] = proxy if creds: request.headers[&quot;Proxy-Authorization&quot;] = b&quot;Basic&quot; + creds # spider.py : 测试随机 proxy 是否 work import json import scrapy from scrapy import Request class TestRandomProxySpider(scrapy.Spider): name = &quot;random_proxy&quot; def start_requests(self): for _ in range(100): yield Request(&quot;http://httpbin.org/ip&quot;, dont_filter=True) yield Request(&quot;https://httpbin.org/ip&quot;, dont_filter=True) def parse(self, response): print json.loads(response.text) # settings.py DOWNLOADER_MIDDLEWARES = { &apos;proxy_example.middlewares.RandomHttpProxyMiddleware&apos;: 543, } HTTPPROXY_PROXY_LIST_FILE = &quot;proxy.json&quot; 3. 实战: 豆瓣电影# Spider.py import json import re import scrapy from scrapy import Request class DmovieSpider(scrapy.Spider): BASE_URL = &quot;https://movie.douban.com/j/search_subjects?type=movie&amp;tag=%s&amp;sort=recommend&amp;page_limit=%s&amp;page_start=%s&quot; MOVIE_TAG = &quot;豆瓣高分&quot; PAGE_LIMIT = 20 page_start = 0 name = &apos;dmovie&apos; allowed_domains = [&apos;movie.douban.com&apos;] start_urls = [BASE_URL % (MOVIE_TAG, PAGE_LIMIT, page_start)] def parse(self, response): infos = json.loads(response.body.decode(&quot;utf-8&quot;)) for movie_info in infos[&quot;subjects&quot;]: movie_item = {} movie_item[&quot;片名&quot;] = movie_info[&quot;title&quot;] movie_item[&quot;评分&quot;] = movie_info[&quot;rate&quot;] yield Request(movie_info[&quot;url&quot;], callback=self.parse_movie, meta={&quot;_movie_item&quot;: movie_item}) if len(infos[&quot;subjects&quot;]) == self.PAGE_LIMIT: self.page_start += self.PAGE_LIMIT url = self.BASE_URL % (self.MOVIE_TAG, self.PAGE_LIMIT, self.page_start) yield Request(url) def parse_movie(self, response): movie_item = response.meta[&quot;_movie_item&quot;] info = response.css(&quot;div.subject div#info&quot;).xpath(&quot;string(.)&quot;).extract_first() fields = [s.strip().replace(&quot;:&quot;, &quot;&quot;) for s in response.css(&quot;div#info span.pl::text&quot;).extract()] values = [re.sub(&quot;\s+&quot;, &quot;&quot;, s.strip()) for s in re.split(&apos;\s*(?:%s):\s*&apos; % &quot;|&quot;.join(fields), info)][1:] movie_item.update(dict(zip(fields, values))) yield movie_item # settings.py DOWNLOADER_MIDDLEWARES = { &apos;douban_movie.middlewares.RandomHttpProxyMiddleware&apos;: 543, } HTTPPROXY_PROXY_LIST_FILE = &quot;proxy.json&quot; USER_AGENT = &quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)&quot; DOWNLOAD_DELAY = 2 ROBOTSTXT_OBEY = False # middleware.py class RandomHttpProxyMiddleware(HttpProxyMiddleware): def __init__(self, auth_encoding=&quot;latin-1&quot;, proxy_list_file=None): if not proxy_list_file: raise NotConfigured self.auth_encoding = auth_encoding # 用两个列表维护 HTTP 和 HTTPS 代理, {&quot;http&quot;: [...], &quot;https&quot;: [...]} self.proxies = defaultdict(list) with open(proxy_list_file) as f: proxy_list = json.load(f) for proxy in proxy_list: scheme = proxy[&quot;proxy_scheme&quot;] url = proxy[&quot;proxy&quot;] self.proxies[scheme].append(self._get_proxy(url, scheme)) @classmethod def from_crawler(cls, crawler): auth_encoding = crawler.settings.get(&quot;HTTPPROXY_AUTH_ENCODING&quot;, &quot;latin-1&quot;) proxy_list_file = crawler.settings.get(&quot;HTTPPROXY_PROXY_LIST_FILE&quot;) return cls(auth_encoding, proxy_list_file) def _set_proxy(self, request, scheme): creds, proxy = random.choice(self.proxies[scheme]) request.meta[&quot;proxy&quot;] = proxy if creds: request.headers[&quot;Proxy-Authorization&quot;] = b&quot;Basic&quot; + creds # proxy.json [ {&quot;proxy_scheme&quot;: &quot;http&quot;, &quot;proxy&quot;: &quot;http://111.155.116.237:8123&quot;}, {&quot;proxy_scheme&quot;: &quot;https&quot;, &quot;proxy&quot;: &quot;https://222.188.190.99:6666&quot;}, {&quot;proxy_scheme&quot;: &quot;https&quot;, &quot;proxy&quot;: &quot;https://60.23.36.250:80&quot;}, {&quot;proxy_scheme&quot;: &quot;https&quot;, &quot;proxy&quot;: &quot;https://120.79.216.57:6666&quot;}, {&quot;proxy_scheme&quot;: &quot;https&quot;, &quot;proxy&quot;: &quot;https://120.92.88.202:10000&quot;}, {&quot;proxy_scheme&quot;: &quot;https&quot;, &quot;proxy&quot;: &quot;https://120.79.151.197:6666&quot;}, {&quot;proxy_scheme&quot;: &quot;http&quot;, &quot;proxy&quot;: &quot;http://118.114.77.47:8080&quot;}, {&quot;proxy_scheme&quot;: &quot;http&quot;, &quot;proxy&quot;: &quot;http://112.74.62.69:8081&quot;}, {&quot;proxy_scheme&quot;: &quot;https&quot;, &quot;proxy&quot;: &quot;https://218.93.166.4:6666&quot;}, {&quot;proxy_scheme&quot;: &quot;http&quot;, &quot;proxy&quot;: &quot;http://58.216.202.149:8118&quot;}, {&quot;proxy_scheme&quot;: &quot;http&quot;, &quot;proxy&quot;: &quot;http://14.118.253.233:6666&quot;} ] 十二. scrapy-redis 分布式爬虫Scrapy-redis 利用 Redis 数据库重新实现了 Scrapy 中的某些组件. 基于 Redis 的请求队列(优先队列, FIFO, LIFO) 基于 Redis 的请求去重过滤器(过滤掉重复的请求) 基于以上两个组件的调度器 Scrapy-redis 为多个爬虫分配爬取任务的方式是: 让所有爬虫共享一个存在于 Redis 数据库中的请求队列(替代各爬虫独立的请求队列), 每个爬虫从请求队列中获取请求, 下载并解析出新请求再添加到 请求队列中, 因此, 每个爬虫即是下载任务的生产者, 又是消费者. 搭建分布式环境 # 在所有机器上安装包 $ pip install scrapy $ pip install scrapy-redis # 启动redis server, 确保分布式环境中每台机器均可访问 redis-server $ redis-cli -h REDIS_SERVER ping 配置项目 1234567891011121314151617# settings.py## 指定爬虫使用的 redis 数据库REDIS_URL = &quot;redis://192.168.1.10:6379&quot;## 使用 scrapy-redis 的调度器替代 scrapy 原版调度器SCHEDULER = &quot;scrapy_redis.scheduler.Scheduler&quot;## 使用 scrapy-redis 的 RFPDupeFilter 作为去重过滤器DUPEFILTER_CLASS = &quot;scrapy_redis.dupefilter.RFPDupeFilter&quot;## 启动 scrapy_redis 的 RedisPipeline 将爬取到的数据汇总到 数据库.ITEM_PIPELINES = &#123; &quot;scrapy_redis.pipelines.RedisPipeline&quot;: 300,&#125;## 爬虫停止后, 保留/清理 redis 中的请求队列及去重即可. True: 保留, False: 清理(默认).SCHEDULER_PERSIST = True Scrapy-redis 提供了一个新的 Spider 基类 RedisSpider, RedisSpider 重写了 start_requests 方法, 他重试从 redis 数据库的某个特定列表中获取起始爬取点, 并构造 Request 对象(dont_filter=False), 该列表的键可通过配置文件设置(REDIS_START_URLS_KEY), 默认为 &lt;spider_name&gt;:start_urls. 在分布式爬取时, 用户运行所有爬虫后, 需要手动使用 Redis 命令向该列表添加起始爬取点, 从而避免重复. # spider.py from scrapy_redis.spiders import RedisSpider class BooksSpider(RedisSpider): # 爬虫 继承 RedisSpider 类 pass # 注释 start_urls # start_urls = [&quot;http://book.toscrape.com&quot;] # 命令行 写入队列开始值. $ redis-cli -h 192.168.1.10 &gt; lpush books:start_urls &quot;http://books.toscrape.com/&quot; 十三. 奇技淫巧1. scrapy 项目的一般步骤 创建 项目 $ scrapy startproject PROJECT_NAME 创建 spider $ cd PROJECT_NAME $ scrapy genspider SPIDER_NAME DOMAIN 封装 Item 类 完成 Spider 类 配置 settings.py ## 指定输出序列 FEED_EXPORT_FIELDS = [] ## 绕过 roobot.txt ## USER_AGENT 配置 编写 Pipeline, 实现 item 字段转换 : settings.py ITEM_PIPELINES = { PIPELINE_NAME: rate, } 运行 crawl $ scrapy list $ scrapy crawl MySpider 2. User-Agent 使用 fake-useragent GitHub - hellysmile/fake-useragent: up to date simple useragent faker with real world database $ pip install fake-useragent 各大搜索引擎的 UA 可以伪装成各大搜索引擎网站的UA， 比如 Google UA 添加referfer字段为 搜索引擎网站 也是有用的，因为网站是希望被索引的，所以会放宽搜索引擎的爬取策略。 useragentstring.com 3. 代理网上的开源代理: https://github.com/xiaosimao/IP_POOL 代理网站: http://www.kuaidaili.com/free/ http://www.66ip.cn/ http://www.goubanjia.com/free/gngn/index.shtml http://www.xicidaili.com/ data5u proxydb 测试网站: 百度 https://httpbin.org/get 十四. 参考链接 精通 Scrapy 网络爬虫 Scrapy 文档 12345678910111213141516171819202122232425262728293031323334353637383940# 1. [First Step](http://www.cnblogs.com/yanjingnan/p/7747636.html)# 2. 基本概念## 2.1 [命令行工具](http://www.cnblogs.com/yanjingnan/p/7748565.html)## 2.2 [spiders 爬虫](http://www.cnblogs.com/yanjingnan/p/7780968.html)## 2.3 Selectors 选择器## 2.4 Items## 2.5 Item Loaders## 2.6 Item Pipeline## 2.7 Feed exports : 输出和存储数据## 2.8 请求和响应## 2.9 连接提取## 2.10 设置, 配置## 2.11 Exceptions# 3. 内置服务## 3.1 Logging## 3.2 Stats Collection## 3.3 Sending e-mail## 3.4 Telnet Console## 3.5 Web Service# 4. Q&amp;A# 5.扩展 scrapy]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>PyPi</tag>
        <tag>爬虫</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible-基本原理与安装配置]]></title>
    <url>%2F2018%2F03%2F15%2FAnsible-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Ansible 基本原理, 安装配置与命令行工具的使用. Ansible 学习总结 一. Ansible 简介Ansible 是使用 Python 开发的, 基于 SSH 协议的, Agentless 的配置管理工具. 其源代码存放于 githb 上, 分隔成 三部分 分别存放在不同的代码仓库上. 主仓库 : https://github.com/ansible/ansible 核心模块 : https://github.com/ansible/ansible-modules-core 其他模块 : https://github.com/ansible/ansible-modules-extras 1. 架构核心引擎： Ansible 核心 核心模块（Core Module）：和大多数运维工具一样，将系统和应用提供的能力模块化，一个模块有点像编程中一个功能接口，要使用的时候调用接口并传参就可以了。比如Ansible的service模块，你要保证名为nginx的service处于启动状态，只需要调用service模块，并配置参数name: nginx，state: started即可。 自定义模块（Custom Modules）:显而易见，如果Ansible的核心模块满足不了你的需求，你可以添加自定义化的模块。 插件（Plugins）：模块功能的补充，如循环插件、变量插件、过滤插件等，也和模块一样支持自定义，这个功能不常用（我没用到过），就不做细说了。 剧本（playbooks）：说到这个，先说说Ansible完成任务的两种方式，一种是Ad-Hoc，就是ansible命令，另一种就是Ansible-playbook，也就是ansible-playbook命令。他们的区别就像是Command命令行和Shell Scripts。 连接插件（connectior plugins）:Ansible默认是基于SSH连接到目标机器上执行操作的。但是同样的Ansible支持不同的连接方法，要是这样的话就需要连接插件来帮助我们完成连接了。 主机清单（host inventory）:为Ansible定义了管理主机的策略。一般小型环境下我们只需要在host文件中写入主机的IP地址即可，但是到了中大型环境我们有可能需要使用动态主机清单来生成我们所需要执行的目标主机（需要云环境支持动态生成Ansible host inventory）。 2. task 执行逻辑每个 playbook 包含多个 task. 每个 task 按次序在所有匹配主机执行, 当所有主机执行完当前 task 之后, 则执行下一个 task. 当某台主机在 playbook 中的某个 task 执行失败之后, 该 playbook 的剩余 task 将不会再在该主机执行, 因此, 可以在修正之后, 重新在该主机执行 playbook. 模块应该是幂等性的, 多次执行的结果应该是相同的. 幂等性的其中一种实现方式时: 提供一个用于检查的模块, 判断模块的执行对象是否达到需要实现的状态, 如果达到状态, 则跳过 task 的执行. command 和 shell 模块在执行某些操作时可能是非幂等性的, 因此, 可以使用 creates 标志辅助实现幂等性. 二. Ansible 任务的执行细节原理1. 角色与依赖: 被管理主机 : 需要 ssh 和 python2.5 或者更高版本. 管理主机 : 需要 Python2.6 或者更高的版本. 有些模块需要额外的依赖, 如 ec2模块 依赖 boto模块, docker 模块依赖 docker-py 等. 2. 工作机制Ansible 默认采用推送模式, 但是也支持 拉取模式, 使用 ansible-pull 命令. 3. 工作原理示例代码: - name: install nginx apt: name=nginx ansible 操作如下: 在管理主机生成安装 nginx 软件包的 python 程序 将该程序复制到 目标服务器. 在目标服务器上完成操作, 执行 程序 等待改程序在所有主机上完成. ansible 执行模块指令的注意事项: 对于每一个任务, ansible 都是并行执行的. 在开始下一个任务之前, ansible 会等待所有主机都完成上一个任务. ansible 任务的执行顺序, 为管理员定义的执行顺序. 幂等性 三. 安装配置1. 安装12$ yum install python-pip$ pip install ansible 2. 配置文件 配置段 ansible.cfg 有 defaults, ssh_connection, paramiko, accelerate 四个配置段, 其具体配置项见ansible 番外篇之 ansible.cfg 配置参数 配置文件及优先级 ansible 配置文件 : ansible.cfg, ansible 使用如下位置和顺序来查找 ansible.cfg 文件 ANSIBLE_CONFIG 环境变量指向的文件 ./ansible.cfg ~/.ansible.cfg /etc/ansible/ansible.cfg 基础示例: [defaults] hostfile = hosts remote_user = ec2-user private_key_file = /path/to/my_private_key host_key_checking = False # 关闭 host key 检查. 四 Ansible 抽象实体1. inventoryAnsible 执行的目标主机的配置文件. Ansible 支持静态 Inventory 文件 和 动态 Inventory , 默认的 静态 Inventory 文件为 /etc/ansible/hosts, 同时支持 Cobbler Inventory , AWS ec2.py 等动态 Inventory. 2. 变量与factAnsible 支持如下变量类型及定义, 可以提高 task 的可复用性和适用性: 自定义变量 注册变量 内置变量 fact 变量 3. 模块模块定义 Ansible 可以在目标主机执行的具体操作, 是由 Ansible 包装好后在这几上执行一系列操作的脚本, 是 Ansible 执行操作的最小粒度.Ansible 支持如下模块类型: 内置模块 自定义模块: 支持多种编程语言, 如 shell, python, ruby 等. 4. task/play/role/playbook task : 由模块定义的具体操作. play : 多个包含 host, task 等多个字段部分的任务定义集合. 是一个 YAML 字典结构. playbook : 多个 play 组成的列表 role : 是将 playbook 分割为多个文件的主要机制, 用于简化 playbook 的编写, 并提高 playbook 的复用性. 五 Ansible 命令行1. ansible123456789101112131415161718192021$ ansible -i INVENTORY HOST_GROUP [ -s ] -m MODEL -a ARGS [-vvvv] -i INVENTORY : 指定 INVENTORY -s : sudo 为 root 执行 -m MODEL : 模块 -a ARGS : 模块参数 -vvvv : 输出详细信息.# 检测是否可以连接到服务器.$ ansible testserver -i hosts -m ping [-vvvv]# 查看服务器运行时间$ ansible testserver -i hosts -m command -a uptime# 参数中包含空格, 应该使用 引号 引起来.$ ansible testserver -i hosts -m command -a "tail /var/log/messages"# 安装 nginx 包$ ansible testserver -s -m apt -a name=nginx# 重启 nginx 服务$ ansible testserver -s -m service -a name=nginx state=restarted 2. ansible-docAnsible 模块的帮助文档. 12345678# 列出所有可用模块$ ansible-doc --list # 查看指定 模块的帮助$ ansible-doc MOD_NAME# 查看模块的示例$ ansible-doc MOD_NAME -s 3. ansible-galaxyansible-galaxy : 创建 role 初始文件和目录 3.1 创建初始 role 文件和目录$ ansible-galaxy init -p playbook/roles web -p /path/to/roles : 指定 roles 的目录, 未指定则为当前目录. 3.2 从 role 仓库中检索, 安装,删除 role.12345678910111213ansible-galaxy [delete|import|info|init|install|list|login|remove|search|setup] [--help] [options]# 检索$ ansible-galaxy search ntp# 安装$ ansible-galaxy install -p ./roles bennojoy.ntp# 列出$ ansible-galaxy list# 删除$ ansible-galaxy remove bennojoy.ntp 4 ansible-vaultansible-vault 用于创建和编辑加密文件, ansible-playbook 可以自动识别并使用密码解密这些文件. 4.1 ansible-vault 命令1234567891011121314151617$ ansible-vault [create|decrypt|edit|encrypt|encrypt_string|rekey|view] [--help] [options] vaultfile.yml SubCmd: - encrypt : 加密 - decrypt : 解密 - create : 创建 - edit : 编辑 - view : 查看 - rekey : 修改密码 Options: --ask-vault-pass : ask for vault password --new-vault-password-file=NEW_VAULT_PASSWORD_FILE : new vault password file for rekey --output=OUTPUT_FILE : output file name for encrypt or decrypt; use - for stdout --vault-password-file=VAULT_PASSWORD_FILE : vault password file -v, --verbose : verbose mode (-vvv for more, -vvvv to enable connection debugging) --version : show program's version number and exit 4.2 与playbook 结合的使用 在 playbook 中引用 vault 文件: 可以在 vars_file 区段像一般文件一样易用 vault 加密的文件. 即, 如果加密了一个 file 文件, 在 playbook 中也无需修改. ansible-playbook 使用用 --ask-value-pass 或 --vault-password-file 参数 $ ansible-playbook myplay.yml --ask-value-pass # password.file 可以为文本文件, 如果该为文件可执行脚本, 则 ansible 使用它的标准输出内容作为密码 $ ansible-playbook myplay.yml --vault-password-file /path/to/password.file 5. ansible-playbook5.1 命令行参数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091Usage: ansible-playbook playbook.ymlOptions: --ask-vault-pass ask for vault password -C, --check don't make any changes; instead, try to predict some of the changes that may occur -D, --diff when changing (small) files and templates, show the differences in those files; works great with --check -e EXTRA_VARS, --extra-vars=EXTRA_VARS set additional variables as key=value or YAML/JSON --flush-cache clear the fact cache --force-handlers run handlers even if a task fails -f FORKS, --forks=FORKS specify number of parallel processes to use (default=5) -i INVENTORY, --inventory-file=INVENTORY specify inventory host path (default=./hosts) or comma separated host list. -l SUBSET, --limit=SUBSET further limit selected hosts to an additional pattern --list-hosts outputs a list of matching hosts; does not execute anything else --list-tags list all available tags --list-tasks list all tasks that would be executed -M MODULE_PATH, --module-path=MODULE_PATH specify path(s) to module library (default=None) --new-vault-password-file=NEW_VAULT_PASSWORD_FILE new vault password file for rekey --output=OUTPUT_FILE output file name for encrypt or decrypt; use - for stdout --skip-tags=SKIP_TAGS only run plays and tasks whose tags do not match these values --start-at-task=START_AT_TASK start the playbook at the task matching this name --step one-step-at-a-time: confirm each task before running --syntax-check perform a syntax check on the playbook, but do not execute it -t TAGS, --tags=TAGS only run plays and tasks tagged with these values --vault-password-file=VAULT_PASSWORD_FILE vault password file -v, --verbose verbose mode (-vvv for more, -vvvv to enable connection debugging)Connection Options: control as whom and how to connect to hosts -k, --ask-pass ask for connection password --private-key=PRIVATE_KEY_FILE, --key-file=PRIVATE_KEY_FILE use this file to authenticate the connection -u REMOTE_USER, --user=REMOTE_USER connect as this user (default=root) -c CONNECTION, --connection=CONNECTION connection type to use (default=smart) -T TIMEOUT, --timeout=TIMEOUT override the connection timeout in seconds (default=10) --ssh-common-args=SSH_COMMON_ARGS specify common arguments to pass to sftp/scp/ssh (e.g. ProxyCommand) --sftp-extra-args=SFTP_EXTRA_ARGS specify extra arguments to pass to sftp only (e.g. -f, -l) --scp-extra-args=SCP_EXTRA_ARGS specify extra arguments to pass to scp only (e.g. -l) --ssh-extra-args=SSH_EXTRA_ARGS specify extra arguments to pass to ssh only (e.g. -R)Privilege Escalation Options: control how and which user you become as on target hosts -s, --sudo run operations with sudo (nopasswd) (deprecated, use become) -U SUDO_USER, --sudo-user=SUDO_USER desired sudo user (default=root) (deprecated, use become) -S, --su run operations with su (deprecated, use become) -R SU_USER, --su-user=SU_USER run operations with su as this user (default=root) (deprecated, use become) -b, --become run operations with become (does not imply password prompting) --become-method=BECOME_METHOD privilege escalation method to use (default=sudo), valid choices: [ sudo | su | pbrun | pfexec | doas | dzdo | ksu | runas ] --become-user=BECOME_USER run operations as this user (default=root) --ask-sudo-pass ask for sudo password (deprecated, use become) --ask-su-pass ask for su password (deprecated, use become) -K, --ask-become-pass ask for privilege escalation password 部分示例 -e var=valur : 传递变量给 playbook # 列出主机, 但不会执行 playbook $ ansible-playbook -i hosts --list-hosts web-tls.yml # 语法检查 $ ansible-playbook --syntax-check web-tls.yml # 列出 task, 但不会执行 playbook $ ansible-playbook -i hosts --list-tasks web-tls.yml # 检查模式, 会检测 playbook 中的每个任务是否会修改主机的状态, 但并不会对主机执行任何实际操作. # 需要注意 playbook 中的 task 中的依赖关系, 可能会报错. $ ansible-playbook [ -C | --check ] web-tls.yml # diff 将会为任何变更远程主机状态的文件输出差异信息. 与 --check 结合尤其好用. $ ansible-playbook [ -D | --diff ] playbook.yml 5.2 ansible-playbook 控制 task 的执行 step --step 参数会在执行每个 task 之前都做提示. $ ansible-playbook --step playbook.yml Perform task: install package (y/n/c) : y : 执行 n : 不执行, 跳过 c : 继续执行剩下 playbook , 并不再提示. start-at-task --start-at-task 用于让 ansible 从指定 task 开始运行 playbook, 而不是从头开始. 常用于 playbook 中存在 bug , 修复之后, 从bug处再次重新运行. tags ansible 允许对一个 task 或者 play 添加一个或多个 tags, 如: - hosts: myservers tags: - foo tasks: - name: install packages apt: name={{ item }} with_items: - vim - emacs - nano - name: run arbitrary command command: /opt/myprog tags: - bar - quux -t TAG_NAME 或 --tags TAG_NAME 告诉 ansible 仅允许具有指定 tags 的 task 或 play. --skip-tags TAG_NAME 告诉 ansible 跳过具有指定 tags 的 task 或者 play. # 仅允许指定 tags 的 task/play $ ansible-playbook -t foo,bar playbook.yml $ ansible-playbook --tags=foo,bar playbook.yml # 跳过指定 tags 的 task/play $ ansible-playbook --skip-tags=baz,quux playbook.yml 6. ansible-consoleREPL console for executing Ansible tasks $ ansible-console [&lt;host-pattern&gt;] [options] 7. ansible-configView, edit and manage ansible configuratin $ ansible-config [view|dump|list] [--help] [options] [ansible.cfg] 8. ansible-inventoryused to display or dump the configured inventory as Ansible sees it. $ ansible-inventory [options] [host|group] 9. ansible-pullpulls playbooks from a VCS repo and executes them for the local host. $ ansible-pull -U &lt;repository&gt; [options] [&lt;playbook.yml&gt;] 10. ansible 连接内网机器与跳板机设置原理 : 借用 ssh ProxyCommand 实现. $ vim ~/.ssh/config Host bastion User ansible # 修改为实际用户 HostName 10.6.17.110 # 配置当前主机到该主机(跳板机)的 ssh-key 认证. ProxyCommand none BatchMode yes Host 172.16.10.* ServerAliveInterval 60 TCPKeepAlive yes ProxyCommand ssh -qaY bastion 'nc -w 14400 %h %p' #or ProxyCommand ssh -W %h:%p bastion ControlMaster auto 六. ansible 优化加速1. SSH Multiplexing (ControlPersist)原理 : 第一次尝试 SSH 连接到远程主机时, OpenSSH 创建一个主链接 OpenSSH 创建一个 UNIX 域套接字(控制套接字), 通过主链接与远程主机相连接 在 ControlPersist 超时时间之内, 再次连接到该远程主机, OpenSSH 将使用控制套接字与远程主机通信, 而不创建新的 TCP 连接, 省去了 TCP 三次握手的时间. Ansible 支持的 SSH Multiplexing 选项列表: 选项 值 说明 ControlMaster auto 开启 ControlPersist ControlPath $HOME/.ansible/cp/ansible-ssh-%h-%p-%r UNIX 套接字文件存放路径, 操作系统对 套接字 的最大长度有限制, 所以太长的套接字, 则 ControlPersist 将不工作, 并且 Ansible 不会报错提醒. ControlPersist 60s SSH 套接字连接空闲时间, 之后关闭 如果启用了 SSH Multiplexing 设置, 并且变更了 SSH 连接的配置, 如修改了 ssh_args 配置项, 那么, 新配置对于之前连接打开的未超时的控制套接字不会生效. 2. fact 缓存2.1 关闭 fact 缓存# ansible.cfg [defaults] gathering=explicit 2.2 开启 fact 缓存请确保, playbook 中没有指定 gather_facts: True 或 gather_facts: False 配置项. # ansible.cfg [defaults] gathering=smart # 缓存过期时间, 单位 秒 fact_cache_timeout=86400 # 缓存实现机制. fact_caching=... 2.2.1 JSONansible 将fact 缓存写入到 JSON 文件中, Ansible 使用文件修改时间来决定fact 缓存是否过期. # ansible.cfg [defaults] gathering=smart # 缓存过期时间, 单位 秒 fact_cache_timeout=86400 fact_caching = jsonfile # 指定 fact 缓存文件保存目录 fact_caching_connection = /tmp/ansible_fact/cache 2.2.2 redis需要安装 redis 包, $ pip install redis;需要本机提供 redis 服务. # ansible.cfg [defaults] gathering=smart # 缓存过期时间, 单位 秒 fact_cache_timeout=86400 fact_caching = redis 2.2.3 memcache需要安装 python-memcached 包, $ pip install python-memcached;需要本机提供 memcached 服务. # ansible.cfg [defaults] gathering=smart # 缓存过期时间, 单位 秒 fact_cache_timeout=86400 fact_caching = memcached 2.3 希望在 playbook 运行之前清除 fact 缓存, 使用 --flush-cache 参数3. pipeline原理: 默认执行 task 步骤: 首先, 基于调用的 module 生成一个 python 脚本; 将 Python 脚本复制到远程主机; 最后, 执行 Python 脚本. 将产生两个 SSH 会话. pipeline 模式 : Ansible 执行 Python 脚本时, 并不复制他, 而是通过管道传递给 SSH 会话, 从而减少了 SSH 会话的数目, 节省时间. 配置: 控制主机开启 pipeline # ansible.cfg [defaults] pipeline=True 远程主机 /etc/sudoers 中的 requiretty 没有启用. Defaults: !requiretty 4. 并发 设置 ANSIBLE_FORKS 环境变量 修改 ansible.cfg 配置文件, forks = 20.]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible task/role/playbook]]></title>
    <url>%2F2018%2F03%2F15%2FAnsible-task-role-playbook%2F</url>
    <content type="text"><![CDATA[使用 Ansible task, role, playbook 定义任务, 实现自动化服务器管理. Ansible 学习总结 一. task1. name可选配置, 用于提示task 的功能. 另, ansible-playbook –start-at-task &lt;task_name&gt; 可以调用 name, 从 task 的中间开始执行. 2. 模块(功能)必选配置, 有模块的名称组成的 key 和 模块参数组成的 value.从 Ansible 前段所使用的 YAML 解析器角度看, 参数将被按照字符串处理, 而不是字典 apt: name=nginx update_cache=yes 3. 复杂参数:ansible 提供一个将模块调用分隔成多行的选择, 可以传递 key 为变量名的字典, 而不是传递字符串参数. 这种方式, 在调用拥有复杂参数的模块时, 十分有用. 如 ec2 模块. - name: install pip pkgs pip: name: &quot;{{ item.name }}&quot; version: &quot;{{ item.version }}&quot; virtualenv: &quot;{{ venv_path }}&quot; with_items: - {name: mazzanine, version: 3.1.10} - {name: gunicorn, version: 19.1.1} 4. environment : 设置环境变量传入包含变量名与值的字典, 来设置环境变量. - name: set the site id script: scripts/setsite.py environment: PATH: &quot;{{ venv_path }}/bin&quot; PROJECT_DIR: &quot;{{ proj_path }}&quot; ADMIN_PASS: &quot;{{ admin_pass }}&quot; 5. sudo, sudo_user切换到 root 或 其他用户执行 task. 6. notify触发 handler 任务. 7. when当 when 表达式返回 True 时, 执行该 task , 否则不执行. 8. local_action : 运行本地任务在控制主机本机上(而目标主机)执行命令. 如果目标主机为多台, 那么, local_action 执行的task 将执行多次, 可以指定 run_once , 来限制 local_action 的执行次数. 1234567891011# 调用 wait_for 模块 : 注: inventory_hostname 的值仍然是远程主机, 因为这些变量的范围仍然是远程主机, 即使 task 在本机执行.- name: wait for ssh server to be running local_action: wait_for port=22 host=&quot;&#123;&#123; inventory_hostname &#125;&#125;&quot; search_regex=OpenSSH# 调用 command 模块 - name: run local cmd hosts: all gather_facts: False tasks: - name: run local shell cmd local_action: command touch /tmp/new.txtxt 9. delegate_to: 在涉及主机之外的主机上运行 task使用场景: 在报警主机中, 启用基于主机的报警, 如 Nagios 向负载均衡器中, 添加一台主机, 如 HAProxy 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 配置 Nagios 示例, inventory_hostname 仍然指 web 主机, 而非 nagios_server.example.com .- name: enable alerts for web servers hosts: web tasks: - name: enable alerts nagios: action=enanle_alerts service=web host=&#123;&#123; inventory_hostname &#125;&#125; delegate_to: nagios_server.example.com---# This playbook does a rolling update for all webservers serially (one at a time).# Change the value of serial: to adjust the number of server to be updated.## The three roles that apply to the webserver hosts will be applied: common,# base-apache, and web. So any changes to configuration, package updates, etc,# will be applied as part of the rolling update process.## gather facts from monitoring nodes for iptables rules- hosts: monitoring tasks: []- hosts: webservers serial: 1 # These are the tasks to run before applying updates: pre_tasks: - name: disable nagios alerts for this host webserver service nagios: 'action=disable_alerts host=&#123;&#123; inventory_hostname &#125;&#125; services=webserver' delegate_to: "&#123;&#123; item &#125;&#125;" with_items: groups.monitoring - name: disable the server in haproxy haproxy: 'state=disabled backend=myapplb host=&#123;&#123; inventory_hostname &#125;&#125; socket=/var/lib/haproxy/stats' delegate_to: "&#123;&#123; item &#125;&#125;" with_items: groups.lbservers roles: - common - base-apache - web # These tasks run after the roles: post_tasks: - name: wait for webserver to come up wait_for: 'host=&#123;&#123; inventory_hostname &#125;&#125; port=80 state=started timeout=80' - name: enable the server in haproxy haproxy: 'state=enabled backend=myapplb host=&#123;&#123; inventory_hostname &#125;&#125; socket=/var/lib/haproxy/stats' delegate_to: "&#123;&#123; item &#125;&#125;" with_items: groups.lbservers - name: re-enable nagios alerts nagios: 'action=enable_alerts host=&#123;&#123; inventory_hostname &#125;&#125; services=webserver' delegate_to: "&#123;&#123; item &#125;&#125;" with_items: groups.monitoring 10. run_once : 值为 True/False该 task 是否只运行一次, 与 local_action 配合十分好用. 在生产应用发布时比较有用. 11. changed_when &amp; failed_when使用 changed_when 和 failed_when 语句改变 Ansible 对 task 是 chenged 状态还是 failed 状态的认定.需要了解命令的输出结果 - name: initialize the database django_manage: command: createdb --noinput --nodata app_path: &quot;{{ proj_path }}&quot; virtualenv: &quot;{{ venv_path }}&quot; register: result changed_when: not result.failed and &quot;Creating tables&quot; in result.out failed_when: result.failed and &quot;Database already created&quot; not in result.msg 12. 循环 名称 输入 循环策略 with_items 列表 对列表元素进行循环 with_lines 要执行的命令 对命令输出结果进行逐行循环 with_fileglob glob 对文件名进行循环 with_first_found 路径的列表 输入中第一个存在的文件 with_dict 字典 对字典元素进行循环 with_flattened 列表的列表 对所有列表的元素顺序循环 with_indexed_items 列表 单次迭代 with_nested 列表 循环嵌套 with_random_choice 列表 单次迭代 with_sequence 整数数组 对数组进行循环 with_subelements 字典的列表 嵌套循环 with_together 列表的列表 对多个列表并行循环 with_inventory_hostname 主机匹配模式 对匹配的主机进行循环 12.1 with_itemswith_items 用于对列表中的元素进行循环. 123456789- name: Send out a slack message user: name: &quot;&#123;&#123; item &#125;&#125;&quot; state: present groups: &quot;wheel&quot; with_items: - test1 - test2 - test3 12.2 with_lineswith_lines 循环结构允许在控制主机上执行任意命令, 并对命令的输出进行逐行迭代. 1234567- name: Send out a slack message slack: domain: example.slack.com token: &quot;&#123;&#123; slack_token &#125;&#125;&quot; msg: &quot;&#123;&#123; item &#125;&#125; was in the list&quot; with_lines: - cat /path/to/name.list 12.3 with_fileglobwith_fileglob 结构对于迭代控制主机上的一系列文件很有用. 12345- name: add public keys to account authorized_key: user=deploy key=&quot;&#123;&#123; lookup(&apos;file&apos;, item) &#125;&#125;&quot; with_fileglob: - /var/keys/*.pub - keys/*.pub 12.4 with_dictwith_dict 可以对字典而不是列表进行迭代. 当使用该结构时, item 循环变量是一个{&quot;key&quot;: some_key, &quot;value&quot;: some_value} 结构的字典. 1234567891011# ansibel_eth0&#123; &quot;address&quot;: &quot;10.0.2.15&quot;, &quot;netmask&quot;: &quot;255.255.255.0&quot;, &quot;network&quot;: &quot;10.0.2.0&quot;&#125;# task- name: iterate over ansible_eth0 debug: msg=&#123;&#123; item.key &#125;&#125;=&#123;&#123; item.value &#125;&#125; with_dict: ansible_etho.ipv4 12.5 with_sequence 以递增的数字顺序生成项序列1234567891011121314151617- hosts: all tasks: ## 创建组 - group: name=evens state=present - group: name=odds state=present ## 创建格式为testuser%02x 的0-32 序列的用户 - user: name=&#123;&#123; item &#125;&#125; state=present groups=evens with_sequence: start=0 end=32 format=testuser%02x ## 创建4-16之间得偶数命名的文件 - file: dest=/var/stuff/&#123;&#123; item &#125;&#125; state=directory with_sequence: start=4 end=16 stride=2 ## 简单实用序列的方法：创建4 个用户组分表是组group1 group2 group3 group4 - group: name=group&#123;&#123; item &#125;&#125; state=present with_sequence: count=4 12.6 with_random_choice 随机选择123456- debug: msg=&#123;&#123; item &#125;&#125; with_random_choice: - "go through the door" - "drink from the goblet" - "press the red button" - "do nothing" 13. tags用于为 task 做逻辑区分 或功能区分, 提供对 task 细粒度的执行控制.特殊 tagsansible内置的特殊tags：always、tagged、untagged、all 是四个系统内置的tag，有自己的特殊意义 always : 指定这个 tag 后，task任务将永远被执行，而不用去考虑是否使用了–skip-tags标记 tagged : 当 --tags 指定为它时，则只要有tags标记的task都将被执行,--skip-tags 效果相反 untagged : 当 --tags 指定为它时，则所有没有tag标记的task 将被执行, --skip-tags效果相反 all: 默认tag, 无需指定，ansible-playbook 默认执行的时候就是这个标记.所有task都被执行系统中内置的特殊tags： 二. playplay 可以想象为连接到主机(host)上执行任务(task)的事务. 选项: hosts : 必选配置, 需要配置的一组主机 控制主机执行顺序order. order 可用参数: inventory: 默认参数, 按照 inventory 提供的顺序 reverse_inventory: 逆序 inventory sorted: 按字母大小排序 reverse_sorted: 按字母大小逆序 shuffle: 随机 12345- hosts: all order: sorted gather_facts: False tasks: - debug: var=inventory_hostname task : 必选配置, 需要在主机上执行的任务 name : 可选配置, 一段注释, 用来描述 play 的功能, ansible 在 play 开始执行的时候, 会把 name 打印出来. sudo : 可选配置, 如果为真, ansible 会在运行每个 task 的时候, 都是用 sudo 命令切换为 (默认) root. vars : 可选配置, 变量与其值组成的列表. 任何合法的 YAML 对象都可以作为变量的值. 变量不仅可以在 tasks 中使用, 还可以在 模板文件 中使用. vars_files : 可选, 把变量放到一个或者多个文件中. gather_facts : 是否收集 fact. handlers : 可选, ansible 提供的 条件机制, 和 task 类似, 但只有在被 task 通知的时候才会运行. 如果 ansible 识别到 task 改变了系统的状态, task 就会触发通知机制. task 将 handler 的名字作为参数传递, 依此来通知 handler. handler 只会在所有任务执行完成之后执行, 而且即使被通知了多次, 也只会执行一次. handler 按照play 中定义的顺序执行, 而不是被通知的顺序. handler 常见的用途就是重启服务和重启服务器. ansible verion &gt; 2.2 之后, 支持 将多个 handler task 注册为一个组, 从而支持对改组的操作, 如下面示例中的 restart web service 123456789101112handlers: - name: restart memcached service: name=memcached state=restarted listen: &quot;restart web services&quot; - name: restart apache service: name=apache state=restarted listen: &quot;restart web service&quot; tasks: - name: restart everything command: echo &quot;this task will restart web service&quot; notify: &quot;restart web service&quot; serial, max_fail_percentage 默认情况下, Ansible 会并行的在所有相关联主机上执行每一个 task. 可以使用 serial 限制并行执行 play 的主机数量. 一般来说, 当 task 失败时, Ansible 会停止执行失败的那台主机上的任务, 但是继续对其他主机执行. 在负载均衡场景中, 可能希望 Ansible 在所有主机都发生失败前让整个 play 停止执行, 否则将会导致, 所有主机都从 负载均衡器上移除, 并且全部执行失败, 最终负载均衡器上没有任何主机的局面. 此时, 可以使用 serial 和 max_fail_percentage 语句来指定, 最大失败主机比例达超过 max_fail_percentage 时, 让整个 play 失败. 如果希望 Ansible 在任何主机出现 task 执行失败的时候, 都放弃执行, 则需要设置max_fail_percentage=0. - name: upgrade packages on servers behind load balancer hosts: myhosts serial: 1 max_fail_percentage: 25 tasks: - name: get the ec2 instance id and elastic load balancer id ec2_facts: - name: task the out of the elastic load balancer local_action: ec2_elb args: instance_id: &quot;{{ ansible_ec2_instance_id }}&quot; state: absent - name: upgrade packages apt: update_cache=yes upgrade=yes - name: put the host back in the elastic load balancer local_action: ec2_elb args: instance_id: &quot;{{ ansible_ec2_instance_id }}&quot; state: present ec2_elbs: &quot;{{ item }}&quot; with_items: ec2_elbs roles : 指定要执行的 role 名称, 可以添加 tags, 变量等参数. pre-task post-task 三. rolerole 是将 playbook 分隔为多个文件的主要机制, 他大大简化了复杂 playbook 的编写, 同时使得 role 更加易于复用. 1. role 的基本构成.每个 role 都会用一个名字, 如 ‘database’, 与该 role 相关的文件都放在 roles/database 目录下. 其结构如下: 每个单独文件都是可选的 task task 定义 roles/database/tasks/main.yml files 需要上传到目标主机的文件: roles/database/files/ templates Jinja2 模板文件. Jinja2 Doc roles/database/templates handlers handler roles/database/handler/main.yml vars 不应被覆盖的变量 roles/database/vars/main.yml defaults 可以被覆盖的默认变量 roles/database/default/main.yml meta role 的依赖信息 roles/database/meta/main.yml default 变量与 vars 变量: default : 希望在 role 中变更变量的值. vars : 不希望变量的值变更. role 中变量命名的一个良好实践: 变量建议以 role 的名称开头, 因为在 Ansible 中不同的 role 之间没有命名空间概念, 这意味着在其他 role 中定义的变量, 或者再 playbook 中其他地方定义的变量, 可以在任何地方被访问到. 如果在两个不同的 role 中使用了同名的变量, 可能导致意外的行为. 2. role 的存放位置 playbook 并列的 roles 目录下; /etc/ansible/roles/ 下 ansible.cfg 中 default 段 roles_path 指向的位置 环境变量 ANSIBLE_ROLES_PATH 指向的位置 3. 在 playbook 中使用 role# mezzaning-single-host.yml - name: deploy mezzanine on vagrant hosts: web vars_file: - secrets.yml roles: - role: database database_name: &quot;{{ mezzanine_proj_name }}&quot; # 定义覆盖变量 database_pass: &quot;{{ mezzanine_proj_name }}&quot; # 定义覆盖变量 - role: mezzanine live_hostname: 192.168.33.10.xip.io domains: - 192.168.33.10.xip.io - www.192.168.33.10.xip.io # mezzaning-across-host.yml - name: deploy postgres vagrant hosts: db vars_files: - secrets.yml roles: - role: database database_name: &quot;{{ mezzanine_proj_name }}&quot; # 定义覆盖变量 database_pass: &quot;{{ mezzanine_proj_name }}&quot; # 定义覆盖变量 - name: deploy mezzanine on vagrant hosts: web vars_files: - secrets.yml roles: - role: mezzanine database_host: &quot;{{ hostvars.db.ansible_eth1.ipv4.address }}&quot; live_hostname: 192.168.33.10.xip.io domains: - 192.168.33.10.xip.io - www.192.168.33.10.xip.io 4. pre-task &amp; post-taskpre-task : 定义在 role 执行之前, 执行的 taskpost-task : 定义在 role 执行之后, 执行的 task. - name: deploy mezzanine on vagrant hosts: web vars_files: - secrets.yml pre_tasks: - name: update the apt cache apt: update_cache=yes roles: - role: mezzanine database_host: &quot;{{ hostvars.db.ansible_eth1.ipv4.address }}&quot; live_hostname: 192.168.33.10.xip.io domains: - 192.168.33.10.xip.io - www.192.168.33.10.xip.io post_tasks: - name: notify Slack that the servers have been updated local_action:&gt; slack domain=acme.slack.com token={{ slack_token }} msg=&quot;web server {{ inventory_hostname }} configured&quot; 5. inclued用于调用位于同一目录下的其他 定义文件, 可用于 Tasks,Playbook, Vars, Handler, Files 等. # task example --- - name: install apt packages apt: pkg={{ item }} update_cache=yes cache_valid_time=3600 sudo: True with_items: - git - libjpeg-dev - libpq-dev - memcached - nginx - include: django.yml - include: nginx.yml # example 2 --- - name: check host environment include: check_environment.yml - name: include OS family/distribution specific variables include_vars: &quot;{{ item }}&quot; with_first_found: - &quot;../defaults/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml&quot; - &quot;../defaults/{{ ansible_distribution | lower }}.yml&quot; - &quot;../defaults/{{ ansible_os_family | lower }}.yml&quot; - name: debug variables include: debug.yml tags: - debug 6. ansible-galaxy : 创建 role 初始文件和目录 创建初始 role 文件和目录 $ ansible-galaxy init -p playbook/roles web -p /path/to/roles : 指定 roles 的目录, 未指定则为当前目录. 从 role 仓库中检索, 安装,删除 role. ansible-galaxy [delete|import|info|init|install|list|login|remove|search|setup] [--help] [options] 检索 $ ansible-galaxy search ntp 安装 $ ansible-galaxy install -p ./roles bennojoy.ntp 列出 $ ansible-galaxy list 删除 $ ansible-galaxy remove bennojoy.ntp 在线网站 https://galaxy.ansible.com 7. dependent role:dependent role 用于指定 role 依赖的其他一个或多个 role, Ansible 会确保被指定依赖的role 一定会优先被执行. Ansible 允许向 dependent role 传递参数 dependent role 一般在 myrole/meta/main.yml 中指定. # roles/web/meta/main.yml dependencies: - { role: ntp, ntp_server=ntp.ubuntu.com } - { role: common } - { role: memcached } 四. playbook : 用于实现 ansible 配置管理的脚本.playbook 其实就是一个字典组成的列表. 一个 playbook 就是一组 play 组成的列表. 一个 play 由 host 的无序集合与 task 的有序列表组成. 每一个 task 由一个模块构成. ansible 中的 True/False 和 yes/no模块参数(如 update_cache=yes)对于值的处理, 使用字符串传递: 真值 yes,on,1,true 假值 no,off,0,false 其他使用 YAML 解析器来处理: 真值 true,True,TRUE,yes,Yes,YES,on,On,ON,y,Y 假值 false,False,FALSE,no,No,NO,off,Off,OFF,n,N 推荐做法: 模块参数: yes/no 其他地方: True,False playbook 文件的执行方法: 使用 ansible-playbook 命令 $ ansible-playbook myplaybook.yml shebang $ chmod +x myplaybook.yml $ head -n 1 myplaybook.yml #!/usr/bin/env ansible-playbook $ ./myplaybook.yml 当 Ansible 开始运行 playbook 的时候, 他做的第一件事就是从他连接到的服务器上收集各种信息. 这些信息包括操作系统,主机名,网络接口等. 建立 nginx web 服务器$ cat web-notls.yml - name: Configure webserver with nginx and tls hosts: webservers sudo: true vars: key_file: /etc/nginx/ssl/nginx.key cert_file: /etc/nginx/ssl/nginx.crt conf_file: /etc/nginx/sites-available/default server_name: localhost tasks: - name: install nginx apt: name=nginx update_cache=yes cache_valid_time=3600 - name: create directories for ssl certificates file: path=/etc/nginx/ssl state=directory - name: copy TLS key copy: src=files/nginx.key desc={{ key_file }} owner=root mode=06-- notify: restart nginx - name: copy TLS certificate copy: src=files/nginx.crt dest={{ cert_file }} notify: restart nginx - name: copy nginx config file copy: src=files/nginx.conf.j2 dest={{ conf_file }} notify: restart nginx - name: enable configuration file: dest=/etc/nginx/sites-enabled/default src={{ conf_file }} state=link notify: restart nginx - name: copy index.html template: src=templates/index.html.j2 dest=/usr/share/nginx/html/index.html mode=0644 handlers: - name: restart nginx service: name=nginx state=restarted 内部变量 ansible_managed : 和模板文件生成时间相关的信息. inventory 文件使用 .ini 格式, 默认为 hosts 文件. [webservers] testserver ansible_ssh_host=127.0.0.1 ansible_ssh_port=22 YAML 文件格式 文件开始. --- 如果没有---标记, 也不影响 ansible 的运行. 注释: # 字符串 : 即使字符串中有空格, 也无需使用引号. 布尔型 : 有多种, 推荐使用 True/False 列表: 使用-作为分隔符 标准列表 - My Fair Lady - Oklahoma - The Pirates of Penzance 内联式列表 [My Fair Lady, Oklahoma, The Pirates of Penzance] 字典: 标准字典 name: tom age: 12 job: manager 内联式字典 {name: tom, age: 12, job: manager} 折行: 使用大于号(&gt;)表示折行 支持变量引用: admin_name: &quot;amdin&quot; admin_email: &quot;{{ admin_name }}@example.com&quot;]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible-配置文件]]></title>
    <url>%2F2018%2F03%2F15%2FAnsible-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Ansible 学习总结 ansible 配置文件 : ansible.cfg, ansible 使用如下位置和顺序来查找 ansible.cfg 文件 ANSIBLE_CONFIG 环境变量指向的文件 ./ansible.cfg ~/.ansible.cfg /etc/ansible/ansible.cfg ansible.cfg 有 defaults, ssh_connection, paramiko, accelerate四个配置段. 一. defaults 段 配置名称 环境变量 默认值 hostfile ANSIBLE_HOSTS /etc/ansible/hosts library ANSIBLE_LIBRARY (none) roles_path ANSIBLE_ROLES_PATH /etc/ansible/roles remote_tmp ANSIBLE_REMOTE_TEMP $HOME/.ansible/tmp module_name (none) command pattern (none) * forks ANSIBLE_FORKS 5 module_args ANSIBLE_MODULE_ARGS (empty string) module_lang ANSIBLE_MODULE_LANG en_US.UTF-8 timeout ANSIBLE_TIMEOUT 10 poll_interval ANSIBLE_POLL_INTERVAL 15 remote_user ANSIBLE_REMOTE_USER current user ask_pass ANSIBLE_ASK_PASS false private_key_file ANSIBLE_PRIVATE_KEY_FILE (none) sudo_user ANSIBLE_SUDO_USER root ask_sudo_pass ANSIBLE_ASK_SUDO_PASS false remote_port ANSIBLE_REMOTE_PORT (none) ask_vault_pass ANSIBLE_ASK_VAULT_PASS false vault_password_file ANSIBLE_VAULT_PASSWORD_FILE (none) ansible_managed (none) Ansible managed: { file} modi ed on %Y-%m-%d %H:%M:%S by {uid} on {host} syslog_facility ANSIBLE_SYSLOG_FACILITY LOG_USER keep_remote_ les ANSIBLE_KEEP_REMOTE_FILES true sudo ANSIBLE_SUDO false sudo_exe ANSIBLE_SUDO_EXE sudo sudo_flags ANSIBLE_SUDO_FLAGS -H hash_behaviour ANSIBLE_HASH_BEHAVIOUR replace jinja2_extensions ANSIBLE_JINJA2_EXTENSIONS (none) su_exe ANSIBLE_SU_EXE su su ANSIBLE_SU false su_flags ANSIBLE_SU_FLAGS (empty string) su_user ANSIBLE_SU_USER root ask_su_pass ANSIBLE_ASK_SU_PASS false gathering ANSIBLE_GATHERING implicit action_plugins ANSIBLE_ACTION_PLUGINS /usr/share/ansible_plugins/action_plugins cache_plugins ANSIBLE_CACHE_PLUGINS /usr/share/ansible_plugins/cache_plugins callback_plugins ANSIBLE_CALLBACK_PLUGINS /usr/share/ansible_plugins/callback_plugins connection_plugins ANSIBLE_CONNECTION_PLUGINS /usr/share/ansible_plugins/connection_plugins lookup_plugins ANSIBLE_LOOKUP_PLUGINS /usr/share/ansible_plugins/lookup_plugins vars_plugins ANSIBLE_VARS_PLUGINS /usr/share/ansible_plugins/vars_plugins filter_plugins ANSIBLE_FILTER_PLUGINS /usr/share/ansible_plugins/ lter_plugins log_path ANSIBLE_LOG_PATH (empty string) fact_caching ANSIBLE_CACHE_PLUGIN memory fact_caching_connection ANSIBLE_CACHE_PLUGIN_CONNECTION (none) fact_caching_prefix ANSIBLE_CACHE_PLUGIN_PREFIX ansible_facts fact_caching_timeout ANSIBLE_CACHE_PLUGIN_TIMEOUT 86400 (seconds) force_color ANSIBLE_FORCE_COLOR (none) nocolor ANSIBLE_NOCOLOR (none) nocows ANSIBLE_NOCOWS (none) display_skipped_hosts DISPLAY_SKIPPED_HOSTS true error_on_unde ned_vars ANSIBLE_ERROR_ON_UNDEFINED_VARS true host_key_checking ANSIBLE_HOST_KEY_CHECKING true system_warnings ANSIBLE_SYSTEM_WARNINGS true deprecation_warnings ANSIBLE_DEPRECATION_WARNINGS true callable_whitelist ANSIBLE_CALLABLE_WHITELIST (empty list) command_warnings ANSIBLE_COMMAND_WARNINGS false bin_ansible_callbacks ANSIBLE_LOAD_CALLBACK_PLUGINS false 示例:123456[defaults]hostfile = hostsremote_user = ec2-userprivate_key_file = /path/to/my_private_keyhost_key_checking = False # 关闭 host key 检查.forks = 20 二. ssh_connection 段 配置名称 环境变量 默认值 ssh_args ANSIBLE_SSH_ARGS -o ControlMaster=auto -o ControlPersist=60s -o ControlPath=&quot;$ANSIBLE_SSH_CONTROL_PATH” control_path ANSIBLE_SSH_CONTROL_PATH %(directory)s/ansible-ssh-%%h-%%p-%%r pipelining ANSIBLE_SSH_PIPELINING false scp_if_ssh ANSIBLE_SCP_IF_SSH false 三. paramiko 段 配置名称 环境变量 默认值 record_host_keys ANSIBLE_PARAMIKO_RECORD_HOST_KEYS true pty ANSIBLE_PARAMIKO_PTY true 四. accelerate 段不推荐使用.]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible-API]]></title>
    <url>%2F2018%2F03%2F15%2FAnsible-API%2F</url>
    <content type="text"><![CDATA[ansible api 开发篇Ansible 学习总结 ansible api Callbacks Inventory Playbook Script https://segmentfault.com/a/1190000008009639 https://serversforhackers.com/c/running-ansible-2-programmatically]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible-模块]]></title>
    <url>%2F2018%2F03%2F15%2FAnsible-%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[Ansible 常用模块使用方法 自定义 Ansible 模块 Ansible 学习总结 一. 内置模块是由 ansible 包装后, 在主机上执行一系列操作的脚本. 1. 查看模块帮助$ ansible-doc MOD_NAME 2. 查找第三方模块$ ansible-galaxy search MOD_NAME 3. 常用模块Ansible 模块索引 apt update_cache=yes 在安装软件之前, 首先更新 repo 缓存. cache_valid_time=3600 上次 repo 缓存的有效时间. upgrade=yes pipAnsible 的 pip 模块支持向 virtualenv 中安装软件包, 并且还支持在没有可用的 virtualenv 时, 自动创建一个. - name: install required python packages pip: name={{ item }} virtualenv={{ venv_path }} with_items: - gunicorn - django - django-compressor 支持 requirements 文件 - name: install required python pkg pip: requirements={{ proj_path }}/{{ reqs_file }} virtualenv={{ venv_path }} Options : chdircd into this directory before running the command [Default: None] editablePass the editable flag for versioning URLs. [Default: True] executableThe explicit executable or a pathname to the executable to be used to run pip for a specific version of Python installed in the system. For example `pip-3.3&apos;, if there are both Python 2.7 and 3.3 installations in the system and you want to run pip for the Python 3.3 installation. It cannot be specified together with the &apos;virtualenv&apos; parameter (added in 2.1). By default, it will take the appropriate version for the python interpreter use by ansible, e.g. pip3 on python 3, and pip2 or pip on python 2. [Default: None] extra_argsExtra arguments passed to pip. [Default: None] nameThe name of a Python library to install or the url of the remote package. As of 2.2 you can supply a list of names. [Default: None] requirementsThe path to a pip requirements file, which should be local to the remote system. File can be specified as a relative path if using the chdir option. [Default: None] stateThe state of module The &apos;forcereinstall&apos; option is only available in Ansible 2.1 and above. (Choices: present, absent, latest, forcereinstall)[Default: present] umaskThe system umask to apply before installing the pip package. This is useful, for example, when installing on systems that have a very restrictive umask by default (e.g., 0077) and you want to pip install packages which are to be used by all users. Note that this requires you to specify desired umask mode in octal, with a leading 0 (e.g., 0077). [Default: None] versionThe version number to install of the Python library specified in the `name&apos; parameter [Default: None] virtualenvAn optional path to a `virtualenv&apos; directory to install into. It cannot be specified together with the &apos;executable&apos; parameter (added in 2.1). If the virtualenv does not exist, it will be created before installing packages. The optional virtualenv_site_packages, virtualenv_command, and virtualenv_python options affect the creation of the virtualenv. [Default: None] virtualenv_commandThe command or a pathname to the command to create the virtual environment with. For example `pyvenv&apos;, `virtualenv&apos;, `virtualenv2&apos;, `~/bin/virtualenv&apos;, `/usr/local/bin/virtualenv&apos;. [Default: virtualenv] virtualenv_pythonThe Python executable used for creating the virtual environment. For example `python3.5&apos;, `python2.7&apos;. When not specified, the Python version used to run the ansible module is used. [Default: None] virtualenv_site_packagesWhether the virtual environment will inherit packages from the global site-packages directory. Note that if this setting is changed on an already existing virtual environment it will not have any effect, the environment must be deleted and newly created. (Choices: yes, no)[Default: no] copyfileservicetemplatesetup实现 fact 收集的模块. 一般无需再 playbook 中调用该模块, Ansible 会在采集 fact 时, 自动调用. $ ansible server_name -m setup -a &#39;filter=ansible_eth*&#39; 其返回值为一个字典, 字典的 key 是 ansible_fact, 他的 value 是一个有实际 fact 的名字与值组成的字典. setup 模块支持 filter 参数, 可以实现 shell 通配符的匹配过滤. - name: gather facts setup: set_fact使用 set_fact 模块在 task 中设置 fact(与定义一个新变量是一样的). 可以在 register 关键字后, 立即使用 set_fact , 这样使得变量引用更简单. - name: get snapshot id shell: &gt; aws ec2 describe-snapshot --filters Name=tag:Name, Valuse=my-snapshot | jq --raw-outpuy &quot;.Snapshots[].SnapshtId&quot; register: snap_result - set_fact: snap={{ snap_result.stdout }} - name: delete old snapshot command: aws ec2 delete-snapshot --snapshot-id &quot;{{ snap }}&quot; command在 command 中保持幂等性的方法: 指定 creates 参数. # 当 Vagrantfile 存在, 则表示已经处于正确状态, 而且不需要再次执行命令, 从而实现幂等性. - name: create a vagrantfile command: vagrant init {{ box }} creates=Vagrantfile 官方文档: - creates a filename or (since 2.0) glob pattern, when it already exists, this step will *not* be run. [Default: None] - removes a filename or (since 2.0) glob pattern, when it does not exist, this step will *not* be run. [Default: None] script实现幂等性方法: creates 和 removes 参数. 官方文档: - creates a filename, when it already exists, this step will *not* be run. [Default: None] - removes a filename, when it does not exist, this step will *not* be run. [Default: None] debug&gt; DEBUG (/opt/virtualEnv/ansibleEnv/lib/python2.7/site-packages/ansible/modules/utilities/logic/debug.py) This module prints statements during execution and can be useful for debugging variables or expressions without necessarily halting the playbook. Useful for debugging together with the &apos;when:&apos; directive. * note: This module has a corresponding action plugin. Options (= is mandatory): - msg The customized message that is printed. If omitted, prints a generic message. [Default: Hello world!] - var A variable name to debug. Mutually exclusive with the &apos;msg&apos; option. [Default: (null)] - verbosity A number that controls when the debug is run, if you set to 3 it will only run debug when -vvv or above [Default: 0] EXAMPLES: # Example that prints the loopback address and gateway for each host - debug: msg: &quot;System {{ inventory_hostname }} has uuid {{ ansible_product_uuid }}&quot; - debug: msg: &quot;System {{ inventory_hostname }} has gateway {{ ansible_default_ipv4.gateway }}&quot; when: ansible_default_ipv4.gateway is defined - shell: /usr/bin/uptime register: result - debug: var: result verbosity: 2 - name: Display all variables/facts known for a host debug: var: hostvars[inventory_hostname] verbosity: 4 postgresql_userpostgresql_dbdjango_managecron# 安装 cron job, 注意 name 参数, 该参数必须要有, 该参数将用于删除计划任务时所使用的名称. - name: install poll twitter cron job cron: name=&quot;Poll twitter&quot; minute=&quot;*/5&quot; user={{ user }} job=&quot;{{ manage }} poll_twitter&quot; # 删除计划任务, 基于 name 参数, 在删除时, 会连带注释一起删掉. - name: remote cron job cron: name=&quot;Poll twitter&quot; state=absent git- name: check out the repository on the host git: repo={{ repo_url }} dest={{ proj_path }} accept_host_key=yes wait_forYou can wait for a set amount of time `timeout’, this is the default if nothing is specified. Waiting for a port to become available is useful for when services are not immediately available after their init scripts return which is true of certain Java application servers. It is also useful when starting guests with the [virt] module and needing to pause until they are ready. This module can also be used to wait for a regex match a string to be present in a file. In 1.6 and later, this module can also be used to wait for a file to be available or absent on the filesystem. In 1.8 and later, this module can also be used to wait for active connections to be closed before continuing,useful if a node is being rotated out of a load balancer pool. Options: active_connection_statesThe list of tcp connection states which are counted as active connections [Default: [u&apos;ESTABLISHED&apos;, u&apos;SYN_SENT&apos;, u&apos;SYN_RECV&apos;, u&apos;FIN_WAIT1&apos;, u&apos;FIN_WAIT2&apos;, u&apos;TIME_WAIT&apos;]] connect_timeoutmaximum number of seconds to wait for a connection to happen before closing and retrying [Default: 5] delaynumber of seconds to wait before starting to poll [Default: 0] exclude_hostslist of hosts or IPs to ignore when looking for active TCP connections for `drained&apos; state [Default: None] hostA resolvable hostname or IP address to wait for [Default: 127.0.0.1] pathpath to a file on the filesytem that must exist before continuing [Default: None] portport number to poll [Default: None] search_regexCan be used to match a string in either a file or a socket connection. Defaults to a multiline regex. [Default: None] sleepNumber of seconds to sleep between checks, before 2.3 this was hardcoded to 1 second. [Default: 1] stateeither `present&apos;, `started&apos;, or `stopped&apos;, `absent&apos;, or `drained&apos; When checking a port `started&apos; will ensure the port is open, `stopped&apos; will check that it is closed, `drained&apos; will check for active connections When checking for a file or a search string `present&apos; or `started&apos; will ensure that the file or string is present before continuing, `absent&apos; will check that file is absent or removed (Choices: present, started, stopped, absent, drained)[Default: started] timeoutmaximum number of seconds to wait for [Default: 300] wait_for_connection : 默认超时时间 600s Waits until remote system is reachable/usable 等待目标主机可以成为 reachable/usable 状态, 即 ssh 22 端口可以连通. - name: Wait 300 seconds, but only start checking after 60 seconds wait_for_connection: delay: 60 # 等待 60s 之后执行 本task timeout: 300 # 超时时间, 默认300s sleep: 2 # 在检查期间, 每次检查之间的间隔时间, 默认为 1s - name: Wait 600 seconds for target connection to become reachable/usable wait_for_connection: wait_for : Waits for a condition before continuing 等待某个主机或端口可用, 适用范围比 wait_for_connection 更加广泛. 可以在本机或目标主机检查其他或本地主机的端口,. - name: Wait 300 seconds for port 22 to become open wait_for: port: 22 sleep: 3 # A resolvable hostname or IP address to wait for. host: &apos;{{ (ansible_ssh_host|default(ansible_host))|default(inventory_hostname) }}&apos; # Can be used to match a string in either a file or a socket connection. search_regex: OpenSSH timeout: 300 # This overrides the normal error message from a failure to meet the required conditions. msg: Timeout to connect through OpenSSH # Either present, started, or stopped, absent, or drained. # When checking a port started will ensure the port is open, stopped will check that it is closed, drained will check for active connections. # When checking for a file or a search string present or started will ensure that the file or string is present before continuing, absent will check that file is absent or removed. state: drained # List of hosts or IPs to ignore when looking for active TCP connections for drained state. exclude_hosts: 10.2.1.2,10.2.1.3 delegate_to: localhost - name: Wait until the process is finished and pid was destroyed wait_for: # Path to a file on the filesystem that must exist before continuing. path: /proc/3466/status state: absent lineinfilestat收集关于文件路径状态的各种信息, 返回一个字典, 该字典包含一个 stat 字段. 部分字段返回值表: 字段 描述 dev inode 所在设备 ID 编号 gid 路径的所属组 ID 编号 inode inode 号 mode 字符串格式的八进制文件模式,如 1777 atime 路径的最后访问时间, 使用 UNIX 时间戳 ctime 路径的创建时间, 使用 UNIX 时间戳, 文件元数据变更时间 mtime 路径的最后修改时间, 使用 UNIX 时间戳 , 文件内容修改时间. nlink 文件硬链接的数量 pw_name 文件所属者的登录名 size 如果是文件, 返回字节单位的文件大小 uid 路径所属者的 uid isblk 如果路径为指定块设备文件, 返回 true ischr 如果路径为指定字符设备文件,返回 true isdir 如果路径为目录, 返回 true isfifo 如果路径为 FIFO(管道), 返回 true isgid 如果文件设置了 setgid , 返回 true isuid 如果文件设置了 setuid , 返回 true islnk 如果文件时符号链接, 返回 true isreg 如果路径是常规文件, 返回 true issock 如果路径是UNIX 域socket, 返回 true rgrp 如果设置所属组可读权限, 返回 true roth 如果设置其他人可读权限, 返回 true rusr 如果设置了属主可读权限, 返回 true wgrp 如果设置所属组可写权限, 返回 true woth 如果设置所属组可写权限, 返回 true wusr 如果设置所属组可写权限, 返回 true xgrp 如果设置所属组可执行权限, 返回 true xoth 如果设置所属组可执行权限, 返回 true xusr 如果设置所属组可执行权限, 返回 true exists 如果存在, 返回 true md5 文件的 md5 值 checksum 文件的hash 值, 可以设置 sha 算法. assertassert 模块在指定的条件不符合是,返回错误, 并失败退出. 主要用于调试.that : 后跟计算表达式msg : 失败后的提示信息. - name: stat /opt/foo stat: path=/opt/foo register: st - name: assert that /opt/foo is a directory assert: that: st.stat.isdir ------- - assert: that: - &quot;my_param &lt;= 100&quot; - &quot;my_param &gt;= 0&quot; msg: &quot;&apos;my_param&apos; must be between 0 and 100&quot; 二. 自定义模块自定义模块存放路径: playbooks/library 1. 使用 script 自定义 模块2. 使用 Python 自定义模块.]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible-变量]]></title>
    <url>%2F2018%2F03%2F15%2FAnsible-%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[摘要 Ansible 学习总结 在 Ansible 中, 变量的作用域是按照主机划分的, 只有针对特定主机讨论变量的值才有意义. 一. 变量1. 定义变量vars : 定义变量的列表或字典vars_file : 指定 定义变量的文件列表 vars 区段的定义, 实际上是在 当前 play 中针对一组主机定义了变量, 但 Ansible 实际做法其实时, 对这个群组的每一个主机创建一个变量的副本. ansible 允许定义于主机或群组有关的变量, 这些变量可以定义在 inventory 文件中, 也可以定义在与 inventory 文件放在一起的独立文件中. Ansible 变量定义位置 变量标识 描述 vars playbook 区段, 为字典列表 vars_file playbook 区段, 为指向文件的列表 host_vars 目录, 主机变量 group_vars 目录, 群组变量 主机变量 inventory中, 单独针对主机的变量 群组变量 inventory中, 单独针对单个群组的变量 2. 显示变量: debug 模块- debug: var=myvarname 3. register 注册变量: 基于 task 的执行结果, 设置变量的值.示例: - name: Run MyProg command: /opt/myprog register: result ignore_errors: True - debug: var=result ignore_errors 语句, 可以实现, 在 task 失败的时候, 是否忽略错误, 继续执行下面的 task, 默认为 False. 访问变量中字典的key, 有两种方式: { { login.stdout } } { { ansible_eth1[&quot;ipv4&quot;][&quot;address&quot;] } } 当 task 在目标主机, 没有执行命令时, 即当目标主机已经符合目标结果时, 输出中没有 stdout,stderr,stdout_lines 三个键值. 如果在 playbook 中使用了注册变量, 那么无论模块是否改变了主机的状态, 请确保你了解变量的内容, 否则, 当你的 playbook 尝试访问注册变量中不存的 key时, 可能会导致失败. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105# 注册变量, 并判断变量的值- hosts: testservers remote_user: root tasks: - name: ls /nono shell: /bin/ls /nono register: result ignore_errors: True - name: test result copy: content=&quot;ok&quot; dest=/tmp/test when: result.rc == 0 - name: test no result copy: content=&quot;no ok&quot; dest=/tmp/test when: result.rc != 0# jinja2 过滤器格式tasks: - command: /bin/false register: result ignore_errors: True - command: /bin/something when: result|failed - command: /bin/something_else when: result|succeeded - command: /bin/still/something_else when: result|skipped# 字符串转换为数字之后, 再去判断tasks: - shell: echo &quot;only on Red Hat 6, derivatives, and later&quot; when: ansible_os_family == &quot;RedHat&quot; and ansible_lsb.major_release|int &gt;= 6# 判断变量是否定义tasks: - shell: echo &quot;I&apos;ve got &apos;&#123;&#123; foo &#125;&#125;&apos; and am not afraid to use it!&quot; when: foo is defined - fail: msg=&quot;Bailing out. this play requires &apos;bar&apos;&quot; when: bar is undefined# 与循环结合使用tasks: - command: echo &#123;&#123; item &#125;&#125; with_items: [ 0, 2, 4, 6, 8, 10 ] when: item &gt; 5- command: echo &#123;&#123; item &#125;&#125; with_items: &quot;&#123;&#123; mylist|default([]) &#125;&#125;&quot; when: item &gt; 5- command: echo &#123;&#123; item.key &#125;&#125; with_dict: &quot;&#123;&#123; mydict|default(&#123;&#125;) &#125;&#125;&quot; when: item.value &gt; 5# roles 包含 when- include: tasks/sometasks.yml when: &quot;&apos;reticulating splines&apos; in output&quot;- hosts: webservers roles: - &#123; role: debian_stock_config, when: ansible_os_family == &apos;Debian&apos; &#125;# 基于变量选择文件和模板- name: template a file template: src=&#123;&#123; item &#125;&#125; dest=/etc/myapp/foo.conf with_first_found: - files: - &#123;&#123; ansible_distribution &#125;&#125;.conf - default.conf paths: - search_location_one/somedir/ - /opt/other_location/somedir/# 使用注册变量- name: test play hosts: all tasks: - shell: cat /etc/motd register: motd_contents - shell: echo &quot;motd contains the word hi&quot; when: motd_contents.stdout.find(&apos;hi&apos;) != -1# 满足条件时, 任务失败tasks: - command: echo faild. register: command_result failed_when: &quot;&apos;faild&apos; in command_result.stdout&quot; - debug: msg=&quot;echo test&quot;- name: Test the plabybook API. hosts: all remote_user: root gather_facts: yes tasks: - name: exec uptime shell: free -b -o | awk &apos;/Mem/ &#123;print $2&#125;&apos; register: f_mem failed_when: f_mem[&apos;stderr&apos;] != &quot;&quot; - debug: msg=&#123;&#123; f_mem &#125;&#125; - name: add task shell: which pip register: pip_installed - debug: msg=&#123;&#123;pip_installed&#125; 4. set_fact 定义新变量使用 set_fact 模块在 task 中设置 fact(与定义一个新变量是一样的). 可以在 register 关键字后, 立即使用 set_fact , 这样使得变量引用更简单. - name: get snapshot id shell: &gt; aws ec2 describe-snapshot --filters Name=tag:Name, Valuse=my-snapshot | jq --raw-outpuy &quot;.Snapshots[].SnapshtId&quot; register: snap_result - set_fact: snap={ { snap_result.stdout } } - name: delete old snapshot command: aws ec2 delete-snapshot --snapshot-id &quot;{ { snap } }&quot; 5. 内置变量 参数 说明 hostvars 字典, key 为 Ansible 主机的名字, value 为所有变量名与相应变量值映射组成的字典 inventory_hostname 当前主机被 Ansible 识别的名字, 如果定义了别名, 则为别名. group_names 列表, 由当前主机所属的所有群组组成 groups 字典, key 为 ansible 群组名, value 为群组成员的主机名所组成的列表. 包括 all 分组和 ungrouped 分组 play_hosts 列表, 成员是当前 play 涉及的主机的 inventory 主机名. ansible_version 字典, 由 Ansible 版本信息组成. hostvars : 在 Ansible 中, 变量的作用域是按照主机划分的, 只有针对特定主机讨论变量的值才有意义. 有时候 , 针对一组主机定义的变量, 该变量实际始于特定的主机相关联的. 例如 vars 区段的定义, 实际上是在 当前 play 中针对一组主机定义了变量, 但 Ansible 实际做法其实时, 对这个群组的每一个主机创建一个变量的副本. hostvars变量包含了在所有主机上定义的所有变量, 并以 ansible 识别的主机名作为 key. 如果 Ansible 还未对主机采集 fact, 那么除非启动 fact 缓存, 否则无法使用 hostvars 访问fact. 有时, 在某一个主机上运行的 task 可能会需要在另一台主机上定义的变量. 例如, web 服务器, 可能需要 数据库服务器的 ansible_eth1.ipv4.address 这个 fact. 如果 数据库服务器为 db.example.com, 那么, 其变量引用为: { { hostvars[&apos;db.example.com&apos;].ansible_eth1.ipv4.address } } - debug: var=hostvars[inventory_hostname] : 输出与当前主机相关联的所有变量. groups : 代表当前 inventory 所定义的所有组的集合, 为一个字典. 示例: web 负载均衡配置文件 backend web-backend {% for host in groups.web %} server { { host.inventory_hostname } } { { host.ansible_default_ipv4.address } }:80 {% endfor %} 示例二: {% for h in groups['web'] -%} {% if h == inventory_hostname %} OPTIONS="-x {{ hostvars[h]['ansible_default_ipv4']['address'] }} -X 11212" {% endif %} {% endfor %} 6. 在命令行设置变量向 ansible-playbook 传入 -e var=value 参数设置变量或传递参数, 有最高优先级. 可以覆盖已定义的变量值. $ ansible-playbook example.yml -e token=123456 希望在变量中出现空格, 需要使用引号: $ ansible-playbook playbooks/greeting.yml -e &apos;greeting=&quot;Oops you have another hello world&quot;&apos; `@filename.yml` 传递参数: $ cat greetvars.yml greeting: &quot;ops you have another hello world&quot; $ ansible-playbook playbooks/greeting.yml -e @greetvars.yml 二. fact当 Ansible 采集 fact 的时候, 他会连接到目标主机收集各种详细信息: CPU 架构,操作系统,IP地址,内存信息,磁盘信息等. 这些信息保存在被称为 fact 的变量中. fact 与其他变量的行为一模一样. 1. setup 模块实现 fact 收集的模块. 一般无需再 playbook 中调用该模块, Ansible 会在采集 fact 时, 自动调用. `$ ansible server_name -m setup -a &apos;filter=ansible_eth*&apos;` 其返回值为一个字典, 字典的 key 是 ansible_fact, 他的 value 是一个有实际 fact 的名字与值组成的字典. setup 模块支持 filter 参数, 可以实现 shell 通配符的匹配过滤. 2. 模块返回 fact如果一个模块返回一个字典且包含名为 ansible_facts 的key, 那么 ansible 将会根据对应的 value 创建响应的变量, 并分配给相对应的主机. 对于返回 fact 的模块, 并不需要使用注册变量, 因为 ansible 会自动创建. 可以自动返回 fact 的模块: $ ansible-doc --list |grep facts - ec2_facts - docker_image_facts 3. 本地 fact可将一个或者多个文件放置在目标主机的 /etc/ansible/facts.d/ 目录下, 如果该目录下的文件以 init格式, JSON格式 或者输出JSON格式的可执行文件(无需参数), 以这种形式加载的 fact 是 ansible_local 的特殊变量. 示例: # 目标主机 $ /etc/ansible/facts.d/books.fact [book] title=Ansible: Up and Running author=Lorin Hochstein publisher=P&apos;Reilly Media # ansible 主机 $ cat playbooks/local.yml - name: get local variables hosts: host_c gather_facts: True tasks: - name: print local variables; debug: var=ansible_local - name: print book title debug: msg=&quot;The Book Title is { { ansible_local.books.book.title } }&quot; 注意 ansible_local 变量值的结构, 因为 fact 文件的名称为 books, 所以 ansible_local 变量是一个字典, 且包含一个名为 &quot;books&quot; 的 key. 三. 变量优先级:以下优先级依次降低: 命令行参数 其他 通过 inventory 文件或 YAML 文件定义的主机变量或群组变量 Fact 在 role 的 defaults/mail.yml 文件中的变量. 四. 过滤器: 变量加工处理Ansible 除了使用 Jinja2 作为模板之外, 还将其用于变量求值. 即, 可以在 playbook 中在 { {} } 内使用过滤器.除了可以用 Jinja2 的内置过滤器外, Ansible 还有一些自己扩展的过滤器. 有些参数, 需要参数, 有些则不需要. Jinja2 内置过滤器Ansible 过滤器 1. default : 设置默认值.# 设置 HOST 变量的默认值, 如果 database 没有被定义, 则使用 localhost . &quot;HOST&quot;: &quot;{ { database | default(&apos;localhost&apos;) } }&quot; 2. 用于注册变量的过滤器对注册变量状态检查状态的过滤器 名称 描述 failed 如果注册变量的值是任务 failed , 则返回 True changed 如果注册变量的值是任务 changed , 则返回 True success 如果注册变量的值是任务 success , 则返回 True skipped 如果注册变量的值是任务 skipped , 则返回 True 示例: - name: Run myprog command: /opt/myprog register: result ignore_errors: True - debug: var=result - debug: msg=&quot;Stop Running the playbook if myprog failed&quot; failed_when: result|failed 3. 用于文件路径的过滤器用于处理包含控制主机文件系统的路径的变量. 过滤器 描述 basename 文件路径中的目录 dirname 文件路径中的目录 expanduser 将文件路径中的 ~ 替换为用户家目录 realpath 处理符号链接后的文件实际路径 示例: vars: homepages: /usr/share/nginx/html/index.html tasks: - name: copy home page copy: src=files/{ { homepages| basename } } desc={ { homepages } } 4. 自定义过滤器Ansible 会在存放 playbook 的目录下的 filter_plugins 目录中寻找自定义过滤器. 也可以放在 /usr/share/ansible_plugins/filter_plugins/ 目录下, 或者 环境变量ANSIBLE_FILTER_PLUGINS 环境变量设置的目录. # filter_plugins/surround_by_quotes.py def surround_by_quote(a_list): return [&apos;&quot;%S&quot;&apos; % an_element for an_element in a_list] class FilterModule(object): def filters(self): return {&apos;surround_by_quote&apos;: surround_by_quote} surround_by_quote 函数定义了 Jinja2 过滤器.FilterModule 类定义了一个 filter 方法, 该方法返回由过滤器名称和函数本身组成的字典. FilterModule 是 Ansible 相关代码, 他使得 Jinja2 过滤器可以再 Ansible 中使用. 五. lookup: 从多种来源读取配置数据.lookup 官方文档说明Ansible 所有的 lookup 插件都是在控制主机, 而不是远程主机上执行的 支持的数据来源表: 名称 描述 file 文件的内容 password 随机生成密码 pipe 本地命令执行的输出 env 环境变量 template Jinja2 模板渲染的结果 csvfile .csv 文件中的条目 dnstxt DNS 的 TXT 记录 redis_ke 对 Redis 的key 进行查询 etcd 对 etcd 中的key 进行查询 file 示例: 在 playbook 中调用 lookup - name: Add my public key as an EC2 key ec2_key: name=mykey key_material=&quot;{ { lookup(&apos;file&apos;, &apos;/home/me/.ssh/id_rsa.pub&apos;) } }&quot; 示例: 使用 Jinja2 模板 # authorized_keys.j2 { { lookup(&apos;file&apos;, &apos;/home/me/.ssh/id_rsa.pub&apos;) } } # playbook - name: copy authorized_host file template: src=authorized_keys.j2 desc=/home/deploy/.ssh/authorized_keys pipe 在控制主机上调用一个外部程序, 并将这个程序的输出打印到标准输出上. 示例: 得到最新的 git commit 使用的 SHA-1 算法的值. - name: get SHA of most recent commit debug: msg=&quot;{ { lookup(&apos;pipe&apos;, &apos;git rev-parse HEAD&apos;) } }&quot; env 获取在控制主机上的某个环境变量的值. 示例: - name: get the current shell debug: msg=&quot;{ { lookup(&apos;env&apos;, &apos;SHELL&apos;) } }&quot; password 随机生成一个密码, 并将这个密码写入到参数指定的(控制主机)文件中. 示例: 生成 deploy 的 Postgre 用户和密码, 并将密码写入到 deploy-password.txt 中: - name: create deploy postgre user postgresql_user: name: deploy password: &quot;{ { lookup(&apos;password&apos;, &apos;deploy-password.txt&apos;) } }&quot; template 指定一个 Jinji2 模板文件, 并返回这个模板渲染的结果. # message.j2 This host runs { { ansible_distribution } } # task - name: output message from template debug: msg=&quot;{ { lookup(&apos;template&apos;, &apos;message.j2&apos;) } }&quot; csvfile 从 csv 文件中读取一个条目. # users.csv username, email lorin, lorin@example.com john, john@example.com sue, sue@example.com # 调用 : 查看名为 users.csv 的文件, 使用逗号作为分隔符来定位区域, 寻找第一列的值是 sue 的那一行, 返回第二列(索引从 0 开始)的值. lookup(&apos;csvfile&apos;, &apos;sue file=users.csv delimiter=, col=1&apos;) --&gt; sue@example.com # 用户名被存储在 username 变量中, 可以用 &quot;+&quot; 连接其他参数, 构建完整的参数字符串. lookup(&apos;csvfile&apos;, username + &apos;file=users.csv delimiter=, col=1&apos;) dnstxt 需要安装 dnspython 包, $ pip install dnspython TXT 记录是 DNS 中一个可以附加在主机名上的任意字符串, 一旦为主机名关联了一条 TXT 记录, 则任何人都可以使用 DNS 客户端获取这段文本. # 使用 dig 查看 TXT 记录 $ dig +short ansiblebook.com TXT &quot;isbn=97801491915325&quot; # task - name: look up TXT record debug: msg=&quot;{ { lookup(&apos;dnstxt&apos;, &apos;ansiblebook.com&apos;) } }&quot; redis-kv 需要安装 redis 包: $ pip install pip 可以使用 redis-kv 获取一个 key 的value, key 必须为字符串. # 设置一个值: $ redis-cli SET weather sunny # task - name: look up value in redis debug: msg=&quot;{ { lookup(&apos;redis_kv&apos;, &apos;redis://localhost:6379,weather&apos;) } }&quot; etcd etcd lookup 默认在 http://127.0.0.1:4001 上查找 etcd 服务器, 可以在执行 ansible-playbook 之前, 通过设置 ANSIBLE_ETCD_URL 改变这个值. # 设置测试值 $ curl -L http://127.0.0.1:4001/v2/keys/weather -XPUT -d value=cloudy # task - name: loop up value in etcd debug: msg=&quot;{ { lookup(&apos;etcd&apos;, &apos;weather&apos;) } }&quot;]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible-流程控制]]></title>
    <url>%2F2018%2F03%2F15%2FAnsible-%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Ansible 本身除了配置管理工具外, 也可以说是一门配置管理语言. 一. 顺序执行serial, max_fail_percentage 二. 循环各种 with_* 循环 Ansible 总是使用 item 作为 循环迭代变量的名字. 循环结构汇总: 官方文档 三. 条件when : 当 when 表达式返回 True 时, 执行该 Task , 否则跳过该 Task.changed_when :faild_when :notify &amp; handlers 触发器 : handler 定义的行为只有在 task 执行结束之后才会被触发, 并且只会被触发一次, 即使被多个 task 触发. 当 ansible 版本大于 2.2 时, 多个 handlers 可以定义为一个 topic, 方便一次触发多个 handlers, 同时将 名称和 handlers 解耦. handlers: - name: restart memcached service: name=memcached state=restarted listen: &quot;restart web services&quot; - name: restart apache service: name=apache state=restarted listen: &quot;restart web service&quot; tasks: - name: restart everything command: echo &quot;this task will restart web service&quot; notify: &quot;restart web service&quot; handlers 的 name 和 listen 的 topic 是位于全局名称空间的. run_once : 四. role类似 其他编程语言中的 函数或类, 可以实现复用.]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible-Inventory]]></title>
    <url>%2F2018%2F03%2F15%2FAnsible-Inventory%2F</url>
    <content type="text"><![CDATA[Ansible 学习总结 inventory : Ansible 可管理主机的集合. 一. 静态 Inventory1. inventory 行为参数示例 : [targets] localhost ansible_connection=local other1.example.com ansible_connection=ssh ansible_ssh_user=mpdehaan ansible_ssh_pass=123456 other2.example.com ansible_connection=ssh ansible_ssh_user=mdehaan ansible_ssh_pass=123456 名称 默认值 说明 ansible_ssh_host 主机的名字 ssh 目的主机的主机名或IP ansible_ssh_port 22 ssh 默认端口号 ansible_ssh_user root ssh 登录使用的用户名 ansible_ssh_pass none ssh 认证使用的密码(这种方式并不安全,我们强烈建议使用 –ask-pass 或 SSH 密钥) ansible_sudo_pass none sudo 密码(这种方式并不安全,我们强烈建议使用 –ask-sudo-pass) ansible_sudo_exe (new in version 1.8) none sudo 命令路径(适用于1.8及以上版本) ansible_connection smart Ansible 使用何种连接模式连接到目标主机 . 与主机的连接类型.比如:local, ssh 或者 paramiko. Ansible 1.2 以前默认使用 paramiko. 1.2 以后默认使用 ‘smart’,’smart’ 方式会根据是否支持 ControlPersist, 来判断’ssh’ 方式是否可行. ansible_ssh_private_key_file none SSH 认证使用的私钥 ansible_shell_type sh 命令所使用的 shell, 除了 sh 外, 还支持 csh,fish,powershell ansible_python_interpreter /usr/bin/python 目标主机上的 python 解释器 ansible_*_interperter none 与 ansible_python_interpreter 的工作方式相同,可设定如 ruby 或 perl 的路径…. 2. ansible.cfg 设置 Inventory 行为参数默认值可以在 [defaults] 中改变一些行为参数的默认值: inventory 行为参数 ansible.cfg 选项 ansible_ssh_port remote_port ansible_ssh_user remote_user ansible_ssh_private_key_file private_key_file ansible_shell_type, shell 的名称 executable, shell 的绝对路径 3. 群组 all 群组 ansible 自动定义了一个群组为 `all` 或 `*` , 包括 inventory 中的所有主机. 群组嵌套 [django:children] web mysql 模式匹配的主机 正则表达式永远以 ~ 开头 | 匹配行为 | 用法示例 | | — | — | | 所有主机 | all | | 所有主机 | * | | 群组的并集 | dev:staging | | 群组的交集 | dev:&amp;staging | | 排除 | dev:!staging | | 通配符 | *.example.com | | 数字范围 | web[1:20].example.com,web[01:20].example.com | | 字母范围 | web-[a-z].example.com | | 正则表达式 | ~web\d\.example\.(com | | 多种模式匹配组合使用 | hosts: dev:staging:&amp;database:!queue | 限制某些主机执行: -l 或 --limit 只针对限定的主机运行. $ ansible-playbook -l hosts playbook.yml $ ansible-playbook --limit hosts playbook.yml # 使用模式匹配语法 $ ansible-playbook -l &apos;staging:&amp;database&apos; playbook.yml 4. 主机与群组变量 主机变量, 在 inventory 文件中: a.example.com color=red b.example.com color=green 群组变量, 在 inventory 文件中: [all:vars] ntp_server=ntp.ubuntu.com [prod:vars] db_primary_host=prod.db.com db_primary_port=5432 db_replica_host=rep.db.com db_name=mydb db_user=root db_pass=123456 [staging:vars] ... 主机变量和群组变量: 在各自的文件中 可以为每个主机和群组创建独立的变量文件. ansible 使用 YAML 格式来解析这些变量文件. host_vars 目录 : 主机变量文件 group_vars 目录 : 群组变量文件 ansible 假设这些目录在包含 playbook 的目录下 或者与 inventory 文件相邻的目录下. 键值格式 : # playbooks/group_vars/production db_primary_host: prod.db.com db_primary_port: 5432 db_replica_host: rep.db.com db_name: mydb db_user: root db_pass: 123456 # 访问方法: {{ db_primary_host }} 字典格式 : # playbooks/group_vars/production db: user: root password: 123456 name: mydb primary: host: primary.db.com port: 5432 replica: host: replica.db.com port: 5432 rabbitmq: host: rabbit.example.com port: 6379 # 访问方法 {{ db.primary.host }} 将 group_vars/production/ 定义为目录, 将多个包含变量定义的 YAML 文件存放其中; # group_vars/production/db db: user: root password: 123456 name: mydb primary: host: primary.db.com port: 5432 replica: host: replica.db.com port: 5432 # group_vars/production/rebbitmq rabbitmq: host: rabbit.example.com port: 6379 二. 动态 inventory如果 inventory 文件标记为可执行, 那么 Ansible 会假设这是一个动态 inventory 脚本, 并且会执行他, 而不是读取他的内容. 1. 动态 inventory 脚本的接口--list : 列出所有群组. 输出为一个 JSON 对象, 该对象名为群组名, 值为主机的名字组成的数组. --host=&lt;host_name&gt; : 输出是一个名为变量名, 值为变量值的 JSON 对象. 包含主机的所有特定变量和行为参数. 2. 在运行时添加主机或群组: add_host, group_by add_host : 调用方式如下: 当做一个模块使用即可 # 使用方法: add_host name=hostname groups=web,staging myvar=myval` # 示例 - name: add the vagrant hosts to the inventory add_host: name=vagrant ansible_ssh_host=127.0.0.1 ansible_ssh_port=2222 ansible_ssh_user=vagrant add_host 模块添加主机仅在本次 playbook 执行过程中有效, 他并不会修改 inventory 文件. group_by : 是一个 模块. 允许在 playbook 执行的时候, 使用 group_by 模块创建群组, 他可以基于已经为每台主机自动设定好的变量值(fact)来创建群组, Ansible 将这些变量称为 fact. - name: grout hosts by distribution hosts: myhosts gather_facts: True tasks: - name: create groups based on Linux distribution group_by: key={{ ansible_distribution }} - name: do something to CentOS hosts hosts: CentOS tasks: - name: install htop yum: name=htop - name: do something to Ubuntu hosts hosts: Ubuntu tasks: - name: install htop apt: name=htop 3. ec2.py &amp; ec2.ini 安装配置 AWS EC2 External Inventory Script ec2.py : 动态 Inventory ec2.ini : Inventory 配置文件. 只支持 Python 2.x 缓存 \$HOME/.ansible/tmp/ansible-ec2.cache \$HOME/.ansible/tmp/ansible-ec2.index 缓存过期时间: 12345# ec2.ini[ec2]cache_max_age = 0 # 默认 300s, 当值为 0 时, 为不使用缓存.$ ./ec2.py --refresh-cache # 强制刷新缓存 群组 自动生成的群组: | 类型 | 示例 | ansible 群组名 | | — | — | — | | Instance | i-123456 | i-123456 | | Instance type | c1.medium | type_c1_medium | | Security group | ssh | secutity_group_ssh | | Keypair | foo | key_foo | | Region | us-east-1 | us-east-1 | | Tag | env=staging | tag_env_staging | | Availability zone | us-easr-1b | us-easr-1b | | VPC | vpc-14dd1b70 | vpc_id_vpc-14dd1b70 | | all ec2 instance | N/A | ec2 | 在群组名中只有字母,连字符,下划线是合法的. 动态 Inventory 脚本会自动将其他的字符(如空格)转换成下划线.如 Name=My cool name 变为 tag_Name_my_cool_server. 群组操作 ec2.py 生成的群组, 支持 Ansible 群组的交集,并集等操作. 自动生成的群组与 静态 inventory 结合使用: 假设 ec2.py 生成的群组中有一个从 tag 取名的群组名为 tag_type_web, 则可以在 静态inventory文件中重新定义, 或者组合群组. 必须在 静态 inventory 中定义一个空的名为 tag_type_web 的群组, 如果没有定义, 则ansible 会报错. 示例如下: [web:children] tag_type_web [tag_type_web] 使用方法 # 简单使用方法 $ ansible -i ec2.py -u ubuntu us-east-1 -m ping # 复杂使用方法. $ cp ec2.py /etc/ansible/hosts &amp;&amp; chmod +x /etc/ansible/hosts/ec2.py $ cp ec2.ini /etc/ansible/ec2.ini $ export AWS_ACCESS_KEY_ID=&apos;AK123&apos; $ export AWS_SECRET_ACCESS_KEY=&apos;abc123&apos; # just for test, you should see your entire EC2 inventory across all regions in JSON. $ ./ec2.py --list [ --profile PROFILE ] --profile : manage multple AWS accounts, a profile example : [profile dev] aws_access_key_id = &lt;dev access key&gt; aws_secret_access_key = &lt;dev secret key&gt; [profile prod] aws_access_key_id = &lt;prod access key&gt; aws_secret_access_key = &lt;prod secret key&gt; --profile prod, --profile dev ec2.ini : is configured for all Amazon cloud services, but you can comment out any features that aren’t applicable. including cache control and destination variables. 三. 静态 Inventory 与 动态 Inventory 结合使用配置步骤如下: 将 动态inventory 和 静态inventory 放在同一目录下; 在 ansible.cfg 中将 hostfile 的值, 指向该目录即可.]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动化测试 Splinter]]></title>
    <url>%2F2018%2F03%2F15%2F%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95-splinter%2F</url>
    <content type="text"><![CDATA[使用 Splinter 做自动化测试.Splinter Doc Splinter是一个使用Python开发的开源Web应用测试工具，它可以帮你实现自动浏览站点和与其进行交互。 Splinter 是一个基于 Selenium, PhantomJS, zope.testbrowser 等已存在浏览器的抽象层度较高的自动化测试工具. 1. 特点 API 简单 多浏览器支持, 支持的 浏览器列表如下: chrome webdriver, firefox webdriver, phantomjs webdriver, zopetestbrowser, remote webdriver 支持 CSS 选择器和 Xpath 选择器 支持 iframe 和 alert 支持执行 JavaScript 支持 ajax 调用和 async JavaScript 2. 入门2.1 安装 安装 python 支持 Python 2.7+ 版本 安装 splinter $ pip install splinter 安装浏览器驱动: 以 chrome 为例: https://chromedriver.storage.googleapis.com/index.html?path=2.35/ 2.2 示例:from splinter import Browser # 初始化 browser browser = Browser() # 打开首页 browser.visit(&apos;http://google.com&apos;) browser.fill(&apos;q&apos;, &apos;splinter - python acceptance testing for web applications&apos;) browser.find_by_name(&apos;btnG&apos;).click() if browser.is_text_present(&apos;splinter.readthedocs.io&apos;): print &quot;Yes, the official website was found!&quot; else: print &quot;No, it wasn&apos;t found... We need to improve our SEO techniques&quot; browser.quit() Browser 对象支持 上下文管理: with Browser() as browser: # code here 3. 基础浏览器行为和交互3.1 网页对象 Browser 对象初始化 browser = Browser(&apos;chrome&apos;) browser = Browser(&apos;firefox&apos;) browser = Browser(&apos;zope.testbrowser&apos;) browser = Browser(driver_name=&quot;chrome&quot;, executable_path=&quot;/path/to/chrome&quot;, user_agent=&quot;Mozilla/5.0 (iPhone; U; CPU like Mac OS X; en)&quot;, incognito=True) 浏览网页 browser.visit(&apos;http://cobrateam.info&apos;) browser.visit(&apos;http://username:password@cobrateam.info/protected&apos;) # basic HTTP 认证 重载网页 browser.reload() You can back and forward on your browsing history using back and forward methods: browser.visit(&apos;http://cobrateam.info&apos;) browser.visit(&apos;https://splinter.readthedocs.io&apos;) browser.back() browser.forward() 获取当前网页的相关内容 browser.title # 网页标题 browser.html # 网页的 html 代码 browser.url # 网页的 url 管理多个窗口, 使用 windows 对象, 例如弹出窗口. browser.windows # all open windows browser.windows[0] # the first window browser.windows[window_name] # the window_name window browser.windows.current # the current window browser.windows.current = browser.windows[3] # set current window to window 3 window = browser.windows[0] window.is_current # boolean - whether window is current active window window.is_current = True # set this window to be current window window.next # the next window window.prev # the previous window window.close() # close this window window.close_others() # close all windows except this one 3.2 查找网页元素 网页元素获取 splinter 支持 6 种元素查找方式, 每种方式均返回列表作为查找结果. 支持 first, last 快捷方式, 查找第一个和最后一个元素. 因为每个页面中, id 的值一般是不重复的, 因此 find_by_id 总是返回只有一个元素的列表. browser.find_by_css(&apos;h1&apos;) browser.find_by_xpath(&apos;//h1&apos;) browser.find_by_tag(&apos;h1&apos;) browser.find_by_name(&apos;name&apos;) browser.find_by_text(&apos;Hello World!&apos;) browser.find_by_id(&apos;firstheader&apos;) browser.find_by_value(&apos;query&apos;) browser.find_by_xpath(&apos;//h1&apos;).first browser.find_by_name(&apos;name&apos;).last browser.find_by_tag(&apos;h1&apos;)[1] 获取元素的值 browser.find_by_css(&apos;h1&apos;).first.value 查找 URL 返回列表作为结果. links_found = browser.find_link_by_text(&apos;Link for Example.com&apos;) links_found = browser.find_link_by_partial_text(&apos;for Example&apos;) links_found = browser.find_link_by_href(&apos;http://example.com&apos;) links_found = browser.find_link_by_partial_href(&apos;example&apos;) Clicking links : These methods return the first element always. # 绝对 url browser.click_link_by_href(&apos;http://www.the_site.com/my_link&apos;) # 相对 url browser.click_link_by_partial_href(&apos;my_link&apos;) browser.click_link_by_text(&apos;my link&apos;) browser.click_link_by_partial_text(&apos;part of link text&apos;) browser.click_link_by_id(&apos;link_id&apos;) 链式查找 Finding method are chainable, so you can find the descendants of a previously found element. divs = browser.find_by_tag(&quot;div&quot;) within_elements = divs.first.find_by_name(&quot;name&quot;) ElementDoesNotExist 异常 If an element is not found, the find_* methods return an empty list. But if you try to access an element in this list, the method will raise the splinter.exceptions.ElementDoesNotExist exception. Clicking buttons You can click in buttons. Splinter follows any redirects, and submits forms associated with buttons. browser.find_by_name(&apos;send&apos;).first.click() browser.find_link_by_text(&apos;my link&apos;).first.click() 表单 browser.fill(&apos;query&apos;, &apos;my name&apos;) browser.attach_file(&apos;file&apos;, &apos;/path/to/file/somefile.jpg&apos;) browser.choose(&apos;some-radio&apos;, &apos;radio-value&apos;) browser.check(&apos;some-check&apos;) browser.uncheck(&apos;some-check&apos;) browser.select(&apos;uf&apos;, &apos;rj&apos;) To trigger JavaScript events, like KeyDown or KeyUp, you can use the type method. browser.type(&quot;type&quot;, &quot;typing text&quot;) If you pass the argument slowly=True to the type method you can interact with the page on every key pressed. Useful for test field’s autocompletion (The browser will wait until next iteration to type the subsequent key). for key in browser.type(&quot;type&quot;, &quot;typing slowly&quot;, slowly=True): pass You can also use type and fill methods in an element. browser.find_by_name(&quot;name&quot;).type(&quot;Steve Jobs&quot;, slowly=True) browser.find_by_css(&quot;.city&quot;).fill(&quot;San Francisco&quot;) 判断元素是否可见. # 返回布尔值 browser.find_by_css(&apos;h1&apos;).first.visible 判断元素是否有 className # 返回布尔值 browser.find_by_css(&apos;.content&apos;).first.has_class(&apos;content&apos;) Interacting with elements through a ElementList object You can invoke any Element method on ElementList and it will be proxied to the first element of the list. So the two lines below are quivalent. assert browser.find_by_css(&apos;a.banner&apos;).first.visible assert browser.find_by_css(&apos;a.banner&apos;).visible 3.3 鼠标大多数鼠标事件目前只支持 Chrome 和 Firefox 27.0.1 支持 mouse_over, mouse_out,单击, 双击, 右击鼠标. mouse_over : puts the mouse above the element. browser.find_by_tag(&apos;h1&apos;).mouse_over() mouns_out : puts the mouse out of the element. browser.find_by_tag(&apos;h1&apos;).mouse_out() click : 单击 browser.find_by_tag(&apos;h1&apos;).click() double_click : 双击 browser.find_by_tag(&apos;h1&apos;).double_click() right_click : 右击 browser.find_by_tag(&apos;h1&apos;).right_click() drag_and_drop : You can drag an element and drop it to another element. The example below drags the &lt;h1&gt; ... &lt;/h1&gt; element and drop it to a container element (identified by a CSS class). draggable = browser.find_by_tag(&apos;h1&apos;) target = browser.find_by_css(&apos;.container&apos;) draggable.drag_and_drop(target) 3.4 Ajax &amp; Async JavaScriptWhen working with Ajax and Asynchronous JavaScript, it’s common to have elements which are not present in the HTML code(they are created with JavaScript, dynamically). In this case, you can use the methods is_element_present and is_text_present to check the existence of an element or text – Splinter will load the HTML and JavaScript in the browser and the check will be performed before processing JavaScript. There is also the optional argument wait_time (given in seconds), it’s a timeout: if the verification method gets True it will return the result (even if the wait_time is not over); if it doesn’t get True, the method will wait until the wait_time is over (sp it’ll return the result). # 检查文本是否 存在 browser = Browser() browser.visit(&apos;https://splinter.readthedocs.io/&apos;) browser.is_text_present(&apos;splinter&apos;) # True browser.is_text_present(&apos;splinter&apos;, wait_time=10) # True, using wait_time browser.is_text_present(&apos;text not present&apos;) # False # 检查文本是否 不存在 browser.is_text_not_present(&apos;text not present&apos;) # True browser.is_text_not_present(&apos;text not present&apos;, wait_time=10) # True, using wait_time browser.is_text_not_present(&apos;splinter&apos;) # False 元素(element)存在性检查, 返回布尔值. # 检查元素是否 存在 browser.is_element_present_by_css(&apos;h1&apos;) browser.is_element_present_by_xpath(&apos;//h1&apos;) browser.is_element_present_by_tag(&apos;h1&apos;) browser.is_element_present_by_name(&apos;name&apos;) browser.is_element_present_by_text(&apos;Hello World!&apos;) browser.is_element_present_by_id(&apos;firstheader&apos;) browser.is_element_present_by_value(&apos;query&apos;) browser.is_element_present_by_value(&apos;query&apos;, wait_time=10) # using wait_time # 检查元素是否 不存在 browser.is_element_not_present_by_css(&apos;h6&apos;) browser.is_element_not_present_by_xpath(&apos;//h6&apos;) browser.is_element_not_present_by_tag(&apos;h6&apos;) browser.is_element_not_present_by_name(&apos;unexisting-name&apos;) browser.is_element_not_present_by_text(&apos;Not here :(&apos;) browser.is_element_not_present_by_id(&apos;unexisting-header&apos;) browser.is_element_not_present_by_id(&apos;unexisting-header&apos;, wait_time=10) # using wait_time 3.5 cookie 管理It is possible to manipulate cookies using the cookies attribute from a Browser instance. The cookies attribute is a instance of a CookieManager class that manipulates cookies, like adding and deleting them. 添加 cookies browser.cookies.add({&quot;key&quot;: &quot;value&quot;}) 检索 cookies browser.cookies.all() 删除 cookies 删除 单个 cookies browser.cookies.delete(&quot;key1&quot;) # 删除 单个 cookies browser.cookies.delete(&quot;key1&quot;, &quot;key2&quot;) # 删除 两个 cookies 删除 所有 cookies browser.cookies.delete() 4. JavaScript 支持You can easily execute JavaScript in drivers which support it. browser.execute_script(&quot;$(&apos;body&apos;).empty()&quot;) You can return the result of the script. browser.evaluate_script(&quot;4+4&quot;) == 8 5. 其他5.1 HTTP 响应码处理及异常处理status_code and this HTTP exception handling is available only for selenium webdriver browser.visit(&quot;http://www.baidu.com&quot;) browser.status_code.is_success() # True browser.status_code == 200 # True browser.status_code.code # 200 当网页返回失败时, 触发 HttpResponseError 错误. try: browser.visit(&apos;http://cobrateam.info/i-want-cookies&apos;) except HttpResponseError, e: print &quot;Oops, I failed with the status code %s and reason %s&quot; % (e.status_code, e.reason) 5.2 iframersYou can use the get_iframe method and the with statement to interact with iframe. You can pass the iframe’s name, id, or index to get_iframe. with browser.get_iframe(&apos;iframemodal&apos;) as iframe: iframe.do_stuff() 5.3 alert and promptsOnly webdrivers (Firefox and Chrome) has support for alerts and prompts You can deal with alerts and prompts using the get_alert method. alert = browser.get_alert() alert.text alert.accept() alert.dismiss() In case of prompts, you can answer it using the fill_with method. prompts = browser.get_alert() prompts.text prompts.fill_with(&quot;text&quot;) prompts.accept() prompts.dismiss() You can use the with statement to interacte with both alerts and prompts too. with browser.get_alert() as alert: alert.do_stuff() IMPORTANT : if there’s not any prompt or alert, get_alert will return None. Remember to always use at least one of the alert/prompt ending methods(accept/dismiss). Otherwise your browser instance will be frozen until you accept or dismiss the alert/prompt correctly. 6. Drivers6.1 Chrome 安装 # 依赖 Selenium $ pip install selenium # 需要安装 chrome 浏览器 使用 headless option for Chrome browser = Browser(&quot;chrome&quot;, headless=True) incognito option: 隐身模式 browser = Browser(&quot;chrome&quot;, incognito=True) emulation option: 仿真模式 from selenium import webdriver from splinter import Browser mobile_enulation = {&quot;driverName&quot;: &quot;Google Nexus 5&quot;} chrome_options = webdriver.ChromeOptions() chrome_options.add_experimental_option(&quot;mobileEmulation&quot;, mobile_enulation) browser = Browser(&quot;chrome&quot;, options=chrome_options) screenshot: Take a screenshot of the current page and saves it locally. screenshot(name=None, suffix=&apos;.png&apos;)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>PyPi</tag>
        <tag>自动化测试</tag>
        <tag>Splinter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fake-useragent-文档]]></title>
    <url>%2F2018%2F03%2F15%2Ffake-useragent-%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[使用 fake-useragent 为爬虫提供 UserAgent.grabs up to date useragent from useragentstring.comrandomize with real world statistic via w3schools.com https://fake-useragent.herokuapp.com/browsers/0.1.5 1. 安装$ pip install fake-useragent 2. 使用from fake_useragent import UserAgent ua = UserAgent() ua.random # and the best one, random via real world browser usage statistic ua.ie # Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US); ua.msie # Mozilla/5.0 (compatible; MSIE 10.0; Macintosh; Intel Mac OS X 10_7_3; Trident/6.0)&apos; ua[&apos;Internet Explorer&apos;] # Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.1; Trident/4.0; GTB7.4; InfoPath.2; SV1; .NET CLR 3.3.69573; WOW64; en-US) ua.opera # Opera/9.80 (X11; Linux i686; U; ru) Presto/2.8.131 Version/11.11 ua.chrome # Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.2 (KHTML, like Gecko) Chrome/22.0.1216.0 Safari/537.2&apos; ua.google # Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_4) AppleWebKit/537.13 (KHTML, like Gecko) Chrome/24.0.1290.1 Safari/537.13 ua[&apos;google chrome&apos;] # Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11 ua.firefox # Mozilla/5.0 (Windows NT 6.2; Win64; x64; rv:16.0.1) Gecko/20121011 Firefox/16.0.1 ua.ff # Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:15.0) Gecko/20100101 Firefox/15.0.1 ua.safari # Mozilla/5.0 (iPad; CPU OS 6_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/6.0 Mobile/10A5355d Safari/8536.25 3. update saved database just:from fake_useragent import UserAgent ua = UserAgent() ua.update() Sometimes, useragentstring.com or w3schools.com changes their html, or down, in such case fake-useragent uses hosted cache server heroku.com fallback .If You don’t want to use hosted cache server (version 0.1.5 added) from fake_useragent import UserAgent ua = UserAgent(use_cache_server=False) 4. caech Exceptionfrom fake_useragent import FakeUserAgentError try: ua = UserAgent() except FakeUserAgentError: pass 5. if you use a unknown useragent , it will not raise a error, but return “Your favorite Browser”.import fake_useragent ua = fake_useragent.UserAgent(fallback=&apos;Your favorite Browser&apos;) ua.just_test_agent &apos;Your favorite Browser&apos;]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>PyPi</tag>
        <tag>爬虫</tag>
        <tag>UserAgent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-装饰器]]></title>
    <url>%2F2018%2F03%2F15%2FPython-%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[摘要装饰器通常是一个命名的对象(不允许 lambda 表达式), 在被(装饰函数)调用时接受单一参数, 并返回另一个可调用对象. 这里的可调用对象, 不仅仅包含函数和方法, 还包括类. 任何可调用对象(任何实现了 call 方法的对象都是可调用的)都可用作装饰器, 他们返回的对象也不是简单的函数, 而是实现了自己的 call 方法的更复杂的类实例. @some_decorator def decorated_function(): pass # 以上写法总是可以替换为显式的装饰器调用和函数的重新赋值: decorated_function = some_decorator(decorated_function) 1. 装饰器定义/使用方法1.1 通用模式: 作为一个函数def mydecorator(function): def wrapped(*args, **kwargs): # 在函数调用之前, 做点什么 result = function(*args, **kwargs) # 在函数调用之后, 做点什么 # 返回结果 return result # 返回 wrapper 作为装饰函数 return wrapped 1.2 实现 call 方法: 作为一个类非参数化装饰器用作类的通用模式如下: class DecoratorAsClass: def __init__(self, function): self.function = function def __call__(self, *args, **kw): # 在调用原始函数之前, 做点什么 result = self.function(*args, **kwargs) # 在调用原始函数之后, 做点什么 # 返回结果 return result 1.3 参数化装饰器 : 实现第二层包装def repeat(number=3): &quot;&quot;&quot; 多次重复执行装饰函数, 返回最后一次原始函数调用的值作为结果. : param number: 重复次数, 默认值为 3 &quot;&quot;&quot; def actual_decorator(function): def wrapped(*args, **kwargs): result = None for _ in range(number): result = function(*args, **kwargs) return result return wrapped return actual_decorator @repeat(2) def foo(): print(&quot;foo&quot;) 带参数的装饰器总是可以做如下装换: foo = repeat(number=3)(foo) 即使参数化装饰器的参数有默认值, 但名字后面也必须加括号 @repeat() def bar(): print(&quot;bar&quot;) 1.4 保存内省的装饰器使用装饰器的常见缺点是: 使用装饰器时, 不保存函数元数据(主要是文档字符串和原始函数名). 装饰器组合创建了一个新函数, 并返回一个新对象, 完全没有考虑原函数的标志. 这将导致调试装饰器装饰过的函数更加困难, 也会破坏可能用到的大多数自动生产文档的工具, 应为无法访问原始的文档字符串和函数签名. 解决这个问题的方式, 就是使用 functools 模块内置的 wraps() 装饰器. from functools import wraps def preserving_decorator(function): @wraps(function) def wrapped(*args, **kwargs): &quot;&quot;&quot;包装函数内部文档&quot;&quot;&quot; return function(*args, **kwargs) return wrapped @preserving_decorator def function_with_important_docstring(): &quot;&quot;&quot;这是我们想要保存的文档字符串&quot;&quot;&quot; pass print(function_with_important_docstring.__name__) print(function_with_important_docstring.__doc__) 2. 装饰器常用示例2.1 参数检查检查函数接受或返回的参数, 在特定上下文中执行时可能有用. # 装饰器代码 rpc_info = {} # 在实际读取时, 这个类定义会填充 rpc_info 字典, 并用于检查参数类型的特定环境中. def xmlrpc(in_=(), out=(type(None), )): def _xmlrpc(function): # 注册签名 func_name = function.__name__ rpc_info[func_name] = (in_, out) def _check_types(elements, types): &quot;&quot;&quot;用来检查类型的子函数&quot;&quot;&quot; if len(elements) != len(types): raise TypeError(&quot;Argumen count is wrong&quot;) typed = enumerate(zip(elements, types)) for index, couple in typed: arg, of_the_right_type = couple if isinstance(arg, of_the_right_type): continue raise TypeError(&quot;Arg #%d should be %s&quot; % (index, of_the_right_type)) def __xmlrpc(*args): # 没有允许的关键词 # 检查输入的内容 if function.__class__ == &quot;method&quot;: checkable_args = args[1:] # 类方法, 去掉 self else: checkable_args = args[:] # 普通函数 _check_types(checkable_args, in_) # 运行函数 res = function(*args) # 检查输入内容 if not type(res) in (tuple, list): checkable_res = (res, ) else: checkable_res = res _check_types(checkable_res, out) # 函数机器类型检查成功 return res return __xmlrpc return _xmlrpc # 使用示例 class RPCView: @xmlrpc((int, int)) # two int --&gt; None def meth1(self, int1, int2): print(&quot;received %d and %d&quot; % (int1, int2)) @xmlrpc((str, ), (int, )) # string --&gt; int def meth2(self, phrase): print(&quot;received %s&quot; % phrase) return 12 # 调用输出 print(rpc_info) # 输出: # {&apos;meth1&apos;: ((&lt;class &apos;int&apos;&gt;, &lt;class &apos;int&apos;&gt;), (&lt;class &apos;NoneType&apos;&gt;,)), &apos;meth2&apos;: ((&lt;class &apos;str&apos;&gt;,), (&lt;class &apos;int&apos;&gt;,))} my = RPCView() my.meth1(1, 2) # 输出: 类型检查成功 # received 1 and 2 my.meth2(2) # 输出: 类型检查失败 # File &quot;D:\VBoxShare\Work\Documents\PyProject\PyCookbook\test.py&quot;, line 57, in &lt;module&gt; # my.meth2(2) # File &quot;D:\VBoxShare\Work\Documents\PyProject\PyCookbook\test.py&quot;, line 25, in __xmlrpc # _check_types(checkable_args, in_) # File &quot;D:\VBoxShare\Work\Documents\PyProject\PyCookbook\test.py&quot;, line 20, in _check_types # raise TypeError(&quot;Arg #%d should be %s&quot; % (index, of_the_right_type)) # TypeError: Arg #0 should be &lt;class &apos;str&apos;&gt; 2.2 缓存缓存装饰器与参数检查十分相似, 不过他重点是关注那些内容状态不会影响输入的函数, 每组参数都可以链接到唯一的结果. 因此, 缓存装饰器可以将输出与计算法所需的参数放在一起, 并在后续的调用中直接返回他(这种行为成为 memoizing). import time import hashlib import pickle cache = {} def is_obsolete(entry, duration): return time.time() - entry[&quot;time&quot;] &gt; duration def compute_key(function, args, kw): &quot;&quot;&quot; 利用已排序的参数来构建 SHA 哈希键, 并将结果保存在一个全局字典中. 利用 pickle 来建立 hash , 这是冻结所有作为参数传入的对象状态的快捷方式, 以确保所有参数都满足于要求. &quot;&quot;&quot; key = pickle.dumps((function.__name__, args, kw)) return hashlib.sha1(key).hexdigest() def memoize(duration=10): def _memoize(function): def __memoize(*args, **kw): key = compute_key(function, args, kw) # 是否已经拥有它了? if (key in cache and not is_obsolete(cache[key], duration)): print(&quot;We got a winner.&quot;) return cache[key][&quot;value&quot;] # 计算 result = function(*args, **kw) # 保存结果 cache[key] = { &quot;value&quot;: result, &quot;time&quot;: time.time() } return result return __memoize return _memoize @memoize() def func_1(a, b): return a + b print(func_1(2, 2)) # 4 print(func_1(2, 2)) # print , 4 @memoize(1) def func_2(a, b): return a + b print(func_2(2, 2)) # 4 time.sleep(1) print(func_2(2, 2)) # 4 缓存值还可以与函数本身绑定, 以管理其作用域和生命周期, 代替集中化的字典. 但在任何情况下, 更高效的装饰器会使用基于高级缓存算法的专用缓存库. 2.3 代理代理装饰器使用全局代理来标记和注册函数. 例如, 一个根据当前用户来保护代码访问的安全层可以使用集中式检查器和相关的可调用对象要求的权限来实现. class User: def __init__(self, roles): self.roles = roles class Unauthorized(Exception): pass def protect(role): def _protect(function): def __protect(*args, **kw): user = globals().get(&quot;user&quot;) if user is None or role not in user.roles: raise Unauthorized(&quot;I won&apos;t tell you.&quot;) return function(*args, **kw) return __protect return _protect tarek = User((&quot;admin&quot;, &quot;user&quot;)) bill = User((&quot;user&quot;,)) class MySecrets: @protect(&quot;admin&quot;) def waffle_recipe(self): print(&quot;use tons of butter&quot;) these_are = MySecrets() user = tarek these_are.waffle_recipe() # use tons of butter user = bill these_are.waffle_recipe() # __main__.Unauthorized: I won&apos;t tell you. 以上模型常用于 Python Web 框架中(权限验证), 用于定义可发布类的安全性. 例如, Django 提供装饰器来保护函数访问的安全. 2.4 上下文提供者上下文装饰器确保函数可以运行在正确的上下文中, 或者在函数前后运行一些代码, 换句话说, 他设定并复位一个特定的执行环境. 例如, 当一个数据项需要在多个线程之间共享时, 就要用一个锁来保护她避免多次访问, 这个锁可以在装饰器中编写. from threading import RLock lock = RLock() def synchronized(function): def _synchronized(*args, **kw): lock.acquire() try: return function(*args, **kw) finally: lock.release() return _synchronized @synchronized def thread_safe(): # 确保锁定资源 pass 上下装饰器通常会被上下文管理器(with) 替代.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-上下文管理]]></title>
    <url>%2F2018%2F03%2F15%2FPython-%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[使用上下文协议创建和管理上下文 使用 contextlib.contextmanager 创建和管理上下文 上下文的基本使用和嵌套方法 1. 编写实现上下文管理器1.1 作为一个类: 上下文管理协议任何实现了 上下文管理协议的对象都可以用作上下文管理器. 该协议包含两个特殊方法: __enter__(self) : 调用该方法, 任何返回值都会绑定到指定的 as 语句. __exit__(self, exc_type, exc_value, traceback) : 接受代码块中出现错误时填入的 3 个参数. 如果没有错误, 三个都为 None. 出现错误时, __exit__ 不应该重新引发这个错误, 因为这是调用者(caller) 的责任. 但他可以通过返回 True 来避免引发异常. 多数情况下, 这一方法只是执行一些清理工作, 无论代码块中发生什么, 他都不会返回任何内容. 代码示例: class ContextIllustration: def __enter__(self): print(&quot;entering context&quot;) def __exit__(self, exc_type, exc_value, traceback): print(&quot;leveling context&quot;) if exc_type is None: print(&quot;With no ERROR&quot;) else: print(&quot;With an ERROR (%s)&quot; % exc_value) with ContextIllustration(): print(&quot;inside&quot;) # 输出: # entering context # inside # leveling context # With no ERROR with ContextIllustration(): raise RuntimeError(&quot;Raised within &apos;with&apos;&quot;) # 输出: # entering context # leveling context # With an ERROR (Raised within &apos;with&apos;) # Traceback (most recent call last): # File &quot;D:\VBoxShare\Work\Documents\PyProject\PyCookbook\test.py&quot;, line 23, in &lt;module&gt; # raise RuntimeError(&quot;Raised within &apos;with&apos;&quot;) # RuntimeError: Raised within &apos;with&apos; 通过返回 True 来避免触发异常: class ContextIllustration: def __enter__(self): print(&quot;entering context&quot;) def __exit__(self, exc_type, exc_value, traceback): print(&quot;leveling context&quot;) if exc_type is None: print(&quot;With no ERROR&quot;) else: print(&quot;With an ERROR (%s)&quot; % exc_value) return True with ContextIllustration(): raise RuntimeError(&quot;Raised within &apos;with&apos;&quot;) # 输出: # entering context # leveling context # With an ERROR (Raised within &apos;with&apos;) 1.2 作为一个函数: contextlib 模块标准库 contextlib 提供了与上下文管理器一起使用的辅助函数: contextmanager, 他可以在一个函数里同时提供 __enter__ 和 __exit__ 两部分, 中间用 yield 分开(函数变成了生成器). from contextlib import contextmanager thelist = [1, 2, 3] @contextmanager def ListTransaction(thelist): workingcopy = list(thelist) yield workingcopy # 尽在没有出现错误时才会修改原始列表. thelist[:] = workingcopy with ListTransaction(thelist) as l: print(l) print(type(l)) 传递给 yield 的值, 用作 __enter__() 方法的返回值, 调用 __exit__() 方法时, 执行将在 yield 语句后恢复. 如果上下文中出现异常, 他将以异常形式出现在生成器函数中.如有需要可以捕获异常, 以上例子中, 异常被传递出生成器, 并其他地方进行处理. 如果出现任何异常, 被装饰函数需要再次抛出异常, 以便传递异常 from contextlib import contextmanager @contextmanager def context_illustration(): print(&quot;Entering context&quot;) try: yield except Exception as e: print(&quot;Leaving context&quot;) print(&quot;with an ERROR (%s)&quot; % e) # 抛出异常 raise else: print(&quot;Leaving context&quot;) print(&quot;with no error&quot;) with context_illustration(): print(&quot;Entering&quot;) # 输出: # Entering context # Entering # Leaving context # with no error with context_illustration(): raise RuntimeError(&quot;MyError&quot;) # 输出: # Entering context # Traceback (most recent call last): # File &quot;D:\VBoxShare\Work\Documents\PyProject\PyCookbook\test.py&quot;, line 18, in &lt;module&gt; # Leaving context # with an ERROR (MyError) # raise RuntimeError(&quot;MyError&quot;) # RuntimeError: MyError contextlib 还提供其他三个辅助函数: closing(element) : 返回一个上下文管理器, 在退出时, 调用该元素的 close() 方法, 对处理流的类很有用. supress(*exceptions) : 他会压制发生在 with 语句正文中的特定异常. redirect_stdout(new_target) : 将代码内任何代码的 sys.stdout 输出重定向到类文件(file-like)对象的另一个文件. redirect_stderr(new_target) : 将代码内任何代码的 sys.stderr 输出重定向到类文件(file-like)对象的另一个文件. 2. 使用方式 基本使用 with context_manager: # code here ... 上下文变量: 使用 as 语句保存为局部变量 __enter__() 的任何返回值都会绑定到指定的 as 子句. with context_manager as context: # code here ... 多个上下文管理器(嵌套) with A() as a, B() as b: # code here ... 等价于嵌套使用: with A() as a: with B() as b: # code here ...]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
        <tag>python 上下文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyStdLib--optparse]]></title>
    <url>%2F2018%2F03%2F15%2FPyStdLib-optparse%2F</url>
    <content type="text"><![CDATA[使用 optparse 解析命令行参数. 代码示例: import optparse p = optparse.OptionParser() p.add_option(&quot;-t&quot;, action=&quot;store_true&quot;, dest=&quot;tracing&quot;) p.add_option(&quot;-o&quot;, &quot;--outfile&quot;, action=&quot;store&quot;, type=&quot;string&quot;, dest=&quot;outfile&quot;) p.add_option(&quot;-d&quot;, &quot;--debuglevel&quot;, action=&quot;store&quot;, type=&quot;int&quot;, dest=&quot;debug&quot;) p.add_option(&quot;--speed&quot;, action=&quot;store&quot;, type=&quot;choice&quot;, dest=&quot;speed&quot;, choices=[&quot;slow&quot;, &quot;fast&quot;, &quot;ludicrous&quot;]) p.add_option(&quot;--coord&quot;, action=&quot;store&quot;, type=&quot;int&quot;, dest=&quot;coord&quot;, nargs=2) p.add_option(&quot;--novice&quot;, action=&quot;store_const&quot;, const=&quot;novice&quot;, dest=&quot;mode&quot;) p.add_option(&quot;--guru&quot;, action=&quot;store_const&quot;, const=&quot;guru&quot;, dest=&quot;mode&quot;) p.set_defaults(tracing=False, debug=0, speed=&quot;fast&quot;, coord=(0, 0), mode=&quot;novice&quot;) opt, args = p.parse_args() print &quot;tracing: &quot;, opt.tracing print &quot;outfile: &quot;, opt.outfile print &quot;debug : &quot;, opt.debug print &quot;speed : &quot;, opt.speed print &quot;coord : &quot;, opt.coord print &quot;mode : &quot;, opt.mode print &quot;args : &quot;, args]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 学习总结]]></title>
    <url>%2F2018%2F03%2F14%2Fdjango-%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[The Django Book 2.0 官网: http://djangobook.com/the-django-book/ 中文: http://djangobook.py3k.cn/2.0/ 英文: http://djangobook-cn.readthedocs.io/en/latest/ django 之零 入门篇 安装 django 开始一个项目 urls 命令汇总 django 之一 视图篇 Django 请求处理流程 视图函数 配置视图函数: URLconf3.1 URLpattern 语法:3.2 URLpattern 支持的正则表达式3.3 URL 配置和松耦合 动态 URL django 之二 模板使用篇 概述 变量 复杂数据类型3.1 列表索引3.2 字典3.3 属性3.4 方法3.5 深层嵌套3.6 context 对象 标签4.1 if/else4.2 for 循环4.3 ifequal/ifnotequal 注释5.1 单行注释5.2 多行注释 过滤器 模板加载与模板目录: { % include % } 模板继承 : { % extends % } django 之三 模板原理扩展篇 RequestContext 和 Context 处理器1.1 Context1.2 RequestContext 模板加载器2.1 加载模板相关变量2.2 默认加载模板方法2.3 其他模板加载器 扩展模板系统3.1 创建模板库(Django 能够导入的基本结构)3.1.1 决定模板库应该放在哪个 Django 应用下.3.1.2 在适当的 Django 应用包里创建一个 templatetags 目录.3.1.3 在 templatetags 中创建两个空文件:3.1.4 自定义模板过滤器3.1.5 自定义模板标签3.1.5.1 编写编译函数3.1.5.2 编写模板节点3.1.5.3 注册标签3.1.5.4 在上下文中设置变量3.1.5.5 标签对 : 分析直至另一个模板标签3.1.5.6 简单标签的快捷方式: django.template.Library.simple_tag()3.1.5.7 包含标签: 通过渲染其他模板显示数据. 编写自定义模板加载器 django 之四 模型篇 MTV 数据库配置 django models &amp; app : 模型安装与基本使用4.1. 在 Django 项目中激活这些模型: 将 books app 添加到配置文件的已安装应用列表中即可.4.2. 验证模型的有效性4.3. 生成数据库4.4. 基本数据访问 外键与多对多关系5.1 外键5.1.1 从多的一端查询一, 返回相关的数据模型对象.5.1.2 从一的一端查询多, 需要使用 QuerySet 对象5.2 多对多关系 更改数据库模式( Database Schema)6.1. 添加字段6.2. 删除字段6.3. 删除多对多关联字段6.4. 删除模型 Managers : 模型对象的行级别功能7.1 增加额外的 Manager 方法7.2 修改初始 Manager QuerySet 模型方法: 模型对象的行级别功能 执行原始 SQL 查询 django 之五 管理工具 Admin 概述1.1 简介1.2 Admin 工作原理 django.contrib 使用 Admin3.1 基本使用3.1.1 激活3.1.2 将 Model 添加到 Admin 管理中3.2 字段选项3.2.1 blank=True : 字段可选3.2.2 blank=True,null=True : 日期型和数字型字段可选3.2.3 verbose_name=NAME : 自定义字段标签 自定义 ModelAdmin 类4.1 自定义列表 : list_display,search_fields4.2 字段过滤器4.3 日期过滤器: date_hierarchy4.4 排序: ordering4.5 自定义编辑表单4.5.1 自定义字段顺序: field4.5.2 多选框: filter_horizontal,filter_vertical –&gt; 用于多对多字段4.5.3 文本框: raw_id_fields –&gt; ForeignKey 用户, 用户组, 权限 django 之六 表单篇进行中 … … django 之七 部署篇进行中 … …]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>PyPi</tag>
        <tag>web development</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible-学习总结]]></title>
    <url>%2F2018%2F03%2F14%2FAnsible-%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Ansible 原理配置篇 Ansible 简介 Ansible 任务的执行细节原理2.1 角色与依赖:2.2 工作机制2.3 工作原理 安装配置3.1 安装3.2 配置文件 Ansible 抽象实体4.1 inventory4.2 变量与fact4.3 模块4.4 task/play/role/playbook Ansible 命令5.1 ansible5.2 ansible-doc5.3 ansible-galaxy5.4 ansible-vault5.5 ansible-playbook ansible 优化加速6.1 SSH Multiplexing (ControlPersist)6.2 fact 缓存6.3 pipeline6.4 并发 Ansible Inventory篇 静态 Inventory1.1 inventory 行为参数1.2 ansible.cfg 设置 Inventory 行为参数默认值1.3 群组1.4 主机与群组变量 动态 inventory2.1 动态 inventory 脚本的接口2.2 在运行时添加主机或群组: add_host, group_by2.3 ec2.py &amp; ec2.ini 静态 Inventory 与 动态 Inventory 结合使用 Ansible task/play/role篇 task play role Ansible api 开发篇Ansible 番外篇之 ansible.cfg 配置 defaults 段 ssh_connection 段 paramiko 段 accelerate 段 (不推荐使用) Ansible 番外篇之模块 内置模块1.1 查看模块帮助1.2 查找第三方模块1.3 常用模块 自定义模块2.1 使用 script 自定义 模块2.2 使用 Python 自定义模块. Ansible 番外篇之变量与fact 变量1.1. 定义变量1.2. 显示变量: debug 模块1.3. register 注册变量: 基于 task 的执行结果, 设置变量的值.1.4. set_fact 定义新变量1.5. 内置变量1.6. 在命令行设置变量 fact2.1. setup 模块2.2. 模块返回 fact2.3. 本地 fact 变量优先级: 过滤器: 变量加工处理4.1. default : 设置默认值.4.2. 用于注册变量的过滤器4.3. 用于文件路径的过滤器4.4. 自定义过滤器 lookup: 从多种来源读取配置数据. file pipe env password template csvfile dnstxt redis-kv etcd Ansible 番外篇之流程控制假如 ansible 是一门开发语言. 循环 条件 函数 与 role]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>PyPi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 汇总]]></title>
    <url>%2F2018%2F03%2F14%2Fpython-%E4%B8%93%E9%A2%98%2F</url>
    <content type="text"><![CDATA[零. py2 VS py3Python2 将在 2018 年停止维护. 已经使用 Python3 兼容的库列表 : PYTHON 3 WALL OF SUPERPOWERS (一) 语法变化 print 不再是一条语句, 而是一个函数 可以使用如下方法, 在 py2 和 py3 之间兼容 from __future__ import print_function print(123) exec 不再是一条语句, 而是一个函数 异常捕获语法由 except exc, var 转变为 except exc as var from module import * 只能用于模块中, 不能用于函数中. sorted 函数与列表的 sort 方法不再接受 cmp 参数, 应该用 key 参数代替. 整数除法返回的是浮点数, 取整运算可以使用 // 运算符. py3 中, 不再使用 staticmethod 装饰器, 没有 self 参数的类方法即静态方法. 所有类都是新式类, 不再有新式类和旧式类的区分, 无需继承 object 对象. 函数注解 扩展的可迭代解包 items = [1,2,3,4,5] a, *rest = items # a = 1, rest = [2,3,4,5] (二) 标准库变化 urlparse asynccore asyncchat(三) 数据类型与集合变化 统一了类和类型. 所有字符串都是 Unicode, 字节(bytes)前添加 b 或 B 前缀, py2 中的 u前缀, 在 Py3 中没有语法意义, 只做兼容. range(), map(), reduce() 等返回的是可迭代对象, 而不再是 list. (四) py2 py3 跨版本兼容常用工具及技术.1. future from __future__ import division : python3 除法 from __future__ import absolute_import : 将所有不以点字符开头的 import 语句格式解释为绝对导入 from __future__ import print_function : 打印函数 from __future__ import unicode_literals : 将每个字符串解释为 Unicode. 2. compat.py将所有兼容性代码放在一个 附加模块中, 通常命名为 compat.py 编写兼容性代码示例 # 使用 sys.version_info import sys if sys.version_info &lt; (3, 0,0): import urlparse def is_string(s): return isinstance(s, basestring) else: from urllib import parse as urlparse def is_string(s): return isinstance(s, str) # 使用 try, except try: import simplejson as json except ImportError: import json six 是另一个跨版本兼容的工具包, 名字起的很有趣, 2 x 3 = six ? ,:) # 使用 six import six if six.PY3: import urlparse def is_string(s): return isinstance(s, basestring) elif six.PY2: from urllib import parse as urlparse def is_string(s): return isinstance(s, str) else: raise ImportError 5. python3 2to3 包2to3 可以协助实现 python2 向 python3 的代码迁移, 他是一个命令行工具. 通常位于 Python 源码的 Tools/scripts 目录中. # 输入如下命令, 他将输出有问题的和可能需要修改的程序部分, 输出格式类似 git diff 输出. $ 2to3 script.py # 显示可用修复项列表 $ 2to3 -l # 指定单独的修复项来修复. $ 2to3 -f xrange script.py 一. Python 类型与对象(一) 内置数据类型(二) 程序结构的内置类型(三) 解释器内置类型二. Python 库(一) Python 标准库 pdb 代码调试技巧 unittest logging random requests datetime time configparser multiprocessing subprocess shutil pickle re signal os threading glob optparse (二) python 第三方库 Flask-学习总结 Ansible-学习总结 Django 学习总结 python celery 任务队列 Scrapy python state_machine 文档及源码分析 python 微信接口 – itchat 文档 python pyecharts-文档笔记 python yaml 解析 Splinter 自动化测试 fake-useragent-文档 三. Python 编程(一) 原理(二) 函数式编程(三) 面向对象编程 python-设计模式 (四) 数据结构与算法(五) 高级主题 装饰器 元编程 自省 描述符 多线程, 多进程, 异步编程 (六) 模块, 包与分发(七) 代码质量检查1. 代码规范 与 PEP82. Pylint3. Flake8四. Python web 编程0. wsgi 与 asgiPEP-0333asgi 1. Werkzeug &amp;&amp; FlaskWerkzeugFlask Flask-学习总结 Flask 扩展之–flask-login Flask 扩展之–flask-pagedown Flask 扩展之–flask-mail Flask 扩展之–flask-moment Flask 扩展之–flask-script Fask 扩展之–flask-sqlalchemy Flask 扩展之–flask-sse Flask 扩展之–flask-socketio Flask 扩展之–flask-whooshee 2. Django Django 学习总结 django之零–入门篇 django之一–视图篇 django之二–模板篇 django之三–模型篇 django之五–表单 django之四–Admin管理工具 django之六–部署篇 django-模板原理及扩展 3. 前端3.1 AngularJS AngularJS高级程序设计读书笔记–大纲篇 AngularJS高级程序设计读书笔记–模块篇 AngularJS高级程序设计读书笔记–控制器篇 AngularJS高级程序设计读书笔记–指令篇之内置指令 AngularJS高级程序设计读书笔记–指令篇之自定义指令 AngularJS高级程序设计读书笔记–过滤器篇 AngularJS高级程序设计读书笔记–服务篇 3.2 Vue五. Python 爬虫1. scrapy Scrapy Scrapy-命令行工具 fake-useragent-文档 2. 其他lxml : 是一个优美的扩展库, 用来快速解析 XML 和 HTML 文档,Requests : 用来取代内建的 urllib2 模块. 六. 数据统计与分析七. DevOps1. Ansible Ansible-学习总结 Ansible-基本原理与安装配置 Ansible task/role/playbook Ansible-配置文件 Ansible-API Ansible-模块 Ansible-变量 Ansible-流程控制 Ansible-Inventory 2. Docker docker 内部组件结构 docker daemon, container,runC docker-daemon-参数最佳实践 3. Kubernet kubernetes 学习笔记 八. Pythonic1. 查询函数参数import inspect print(inspect.getargspec(func)) 2. 查询对象所属的类和类名称a = [1,2,3] print a.__class__ print a.__class__.__name__ 查询父类 cls.__base__ 3. 百分号 模板格式 : %[(name)][flags][width].[precision]typecode 示例 : tpl = &quot;i am %(name)s, and i am %(age)d years old.&quot; % {&quot;name&quot;: &quot;bob&quot;, &quot;age&quot;: 22} 4. 获取本机 mac 地址 和 IP 地址获取本地 mac 地址 import uuid def get_mac_address(): mac=uuid.UUID(int = uuid.getnode()).hex[-12:] return &quot;:&quot;.join([mac[e:e+2] for e in range(0,11,2)]) 获取 ip 地址 import socket #获取本机电脑名 myname = socket.getfqdn(socket.gethostname( )) #获取本机ip myaddr = socket.gethostbyname(myname) print myname print myaddr 5. 模块全局变量模块全局变量 __name__ : 模块名, 如果是主文件, __name__ == &quot;__main__&quot;, 否则等于 模块名. __file__ : 当前模块文件的绝对路径. __package__ : 模块所属的包, 当前文件为 None, __doc__ : 模块文档. 文档最开头, 三引号 包围的内容. __cached__ : 缓存, py 3.x, 实质是一个 pyc 文件. __loader__ : __builtins__: __spec__ : 6. 命令行获取密码保护: getpassgetpass 密码处理 &gt;&gt; import getpass &gt;&gt; password = getpass.getpass(&quot;Plz input passwd:&quot;) 7. 函数定义, 函数调用, 函数作用域示例1 def makeActionsA(): acts = [] for i in range(5): acts.append(lambda x: i ** x) return acts acts = makeActionsA() acts[0](2) # 16 acts[1](2) # 16 acts[2](2) # 16 acts[3](2) # 16 acts[4](2) # 16 以上代码, 原本的意思, 是要实现 返回 4 个函数, 其中每个 i 的值都不一样(参见示例2). 但事实是, 返回的所有的 i 的值都是 4 , 原因如下: acts.append(lambda x : i ** x) 该语句只是定义了函数, 而函数只有在调用时, 才会实际执行其中的语句, 既示例中的 for 循环, 只是定义了 4 个 一模一样的函数 lambda x : i ** x 当在执行 acts[n](2) 时, 才会实际执行函数定义的语句, 此时, i 的值为循环元素最后一个值 4, 因为 Python 函数查找变量的 LEGB 原则, 此时 lambda 函数回向上层函数中, 查找变量 i, 此时 i 为 4. 既, 所有 acts 中的函数中的 i , 在函数执行并查找 i 变量时, 得到的是同一个值 4. 示例2 def makeActionsA(): acts = [] for i in range(5): acts.append(lambda x, i = i : i ** x) return acts acts = makeActionsA() acts[0](2) # 0 acts[1](2) # 1 acts[2](2) # 4 acts[3](2) # 9 acts[4](2) # 16 以上示例实现了, 当 i 为不同值的 lambda 函数. 其核心原理仍然有关函数的定义, 调用, 及作用域. 当定义 lambda 函数时, 默认参数 i 同时被定义, 为当前 for 循环中的 i 值. 同时, lambda 的函数体, 仍然只是 i ** x 表达式, 此时 函数体中的 i 值, 仍未赋值(因为尚未调用). 当调用函数时, acts0 , 此时, 函数体执行时的 i 的值, 不取自于 嵌套函数, 而取自于 lambda 函数自己定义时, 传入的默认参数 i, 而默认参数 i 的值, 在不同的函数定义中时不同的, 最终实现了, 不同 lambda 函数定义生成的 acts 列表. 8. enumerates = range(10) # s 是一个 列表 # 普通写法 for inx in range(len(s)): print inx, s[inx] # pythonic 写法 for inx, val in enumerate(s): # inx 从 0 开始 print inx, val for inx, val in enumerate(s, 1): # inx 从 1 开始 print inx, val 9. 使用 join 连接字符12letters = ["s", "p", "a", "m"]word = "".join(letters) 10. 使用 format 格式化字符串11. 解包九. 杂项0. 源码安装 python3centos 安装 python3 环境及 pip3 yum 安装 $ yum install python34 # 安装python3.4 只有centos7 中才有. $ curl https://bootstrap.pypa.io/get-pip.py |python3 # 安装pip3 源码安装 : 自带 pip3 $ yum install gcc zlib-devel bzip2-devel openssl-devel ncurser-devel $ wget https://www.python.org/ftp/python/3.5.1/Python-3.5.1.tgz $ tar xf Python-3.5.1.tgz &amp;&amp; cd Python-3.5.1 $ ./configure --prefix=/opt/python-3.5 $ make &amp;&amp; make install $ vim /etc/profile.d/python3.sh export PATH=$PATH:/opt/python-3.5/bin $ source /etc/profile.d/python3.sh $ python3 -V $ pip3 -V $ pip3 install --upgrade pip Amazon Linux EC2 安装 python3主要在 openssl-devel 上出问题, 因为 gcc 的 devel 包的版本太低. $ rpm --nodeps -e openssl $ ln -sv /usr/local/platform/openssl/lib/libssl.so.1.0.0 /lib64/libssl.so.10 $ ln -sv /usr/local/platform/openssl/lib/libcrypto.so.1.0.0 /lib64/libcrypto.so.10 $ yum groupinstall &quot;Development tools&quot; -y $ yum install openssl-devel -y $ ./configure --prefix=/opt/python3 &amp;&amp; make &amp;&amp; make test &amp;&amp; make install amazon 2015.9 linux 无法安装 gcc: 从 amzn-ami-hvm-2017.03.rc-1.20170327-x86_64-ebs (ami-0074e160) linux 上下载 对应的 glibc-headers, glibc-devel 版本, 然后 yum install gcc 1. python 命令行python 命令行与环境变量 $ python [-bBdEiOQsRStuUvVWxX3?] [-c command | -m module-name | script | - ] [args] # 博客 email 防爬 : 使用编码转换后的字符串, 如使用 base64 编码 $ python -c &quot;from __future__ import print_function; import base64; print(base64.b64decode(&apos;YWRtaW5AZXhhbXBsZS5jb20=&apos;))&quot; # 简单 web 服务, 根目录为当前目录 $ python -m SimpleHTTPServer # 支持 CGI 脚本 $ python -m CGIHTTPServer # 执行完脚本之后, 进入交互式解释器, 并保存命名空间. ipython 也支持. $ python -i SCRIPT.py $ ipython -i SCRIPT.py Python 2.7 中 -o 具有如下效果: python 字节码扩展名变为 .pyo sys.flags.optimize set to 1 __debug__ if False asserts 语句不在执行. -oo 效果, 包含上面的效果: sys.flags.optimize set to 2 文档字符串不可用. 2. ipython 解释器.3. pip 包管理 安装 pip python3 自带, 无需安装 $ easy_install pip $ yum install python-pip 安装 第三方包 $ pip install PKG_NAME # 最新版本 $ pip install PKG_NAME==1.0.4 # 指定版本 $ pip install &apos;PKG_NAME&gt;=1.0.4&apos; # 最低版本 # 指定安装版本 $ pip install Django==1.6.8 一次安装多个包 $ pip install BeautifulSoup4 fabric virtualenv 从文本中安装, 文本中为包名, 一行一个, 可以指定版本号 $ pip install -r requirements.txt 导出当前已经安装的包 $ pip freeze &gt;requirements.txt 列出已安装的包 $ pip list $ pip list --outdates # 列出以过期的包 查看已安装包的详细信息. $ pip show PKG_nAME # 显示包的详细信息. 搜索安装包 $ pip search &quot;KEY_WORD&quot; 卸载 $ pip uninstall xlrd 升级 $ pip install bpython --upgrade $ pip install bpython -U 4. virtualenv 虚拟环境独立python环境管理,virtualenvwrapper 使得virtualenv变得更好用. 适用于多版本 python 情况, 也可用于保持 Pypi 包的整洁干净的环境. 安装 $ pip install virtualenv virtualenvwrapper # 修改.bash_profile , 添加如下语句 $ vim .bash_profile +export WORK_HOME=$HOME/.virtualenvs +export PROJECT_HOME=$HOME/workspace +source /usr/local/bin/virtualenvwrapper.sh 使用示例: $ virtualenv --no-site-packages venv # 创建虚拟环境 $ source venv/bin/active # 进入虚拟环境 (venv) $ deactivate # 退出虚拟环境 命令管理 virtualenvwrapper: $ mkvirtualenv ENV : 创建运行环境ENV $ rmvirtualenv ENV : 删除运行环境ENV $ mkproject mic : 创建mic项目和运行环境mic $ mktemenv : 创建临时运行环境 $ workon bsp : 工作在bsp运行环境 $ lsvirtualenv : 列出可用的运行环境 $ lssitepackages : 列出当前环境安装了的包 $ source /path/ENV_NAME/bin/active : 进入ENV_NAME虚拟环境 添加钩子 5. 语义化版本语义化版本(Semantic Versioning, SEMVER), 版本格式为: 主版本号.次版本号.修订号, 版本号递增规则如下: 主版本号(MAJOR) : 增加不兼容 API 修改. 次版本号(MINOR) : 相后兼容的功能性新增. 修订版本号(PATCH) : 向后兼容的问题修正.]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 标准库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask-学习总结]]></title>
    <url>%2F2018%2F03%2F14%2Fflask-%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Flask是一个简洁的 Python_web 框架. 零. virtualenv 虚拟环境配置.$ easy_install pip $ pip install virtualenv $ virtualenv venv # 创建名称为 venv 的虚拟环境 $ source venv/bin/active # 进入 venv 虚拟环境 (venv) $ pip install flask # 在虚拟环境中安装 flask 包 (venv) $ deactivate # 从虚拟环境退出 一. 基本配置1. 创建并启动程序实例示例 : from flask import Flask app = Flask(__name__) # Flask 类的构造函数只有一个必须制定的参数, 即程序主模块或包的名字. # route here if __name__ == &quot;__main__&quot;: # 程序启动后进入轮训, 等待并处理请求. app.run(debug=True) # 启动服务器,并启用调试模式, 激活调试器和重载程序. 2. 配置app.config 字典用来存储框架, 扩展和程序本身的配置变量. 使用标准的字典语法就可把配置值添加到 app.config 对象中. 示例代码 : from flask import Flask app = Flask(app) app.config[&quot;SECRET_KEY&quot;] = &quot;hard to guess string&quot; 该对象还提供了一些其他方法, 可以从文件或环境中导入配置值. 3. 路由 = 装饰器 + 视图函数.处理URL 和 视图函数 之间映射关系的程序成为路由. 1.生成路由映射 1. app.route 装饰器 最简单方式是使用 app.route 装饰器. 示例代码 : @app.route(&quot;/&quot;, methods=[&quot;GET&quot;, &quot;POST&quot;]) # methods 为请求方法. def index(): # 视图函数. return &quot;&lt;h1&gt;Hello World&lt;/h1&gt;&quot; @app.route(&quot;/user/&lt;name&gt;&quot;) # 尖括号中的就是动态内容, 任何能匹配静态部分的 URL 都会映射到这个路由上. 调用视图函数时, Flaks 会将动态部分作为参数传入函数. def user(name): return &quot;&lt;h1&gt;Hello , %s&lt;/h1&gt;&quot; % name 动态视图函数类型定义 : int : 匹配动态片id 为整数的 URL. `/user/&lt;ind:id&gt;` float : 浮点数 path : path 类型也是字符串, 但不把斜线视作分隔符, 而将其视为动态片段的一部分. `/user/&lt;path:dir_path&gt;` 2. app.add_url_rule() 3. app.errorhandler() 错误页面 示例代码 : @app.errorhandler(404) def page_not_found(e): return render_template(&apos;404.html&apos;), 404 @app.errorhandler(500) def internal_server_error(e): return render_template(&apos;500.html&apos;), 500 2.查看路由映射 &gt;&gt; from hello import app &gt;&gt; app.url_map Map([&lt;Rule &apos;/&apos; (HEAD, POST, OPTIONS, GET) -&gt; main.index&gt;, &lt;Rule &apos;/static/bootstrap/&lt;filename&gt;&apos; (HEAD, OPTIONS, GET) -&gt; bootstrap.static&gt;, &lt;Rule &apos;/static/&lt;filename&gt;&apos; (HEAD, OPTIONS, GET) -&gt; static&gt;]) 二. 请求-响应模型.HTTP 协议的基本模型即 请求 响应. 1. 上下文Flask 使用上下文, 让特定的变量在一个线程中全局可访问, 而不会干扰其他线程. Flask 中的上下文包含 程序上下文 和 请求上下文 . Flask 在分发请求之前激活(或推送)程序和请求上下文, 请求处理完成后将其删除. 程序上下文本推送后, 就可以在线程中使用 current_app 和 g 变量. 请求上下文本推送后, 就可以使用 request 和 session 变量. 如果使用这些变量时, 没有激活程序上下文或请求上下文, 就会导致错误. 很多 Flask 扩展都假设已经存在激活的程序上下文和请求上下文, 所以 使用不同线程执行 Flask 扩展时, 需要手动激活上下文. 1. 程序上下文 变量名称 上下文 说明 current_app 程序上下文 当前激活程序的程序实例 g 程序上下文 处理请求时做临时存储的对象. 每次请求都会重设这个变量 2. 请求上下文 变量名称 上下文 说明 request 请求上下文 请求对象, 封装了客户端发出的 HTTP 请求中的内容 session 请求上下文 用户会话, 用于存储请求之间需要 “记住” 的值的字典 示例 : 在视图函数中使用上下文 from flask import request @app.route(&apos;/&apos;) def index(): user_agent = request.headers.get(&quot;User-Agent&quot;) return &quot;&lt;p&gt;Your browser is %s&lt;/p&gt;&quot; % user_agent 示例 : 在 shell 中使用上下文(手动推送上下文). &gt;&gt; from hello import app # hello 为程序主文件 &gt;&gt; from flask import current_app &gt;&gt; current_app.name # 未激活程序上下文就调用 current_app 导致错误. Traceback (most recent call last): ... RuntimeError : working outside of application context. &gt;&gt; app_ctx = app.app_context() # 获取程序上下文 &gt;&gt; app_ctx.push() # 推送上下文 &gt;&gt; current_app.name &quot;hello&quot; 2. 请求钩子(注册通用函数)Flask 提供了注册通用函数的功能, 注册的函数可在请求被分发到视图函数之前或之后调用. 请求钩子函数 说明 before_first_request 注册一个函数, 在处理第一个请求之前运行. before_request 注册一个函数, 在每次请求之前运行. after_request 注册一个函数, 如果没有未处理的异常抛出, 在每次请求之后运行. teardown_request 注册一个函数, 即使有未处理的异常抛出, 在每次请求之后运行. 在请求钩子函数和视图函数之间共享数据, 一般使用上下文全局变量 g . before_request 钩子在应用到蓝本时, 只能对应到针对蓝本的请求上; 如想在蓝本中使用针对程序全局请求的钩子, 必须使用 before_app_request . 示例代码 : @auth.before_app_request def before_request(): if current_user.is_authenticated() and not current_user.confirmed and \ request.endpoint[:5] != &apos;auth.&apos; and \ request.endpoint != &apos;static&apos;: return redirect(url_for(&quot;auth.unconfirmed&quot;)) 3. 响应 : 响应内容, 响应码, 响应首部.Flask 返回响应有 4 种方式: return : 在视图函数中返回响应. return “响应内容或模板”, 响应码, {响应首部字典} Response 对象 : flaks.make_response() make_response() 函数接受 1个, 2个, 或 3个参数, 并返回一个 Response 对象. 示例代码 : from flask import make_response @app.route(&quot;/&quot;) def index(): response = make_response(&quot;&lt;p&gt;This Document carries a cookie !&lt;/p&gt;&quot;) response.set_cookie(&quot;answer&quot;, &quot;42&quot;) return response 重定向 . 重定向是一种特殊的响应类型, 这种响应没有页面文档, 只会告诉浏览器一个新地址, 浏览器在得到新地址之后, 自动重新请求加载新地址. 重定向可以使用 3个 值形式的返回值生成, 可在 Response 对象中设定. 但是 Flask 提供了 redirect() 辅助函数, 用于生成这种响应. 示例代码 : from flask import redirect @app.route(&quot;/&quot;) def index(): return redirect(&quot;http://www.example.com&quot;) abort() : abort() 处理错误. 示例代码 : from flask import abort @app.route(&quot;/user/&lt;id&gt;&quot;) def get_user(id): user = load_user(id) if not user: abort(404) return &quot;&lt;h1&gt;Hello , %s !&lt;/h1&gt;&quot; % user.name 注意 : abort 不会把控制权交给调用它的函数, 而是抛出异常把控制权交给 web 服务器. 三. 大型程序组织结构Flaks 并不强制要求大型项目使用特定的组织方式, 程序的结构组织方式完全有开发者自己决定. 1. 项目结构示例├── app │ ├── __init__.py │ ├── email.py │ ├── models.py │ ├── main / │ │ ├── __init__.py │ │ ├── errors.py │ │ ├── forms.py │ │ ├── views.py │ ├── static / │ └── templates / ├── config.py ├── manage.py ├── venv / ├── migrations / ├── requirements.txt └── tests / ├── __init__.py ├── test_*.py 文件夹类 : app : Flask 程序 migrations : 数据库迁移脚本 tests : 单元测试脚本 venv : 虚拟环境 文件类 : requirements.txt : 程序依赖包 config.py : 存储配置 manage.py : 启动脚本及程序任务. 2. 配置选项 : 层次的配置类.import os basedir = os.path.abspath(os.path.dirname(__file__)) class Config: SECRET_KEY = os.environ.get(&apos;SECRET_KEY&apos;) or &apos;hard to guess string&apos; SQLALCHEMY_COMMIT_ON_TEARDOWN = True FLASKY_MAIL_SUBJECT_PREFIX = &apos;[Flasky]&apos; FLASKY_MAIL_SENDER = &apos;Flasky Admin &lt;flasky@example.com&gt;&apos; FLASKY_ADMIN = os.environ.get(&apos;FLASKY_ADMIN&apos;) @staticmethod def init_app(app): pass class DevelopmentConfig(Config): DEBUG = True MAIL_SERVER = &apos;smtp.googlemail.com&apos; MAIL_PORT = 587 MAIL_USE_TLS = True MAIL_USERNAME = os.environ.get(&apos;MAIL_USERNAME&apos;) MAIL_PASSWORD = os.environ.get(&apos;MAIL_PASSWORD&apos;) SQLALCHEMY_DATABASE_URI = os.environ.get(&apos;DEV_DATABASE_URL&apos;) or \ &apos;sqlite:///&apos; + os.path.join(basedir, &apos;data-dev.sqlite&apos;) class TestingConfig(Config): TESTING = True SQLALCHEMY_DATABASE_URI = os.environ.get(&apos;TEST_DATABASE_URL&apos;) or \ &apos;sqlite:///&apos; + os.path.join(basedir, &apos;data-test.sqlite&apos;) class ProductionConfig(Config): SQLALCHEMY_DATABASE_URI = os.environ.get(&apos;DATABASE_URL&apos;) or \ &apos;sqlite:///&apos; + os.path.join(basedir, &apos;data.sqlite&apos;) config = { &apos;development&apos;: DevelopmentConfig, &apos;testing&apos;: TestingConfig, &apos;production&apos;: ProductionConfig, &apos;default&apos;: DevelopmentConfig } 基类 Config 中包含通用配置, 子类分别定义专用的配置. 如果需要还可以添加其他的配置类. 配置类可以定义 init_app() 类方法, 其参数是程序实例. 在这个方法中, 可以执行对当前环境的配置初始化. 现在 , 基类 Confifg 中的 init_app() 方法为空. config 字典中注册了不同的配置环境, 而且还注册了一个默认配置(开发环境). 3. 程序包程序包用来保存程序的所有代码,模板和静态文件. 1) 程序工厂函数在单个文件中开发程序很方便, 但却有个很大的缺点, 因为程序在全局作用域中创建, 所以无法动态修改配置. 运行脚本时, 程序实例已经创建完毕, 再修改配置为时已晚. 这一点对单元测试尤其重要, 因为有事为了提高测试覆盖度, 必须在不同的配置环境中运行程序. 解决办法就是 : 延迟创建程序实例, 把创建过程移到可现实调用的工厂函数中. 这种方法不仅可以给脚本流出配置程序的时间, 还能够创建多个程序实例, 这些实例有时在测试中非常有用. 构造文件示例 : # app/__init__.py from flask import Flask from flask_bootstrap import Bootstrap from flask_moment import Moment from flask_mail import Mail from flask_sqlalchemy import SQLAlchemy from config import config bootstrap = Bootstrap() mail = Mail() moment = Moment() db = SQLAlchemy() def create_app(config_name): app = Flask(__name__) app.config.from_object(config[config_name]) config[config_name].init_app(app) bootstrap.init_app(app) mail.init_app(app) moment.init_app(app) db.init_app(app) # 附加路由和自定义的错误页面 return app 构造文件导入了大多数正在使用的 Flask 扩展. 由于尚未初始化所需的程序实例, 所以没有初始化扩展, 创建扩展类时, 没有向构造函数传入参数. create_app() 函数就是程序的工厂函数, 接受一个 参数, 就是程序使用的配置名称. 配置类在 config.py 文件中定义, 其中保存的配置可以使用 Flaks app.config 配置对象提供的 from_object() 方法直接导入程序. 至于配置对象, 则可以通过名字从 config 字典中选择. 程序创建并配置好后, 就能初始化扩展了. 在之前创建的扩展对象上调用 init_app() 可以完成初始化过程. 工厂函数返回创建的程序示例, 不过,现在工厂函数创建的程序还不完整, 因为没有路由和自定义的错误页面处理程序. 2) 蓝本转换成程序工厂函数的操作让定义路由变复杂了. 在当脚本程序中, 程序实例存在于全局作用域中, 路由可以直接使用 app.route 装饰器定义. 但现在程序在运行时创建, 只有调用 create_app() 之后才能使用 app.route 装饰器, 这是定义路由就太晚了. 错误页面处理程序使用 app.errorhandler 装饰器, 也面临同样的困难. 解决方法 : 蓝本 创建蓝本 蓝本中可以定义路由, 不同的是, 在蓝本中定义的路由处于休眠状态, 直到蓝本注册到程序上后, 路由才真正成为程序的一部分. 使用位于全局作用域中的蓝本时, 定义路由的方法几乎和单脚本程序一样. 蓝本可以在单个文件中定义, 也可使用更结构化的方式在包中的多个模块中创建. 为了获取更大的灵活性, 程序包中创建了一个子包, 用于保存蓝本. 示例 : # app/main/__init__.py from flask import Blueprint main = Blueprint(&apos;main&apos;, __name__) # 通过实例化一个 Blueprint 类对象创建蓝本, 该构造函数必须制定两个参数 : 蓝本名称 , 蓝本所在的包或模块(__name__即可). from . import views, errors # views 模块保存程序路由, errors 模块保存页面错误处理程序. 导入这两个模块,可以路由和错误处理程序与蓝本关联起来. ** views 和 errors 在 __init__.py 脚本的末尾导入, 是为了避免循环导入依赖 ,因为在 两个模块中, 还有导入 蓝本 main. 注册蓝本 蓝本在 工厂函数 create_app() 中注册到程序上. 示例 : # app/__init__.py #... from .main import main as main_blueprint app.register_blueprint(main_blueprint) from .auth import auth as auth_blueprint app.register_blueprint(auth_blueprint, url_prefix=&quot;/auth&quot;) # url_prefix 使得蓝本中定义的路由都会加上指定前缀. return app 蓝本中的错误处理程序 在蓝本中编写错误处理程序, 如果使用 errorhandler 装饰器, 那么只有蓝本中的错误才能触发处理程序; 要想注册程序全局的错误处理程序, 必须使用 app_errorhandler . 示例 : # app/main/errors.py from flask import render_template from . import main @main.app_errorhandler(404) def page_not_fount(e): return render_template(&apos;404.html&apos;), 404 @main.app_errorhandler(500) def page_not_fount(e): return render_template(&apos;500.html&apos;), 500 蓝本中的路由程序 蓝本中的视图函数,与单脚本中的视图函数有两点不同: 路由装饰器由蓝本提供. url_for() 的用法不同. 需要加上蓝本的名字. 如下 : url_for(&apos;main.index&apos;) # 全局通用 url_for(&apos;.index&apos;) # 简写形式, 只在当前蓝本中使用. flask 为蓝本中的全部断点加上了一个命名空间, 这样在不同蓝本中使用相同的端点名称定义视图函数, 就不会产生冲突了. 命令空间的名称就是蓝本的名称. 这也是 url_for() 写法不同的原因. # app/main/views.py from datetime import datetime from flask import render_template, session, redirect, url_for from . import main from .forms import NameForm from .. import db from ..models import User @main.route(&quot;/&quot;, methods=[&quot;GET&quot;, &quot;POST&quot;]) def index(): form = NameForm() if form.validate_on_submit(): # ... return redirect(url_for(&quot;.index&quot;)) return render_template(&quot;index.html&quot;, current_time=datetime.utcnow(), form=form, name=session.get(&quot;name&quot;), known=session.get(&quot;known&quot;)) 4. 启动脚本顶级文件夹中的 manage.py 用于启动程序. 示例 : # manage.py import os from app import create_app, db from app.models import User, Role from flask_script import Manager, Shell from flask_migrate import Migrate, MigrateCommand app = create_app(os.getenv(&quot;FLASK_CONFIG&quot; or &quot;default&quot;)) # 创建程序. manager = Manager(app) # 初始化 Flask-Script migrate = Migrate(app, db) # 初始化 Flask-Migrate def make_shell_context(): return dict(app=app, db=db, Role=Role, User=User) manager.add_command(&quot;shell&quot;, Shell(make_context=make_shell_context)) manager.add_command(&quot;db&quot;, MigrateCommand) if __name__ == &quot;__main__&quot;: manager.run() 5. 需求文件生成需求文件 : $ pip freeze &gt; requirements.txt 依据需求文件创建新的虚拟环境 : $ pip install -r requirements.txt 配置文件的导入包含一般在开发环境中, 可以将 requirements.txt 文件替换为 requirements 文件夹, 其中包含不同环境的配置文件 : common.txt # 基础包 prod.txt # 生产专用包 demo.txt # 测试专用包 其中 prod.txt 和 demo.txt 可以从 common.txt 中导入, 而无需重复包名, 格式如下: $ cat demo.txt -r common.txt ForgerPy==0.1 6. 创建数据库要在新数据库中创建数据表。如果使用 Flask-Migrate 跟踪迁移，可使用如下命令创建数据表或者升级到最新修订版本： $ python manage.py shell &gt; db.create_all() $ python manage.py db upgrade 四. Flask 模板1. Jinja22. Mako五. Flask 其他1. url_for()url_for() 辅助函数 : 使用程序 URL 映射中保存的信息, 生成 URL. 可用于 视图函数中, 或者 Jinja2 模板中. 相对地址 url_for(view_func) 示例 : url_for(&apos;index&apos;) 绝对地址 url_for(view_func, exterual=True) 动态地址 url_for(view_func, key=value) 动态参数 url_for(view_func, page=2) 静态文件 url_for(&apos;static&apos;, filename=&quot;filename&quot;) 在 蓝本 中 url_for(Blueprint_Name.view_func) 2. Flash 消息消息是 Flask 的核心特性. 1) 在视图函数中使用消息示例代码 : from flask import flash @app.route(&quot;/&quot;, methods=[&quot;GET&quot;, &quot;POST&quot;]) def index(): form = NameForm() if form.validate_on_submit(): old_name = session.get(&quot;name&quot;) if old_name is not None and old_name != form.name.data : flash(&quot;Looks lick you have changed your name !&quot;) session[&quot;name&quot;] = form.name.data return redirect(url_for(&apos;index&apos;)) return render_template(&apos;index.html&apos;, form=form, name=session.get(&quot;name&quot;)) 2) 在模板中渲染消息.Flask 把 get_flashed_messages() 函数开放给模板, 用来获取并渲染消息. 仅在 视图函数中调用 flash() 函数并不能把消息显示出来, 程序使用的模板需要渲染这些消息. 最好在基模板中渲染 Flash 消息, 因为这样所有的页面都能使用这些消息. {% block content %} < div class="container"> {% for message in get_flashed_messages() %} < div class="alert alert-warning"> < button type="button" class="close" data-dismiss="alert" >&times; {{ message }} < /div > {% endfor %} {% block page_content %}{% endblock %} &lt;/div &gt; {% endblock %} 在模板中使用循环是因为在之前的请求循环中每次调用 flash() 函数都会生成一个消息, 所以可能有很多消息在排队等待显示. get_flash_messages() 函数获取的消息在下次调用时不会再次返回, 因此 Flash 消息只显示一次, 然后就消失了. 六. Flask 扩展Flask 被设计为可扩展模式, 故而没有提供一些重要的功能, 如数据库和用户认证, 所以开发者可以自由选择最合适程序的包, 或者自行开发. 专为 Flask 开发的扩展都暴露在 flask.ext 命名空间下. Flask 扩展的通用初始化方法 : 把程序实例作为参数传给构造函数, 初始化主类的实例. 创建的对象可以在各个扩展中使用. werkzeug : WSGI 工具集 flask-script flask-moment flask-wtf : 表单处理 flask-mail : 邮件发送 flask-sqlalchemy : SQL ORM flask-migrate : 数据库迁移 flask-login : 登录用户管理 flask-pagedown : Markdown 支持 flask-HTTPAuth : HTTP 认证 Flask-Babel : 提供国际化和本地化支持。 FLask-RESTful : 开发 REST API 的工具。 Celery : 处理后台作业的任务队列。 Frozen-Flask : 把 Flask 程序转换成静态网站。 Flask-Debug Toolbar : 在浏览器中使用的调试工具。 Flask-Assets : 用于合并、压缩、编译 CSS 和 Java Script 静态资源文件。 Flask-OAuth : 使用 OAuth 服务进行认证。 Flask-Open ID : 使用 Open ID 服务进行认证。 Flask-Whoosh Alchemy : 使用 Whoosh 实现 Flask-SQLAlchemy 模型的全文搜索。 Flask-KVsession : 使用服务器端存储实现的另一种用户会话。 flask-socketio : 服务器端与客户端双向通信.实时数据流. flask-sse : 服务器端向客户端发送事件.实时数据流. flask-whooshee : 基于 whooshee 的全文索引flask 插件, 可与 SQLAlchemy 无缝集成. 七. Flask 信号$ pip search blinker 八. 参考链接Flask web 开发 : 基于Python的Web应用开发实战]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>web development</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime-Text-使用总结]]></title>
    <url>%2F2018%2F03%2F14%2FSublime-Text-%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[初始化配置设置 Linux 换行符Perference-&gt;Setting-*. 设置对象是 default_line_ending, 这个参数有三 个可用选项： - system : system是根据当前系统情况设置, - windows : windows使用的CRLF, - unix : unix使用的是 LF 设置 tab 为 4 个空格.Preference -&gt; Settings-User // The number of spaces a tab is considered equal to &quot;tab_size&quot;: 4, // Set to true to insert spaces when tab is pressed &quot;translate_tabs_to_spaces&quot;: true, 自动保存Preference -&gt; Settings-User &quot;save_on_focus_lost&quot;: true 手动安装插件插件Preference -&gt; Browse Package 把下载的插件解压到打开的文件夹中, 解压后即可. 去除解压后文件夹中的 `-` 等字符, 重启 sublime 即可. install package controllSUBLIME TEXT 3 import urllib.request,os,hashlib; h = &apos;df21e130d211cfc94d9b0905775a7c0f&apos; + &apos;1e3d39e33b79698005270310898eea76&apos;; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( &apos;http://packagecontrol.io/&apos; + pf.replace(&apos; &apos;, &apos;%20&apos;)).read(); dh = hashlib.sha256(by).hexdigest(); print(&apos;Error validating download (got %s instead of %s), please try manual install&apos; % (dh, h)) if dh != h else open(os.path.join( ipp, pf), &apos;wb&apos; ).write(by) SUBLIME TEXT 2 import urllib2,os,hashlib; h = &apos;df21e130d211cfc94d9b0905775a7c0f&apos; + &apos;1e3d39e33b79698005270310898eea76&apos;; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); os.makedirs( ipp ) if not os.path.exists(ipp) else None; urllib2.install_opener( urllib2.build_opener( urllib2.ProxyHandler()) ); by = urllib2.urlopen( &apos;http://packagecontrol.io/&apos; + pf.replace(&apos; &apos;, &apos;%20&apos;)).read(); dh = hashlib.sha256(by).hexdigest(); open( os.path.join( ipp, pf), &apos;wb&apos; ).write(by) if dh == h else None; print(&apos;Error validating download (got %s instead of %s), please try manual install&apos; % (dh, h) if dh != h else &apos;Please restart Sublime Text to finish installation&apos;) 大块方框,Sublime &gt; Preferences &gt; Package Settings &gt; Anaconda &gt; Settings User {&quot;anaconda_linting&quot;: false} 中文输入法光标跟随Packages Control -&gt; install -&gt; IMESupport 常用插件SublimeLinter : 用于高亮提示用户编写的代码中存在的不规范和错误的写法, 支持 JavaScript、CSS、HTML、Java、PHP、Python、Ruby 等十多种开发语言. SideBarEnhancements : SideBarEnhancements是一款很实用的右键菜单增强插件；在安装该插件前, 在Sublime Text左侧FOLDERS栏中点击右键, 只有寥寥几个简单的功能 Javascript-API-Completions : 支持Javascript、JQuery、Twitter Bootstrap框架、HTML5标签属性提示的插件, 是少数支持sublime text 3的后缀提示的插件, HTML5标签提示sublime text3自带, 不过JQuery提示还是很有用处的, 也可设置要提示的语言. Git : Glue : 会在界面下方显示一个小窗口, 你可以在那里写Shell脚本. 这样一来, 你的编辑器就不仅仅局限于使用Git了 GitGutter &amp; Modific : 这些插件可以高亮相对于上次提交有所变动的行, 换句话说是实时的diff工具 GitGutter : 这是一个小巧有用的插件, 它会告诉你自上次git commit以来已经改变的行. 一个指示器显示在行号的旁边. PlainTasks : 杰出的待办事项表！所有的任务都保持在文件中, 所以可以很方便的把任务和项目绑定在一起. 可以创建项目, 贴标签, 设置日期. 有竞争力的用户界面和快捷键. Lua : Python : AllAutocomplete : 搜索全部打开的标签页 Emmet : HTML 快速补全 markdown : anaconda : Python IDE anaconda 不能与 jedi 同时存在, 会出现 左括号无法写入的情况. GBK support : 支持 GBK 编码 SublimeTmpl : 支持文件模板, git 地址. 默认模板支持及快捷键 ctrl+alt+h html ctrl+alt+j javascript ctrl+alt+c css ctrl+alt+p php ctrl+alt+r ruby ctrl+alt+shift+p python 添加自定义模板文件及快捷键 : 参考 https://segmentfault.com/a/1190000008674119 1. 新建并编辑自定义模板文件 Packages\User\SublimeTmpl\templates\hexomd.tmpl --- title: ${saved_filename} date: ${date} categories: tags: --- 摘要 &lt;!-- more --&gt; 正文 2. sublime 模板文件定义 : Commands-User [ { &quot;caption&quot;: &quot;Tmpl: Create Hexo Markdown&quot;, &quot;command&quot;: &quot;sublime_tmpl&quot;, &quot;args&quot;: {&quot;type&quot;: &quot;hexomd&quot;} } ] 3. 快捷键定义 : KeyBing-User [ { &quot;keys&quot;: [&quot;ctrl+alt+m&quot;], &quot;command&quot;: &quot;sublime_tmpl&quot;, &quot;args&quot;: {&quot;type&quot;: &quot;hexomd&quot;}, &quot;context&quot;: [{&quot;key&quot;: &quot;sublime_tmpl.hexomd&quot;}] } ] 4. 用户设置定义 : Settings-User { # 支持 ${saved_filename} 变量 &quot;enable_file_variables_on_save&quot;: true, } 设置快捷键. 在SublimeText里, 打开Preferences -&gt; Key Bindings - User, 我设置的快捷键：[ { &quot;keys&quot;: [&quot;ctrl+f9&quot;], &quot;command&quot;: &quot;build&quot; }, { &quot;keys&quot;: [&quot;f10&quot;], &quot;command&quot;: &quot;build&quot;, &quot;args&quot;: {&quot;variant&quot;: &quot;Run&quot;} }, { &quot;keys&quot;: [&quot;ctrl+shift+x&quot;], &quot;command&quot;: &quot;toggle_comment&quot;, &quot;args&quot;: { &quot;block&quot;: true } }, ]]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>sublime</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown 语法总结]]></title>
    <url>%2F2018%2F03%2F14%2Fmarkdown-%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[段落标题 在行首插入 1 - 6 个 # ,对应 标题1 - 标题6 ## 会在标题下面插入一个横线, 作为分割. 区块引用 普通区块引用 嵌套区块引用 列表 有序列表 数字 + . 无序列表 * + - , 作用相同, 无差别 代码 代码块 –&gt; 推荐 \``` 使用 三个反引号, 无需制表符, 并且带 行号. 1 `1.代码块 缩进4个空格, 或一个制表符, 代码块会一直持续到没有缩进的哪一行, 或者文件结尾 2.小段代码 反引号包含小段代码 分割线 三个以上的星号`*`,减号`-`, 来建立一个分割线, 行内不能有其他东西, 也可用于强制分页. 链接 普通链接 行内式 [Name](http://www.baidu.com &quot;Title&quot;) 引用式 定义: [id]: http://example.com &quot;Optionnal Title&quot; 引用: [Name][id] 图片 行内式 ![Alt text](/path/to/img.jpg &quot;Optional title&quot;) 引用式 定义: [id]: url/to/image &quot;Optional title attribute&quot; 引用: ![Alt text][id] Markdown 无法指定图片的宽高, 如果需要请使用 自动链接 针对URL : &lt;http://www.baidu.com&gt; 针对邮箱 : &lt;admin@example.com&gt; 强调 斜体 *WORD* 加粗 **WORD** 转义 : 在一些符号前面加上 反斜杠 来插入特殊符号 9.表格基本 | 表头 | 表头 | 表头 | 表头 | | -- | --- | --- | --- | | 内容 | 内容 | 内容 | 内容 | 表格对齐 | :-- | ---&gt; 左对齐 | ---: | ---&gt; 右对齐 | :---:| ---&gt; 居中对齐 颜色 `&lt;font color=&quot;blue&quot;&gt;GREEN&lt;/font&gt;` GREEN 删除线 ~~这里是删除内容~~ 效果 : 这里是删除内容 区块元素 段落 1. 类 Setext 格式 : 底线 形式 最高阶标题 : ==== 第二阶标题 : ---- 示例 : This is H1 ========== This is H2 ---------- 2. 类 atx 格式 : # 形式 在行首插入 1 - 6 个 # , 对应标题1 - 标题6 示例 : # This is H1 ## This is H2 ### This is H3 ** 可以选择性的 [闭合] 类 atx 样式的标题 : 在行尾加上 # , 而且行尾的 # 数量也无需同开头一样. 区块引用 Blockquotes 普通区块引用 : &gt; &gt; This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet, &gt; consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. &gt; Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. 嵌套区块引用 : 根据层次加上不同数量的 &gt; &gt; This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet, &gt;&gt; consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. &gt;&gt; Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. 引用的区域也可以使用其他的 Markdown 语法 : 包括标题,列表,代码区块等. 列表 有序列表 : 数字 + . 无序列表 : * + - , 作用相同, 无差别. ** 层次化表示, 需要缩进. ** 转义 : \ 如 : 1991\.12\.12 代码区块 缩进4个空格 , 或者 1 个制表符. 代码区块会一直持续到没有缩进的那一行, 或是文件结尾. ** 代码区块中, 一般 Markdown 语法不会被转换. 代码 小段代码 `CODE` `` CODE `` ** 多个反引号时, 可以在代码中使用 反引号本身. ** 代码区段的起始和结束端都可以放入一个空白，起始端后面一个，结束端前面一个，这样你就可以在区段的一开始就插入反引号 ** 在代码区段内，&amp; 和尖括号都会被自动地转成 HTML 实体，这使得插入 HTML 原始码变得很容易 分割线 : 三个以上的星号,减号,底线来建立一个分割线, 行内不能有其他东西. 型号或减号之间可以插入空格. *** * * * --- - - - - - 链接 链接文字 : [文字] 行内式 [Name](http://www.baidu.com &quot;Title&quot;) 相对路径 [logo](/static/logo.jpg &quot;logo&quot;) 参考式 : 先定义, 后引用 定义 : 在文档的任意处, 把这个标记的链接内容定义出来： [id]: http://example.com &quot;Optionnal Title&quot; 引用 : 不区分大小写 [Name][id] 示例 : [foo]: http://example.com/ &quot;Optional Title Here&quot; [foo]: http://example.com/ &apos;Optional Title Here&apos; [foo]: http://example.com/ (Optional Title Here) [id]: &lt;http://example.com/&gt; &quot;Optional Title Here&quot; [link text][a] [link text][A] 强调 : *WORDS* : &lt;em&gt; _WORDS_ : &lt;em&gt; **WORD** : &lt;strong&gt; __WORD__ : &lt;strong&gt; \* : 转义 \_ : 转义 ** 如果 * 和 _ 两边都有空白的话，它们就只会被当成普通的符号。 图片 行内式 ![Alt text](/path/to/img.jpg) ![Alt text](/path/to/img.jpg &quot;Optional title&quot;) 参考式 ![Alt text][id] [id]: url/to/image &quot;Optional title attribute&quot; ** Markdown 无法指定图片的 宽高, 如果需要可以使用 &lt;img&gt; 标签. 自动链接 : 针对 URL 和 Email 地址 &lt;http://example.com/&gt; &lt;address@example.com&gt; 反斜杠 : 转义 Markdown 支持一下这些符号前面加上 反斜杠 来帮助插入普通的符号. \ 反斜线 ` 反引号 * 星号 _ 底线 {} 花括号 [] 方括号 () 括弧 # 井字号 + 加号 - 减号 . 英文句点 ! 惊叹号 免费编辑器 Windows 平台 MarkdownPad MarkPad Linux 平台 ReText Mac 平台 Mou 在线编辑器 Markable.in Dillinger.io 浏览器插件 MaDe (Chrome) 高级应用 Sublime Text 2 + MarkdownEditing / 教程]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>markdown</tag>
        <tag>标记语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+nexT 博客建设指南]]></title>
    <url>%2F2018%2F03%2F14%2FHexo-nexT-%E5%8D%9A%E5%AE%A2%E5%BB%BA%E8%AE%BE%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[Hexo 搭建 Github 博客开始使用安装 git$ yum install git -y 安装 NodeJS$ git clone https://github.com/creationix/nvm.git $ source nvm/nvm.sh $ nvm install stable # nvm 使用国内源 $ alias cnpm=&quot;npm --registry=https://registry.npm.taobao.org \ --cache=$HOME/.npm/.cache/cnpm \ --disturl=https://npm.taobao.org/dist \ --userconfig=$HOME/.cnpmrc&quot; # 或者: $ npm install -g cnpm --registry=https://registry.npm.taobao.org 设置 Github注册 github创建 github page创建仓库, 仓库的名字要和你的账号对应, 格式为: USERNAME.github.io 安装 hexo-cli$ chmod 755 /root &amp;&amp; mkdir -m 755 -p /root/.npm/_logs $ npm install -g hexo-cli $ chmod 700 /root $ npm install -g hexo-cli 建站安装配置$ hexo init &lt;floder&gt; $ cd &lt;floder&gt; $ npm install 文件件目录结构 . ├── _config.yml # 网站的配置信息, 可以在此配置大部分参数 ├── package.json # 应用程序的信息. EJS, Stylus 和 Markdown renderer 已默认安装，您可以自由移除。 ├── scaffolds # 模板文件夹, 当新建文章时, Hexo 会根据 scaffold 来建立文件. | # Hexo 的模板是指在新建的 markdown 文件中默认填充的内容, 每次新建一篇文章时都会包含这个修改. ├── source # 存放用户资源. 除 _posts 文件夹外, 开头命名为 _ 的文件/文件夹和隐藏的文件都会被忽略. | | # Markdown 和 HTML 文件会被解析并放到 public 文件夹, 而其他文件会被拷贝过去. | ├── _drafts | └── _posts └── themes # 主题文件夹, Hexo 会根据主题来生成静态内容. # 安装 next theme, 可选. $ mkdir themes/next $ curl -s https://api.github.com/repos/iissnan/hexo-theme-next/releases/latest | grep tarball_url | cut -d &apos;&quot;&apos; -f 4 | wget -i - -O- | tar -zx -C themes/next --strip-components=1 # 修改默认 主题设置, 可选 $ vim _config.yml theme: next # 安装 hexo server $ npm install hexo-server --save # 启动 hexo server $ hexo server --ip=0.0.0.0 写文章与提交部署安装 hexo-deployer-git 部署方式 $ npm install hexo-deployer-git --save # 配置部署方式 $ vim _config.yml deploy: type: git repo: https://github.com/pyfdtic/pyfdtic.github.io.git branch: master 写文章 # hexo new &quot;TITLE&quot; $ vim source/_posts/TITLE.md --- title: first post date: 2018-03-14 17:08:36 categories: - test tags: - tag-a - tag-b - tag-c --- # content 写摘要: --- 这里是摘要 &lt;!-- more --&gt; 这是正文 生成静态文件并部署 $ hexo g -d 密钥认证提交 $ vim _config.yml 其中 repo 配置为 ssh 协议地址 # 语言配置 language: zh-Hans $ 在 github 上配置 ssh 密钥. 配置主题文档 $ vim themes/next/_config.yml # 主页预览显示 auto_excerpt: enable: true length: 250 # 选择不同的主体 #scheme: Muse scheme: Mist # 主页设置 menu: home: / || home about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive tags/categories 页面 # tags $ hexo new page &quot;tags&quot; $ vim source/tags/index.md --- title: Tags date: 2018-03-14 18:09:40 type: &quot;tags&quot; comments: false --- $ vim themes/next/_config.yml menu: # ... tags: /tags/ || tags # ... # categories $ hexo new page &quot;categories&quot; $ vim source/categories/index.md --- title: Tags date: 2018-03-14 18:09:40 type: &quot;categories&quot; comments: false --- $ vim themes/next/_config.yml menu: # ... categories: /categories/ || th # ... about页面 $ hexo new page &quot;about&quot; 文章置顶 + 置顶标签 # 安装所需包 $ npm uninstall hexo-generator-index $ npm install hexo-generator-index-pin-top -g # 编辑文章元信息, 添加 top 信息. ## top 后面可以跟 true, 也可以跟数字, 数字越大, 越靠前. --- title: hexo+GitHub博客搭建实战 date: 2017-09-08 12:00:25 categories: 博客搭建系列 top: 1 --- # 设置置顶标志 $ vim themes/next/layout/_macro/post.swig 在 &lt;div class=&quot;post-meta&quot;&gt; 后插入如下代码: {% if post.top %} [置顶] | {% endif %} 谷歌/百度统计 $ vim _config.yml google_analytics: UA-[numbers] baidu_analytics: your-analytics-id 站内搜索: $ npm install hexo-generator-searchdb --save $ vim _config.yml search: path: search.xml field: post format: html limit: 10000 $ vim themes/next/_config.yml local_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: -1 站点地图: $ npm install hexo-generator-sitemap $ vim themes/next/_config.yml menu: # ... sitemap: /sitemap.xml || sitemap $ 在 google Search console 提交 siteamp 地图. 配置资源文件夹 $ mkdir source/images # 在文章中引用 ![](/images/image.jpg) 主题配置参考站点配置 # ============================================================================= # NexT Theme configuration # ============================================================================= avatar: https://avatars1.githubusercontent.com/u/32269?v=3&amp;s=460 # Duoshuo duoshuo_shortname: notes-iissnan # Disqus disqus_shortname: # Social links social: GitHub: https://github.com/iissnan Twitter: https://twitter.com/iissnan Weibo: http://weibo.com/iissnan DouBan: http://douban.com/people/iissnan ZhiHu: http://www.zhihu.com/people/iissnan # Creative Commons 4.0 International License. # http://creativecommons.org/ # Available: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zero creative_commons: by-nc-sa # Google Webmaster tools verification setting # See: https://www.google.com/webmasters/ google_site_verification: VvyjvVXcJQa0QklHipu6pwm2PJGnnchIqX7s5JbbT_0 # Google Analytics # Google分析ID google_analytics: # 百度分析ID baidu_analytics: 50c15455e37f70aea674ff4a663eef27 # Specify the date when the site was setup since: 2011 # ============================================================================= # End NexT Theme configuration # ============================================================================= 主题配置文件 menu: home: / categories: /categories archives: /archives tags: /tags #about: /about # Place your favicon.ico to /source directory. favicon: /favicon.ico # Set default keywords (Use a comma to separate) keywords: &quot;Hexo,next&quot; # Set rss to false to disable feed link. # Leave rss as empty to use site&apos;s feed link. # Set rss to specific value if you have burned your feed already. rss: # Icon fonts # Place your font into next/source/fonts, specify directory-name and font-name here # Avialable: default | linecons | fifty-shades | feather #icon_font: default #icon_font: fifty-shades #icon_font: feather icon_font: linecons # Code Highlight theme # Available value: normal | night | night eighties | night blue | night bright # https://github.com/chriskempson/tomorrow-theme highlight_theme: normal # MathJax Support mathjax: # Schemes scheme: Mist # Automatically scroll page to section which is under &lt;!-- more --&gt; mark. scroll_to_more: true # Automatically add list number to toc. toc_list_number: true ## DO NOT EDIT THE FOLLOWING SETTINGS ## UNLESS YOU KNOW WHAT YOU ARE DOING # Use velocity to animate everything. use_motion: true # Fancybox fancybox: true # Static files vendors: vendors css: css images: images # Theme version version: 0.4.2 删除文章$ hexo clean $ hexo g -d 配置 _config.ymlgodaddy 域名解析至 github.io假设域名为 example.com, 希望将 www.example.com 解析到 exampl.github.io 在 exampl.github.io 的 git 仓库中添加 CNAME 文件, 内容为 www.example.com, 并将 CNAME 文件放到 source 目录下, 可以防止每次 hexo deploy CNAME 文件被覆盖掉. 在 godaddy 购买域名 管理域名 DNS 解析, 添加两条记录, 其中 192.30.252.154 是 github.io 的ip 地址. CNAME www example.github.io A @ 192.30.252.154 添加完成之后, 等待域名生效. 网站 参数 描述 title 网站标题 subtitle 网站副标题 description 网站描述, 网站 SEO author 作者. 显示文章的作者 language 网站使用的语言 timezone 网站时区. Hexo 默认使用浏览器时区 网址 参数 描述 默认值 url 网址 - root 网站根目录 - permalink 文章的永久链接 :year/:mouth/:day/:title permalink_defaults 永久链接中各部分的默认值 网站存放在子目录, 如果网站存放在子目录中, 如 http://yoursite.com/blog , 则需要把 url 设为 ‘http://yoursite.com/blog&#39;, 并把 root 设为 /blog/; 目录 参数 描述 默认值 source_dir 资源文件夹, 用于存放内容 source public_dir 公共文件夹, 用于存放生成的站点文件 public tag_dir 标签文件夹 tags archive_dir 归档文件夹 archives category_dir 分类文件夹 categories code_dir include code 文件夹 downloads/code i18n_dir 国际化(i18n)文件夹 :lang skip_render 跳过指定文件的渲染, 可使用 glob 表达式来匹配路径 如果刚接触 hexo , 则没必要设置以上各值. 文章 参数 描述 默认值 new_post_name 新文章的文件名称 :title.md default_layout 预设布局 post auto_spacing 在中文和英文之间加入空格 false titlecase 把标题转换为 title case false external_link 在新标签中打开链接 true filename_case 把文件名称转换为 (1) 小写或 (2) 大写 0 render_drafts 显示草稿 false post_asset_folder 启动 Asset 文件夹 false relative_link 把链接改为与根目录的相对位址 false future 显示未来的文章 true highlight 代码块的设置 默认情况下，Hexo生成的超链接都是绝对地址. 建议使用绝对地址. 分类 &amp; 标签 参数 描述 默认值 default_category 默认分类 uncategorized category_map 分类别名 tag_map 标签别名 日期/时间格式Hexo 使用 Moment.js 来解析和显示时间. 参数 描述 默认值 date_format 日期格式 YYYY-MM-DD time_format 时间格式 H:mm:ss 分页 参数 描述 默认值 per_page 每页显示的文章数量(0= 关闭分页功能) 10 pagination_dir 分页目录 page 扩展 参数 描述 默认值 theme 当前主题名称, 值为 false 时禁用主题 deploy 部署部分的设置 指令$ hexo SUB_CMD PARAM init [floder] : 新建一个网站. floder 为空时, 为当前文件夹. new [layout] &lt;title&gt; : 新建一篇文章, 如果没有设置`layout`的话, 默认使用 `_config.yml` 中的 `default_layout` 参数代替. 如果标签包含空格, 请使用引号. generate : 生成静态文件. 可以简写为 &quot;hexo g&quot; --d, --deploy : 文件生成后, 立即部署网站 -w, --watch : 监视文件变动. publish [layout] &lt;filename&gt; : 发表草稿 server : 启动服务器, 默认为 &quot;http://localhost:4000/&quot; -p, --port : 指定端口 -s, --static : 只使用静态文件, -l, --log : 启动日志记录, 使用覆盖记录格式. deploy : 部署网站. 可以简写为 &quot;hexo d&quot; -g, --generate : 部署之前预先生成静态文件. render &lt;file1&gt; [file2] ... : 渲染文件. -o, --output : 设置输出路径. migrate &lt;type&gt; : 从其他博客系统迁移. clean : 清除缓存文件(db.json) 和 已生成的静态文件(public). 在某些情况下(尤其是更换主题后), 如果发现对网站的更改无论如何不生效, 可能需要运行该命令. list &lt;type&gt; : 列出网站资料 version : 显示 hexo 版本 --safe : 在安全模式下运行, 不会载入插件和脚本. 当安装新插件遇到问题时, 可以尝试以安全模式重新执行. --debug : 在终端中显示调试信息, 并记录到 debug.log. --silent : 隐藏终端信息 --config custom.yml : 自定义配置文件路径, 执行后将不再使用 _config.yml --draft : 显示 source/_drafts 文件夹中的草稿万丈. --cwd /path/to/cwd : 自定义当前工作目录. 基本操作写作新建文章新建一篇文章: $ hexo new [layout] &lt;title&gt; 可以在 layout 中指定文章的布局(layout), 默认为 post, 可以通过修改 _config.yml 中的 default_layout 参数来指定默认布局. 文章布局Hexo 有三种默认布局: post, page, draft. 他们分别对应不同的路径, 用户自定义的其他布局和post相同, 都将存储在source/_posts 文件夹. 布局 路径 post source/_posts page source draft source/_drafts 如果你不希望你的文章被处理, 可以将 Front-Matter 中的 layout: 设置为 false 草稿草稿(draft) 默认不会显示在页面中, 可以在执行时加上 --draft 参数, 或是把 render_drafts 参数设置为 true 来预览草稿. draft 为草稿布局, 保存与 source/_drafts 目录, 可以通过 publish 命令将草稿移动到source/_posts 文件夹, publish 与 new 使用方式十分类似. $ hexo publish [layout] &lt;title&gt; 文件名称Hexo 默认以标题作为文件名称, 可以编辑 new_post_name 参数来改变默认的文件名称.如 :year-:month-:day-:title.md. 变量 描述 :title 标题(小写, 空格将被替换为短杠) :year 建立年份, 如 2016 :mouth 建立月份, 前导有零, 如 04 :i_mouth 建立月份, 前导无零, 如 4 :day 建立的日期, 前导有零, 如 07 :i_day 建立的日期, 前导无零, 如 7 模板(scaffold)使用方法在新建文章时, Hexo 会根据 scaffolds 文件夹内向对应的文件来建立新文件. 如: # hexo 在 scaffolds 文件夹中寻找 photo.md , # 并根据其内容建立文章. $ hexo new photo &quot;My Gallery&quot; 模板中的可用变量 变量 描述 layout 布局 title 标题 date 文件建立日期 Front-matter使用格式及预定义参数Front-matter 是文件最上方以 --- 分割的区域, 用于指定个别文件的变量. title: Hello World date: 2013/7/12 20:46:25 --- 预定义参数列表如下: 参数 描述 默认值 layout 布局 title 标题 date 建立日期 文件建立日期 updated 更新日期 文件跟新日期 comments 开启文章评论功能 true tags 标签(不适用于分页) categories 分类(不适用于分页) permalink 覆盖文章网址 分类和标签只有文章支持分类和标签, 可以在 Front-matter 中设置. 分类: 分类有顺序性和层次性, 如 Foo,Bar 不等于 Bar, Foo 标签: 标签没有顺序和层次 示例: categories: - Diary tags: - PS3 - Games WordPress 支持对一篇文章设置多个分类, 而且这些分类可以是同级的, 也可以是父子分类. 但 Hexo 不支持指定多个同级分类. 如下的分类, Life 将成为 Diary 的子分类. categories - Diary - Life JSON Front-matter可以使用 JSON 来编写 Front-matter, 只需将 --- 替换为 ;;; 即可: &quot;title&quot;: &quot;Hello World&quot; &quot;date&quot;: &quot;2013/7/12 20:46:25&quot; ;;; 标签插件(Tag Plugins)标签插件和 Front-matter 中的标签不同, 标签插件是用于在文章中快速插入特定内容的插件 引用块在文章中插入引言, 可包含作者, 来源 和 标题. 格式 {% blockquote [author[, source]] [link] [source_link_title] %} CONTENT {% endblockquote %} 示例 # 引用网络上的文章 {% blockquote Seth Godin http://sethgodin.typepad.com/seths_blog/2009/07/welcome-to-island-marketing.html Welcome to Island Marketing %} Every interaction is both precious and an opportunity to delight. {% endblockquote %} # 引用书上的句子 {% blockquote David Levithan, Wide Awake %} Do not just seek happiness for yourself. Seek happiness for all. Through kindness. Through mercy. {% endblockquote %} 代码块在文章中插入代码. 格式 {% codeblock [title] [lang:language] [url] [link text] %} CODE_SNIPPET {% endcodeblock %} 示例 # 附加说明和网址 {% codeblock _.compact http://underscorejs.org/#compact Underscore.js %} _.compact([0, 1, false, 2, '', 3]); => [1, 2, 3] {% endcodeblock %} # 指定语言 {% codeblock lang:objc %} [rectangle setX: 10 y: 10 width: 20 height: 20]; {% endcodeblock %} 反引号代码块使用三个反引号类包裹的代码块: ``` [language] [title] [url] [link text] code snippet ``` Pull Quote{% pullquote [class] %} content {% endpullquote %} jsFiddle{% jsfiddle shorttag [tabs] [skin] [width] [height] %} Gist{% gist gist_id [filename] %} 3iframe{% iframe url [width] [height] %} Image{% img [class names] /path/to/image [width] [height] [title text [alt text]] %} Link在文章中插入链接, 并自动给外部链接添加 target=&quot;_blank&quot; {% link text url [external] [title] %} Include Code插入source文件夹内的代码文件. {% include_code [title] [lang:language] path/to/file %} Youtube插入 Youtube 视频. {% youtube video_id %} Vimeo插入 vimeo 视频 {% vimeo video_id %} 引用文章引用其他文章的链接. {% post_path slug %} {% post_link slug [title] %} 引用资源引用文章的资源 {% asset_path slug %} {% asset_img slug [title] %} {% asset_link slug [title] %} Raw如果希望在文章中插入 Swig 标签, 可以尝试使用 Raw 标签, 以免发生解析异常. {% raw %} content {% endraw %} 资源文件夹资源Asset代表 source 文件夹中除了文章以外的所有文件, 如图片,CSS,JS文件等. 如在 source/images 文件夹中的图片, 可以使用类似于![](/images/NAME.jpg) 方法访问他们. 文章资源文件夹更加组织化的管理资源, 可以通过修改 config.yml 文件中的 post_asset_folder 选项设为 true 来打开. post_asset_folder: true 打开资源文件管理功能之后, Hexo 将会在每一次通过 hexo new [layout] &lt;title&gt; 命令创建新文章时自动创建一个文件夹. 这个资源文件夹间会有与这个 markdown 文件一样的名字. 将所有与该文章有关的资源放在这个关联文件夹中之后, 可以通过相对路径来引用这些资源, 这样就得到了一个更简单而且方便的得多的工作流. 相对路径引用的标签插件通过常规的 markdown 语法和相对路径来引用图片和其他资源可能会导致他们在存档页和主页上显示不正常. 可以使用如下方式引用资源, 解决这个问题: {% asset_path slug %} {% asset_img slug [title] %} {% asset_link slug [title] %} 如, 当打开文章资源文件夹功能后, 资源文件夹中有一个 example.jpg 图片, 正确的引用该图片的方式是使用如下的标签插件, 而不是 markdown, 该图片将会同时出现在文章和主页及归档页中: {% asset_img example.jpg This is an example image %} 数据文件有时, 可能需要在主题中使用某些资料, 而这些资料并不在文章内, 并且是需要重复使用的, 那么可以使用 Hexo 3.0 新增的 数据文件功能, 此功能会载入 source/_data 内的 YAML 或 JSON 文件, 以方便在网站中复用这些文件. # source/_date/menu.yml Home: / Gallery: /gallery/ Archives: /archives/ # 在模板中引用这些资料: &lt;% for (var link in site.data.menu) { %&gt; &lt;a href=&quot;&lt;%= site.data.menu[link] %&gt;&quot;&gt; &lt;%= link %&gt; &lt;/a&gt; &lt;% } %&gt; # 渲染结果 &lt;a href=&quot;/&quot;&gt; Home &lt;/a&gt; &lt;a href=&quot;/gallery/&quot;&gt; Gallery &lt;/a&gt; &lt;a href=&quot;/archives&quot;&gt; Archives &lt;/a&gt; 服务器hexo-serverHexo 3.0 把服务器独立成了个别模块, 必须先安装 hexo-server 才能使用. # 安装 $ npm install hexo-server --save # 启动服务器, 默认 http://localhost:4000 $ hexo server [-p PORT] [-i IP_ADDRESS] [-s] -s : 静态模式, 服务器只处理 public 文件夹内的文件, 而不会处理文件变动, 在执行时, 应该先自行执行 hexo generate, 常用于生产环境. -i IP_ADDRESS : 指定IP地址, 默认为 0.0.0.0 . -p PORT : 指定监听端口. PowPow 是 Mac 系统上的零配置 Rack 服务器, 他也可以作为一个简单易用的静态文件服务器来使用. # 安装 $ curl get.pow.cx | sh # 设置: 在 ~/.pow 文件夹建立链接(symlink) $ cd ~/.pow $ ln -s /path/to/myapp # 网站将在 http://myapp.dev 下运行, 网址根据链接名称而定. 生成器生成文件:$ hexo generate [--watch] --watch : 监视文件变动并立即重新生成静态文件. 在生成时对比文件的 SHA1 , 只有变动的文件才会写入. 完成后部署如下两个命令功能相同, 让 Hexo 在生成完毕后自动部署网站. $ hexo generate --deploy $ hexo g -d # 上述命令的简写 $ hexo deploy --generate $ hexo d -g # 上述命令的简写 部署部署步骤 $ vim _config.yml deploy: type: git $ hexo deploy git 部署# 安装 hexo-deployer-git $ npm install hexo-deployer-git --save # 修改 _config.yml deploy: type: git repo: &lt;REPOSITORY URL&gt; branch: &lt;GIT BRANCH&gt; message: &lt;自定义提交信息&gt; # 默认为 Site updated: {{ now('YYYY-MM-DD HH:mm:ss') }} # 部署 $ hexo deploy Heroku 部署# 安装 hexo-deployer-heroku $ npm install hexo-deployer-heroku --save # 修改 _config.yml deploy: type: heroku repo: &lt;REPOSITORY URL&gt; message: &lt;自定义提交信息&gt; # 默认为 Site updated: {{ now('YYYY-MM-DD HH:mm:ss') }} # 部署 $ hexo deploy 自定义永久链接(Permalink)https://hexo.io/zh-cn/docs/permalinks.html 主题修改主题 在 themes 文件夹内, 创建一个任意名称的文件夹, 修改 _config.yml 内的 theme 设定, 即可切换主体题 主题目录结构. ├── _config.yml ├── languages ├── layout ├── scripts └── source _config.yml主体的配置文件, 修改时会自动更新, 无需重启服务器. languages语言文件夹, 参见国际化 layout布局文件夹, 用于存放主题的模板文件, 决定网站内容的呈现方式. Hexo 内建 Swig 模板引擎, 可以另外安装插件来获得 EJS, Haml, Jade 支持, Hexo 根据模板文件的扩展名来决定所使用的模板引擎. scripts脚本文件夹, 在启动时, Hexo 会自定载入此文件夹内的 JavaScript 文件. source资源文件夹, 除了模板以外的 Asset, 如 CSS , JavaScript 文件等, 都应该放在这个文件夹中. 文件或文件夹前缀为 _ (下划线) 或 隐藏的文件会被忽略. 如果文件可以被渲染的话, 会经过解析然后存储到 public 文件夹, 否则会直接拷贝到 public 文件夹. 模板https://hexo.io/zh-cn/docs/templates.html 变量https://hexo.io/zh-cn/docs/variables.html 辅助函数https://hexo.io/zh-cn/docs/helpers.html#toc 国际化(i18n)https://hexo.io/zh-cn/docs/internationalization.html 插件https://hexo.io/zh-cn/docs/plugins.html nexThttp://theme-next.iissnan.com/getting-started.html#third-party-services 参考文档hexo-theme-nexthexo-wiki hexo 文档 - 中文hexo 文档 - 英文nexT 主题配置文档]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>markdown</tag>
        <tag>Hexo</tag>
        <tag>nexT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python wsgi 文档翻译]]></title>
    <url>%2F2018%2F03%2F13%2Fpython-wsgi-doc%2F</url>
    <content type="text"><![CDATA[一. 背景知识WSGI(The Python Web Server Gateway Interface) 为 Web Server 和 Python Web Application 之间提供了标准的数据通道. 是 Python 界的 一个广泛的可用的 WEB API 规范, 使 web server 提供更加规范的 API, 给 web Application, 从而使 开发者更加专注于业务逻辑. WSGI 仅仅作为 Python Web 开发的一个标准, 开发者必须将 WSGI 实践到开始实践之中, 否则不会对现有的 web server 和 web Application 拥有实质影响. 二. WSGI 规则WSGI 涉及到两个方面: ① web server, ② Web Application. WebServer 端需要调用一个 可调用对象, 该对象由 WebApplication 提供. 但是, 可调用对象如何进行调用, 取决于 WebServer. 但是, WebServer 在调用 WebApplication 提供的 可调用对象时, 不能有任何依赖或针对某种特定的 可调用对象类型. 一个可调用对象, 可以是一个 函数, 方法, 类, 或实现了 call 方法的实例. 1. 字符串问题一般来讲, HTTP 中, 字符串以字节流形式传输, 但是在 Python 中, 字符串使用 Unicode 编码, 而不是 bytes. 因此, 需要在可用 API 和 正确的字符串转换之间寻求平衡, 特别是当 python 有多重 str 类型时. WSGI 定义了两种类型的 string : Native String, 文本字符串, 可用str() 函数转换, 用于 请求/响应头 和 元数据. Bytestrings , 用于 请求体/响应体. 尽管 Python 的 str 类型使用 Unicode 编码, 但是在底层, 文本字符串任然会被转换为 bytes , 使用 Latin-1 编码. 2. WebApplication/FrameworkWebApplication 对象应该是一个可调用对象, 它可以是一个 函数, 方法, 类, 或者一个实现了 call 方法的实例. 同时, 要确保该可调用对象, 可以被多次调用. 因为事实上, 所有的 WebServer 都会产生这样的重复请求. 如下是两个 WebApplication 的示例, 其中一个是 funciton, 一个是 类. 123456789101112131415161718192021222324252627282930313233HELLO_WORLD = b'Hello world!\n'def simple_app(environ, start_response): """ Simplest possible application object. """ status = "200 OK" response_headers = [("Content-type", "text/plain")] start_response(status, response_headers) return [HELLO_WORLD]class AppClass: """Produce the same output, but using a class *AppClass* is the 'application' here, so calling it returns an instance of *AppClass*, which is then the iterable return value of the `application callable` as required by the spec. If we wanted to use *instances* of *AppClass* as application objects instead, we would have to implement a `__call__` method, which would be invoked to excute the applications, and we should be invoked to execute the application, and we would need to create an instance for use by te server or gateway. """ def __init__(self, environ, start_response): self.environ = environ self.start = start_response def __iter__(self): status = "200 OK" response_headers = [("Content-type", "text/plain")] self.start(status, response_headers) yield HELLO_WORLD WebApplication 必须接受两个位置参数, 惯例命名为 environ 和 start_response. WebServer 必须采用位置参数的方式, 调用 WebApplication 对象, 如 result = application(environ, start_response) environ : 是一个字典, 包含 CGI-style 的环境变量. 该字典必须是一个 Python 原生字典, 而不能是 dict 的子类, 或 UserDict 其他模拟实现. WebApplication 可以使用 Python 字典支持的任何方法, 使用 environ 对象. environ 对象必须包含一些 WSGI 要求的变量, 和 WebServer 需要的其他扩展参数. start_response : start_response 是一个可调用对象, 该对象可接受两个位置参数(惯例命名为 status 和 response_headers), 和一个可选参数(惯例命名为 exc_info). WebApplication 必须使用 上面的位置参数, 调用 start_response , 例如: start_response(status, response_headers). status 参数是一个 999 Message here 格式的 字符串. response_headers 参数是一个 格式(header_name, header_value) 元组组成的列表, 用于描述 HTTP 响应头部信息. exc_info 参数只在 WebApplication 发生错误, 并试图显示错误信息时使用. start_response 可调用对象必须返回一个 write(body_data) 可调用对象, 其中 body_data 参数为一个 bytestring, 是 HTTP 响应体的一部分. (write() callable is provided only to support certain existing frameworks’ imperative output APIs, it should not be used by new applications or frameworks if it can be avoided). 当 WebApplication 被 WebServer 调用时, 它必须返回一个 可迭代的返回 zero 或 bytestring 的可迭代对象. 这可以通过多种方式实现, 如 返回一个 bytestring 组成的列表, 一个生成器, 一个实现了迭代协议的类实例. WebServer 或 WebGateway 返回迭代的字符串给客户端, 并且不缓存任何数据. WebApplication 或 WebGateway 将 WebApplication 返回的可迭代的字符串, 当做二进制字符数据来处理. 因此, WebApplication 必须保证其返回的字符串对于客户端是格式化的可显示的格式, 如换行符等. 如果对 WebApplication 返回的对象调用 __len__(iterable) 方法成功, 则该方法必须正确返回其 长度, 因为 __len__() 返回的值将作为 Content-Length 的值. 如果 WebApplication 返回的对象, 实现了 __close__() 方法, WebServer 必须在每次请求结束的时候, 调用该方法, 无论该次请求是否正确完成. 当 WebApplication 返回 生成器或自定义的迭代器时, 不应当假设该生成器或迭代器会被完全消费完, 因为, 它可能会被 WebServer 过早的关闭. the application must invoke the start_response() callable before the iterable yields its first body bytestring, so that the server can send the headers before any body content. However, this invocation may be performed by the iterable’s first iteration, so servers must not assume that start_response has been called before they negin iterating over the iterable. Finally, server and gateways must not directly use any other attributes of the iterable returned by the application, unless it is an instance of a type specific to that server or gateway, such as a file wrapper return by wsgi.file_wrapper. In the general case, only attributes specified here, or accessed via e.g. the PEP 234 iteration APIs are acceptable. 2.1 environ 变量environ 必须包含如下的 CGI 环境变量. REQUEST_METHOD : 必选, HTTP 请求方法 SCRIPT_NAME : 请求的 URL 的 path 部分, 一般为 / PATH_INFO : 请求的 URL 的 path 部分, QUERY_STRING : 可选, 请求 URL 中 ?, 后面的部分. CONTENT_TYPE : 可选, HTTP Content-Type CONTENT_LENGTH : 可选, HTTP Content-Length SERVER_NAME, SERVER_PORT : SERVER_PROTOCOL : “HTTP/1.0” 或 “HTTP/1.1” HTTP_Variables : 其他对应的客户端支持的 HTTP 请求头. 一个 WebServer 应当竟可能多的提供 CGI 变量, 例如 HTTPs=on 等. 除此之外, environ 还可以提供 任意数量的 操作系统环境变量, 并且, 必须包含如下的 WSGI 规定的变量. Variable Value wsgi.version 一个元组, WSGI 版本, 当前版本为 (1, 0) wsgi.url_scheme http 或 https wsgi.input An input stream (file-like object) from which the HTTP request body bytes can be read. wsgi.errors An output stream (file-like object) to which error output can be written, for the purpose of recording program o rother errors in a standardized and possibly centralized location. This should be a text mode stream, and assume that it will be converted to the correct line ending by the server/gateway. wsgi.multithread This value should evaluate true if the application object may be simultaneously invoked by another thread in the same process, and should evaluate false otherwise. wsgi.multiprocess This Value shoudl evaluate true if an equivalent application object may be simultaneously invoked another process, and should evaluate false otherwise. wsgi.run_once This value should evaluate true it the server or gateway expects(but not guatantee) that the application will only be invoked this one time during the life of its containing process. Normally, this will only be true for a gateway based on CGI (or something similar). 最后, environ 变量字典可以包含任意的自定义变量, 这些变量应当只包含 小写字符, 数字, 点好, 下划线等, 而且应当使用一个唯一的自定义前缀. 2.2 Input and Error StreamsWebServer 提供的 Input 和 Error 流, 必须支持如下的方法. Method Stream Notes read(size) input a readline() input a,b readlines(hint) input a,c __iter__() input flush() errors d write(str) errors writelines(seq) errors a : WebServer 不要求获取传给客户端的 Content-Length, 但是需要提供一个 end-of-line 的条件测试, 方便 WebApplication 读取该字段的内容. 同时, WebApplication 不应当试图读取多于 CONTENT_LENGTH 变量规定大小的数据. WebServer 应当允许被无参数的调用 read() 方法, 并且返回客户端 input stream 数据流的大小. 当 WebServer 接收到空的 input stream 或 大量耗尽资源的请求时, 应当返回空的 bytestrings . b : WebServer 应当提供支持可选参数 size 的方法 readline(). c : readlines() 方法 的 可选参数 hint 对于 调用者和实施者来说都是可选的. WebApplication 可以选择不支持 该方法, WebServer 也可以忽略它. d : since the errors stream may not be rewound, servers and gateways are free to forward write opertions immediately, without buffering. In this case, the flush() method may be a no-op. Portable applications, however, cannot assume that output is unbuffered or that flush() is a no-op. They must call flush() if they need to ensure that output has in fact been written.(For example, to minimize intermingling of data from multiple processes writing to the same error log). 对于考虑兼容性和普适性的 WebServer 来说, 上面表格中的方法必须要支持. 遵守这些规格实现的 WebApplication, 必须要保证不使用 input 和 output 对象的任何可调用方法和属性. 尤其的, WebApplication 一定不要尝试关闭这些 stream 对象, 即使该对象提供了 close() 方法. 2.3 start_response() 可调用对象调用方法 start_response(status, response_headers, exc_info=None), 其中的参数, 必须为位置参数, 而不能是关键字参数. 该方法调用返回的结果是一个 write(body_data) 的可调用对象, 用作 HTTP 响应. status 参数是一个 HTTP status 字符串, 包含以空格分隔的 HTTP 响应码 和 HTTP 响应字符串, 类似: 200 OK, 404 Not Found. 该字符串 无需包含控制字符, 如换行符, 回车等. response_headers 是一个由多个 (header_name, header_value) 元组组成的标准 Python 列表. WebServer 可以使用任何 Python List 支持的方法调用该列表. 每个 header_name 必须是一个可用的 HTTP 头字段, 并且不包含 特殊标点符号. 每个 header_value 必须不能包含任何控制字符, 包括回车和换行. 通常情况下, WebServer 需要保证响应客户端的数据包含正确的响应头, 任何 WebApplication 遗漏的 HTTP 首部, WebServer 需要将该首部添加到 HTTP 响应中. 例如, HTTP 响应中的 Data 首部和 Server 首部通常由 WebServer 添加. WebApplication 和 Middleware 应当禁止使用 HTTP/1.1 的 hop-by-hop 特性或首部, 同时, 任何等价的 HTTP/1.0 中的特性或首部, 都会影响到客户端到服务端的持久连接. 这些特性只有在特定领域的 web server 中才有, 因此, WebServer 应当将他作为一个 error 并 抛出草屋, 当 WebApplication 尝试发送这些信息的时候. 当 WebServer 调用 start_response() 时, 应当检查所有首部中的 error, 并在检查出错误时, 将这些 error 抛出. 然而, start_response() 必须禁止传输 来自 WebApplication 的首部. 反之, 它必须为 WebServer 保存这些信息, 并在 WebApplication 的完成首次迭代的时候返回这些信息 或 WebApplication 首次调用 write() 方法时. 即, 响应首部必须要在有真正的 响应体可用时, 或 WebApplication 返回的迭代器迭代完成之后, 才能返回. 这种延迟的相应首部传输是为了保证 直到最后时刻使用缓存的或者异步的 WebApplication 可以用 Error 信息替换原有的首部信息. 例如, 当一个错误在 WebApplication 缓存内部被抛出, WebApplication 可以把响应首部从 200 OK 修改为 500 Internal Error. 当提供 exc_info 参数时, 它必须是一个 Python 的 sys.exc_info() 元组. 只有当 start_response() 被一个错误处理器调用时, exc_info 参数才应该被提供. 如果提供 exc_info 参数, 并且 尚未生成 HTTP 首部时, start_response() 方法应当使用当前缓存的 HTTP 响应首部替换新的响应首部, 因此, 以此实现 在错误发生时, 允许 WebApplication 修改返回给客户端的响应内容. 然而, 当 exc_info 被提供, 并且 响应首部已经发送给客户端, start_response() 必须抛出一个错误, 同时使用 exc_info 元组再次抛出错误. 1raise exc_info[1].with_traceback(exc_info[2]) 上面的代码会再次抛出被 WebApplication 捕获的错误, 同时, 原则上会终止 WebApplication . 如果 WebApplication 带 exc_info 参数调用 start_response , WebApplication 一定不能捕获任何被 start_response() 抛出的异常. 相反, WebApplication 应当将这样的异常传递给 WebServer , 由它来处理. 只有当 exc_info 参数提供时, WebApplication 可能会多次调用 start_response. 更精确的讲, start_response 已经被 WebApplication 调用, 如果再次使用 不带 exc_info 的参数调用 start_response 方法, 将是致命的错误, 包括第一个调用 start_response 就抛出错误的情况. 123456def start_response(status, response_headers, exc_info=None): if exc_info: try: # do stuff w/exc_info here finally: exc_info = None # Avoid circular ref. 2.4 处理 Content-Length 首部当 WebApplication 提供 Content-Length 首部时, WebServer 绝对不能传输多余此 Content-Length 指定数量的 bytes 给客户端, 而是在获取足够数据时, 停止迭代响应, 或者在 WebApplication 尝试抛出多个这个数量的数据时, 抛出一个异常. 当然, 如果 WebApplication 未能提供做够的数据符合 Content-Length 的数量时, WebServer 应当关闭链接或记录并报告错误. 如果 WebApplication 未能提供 Context-Length 首部, WebServer 应当使用适当的手段来处理这种情况. 最简单的办法是 当响应完成时, 关闭到 客户端的链接. 然而, 在某些情况下, WebServer 可能生成一个 Content-Length 首部或至少避免关闭一个到客户端的链接. 如果 WebApplication 没有调用 write() 可调用方法, 而是返回了一个可迭代的对象, 其长度len()为 1, 则 WebServer 可以自主决定使用迭代对象返回的第一个 bytestring 长度作为 Content-Length. 如果, WebServer 端和 客户端均支持 HTTP/1.1 chunked encoding 特性, WebServer 可能使用 chunked encoding 方式 为每次 write() 或 迭代器迭代 发送 chunk, 并为其生成适当的 Content-Length 首部. 这种方式, 将允许 WebServer 保持到客户端的长连接. 这种情况下, WebServer 必须完全遵守 RFC 2616 规范, 或者使用其他的策略生成 Content-Length. WebApplication 决不能在其输出结果中, 生成任何类型的 Transfer-Encoding首部, 这些首部应当有 WebServer 生成 2.5 Buffering 和 Streaming一般来讲, WebApplication 可以通过缓存其输出结果,并一次性发送给 WebServer 达到最佳性能. 现在 Zope 的常用方式是: 将输出缓存到一个 StringIO 或其他类似对象中, 然后一次 将生成的首部和所有结果 传输给 WebServer. 在 WSGI 中实现这种效果的方式是: 返回一个只包含一个结果的可迭代对象, 该可迭代对象包含 一个单独的 bytestring 形式的响应信息. 这也是一种给 WebApplication 的推荐方式. 对于大文件 或者 特殊用途的 HTTP streaming (如 multipart server push)来说, WebApplication 可能需要返回小块的相应结果(以避免一次加载太大的文件到内存中). For large file, however, or for specialized uses of HTTP streaming (such as multipart ‘server push’), an application may need to provide output in smaller blocks (e.g. to avoid loading a large file info memory). It’s also sometimes the case that part of a response may be time-consuming to produce, but it would be useful to send ahead the portion of the response that precedes it. 这种情况下, WebApplication 通常返回一个迭代器(或生成器), 该迭代器使用 block-by-block 的方式生成响应体. These blocks may be broken to coincide with mulitpart boundaries (for server push), or just before time-consuming tasks (such as reading another block of another block of an on-disk file). WebServer 绝对不能延迟传输任何 block, 它要么 一次传输所有的 block 给客户端, 或者保证 持续传输每个 block 给客户端知道 WebApplication 生成它的下一个 block. WebServer 可以采用如下的一种或多种方式实现这种保证: 在将控制权返回为 WebApplication 之前, 发送整个 block 给操作系统(并且要求 操作系统层级的缓存被清空). 在 WebApplication 生成下一个 block 的同时, 使用不同的线程来保证整个 block 被持续的传输给客户端, 发送整个 block 给它的上层 WebServer 或 WebGateway, 这只适用于 Middleware . WSGI 协议通过这种保证, 允许 WebApplication 保证, 其响应数据会被均衡的传输给任意节点. By providing this guarantee, WSGI allows applications to ensure that transmission will not become stalled at an arbitraty point in their output data. This is critical for proper functioning of e.g. multipart “server push” streaming, where data between multipart boundaries should be transmitted in full to the client. 2.6 Middleware Handling of Block Boundaries为了更好的支持异步 WebApplication 和 WebServer, Middleware 组件不能 在等待 WebApplication 迭代器返回多个值时, 阻塞迭代. 如果 Middleware 组件 在响应请求之前 需要积攒多个数据块, 他必须 yield 一个空的 bytestring. 这种要求的另一种实现方法是, 一个 Middleware 组件每次必须 从 WebApplication 返回的可迭代对象中 yield 至少一个值. 如果 Middleware 不能 yield 值, 则返回一个 空的 bytestring. 这种要求可以保证异步 WebApplication 和 WebServer 能够协同合作, 以便减少需要的线程数. 这种要求同事意味着, Middleware 必须 尽快的从 WebApplication 返回的迭代器中 返回可迭代对象. 这同时也禁止了 Middleware 使用 write() 可调用对象取传输数据. Middleware 组件只能使用其上游 WebServer 的 write() 可调用对象来传输数据. 2.7 write() 可调用方法一些也已存在的 WebApplication 框架 API 支持无缓存的 删除, 这种方式是与 WSGI 规定的方式不同的. 尤其是, 这些 WebApplication 提供一个 write 函数或方法, 用于写入无缓存的数据块, 或者他们也会提供一个 指出缓存的 write 方法和一个 flush 机制来情况缓存. 不幸的是, 这些 API 无法按照 遵循WSGI 的 WebApplication 返回的可迭代对象那样执行, 除非使用了线程或其他机制. 如果可以避免的话, 新的 WSGI WebApplication 不应该使用 write 可调用方法. write() 方法严格讲是一个 hack 方法, 用于支持必要的 streaming API. 通常来讲, WebApplication 应当通过他们返回的可迭代对象来使用其标准输出, 同时, 这也使得 WebApplication 在同一个 Python 线程中交叉运行task 成为可能, 潜在的为 WebServer 提升了更好的吞吐能力. write 返回由 start_response 方法返回, 它只接受一个参数: 一个字节字符, 用作 HTTP 响应体的一部分. 这种处理方式和 WebApplication 返回的可迭代对象的处理方式是一样的. 换言之, 在 write() 返回之前, 必须保证已被传递的 字节字符, 要么完全被传输给客户端, 要么被 WebApplication 缓存. 一个 WebApplication 必须返回一个可迭代对象, 即使他使用 write() 来处理部分或全部的数据. 返回的 可迭代对象可以为空, 但是它 yield 非空字节字符, 这些非空的返回结果, 必须被 WebServer 正确的处理. WebApplication 必须不能调用 write 方法在他们的返回迭代器的内部. Applications must not invoke write() from within their return iterable, and therefore any bytestrings yielded by the iterable are transmitted after all bytestrings passed to write have been sent to the client. 2.8 Unicode 引发的问题HTTP 协议不支持 unicode 编码, 所有的 编码和解码 必须有 WebApplication 处理, 任何从 WebServer 传入或传出的字符必须是 str 或 bytes 类型, 而不是 unicode. 在应该使用 string 对象的地方使用 unicode 对象的结果是未定义的. 同时需要注意的是, 任何传给 start_response 作为 HTTP 响应码和响应首部的字符, 必须遵守 RFC 2616 的编码规定. 即, 这些字符要么是 ISO-8859 编码 或者是 RFC 2047 支持的 MIME 类型编码. 在 Python 平台中, 所有的 str 或 StringType 类型字符都是 Unicode-based 的. all strings referred to in this specification must contain only code points representable in ISO-885901 encoding. WebApplication 提供的字符包含其他 Unicode 字符串是一个致命的错误. 类似地, WebServer 和 WebGateway 必须不支持 WebApplication 中包含其他的 Unicode 字符. Again, all objects referred to in this specification as strings must be of type str or StringType, and must not be of type Unicode or UnicodeType. And, even if a given platform allows for more than 8 bits per character in str/StringType objects, only the lower 8 bits may be used, for any value referred to in this specification as a ‘string’. 2.9 错误处理通常情况下, WebApplication 应当捕获其内部的错误, 并在客户端浏览器展示相关的帮助信息. 然而, 为了展示这些帮助信息, WebApplication 必须尚未真正的发送任何数据给客户端, 或者 it risks corrupting the response. WSGI 因此提供一种机制, 可用于向允许 WebApplication 发送其错误帮助信息, 或者自动忽略 start_response 的 exc_info 参数. 123456789101112try: # regular application code here status = "200 OK" response_headers = [("content-type", "text/plain")] start_response(status, response_headers) return ["normal body goes here"]except: # XXX shoule trap runtime issues like MemoryError, KeyboardInterrupt # in a separate handler before this bare `except:` ... status = "500 Oops" start_response(status, response_headers, sys.exc_info()) return ["error body goes here"] 当一个异常发生时, 如果没有 输出被写入, 对 start_response 的调用将会正常返回, 并且 WebApplication 会返回错误信息给客户端浏览器. 然而, 如果有任何输出已经被传输给客户端, start_response 将会再次抛出该异常. 这种异常不应当被 WebApplication 捕获, 因此, WebApplication 应当忽略它. 然后又 WebServer 捕获该异常, 并忽略 WebApplication 的返回内容. WebServer 应当捕获并记录任何 终止 WebApplication 或 终止 WebApplication 返会迭代对象迭代 的异常结果. 当 WebApplication 发生错误时, 如果响应内容的一部分已经发送给客户端, WebServer 或 WebGateway 可以尝试将错误信息添加到 返回给客户端的结果中. 另外, 如果已发送的响应中包含 text/* 类型内容, 则 WebApplication 知道如何干净的修改. 一些 Middleware 组件可能希望提供附加的 异常处理服务, 或者拦截并替代 WebApplication 的错误帮助信息. 这种情况下, Middleware 可能选择不再抛出 应用到 start_response 的 exc_info 异常, 取而代之的是, 抛出一个 Middleware 的自定义异常, 或者只是简单的返回不包含任何异常的响应. 这种处理方式, 将会导致 WebApplication 返回 可迭代的错误信息, 并允许 Middleware 捕获并修改这些错误输出信息. These techniques will work as long as appliocation authors. Always provide exc_info when beginning an error response. Never trap errors raised by start_response when exc_info is being provided. 2.10 HTTP/1.1 Expect/Continue 机制选择支持 HTTP/1.1 的 WebServer 必须要支持 HTTP/1.1 的 Expect/continue 机制, 可以有以下几种实现方式: Respond to request containing an Expect: 100-continue request with an immediate 100 continue resposne, and proceed normally. Proceed with the request normally, but provide the application with a wsgi.input stream that will send the 100 continue response if/when the application first attempts to read from the input stream. The read request must then remain blocked until the client responds. Wait until the client decides that the server does not support expect/continue, and sends the request body on its own (this is suboptimal, and is not recommended). Not that these behavior restrictions do not apply for HTTP 1.0 requests, or for requests that are not directed to an application object. For more information on HTTP/1.1 Expect/Continue, see RFC 2616 sections 8.2.3 and 10.1.1 . 2.11 其他 HTTP 特点通常来讲, WebServer 应当 paly dumb, 并允许 WebApplication 完全控制它输出. WebServer 只有在不修改 WebApplication 返回结果的语义的情况下, 才可以修改 WebApplication 的原生的返回. WebApplication 开发者可以添加 Middleware 组件来支持额外的功能特性, 所以, WebServer 开发者应当在其开发计划中尽量保守. 某种意义上, WebServer 应当把自己当做 HTTP 的网关服务器, 而把 WebApplication 当做 ‘真正的’ 服务器. 然而, 由于 WSGI WebServer 和 WebApplication 之间通讯不是走 HTTP 协议, 因此, RFC 2616 中说明的 hop-by-hop 首部不支持 WSGI 组件之间的通讯. WSGI 的 WebApplication 一定不要生成任何 hop-by-hop 的首部, 尝试使用 这些HTTP 特性可能需要他们生成这些 首部, 或者依赖 传入的 environ 字典中包含 hop-by-hop 首部信息. WSGI WebServer 必须处理任何传入的 hop-by-hop 首部, 例如 编码传入的 Transfer-Encoding. 这些规则可以应用到多种 HTTP 特性, 应当清楚的是, WebServer 可能会处理缓存有效性, 通过 If-None-Mathc 和 If-Modified-Since 请求头和 Last-Modified 和 Etag 响应首部. 但是这些不是强制性的, WebApplication 应当自主的控制缓存的有效性来支持这些特性. 类似的, 一个 WebServer 可能会 重新编码 或 传输编码 WebApplication 的相应内容, 但是 WebApplication 应该选择一个适合自己的内容编码方式, 并且, 切忌应用 传输编码( transport encoding). A server may transmit byte ranges of the application’s response if requestd by the client, and the application doesn’t natively support byte ranges. Again, however, the application should perform this function on its own if desired. 需要注意的是, WebApplication 无需实现所有的 HTTP 特性, 并且有的 HTTP 特性可以部分或完全的 由 Middleware 组件实现. 2.12 线程支持线程支持是依赖于 WebServer 端的支持特性的. 支持并发处理多个请求的 WebServer 也应当同时提供 在一个单独的线程中运行 WebApplication 的方法. 这样, 费线程安全的 WebApplication 和 Web 框架也可以使用这些 WebServer. 2.13 Application ConfigurationWSGI 协议并不定义一个 WebServer 如何选择或者获取一个 WebApplication 来调用, 这些细则是 WebServer 高度定制化实现的. 因此, 只能期望 WebServer 开发者在文档中写清楚 WebServer 是如何执行一个特定的 WebApplication 对象的, 并且需要哪些选项和参数. WebServer 开发者应当在文档中记录如何调用框架的功能函数创建一个 WebApplication. 最终, 一些 WebApplication , 框架, Middleware 可能希望使用 environ 字典来接受简单的字符串配置选项. WebServer 应当通过 允许一个 WebApplication 部署者提供存放在 environ 中的简单的 key-valu 对 来支持这种方式. 最简单的例子就是, 这种方式能支持从 os.environ 中得到的系统环境变量拷贝到 environ 字典中, 因为部署者可以自定义 WebApplication 运行环境的特定的变量, 或者 在使用 CGI 的环境中, 可以通过 WebServer 的环境变量来设置额外变量. Application should try to keep such required variables to a minimum, since not all servers will support easy configuration of them. Of course, even in the worst case, persons deploying an application can create a script to supply the necessary configuration values: 12345from the_app import applicationdef new_app(environ, start_response): environ["the_app.configval1"] = "something" return application(environ, start_response) 但是, 目前已存的大多数 WebApplication 和 框架可能只是需要 从 environ 中获取一个简单的值, 来说明当前 WebApplication 的特定配置文件的位置, 然后, WebApplication 会缓存该值的结果. 2.14 URL 重建如果一个 WebApplication 希望重建一个请求的完整的 URL, 它可能使用下面的算法来实现: 1234567891011121314151617181920from urllib.parse import quoteurl = environ["wsgi.url_scheme"] + "://"if environ.get("HTTP_HOST"): url += environ["HTTP_HOST"]else: url += environ["SERVER_NAME"] if environ["wsgi.url_scheme"] == "https": if environ["SERVER_PORT"] != "443": url += ":" + environ["SERVER_PORT"] else: if environ["SERVER_PORT"] != "80": url += ":" + environ["SERVER_PORT"]url += quote(environ.get("SCRIPT_NAME", ""))url += quote(environ.get("PATH_INFO", ""))if environ.get("QUERY_STRING"): url += "?" + environ["QUERY+STRING"] 需要注意的是, 上面算法重建出的 URL 可能并不精确的等于 用户请求的 URL. 例如, WebServer 重写的 URL 可能修改了客户单请求的原有的 URL, 并替换为 权威格式. 3. WebServer/Gateway每当 WebServer 端从 HTTP 客户端接受到一个请求, 都会调用一个 WebApplication , 并指向该 WebApplication. 示例代码: 如下是一个 简单的 CGI gateway, 使用 function 实现, 以一个 application 作为参数. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import os, sysenc, esc = sys.getfilesystemencoding(), "surrogateescape"def unicode_to_wsgi(u): # Convert an environment variable to a WSGI 'bytes-as-unicode' string # return `u.encode(enc, esc).decode("iso-8859-1")` return u.encode(enc, esc).decode("iso-8859-1")def wsgi_to_bytes(s): return s.encode("iso-8859-1")def run_with_cgi(application): environ = &#123;k: unicode_to_wsgi(v) for k,v in os.environ.items()&#125; environ["wsgi.input"] = sys.stdin.buffer environ["wsgi.errors"] = sys.stderr environ["wsgi.version"] = (1, 0) environ["wsgi.multithread"] = False environ["wsgi.multiprocess"] = True environ["wsgi.run_once"] = True if environ.get("HTTPS", "off") in ("on", "1"): environ["wsgi.url_scheme"] = "https" else: environ["wsgi.url_scheme"] = "http" headers_set = [] headers_sent = [] def write(data): out = sys.stdout.buffer if not headers_set: raise AssertionError("Write() before start_response()") elif not headers_sent: # before the first output, send the stored headers. status, response_headers = headers_sent[:] = headers_set out.write(wsgi_to_bytes("Status: %s\r\n" % status)) for header in response_headers: out.write(wsgi_to_bytes("%s: %s\r\n" % header)) out.write(wsgi_to_bytes("\r\n")) out.write(data) out.flush() def start_response(status, response_headers, exc_info=None): if exc_info: try: if headers_sent: # Re-raise original exception if headers sent raise exc_info[1].with_traceback(exc_info[2]) finally: exc_info = None # avoid dangling circular ref elif headers_set: raise AssertionError("headers already set!") headers_set[:] = [status, response_headers] # Note: error checking on the headers should happen here, # *after* the headers are set. That way, if an error occurs, # start_response can only be re-called with exc_info set. return write result = application(environ, start_response) # 参见上面的 AppClass. try: for data in result: if data: # don't send headers until body appears. write(data) if not headers_sent: write("") # sned headers now if body war empty finally: if hasattr(result, "close"): result.close() 3.2 WebServer 的高级扩展 APIWebServer 开发者可以向 WebApplication 暴露特定的 API, 以便实现特殊的用途和目的. 最简单的情况下, 只需定义一个 environ 变量即可, 比如 mod_python.some_api. 但是, 很多情况下, 可能存在 Middleware 组件会使 API 的暴露变得困难. 例如, 一个暴露 HTTP 首部的 API 可以定义的 environ 中, 但是, 他可能会 由于 Middleware 对 environ 的修改而返回不同的结果. 通常情况下, 任何复制,代替,绕过 WSGI 功能的 扩展 API 都可能会有与 Middleware 组件不兼容的风险. WebServer 的开发者不应该假设 没有人使用 Middleware 组件, 因为一些框架开发者尤其倾向于使用各种各样的 Middleware 组件组织或者重构框架. 所以为了最大的兼容性, 提供可以替代 WSGI 部分功能的扩展 API 的 WebServer ,必须设计这些 API, 这样才可以调用那些被替换的原生 API (So, to provide maximum compatibility, servers and gateways that provide extension APIs that replace some WSGI functionality, must design those APIs so that they are invoked using the portion of the APIs that they replace). For example, an extension API to access HTTP request headers must require the application to pass in its current environ, so that the server/gateway may verify that HTTP headers accessible via the API have not been altered by middleware. If the extension API cannot guarantee that it will always agree with environ about the contents of HTTP headers, it must refuse service to the application, e.g. by raising an error, returning None instead of a header collection, or whatever is appropriate to the API. 类似的, 如果一个扩展 API 提供一个 重写响应体和响应首部的替代方法, 它应当要求 start_response() 方法被传入调用, 在 WebApplication 可以包含这些扩展的服务. 如果传入的对象不是 WebServer 原生提供给 WebApplication 的那个对象, 则不能保证操作的正确性, 而且很可能拒绝为 WebApplication 提供扩展服务. 该指导方针同样适用于在 Middleware 中添加 cookie 解析, form 变量, session 和 environ 等其他信息. 特别的, Middleware 应当以 函数的方式提供这些 操作 environ 特性, 而不是简单的在 environ 中填充变量(键值对). 这将有助于保证 相关的信息是在经过经过其他 Middleware, 或者 URL 重写, 或者 environ 修改之后, 从 environ 中计算得来. 在 WebServer 和 Middleware 的开发过程中遵循 安全扩展(safe extension)的准则是十分重要的. in order to avoid a future in which middleware developers are forced to delete any and all extension APIs from environ to ensure that their mediation isn’t being bypassed by applications using those extensions. 3.3 Optional Platform-Specific File Handling一个操作系统环境可能提供特殊的高性能的文件传输机制, 例如 Unix 系统的 sendfile() 调用. WebServer 可以通过一个environ 中的可选的 wsgi.file_wrapper 键值来暴露该功能. WebApplication 可以使用这个 file wrapper 来转换一个 文件或类文件对象 为一个可迭代对象: 1234if 'wsgi.file_wrapper' in environ: return environ["wsgi.file_wrapper"](filelike, block_size)else: return iter(lambda: filelike.read(block_size), "") 如果 WebServer 支持 wsgi.file_wrapper, 对象必须是可调用的, 且支持一个必选的位置参数, 一个可选的位置参数. 第一个必选参数是一个要传输的 类文件对象, 第二个可选参数是 建议的 字节大小. 该可调用对象必须返回一个可迭代对象, 并且不能传递(transmission) 任何数据, 直到 WebServer 真正接受从 WebApplication 接到可迭代对象作为返回值. 被 WebApplication 支持的, 被称为 类文件的对象必须包含一个 read() 方法, 该方法接受一个可选的 size 参数. 该对象可能有一个 close() 方法, 如果有 close() 方法, 被 wsgi.filr_wrapper 返回的 可迭代对象必须包含一个 close() 方法来调用 类文件对象的原声的 close() 方法. 如果该类文件对象包含其他 与Python原声文件对象 相同的方法或属性(如 fileno()), 则 wsgi.file_wrapper 可以假设这些方法和属性与 Python 内置文件对象具有相同的语义. 任何平台特定的 file handling 实现必须在 WebApplication 返回之后才会发生(处理), 并且 WebServer 会检查 是否返回了该对象. 再次, 由于 Middleware, 错误处理程序等的存在, 不能保证 人恶化 file_wrapper 被真正的使用. 除了需要包含 close() 方法之外, WebApplication 返回的 file_wrapper 应当与 WebApplication 返回 iter(filelike.read, &quot;&quot;) 一样. In other words, transmission should begin at the current position within the ‘file’ at the time that transmission begins, and continue until the end is reached, or until Content-Length bytes have been written.(If the application doesn’t supply a Content-Length, the server may generate one from the file using its knowledge of the underlying file implemnentation). 主要注意的是, 即使 对象 不适合平台的 API, wsgi.file_wrapper 必须任然返回一个实现了 read() 方法和 close() 方法的迭代器. 这样, 使用 file_wrapper 的 WebApplication 就可以实现跨平台移植. 如下是一个简单的 平台无关的 file_wrapper 类, 适合 新老版本的 Python 12345678910111213141516class Filewrapper: def __init__(self, filelike, blksize=8192): self.filelike = filelike self.blksize = blksize if hasattr(filelike, "close"): self.close = filelike.close def __getitem__(self, key): data = self.filelike.read(self.blksize) if data: return data raise IndexError 如下是一个 WebServer 中的代码片段, 用于提供 到特定平台的 API 12345678910111213141516environ['wsfi.file_wrapper'] = Filewrapperresult = application(environ, start_response)try: if isinstance(result, Filewrapper): # check if result.filelike is usable w/platform-specific # API, and if so, use that API to transmit the result. # If not, fall through to normal iterable handling loop below. for data in result: # etc.finally: if hasattr(result, "close"): result.close() 4. MiddlewareMiddleware 是一个组件, 它同时兼具 Server 和 Application 的角色. 对于 Application 来讲, 它是 Server; 对于 Server , 它又表现为一个 Application. Middleware 可能具有如下功能: 根据请求的 目标URL, 在重写相应的 environ 变量后, 将请求路由到指定的 Application; 允许多个 Application 同时运行在一个 process 内部. 通过网络转发请求和响应, 实现负载均衡或者远程处理. 对内容进行后期处理, 比如应用 XSL 自定义模板. Middleware 的存在对于 WebServer 端和 WebApplication 端来讲都应该是透明的, 并且没有特殊的依赖. 用户在使用 Middleware 时, 只需简单的将 Middleware 组件提供给 WebServer 即可, 就像他是一个 WebApplication 一样, 然后配置 Middleware 组件调用 WebApplication 即可. Of course, the “application” that the middleware wraps may in fact be another middleware component wrapping another application, and so on, creating what is referred to as a “middleware stack”. 大多数情况下, Middleware 必须严格与 WebServer 和 WebApplication 适配, 因此, Middleware 的约束与依赖, 可能要比淡村的 WebServer 和 WebApplication 更多. 如下是一个 Middleware 示例代码, 用于将 text/plain 转换为 pig Latin. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364from piglatin import piglatinclass LatinIter: """ Transform iterated output to piglation, if it's okey to do so Note that the 'okayness' can change until the application yields its first non-empty betestring, so `transform_ok` has to be a mutable truth value. """ def __init__(self, result, transform_ok): if hasattr(result, "close"): self.close = result.close self._next = iter(result).__next__ self.transform_ok = transform_ok def __iter__(self): result self def __next__(self): if self.transform_ok: return piglatin(self._next) # call must be byte-safe on Py3 else: return self._next()class Latinator: # by default, don't transform output. transform = False def __init__(self, application): self.application = application def __call__(self, environ, start_response): transform_ok = [] def start_latin(status, response_handers, exc_info=None): # Reset ok flag, in case this is a repeat call del transform_ok[:] for name, vlaue in response_handers: if name.lower() == "content-type" and value == "text/plain": transform_ok.append(True) # Strip context-length if present, else it'll be wrong. response_handers = [(name, value) for name, value in response_handers if name.lower() != "content-length"] break write = start_response(status, response_handers, exc_info) if transform_ok: def write_latin(data): write(piglatin(data)) # call must be byte-safe on Py3 return write_latin else: return write return LatinIter(self.application(environ, start_latin), transform_ok)# Run foo_app under a Latinator's control, using the example CGI gatewayfrom foo_app import foo_apprun_with_cgi(Latinator(foo_app)) 三. 杂项1. pep-0333 和 pep-3333pep-3333 是为了适用 python3 而对 pep-0333 的升级. 2. 生词1234567891011121314perface : 前言 abstract : 摘要, 抽象. rationale : 基本原理 specification : 规则, 说明书. reconstruction : 重建, 再建, 改造. amendments : 修正 incorporate : 包含, 吸收, 体现. procedural : 程序性的 revision : 修正 vice : 恶习, 缺点, 代替的 By contras : 作为对比. implement : 实现 illustrate : 举例说明 surrogate : 代理 四. 文档地址: PEP-3333 PEP-3333 中文 PEP-0333]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>web development</tag>
        <tag>wsgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 类, OOP 与 元编程]]></title>
    <url>%2F2018%2F03%2F13%2Fpython-%E7%B1%BB-OOP-%E5%85%83%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Python 闭合(clusure)/工厂函数 : 一个能够记住嵌套作用域的变量值得函数, 尽管那个作用域或许已经不存在了. python 保持状态信息的方法: 全局变量 非本地变量 nonlocal 类属性 函数属性 函数1. 函数作用域2. 函数参数函数参数匹配表: 语法 位置 解释 func(value) 调用者 常规参数: 通过位置进行匹配 func(name=value) 调用者 关键字参数, 通过变量名进行匹配 func(*sequence) 调用者 以 name 传递所有的对象, 并作为独立的基于位置的参数 func(**dict) 调用者 以 name 成对的传递所有的关键字/值, 并作为独立的关键字参数 def func(name) 函数 常规参数, 通过位置或变量名进行匹配 def func(name=value) 函数 默认参数值, 如果没有在调用中传递的话 def func(*name) 函数 匹配并收集(在元组中)所有包含位置的参数 def func(**name) 函数 匹配并收集(在字典中)所有包含位置的参数 def func(args,name) , def func(, name=value) 函数 参数必须在调用中按照关键字传递( Python 3.0) name=value 的形式在调用时和 def 中有两种不同的含义. 在调用中代表关键字参数, 在函数头部代表默认值参数 参数顺序: 在函数调用中, 参数必须以如下顺序出现: 位置参数 , 关键字参数, *sequence, **dict 在函数定义中, 参数必须以如下顺序出现: 一般参数 , 默认参数, *name, name 或 name=value keyword-only 参数, **name 参数 3. 高阶函数3.1 递归3.2 函数对象1. 间接调用def echo(msg): print msg schedule = [(echo, &quot;SPAM&quot;), (echo, &quot;HAM&quot;)] for (func, arg) in schedule: func(arg) # 偏函数 def make(lable): def echo(msg): print lable + &quot;:&quot; + msg return echo f = make(&quot;SPAM&quot;) f(&quot;HAM&quot;) 2. 函数内省f.__name__ dir(f) f.__code__ dir(f.__code__) f.__code__.co_varnames f.__code__.co_argcount 3. 函数属性函数属性可以用来直接把状态信息附加到函数对象, 而不必使用全局,非本地,类等其他技术.函数属性可以在函数的任何地方访问, 也是模拟其他语言中”静态本地变量”的一种方式: 这种变量的名称对于一个函数来说是本地的, 但是, 其值在函数退出后仍然保留.函数属性与对象相关, 而不是与作用域相关. f.age = 12 f.age += 11 f.job = &quot;manager&quot; dir(f) 4. python 3.0 函数注解在 Python 3.0 中可以给函数对象添加注释信息 – 与函数的参数和结果相关的任意用户自定义数据. 注解本身是可选的, 并且自身不做任何事情, 当使用注解时, 他将直接附加到函数的 __annotations__ 属性, 供其他用户使用. 语法: 函数注解编写在 def 头部行, - 参数 :紧随参数名之后的冒号之后, 并且出现在函数默认值之**前**; - 返回值 : 编写与紧跟在参数列表之后的一个 `-&gt;` 之后. def func(a: &quot;SPAM&quot; = 4, b: (1,10) = 5, c: float = 6) -&gt; int: return a + b + c func(1,2,3) # 6 func() # 15 func(1, c=10) # 16 func.__annotations__ # {&quot;a&quot;: &quot;SPAM&quot;, &quot;b&quot;: (1,10), &quot;c&quot;: &lt;class &apos;float&apos;&gt;, &quot;return&quot;: &lt;class &apos;int&apos;&gt;} 调用一个注解过的函数, 与普通函数无异. 但, 当注解被定义的时候, Python 将其收集到 FUNC.__annotations__ 字典, 并将它附加给函数对象本身. 参数名变成键. 如果编写了返回值注解, 键为 ‘return’. 由于注解只是附加到一个 python 对象的python 对象, 注解可以直接处理. 注解可以用作参数类型或值得限制, 并且较大的 API 可能使用这一功能作为注册函数接口信息的方式. 注解只在 def 语句中生效, 在 lamdba 表达式中无效 3.3 匿名函数 lambdalamdba 是一种生成函数对象的表达式形式. 这个表达式创建了一个之后能调用的函数, 但是他返回一个函数而不是将这个函数赋值给一个变量名, 这也是 lambda 被称为匿名函数(没有函数名)的原因. lambda 是一个表达式, 而不是一个语句; lambda 的主体是一个单个的表达式, 而不是一个代码块. 在 lambda 主体中大代码遵循与 def 定义函数相同的作用于查找法则, LEGB. L = [ lambda x : x**2, lambda x: x ** 3, lambda x : x ** 4] for i in L: print i(2) # 4,8,16 # f 被赋值给一个 lambda 表达式创建的函数对象. f = lambda x,y,z : x + y + z # lamdba 支持默认参数: x = (lamdba a=&quot;fee&quot;, b=&quot;fie&quot;, c=&quot;foe&quot;: a + b + c) # 两个数中, 取最小值. lower = (lambda x,y: x if x &lt; y else y) 3.4 函数式编程函数式编程就是对序列应用一些函数的工具. 在 python 3 中, map 和 filter 都返回可迭代对象. mapmap 函数会对一个序列对象中每一个元素应用被传入的函数, 并且返回一个包含了所有函数调用结果的一个列表. 在 Python 3 中, map 是一个可迭代对象 # 普通定义形式 def inc(x): return x + 10 map(inc, range(1,5)) # lambda 定义形式 map(lambda x : x + 10, range(1,5)) # 在 python 3 中 list(map(inc, range(1,5))) list(map(lambda x : x + 10, range(1,5))) 高级用法: 多个序列时, map 期待一个 N 参数的函数用于 N 序列. pow(3,4) # 81 map(pow, [1,2,3], [2,3,4]) # 1,8,81 filter(func, list)对于 list 中的每个元素, 作为参数传入 func 中, 并将所有 func 返回真的 元素, 加入到 结果列表中返回. # 返回列表中, 所有大于 0 的值. filter(lambda x : x &gt; 0, range(-5,5)) # python 3 中 list(filter(lambda x : x &gt; 0, range(-5,5))) reduce(func, list)reduce 中的 func 接受两个参数, 并返回一个结果. 首先将 func 用于 list 中的前两个元素, 然后将返回的结果与list 中的下一个元素, 作为参数, 再次传入 func, 依次类推. 最后返回一个单个元素的结果. reduce 接受一个迭代器来处理, 但是, 他本身并不是迭代器, 而是返回单个结果. 在 python 3 中, 需要从 functools 中导入. # python 3 from functools import reduce reduce((lambda x, y : x + y), range(1,5)) # 10 # python 2.6 reduce((lambda x, y : x + y), range(1,5)) 迭代和解析 模块模块和模块包是 python 中程序代码重用的最高层次. import: 导入:在 Python 中导入并非只是把一个文件文本插入另一个文件而已, 导入其实是运行时的运算, 会执行如下三个步骤: 找到模块文件 –&gt; 标准模块搜索路径. 编译成位码 python 检查文件的时间戳, 如果发现字节码文件比源代码文件旧, 就会在程序运行时自动重新生成字节代码. 如果发现 字节码文件不比源码文件旧, 则跳过编译步骤, 直接加载 pyc 字节码文件. 当文件导入时, 就会进行编译. 因此通常不会看到顶层文件的字节码文件, 除非顶层文件也被其他文件导入: 只有被导入的文件才会在机器上留下字节码 .pyc 文件. 顶层文件的字节码时在内存中使用后就丢弃了; 被导入文件的字节码则保存在文件中从而可以提高之后导入的运行速度. 执行模块的代码来创建其所定义的对象. 这三个步骤只在程序执行时, 模块第一次导入时才会运行. 之后, 导入相同模块时, 会跳过三个步骤, 而只是提取内存中已加载的模块对象. Python 把载入的模块存储到一个名为 sys.modules 的表中, 并在一次导入操作的开始检查该表, 如果模块不存在, 才会启动上面的三个步骤. 模块搜索路径 程序主目录 PYTHONPATH 目录(如果有定义) 标准链接库目录 任何 .pth 文件的内容(如果存在) 打印模块搜索路径: import sys print sys.path # 导入操作, 会从左自右搜索列表中的每一个目录 sys.path.append(dirname) # 添加新的目录 模块文件选择: 源代码文件 .py 字节码文件 .pyc 目录, 包导入 编译扩展模块(通常使用C 或 C++ 编写), 导入时使用动态链接. 用 C 编写的编译好的内置模块, 并通过静态链接至python zip 文件组, 导入时会自动解压 内存内映像, 对于 frozen 可执行文件 java 类, 在 Jython 版本的 python 中. .NET 组件, 在 IronPython 版本的 python 中. 导入钩子用于重新定义 import 操作所做的事, 如从归档中加载文件, 执行解密.使用 import 函数, 订制 import 操作. distutilsPython 的第三方扩展, 通常是会用 distutils 工具自动安装. distutils 自带 setup.py 脚本, 该脚本导入并使用 distutils 模块, 将该扩展放在属于模块自动搜索路径一本的目录内, 通常为 Lib/site-pacgages 子目录中. 第三方开源的 eggs 系统, 功能更强大, 增加了对已安装的 python 软件的依存关系的检查. OOP类也是命名空间. 类与模块的不同: 支持多个对象的产生 命名空间继承 运算符重载. 运算符重载就是让用类写成的对象, 可截获并响应用在内置类型上的运算: 加法, 切片,打印, 点号运算符等. 以上只是自动分发机制: 表达式和其他内置运算流程需要经类的实现来控制. 运算符只是表达式对方法的分发机制. 运算符重载时可选的功能, 主要是替其他 Python 程序员开发工具的人在使用, 而不是那些应用程序开发人员在使用. 以双下划线命名的方法(xx) 是特殊钩子. Python 为每种运算和特殊命名的方法之间, 定义了固定不变的映射关系. 当时李出现在内置运算时, 这类方法会自动调用. 类可覆盖多数内置类型运算.有几十种特殊运算符重载的方法的名称, 几乎可截获并实现内置类型的所有运算, 他不仅包括了表达式, 而且打印和对象建立这类基本运算也包含在内. 运算符覆盖方法没有默认值, 而且也不需要. 如果类没有定义或继承运算符重载方法, 就是说相应的运算在类实例中并不支持. 例如, 如果类没有定义 add 方法, 则 + 表达式就会引发异常. 运算符可让类与 python 的对象模型相继承. 重载类型运算时, 以类实现的用户定义对象的行为就会像内置对象一样, 因此, 提供了一致性, 以及与预期接口的兼容性. 类对象和实例对象: 类对象提供默认行为, 是实例对象的工厂. 实例对象是程序处理的实际对象: 各自都有独立的命名空间, 但是继承(可自动存取)创建该实例的类中的变量名. 类对象来源于语句, 而实例来自于调用. 类对象提供默认行为: class 语句创建类对象并将其赋值给变量名. class 语句内的赋值语句会创建类的属性. class 语句的作用域会变成类属性的命名空间. 类属性提供对象的状态和行为. 类对象的属性记录状态信息和行为, 可由这个类所创建的所有实例共享. 实例对象是具体的元素: 像函数那样调用类对象会创建新的实例对象. 每个实例对象继承类的属性并获得自己的命名空间. 在方法内对 self 属性做赋值运算会产生每个实例自己的属性. 重载在类的继承树中较低处发生的重新定义的, 取代属性的行为. 命名空间对象的属性通常都是以字典的形式实现的, 而类继承树(一般而言)只是连接至其他字典的字典而已. dict 属性是针对大多数大多数基于类的对象的命名空间字典(一些类也可能用 slots 中定义了的属性, 这是一个高级而少用的功能) python 在内存中类树常量的表示方法: class : 查看当前实例的父类. bases : 查看当前类的父类的元组. Python 的 OOP 其实就是在已连接命名空间内寻找属性而已. 方法函数中的特殊 self 参数和 init 构造函数是 Python 的 OOP 的两个基石. 27 更多实例构造函数行为方法运算符重载子类 类方法总是可以在一个实例中调用(这是通常方法, python 自动把该实例发送给 self 参数), 或者通过类来调用(较少见的方式, 其中我们必须手动的传递实例). 如下的常规方法调用: instance.method(args ...) 由 python 自动转换为如下的同等形式: class.method(instance, args ...) class Person: def __init__(self, name, job=None, pay=0): self.name = name self.job = job self.pay = pay def get_raise(self, percent): self.pay = self.pay * (1 + percent) class Manager(Person): def get_raise(self, percent, bonus=0.1): Person.get_raise(self, percent + bonus) 订制构造函数内省工具将对象存储到数据库中 Python OOP 的重要概念: 实例创建 –&gt; 填充实例属性 行为方法 –&gt; 在类方法中封装逻辑 运算符重载 –&gt; 为打印这样的内置操作提供行为 订制行为 –&gt; 重新定义子类中的方法以使其特殊化. 订制构造函数 –&gt; 为超类步骤添加初始化逻辑 装饰器和元类 内省工具 METHODNAME : 用于不想做其他用途的方法.__METHODNAME : Python 自动扩展 包含两个 ““ 前缀的方法, 以包含类的名称, 从而使他们变得整整唯一. 该功能称为 “伪私有类属性”. 28 代码编写细节:class 语句 方法继承 属性树的构造 继承方法的专有化 类接口技术 class Super: def method(self): print &quot;In Super.method&quot; def delegate(self): self.action() class Inheritor(Super): pass class Replacer(Super): def method(self): print &quot;In Replacer Method&quot; class Extender(Super): def method(self): print &quot;Starting Extender.method&quot; Super.method(self) print &quot;Ending Extender.method&quot; class Provider(Super): def action(self): print &quot;In Provider.action&quot; if __name__ == &quot;__main__&quot;: for klass in (Inheritor, Replacer, Extender): print &quot;\n&quot; + klass.__name__ + &apos;...&apos; klass().method() print &quot;\n Provider&quot; x = Provider() x.delegate() 抽象超类 : 类的部分默认行为由其子类所提供. 如上面代码中的 Provider 向其超类 Super 提供 action 方法. 类的编写者, 通常会使用 assert 语言, 使得这种子类需求更为明显, 或者引发内置的异常 NotImplementedError. 即如果子类中没有方法定义来替代超类中的默认方法, 将会得到异常. class Super: def delegate(self): self.action() def action(self): assert False, &quot;Action must be defined&quot; class Super: def delegate(self): self.action() def action(self): raise NotImplementedError(&quot;Action must be defined.&quot;) 抽象超类也可以由特殊的类语法来实现, 其编写方法根据版本不同, 而有所变化. # python 3 form abc import ABCMeta, abstractmethod class Super(metaclass=ABCMeta): @abstractmethod def method(self): pass # python 2.6 class Super: __metaclass__ = ABCMeta @abstractmethod def method(self): pass 使用这种方式编写的代码, 带有一个抽象方法的类是不能继承的(即, 我们不同通过调用它来创建一个实例), 除非其所有的抽象方法都已经在子类中定义了. 命名空间 简单变量名 属性名称 禅: 赋值将变量名分类 命名空间字典 命名空间链接 文档字符串类与模块的关系 29 运算符重载运算符重载只是意味着在类方法中拦截内置操作 : 当类的实例出现在内置操作中, Python自动调用重载的方法, 并且该方法的返回值编程了相应操作的结果. 运算符重载让类拦截常规的 python 运算. 类可重载所有 python 表达式运算符 类可重载打印,函数调用,属性点号运算等内置运算. 重载使 类实例的行为像内置函数 重载使通过提供特殊名称的类方法来实现的. 在类中, 对内置对象(如整数和列表)所能做的事, 几乎都有相应的特殊名称的重载方法. 常见运算符重载方法:构造函数和表达式init : 构造函数sub : 减法 class Number: def __init__(self, start): self.data = start def __sub__(self, other): return Number(self.data - other) s = Number(6) y = s - 2 print type(y) print y.data 索引和分片:getitem 索引运算: class Indexer: def __getitem__(self, index): return index ** 2 X = Indexer() print X[2] 拦截分片分片边界绑定到了一个分片对象中, 并且传递给索引的列表实现. 分片语法主要是用一个分片对象进行索引的语法糖. class Indexer: data = [5, 6, 7, 8, 9] def __getitem__(self, index): print &quot;GetItem: &quot;, index return self.data[index] X = Indexer() # GetItem: slice(2, 4, None) print X[2:4] # [7, 8] 当针对分片调用时, 方法接受一个分片对象, 他在一个新的索引表达式中直接传递给嵌套的列表索引. setitem__setitem__ 索引赋值方法类似的拦截索引和分片赋值, 他为后者接受了分片对象, 可能一同样的方式传递到另一个索引赋值中. def __setitem__(self, index, value): # ... self.data[index] = value 在 Python 3.0 之前, 类也可以定义 __getslice__ 和 __setslice__ 方法来专门拦截分片获取和赋值, 他将传递一些列的分片表达式, 并且优先于 __getitem__ 和 __setitem__ 用于分片. 但是这些方法已经在 python 3.0 中移除了. getitem : 索引迭代 –&gt; 这种迭代只是迭代的一种退而求其次的方式.for 循环每次循环是都会调用类的 getitem , 并持续搭配有更高的偏移值. 这是买一送一的情况: 任何会响应索引运算的内置或用户定义的对象, 同样会响应迭代. 任何支持 for 循环的类, 也会自动支持 Python 所有迭代环境, 如 成员关系测试 in , 列表解析, 内置函数 Map, 列表和元组赋值运算及类型构造方法. 在实际应用中, 这个技巧可以用于建立提供序列接口的对象, 并新增逻辑到内置的序列类型运算. class Stepper: def __getitem__(self, i): return self.data[i] x = Stepper() x.data = &quot;spam&quot; for item in X: print item, # s p a m 迭代器对象: iter, next迭代环境是通过调用内置函数 iter 去尝试寻找 iter 方法来实现的, 而这种方法应该返回一个迭代器对象.如果已经提供了, Python 会重复调用这个迭代器的 next 方法, 知道发生 StopIteration 异常.如果没有找到这类 iter 方法, Python 会改用 getitem 机制, 通过偏移量重复索引, 知道发生 IndexError 异常. 在 iter 机制中, 列就是通过实现迭代协议来实现用户自定义的迭代器的. 单一迭代器对象, iter 只需返回 self 即可. 生成器函数和表达式, 以及map, zip 这样的内置函数, 都是单迭代对象. class Squares: def __init__(self, start, stop): self.value = start - 1 self.stop = stop def __iter__(self): return self def __next__(self): # def next(self): Python 2.6 if self.value == self.stop: raise StopIteration self.value += 1 return self.value ** 2 for i in Squares(1, 5): print i, # 1 4 9 16 25 多迭代对象 : range 内置函数和其他内置类型(如列表), 支持独立位置的多个活跃迭代器. # 多活跃迭代器. S = &quot;ace&quot; for x in S: for y in S: print x + y # 类实现示例: class SkipIterator: def __init__(self, wrapped): self.wrapped = wrapped self.offset = 0 def __next__(self): if self.offset &gt;= len(self.wrapped): raise StopIteration else: item = self.wrapped[self.offset] self.offset += 1 return item class SkipObj: def __init__(self, wrapped): self.wrapped = wrapped def __iter__(self): return SkipIterator(self.wrapped) if __name__ == &quot;__main__&quot;: alpha = &quot;abcdef&quot; skipper = SkipObj(alpha) I = iter(skipper) print(next(I), next(I), next(I)) for x in skipper: for y in skipper: print(x + y, end=&quot; &quot;) 成员关系: contains &gt; iter &gt; getitem迭代器的内容比我们看到的还要丰富. 运算符重载往往是多个层级的: 类可以提供特定的方法, 或者用作退而求其次选项的更通用的替代方案. 在迭代领域, 通常把 in 成员关系运算符实现为一个迭代, 使用 iter 方法或 getitem 方法. 如果要支持更加特定的成员关系, 类可能编写一个 container 方法, container 方法应该把成员关系定义为对一个映射应用键(并且可以使用快速查找), 以及用于序列的搜索. 三个方法的优先级如下: __container__ &gt; __iter__ &gt; __getitem__ # 依次注释掉 __container__, __iter__ 查看输出效果. class Iters: def __init__(self, value): self.data = value def __getitem__(self, i): print(&quot;get[%s]: &quot; % i, end=&quot;&quot;) return self.data[i] def __iter__(self): print(&quot;iter =&gt; &quot;, end=&quot;&quot;) self.ix = 0 return self def __next__(self): print(&quot;next:&quot;, end=&quot;&quot;) if self.ix == len(self.data): raise StopIteration item = self.data[self.ix] self.ix += 1 return item def __contains__(self, x): print(&quot;contains: &quot;, end=&quot;&quot;) return x in self.data X = Iters([1, 2, 3, 4, 5]) print(3 in X) for i in X: print(i, end=&quot; | &quot;) print() print([i ** 2 for i in X]) print(list(map(bin, X))) I = Iters(X) while True: try: print(next(I), end=&quot; @ &quot;) except StopIteration: break 属性索引:getattrgetattr 方法是拦截属性点号运算. 更确切的说, 当通过对未定义(不存在)的属性名称和实力进行点号运算时, 就会使用属性名称作为字符串调用这个方法. 如果 Python 可通过其继承树搜索流程找到这个属性, 该方法就不会被调用. 因为有这种情况, 所以 getattr 可以作为钩子来通过通用的方式响应属性请求. # 下例子中, Empty 和 其实例本身没有属性, __getattr__ 让其看起来像是一个属性, 实际上, age 变成了一个动态计算的属性. class Empty: def __getattr__(self, attrname): if attrname == &quot;age&quot;: return 12 else: raise AttributeError(attrname) x = Empty() print(x.age) print(x.name) getattr 做实际内容委托和内容属性. setattrsetattr 会拦截所有属性的赋值语句. 如果定义了这个方法, self.attr = value 会变成 self.setattr(“attr”, value). 这一点技巧性很高, 因为在 setattr 中对任何self 属性做赋值, 都会再调用 setattr, 导致无穷递归循环, 最后堆栈溢出. 如果希望使用该方法, 要确定是通过对属性字典做索引运算来赋值任何势力属性的.即, 使用 self.dict[“name”] = x 而不是 self.name = x. class AccessControl: def __setattr__(self, key, value): if key == &quot;age&quot;: self.__dict__[key] = value else: raise AttributeError(key + &quot; not Allow!&quot;) x = AccessControl() x.age = 40 print(x.age) x.name = &apos;tom&apos; 其他属性管理工具 __getattribute__ 方法拦截所有的属性获取, 而不只是那些未定义的, 但是当使用它的时候, 必须必使用 getattr 更小心的避免循环. Property 内置函数允许我们把方法和特定类属性上的获取和设置操作关联起来. 描述符提供了一个协议, 把一个类的 get, set 方法与对特定类属性的访问关联起来. 模拟实例属性的私有性如下是 Python 中实现属性私有性(即如法在类外对属性名进行修改)的首选方法. 为使其更有效, 必须增强他的功能, 让子类能够设置私有属性, 并且使用 getattr 和包装(有时称为代理) 来检测对私有属性的读取. 更完整的方案是使用 类装饰器 来实现拦截和验证属性. class PrivateEcx(Exception): pass class Privacy: def __setattr__(self, attrname, value): if attrname in self.privates: raise PrivateEcx(attrname, self) else: self.__dict__[attrname] = value class Test1(Privacy): privates = [&quot;age&quot;] class Test2(Privacy): privates = [&quot;name&quot;, &quot;age&quot;] def __init__(self): self.__dict__[&quot;name&quot;] = &apos;tom&apos; x = Test1() y = Test2() print(x.privates, y.privates) x.name = &quot;jerry&quot; # success y.name = &quot;sue&quot; # fail y.age = 30 # fail x.age = 40 # fail 对象的字符串表达形式 repr &amp; strrepr &amp; str 可替对象定义更好的显示格式, 而不是使用默认的实例显示. str : 打印操作会首先尝试 str 和 str 内置函数(print 运行的内部等价形式). 他通常应该返回一个用户友好的显示.repr : 用于所有其他的环境中: 用于交互式模糊四线提示回应以及 repr 函数. 他通常应该返回一个编码字符串, 可以用来重新创建对象, 或者给开发者一个详细的提示. 如果没有定义 str , 打印还是使用 repr , 但反过来并不成立. 其他环境, 如交互式响应模式, 只是使用 repr , 并且根本不尝试 str . class Addr: def __init__(self, value=0): self.data = value def __add__(self, other): self.data += other x = Addr() print(x) class AddRepr(Addr): def __repr__(self): return &quot;AddRepr(%s)&quot; % self.data y = AddRepr(2) print(y) y + 1 print(y) print(str(y), repr(y)) 如果想让所有环境都用统一的显示, repr 是最佳选择. 注意: repr 和 str 必须返回字符串, 其他的结果类型, 不会转换并会引发错误. 如果必要的话, 请确保一个转换器处理他. 根据一个容器的字符串转换逻辑, str 的用户友好的显示可能只有当对象出现在一个打印操作顶层的时候才应用, 嵌套到较大对象中的对象可能用其 repr 或默认方法打印. 为确保一个定义显示在所有的环境中都显示, 而不管容器是什么, 请编写 repr , 而不是 str . 左侧叫法(add), 右侧加法(radd)和原处加法(iadd):__add__ : 当 + 左侧的对象是类实例, 而右边对象不是类实例时.__radd__ : 当 + 右侧的对象是类实例, 而左边对象不是类实例时.__iadd__ : 当不同类的实例混合出现在表达式时, Python 优先选择左侧的那个类. class Commuter: def __init__(self, val): self.val = val def __add__(self, other): print(&quot;add&quot;, self.val, other) return self.val + other def __radd__(self, other): print(&quot;radd&quot;, self.val, other) return other + self.val x = Commuter(88) y = Commuter(99) x + 1 1 + y x + y # 原处加法 class Number: def __init__(self, val): self.val = val def __add__(self, other): return Number(self.val + other) m = Number(5) m += 1 m += 1 print(m.val) 每个二元运算符都有类似的右侧和原处重载方法, 他们以相同的方式工作(如 mul, rmul, imul). 右侧方法是一个高级话题, 并且在实际中很少用到, 只有在需要运算符有交换性质的时候, 才会编写他们, 并且只有在正真需要支持这样的运算符的时候, 才会使用. 如矢量运算等. Call 表达式callclass Callee: def __call__(self, *args, **kwargs): print(&quot;Called: &quot;, args, kwargs) C = Callee() C(1, 2, 3) C(1, 2, 3, x=4, y=5) 带有 call 的类和实例, 支持与常规函数和方法完全相同的参数语法和定义. 所有参数传递方式, call 方法都支持, 传递给实例的任何内容都会传递给该方法, 包括通常隐式的实例参数. class C: def __call__(self, a, b, c=5, d=6): ... class C: def __call__(self, *args, **kwargs): ... class C: def __call__(self, *args, d=6, **kwargs): ... 像这样的拦截表达式允许类实例模拟类似函数的外观, 但是, 也在调用中保持了状态信息以供使用. 当需要函数的API 编写接口时, call 就变得很有用: 这可以编写遵循所需要的函数来调用接口对象, 同时又能保留状态信息. class Prod: def __init__(self, value): self.value = value def __call__(self, other): return self.value * other x = Prod(4) print(x(2)) # 8 函数接口和回调代码 比较:lt &amp; gt : 比较方法, 没有右端形式, 相反, 当只有一个运算数支持比较的时候, 使用其对应方法. 比较运算符没有隐式关系, 如 == 并不表示 != 是假的, 因此 eq 和 ne 应该定义为确保两个运算符都正确的使用. cmp : python 2.6 , 如果没有定义更为具体的比较方法的话, 对所有比较使用该方法, 它返回一个 小于, 等于 或 大于 0 的数, 以表示比较其两个参数(self 和 另一个参数)的结果. 该方法往往使用 cmp(x, y) 内置函数来计算器结果. Python 3 删除了 cmp 和 cpm() . class C: data = &quot;spam&quot; def __gt__(self, other): return self.data &gt; other def __lt__(self, other): return self.data &lt; other X = C() print(X &gt; &quot;ham&quot;) # True, __gt__ print(X &lt; &quot;ham&quot;) # False, __lt__ 布尔测试 : bool &amp; len在布尔环境中, Python 首先尝试 bool 来获取一个直接的布尔值, 然后, 如果没有该方法, 就尝试 len 根据对象的长度确定一个真值. class Truth: def __bool__(self): return True X = Truth() if X: print(&quot;Yes!&quot;) class Truths: def __len__(self): return 0 Python 2.6 中 bool 仅仅被当做一个特殊方法, 而不是重载布尔运算符. 如果需要重载, 请使用 nonzero 方法, Python 3 把 python 2.6 中的 nonzero 改名为 bool. 同时, len 在 python 2.6 和 Python 3 中都作为 运算符重载的候补. class C: def __nonzoro__(self): print &quot;in nonzero&quot; return False 对象析构函数 : del当实例对象的最后一次引用失去时, 执行 del 方法. 但是由于无法轻易预测垃圾何时回收, 该方法实际上较少使用. class Life: def __init__(self, name=&quot;Unknown&quot;): print(&quot;hello&quot;, name) self.name = name def __del__(self): print(&quot;Goodby&quot;, self.name) brian = Life(&quot;brian&quot;) # hello brian brian = 123 # Goodby brian 30 类的设计: 如何使用类来对有用的对象进行建模.常用设计模式: 继承: 是一个关系从程序员的角度来看, 继承是由属性点号运算启动的, 由此出发实例, 类以及任意超类中的变量名搜索.从设计师的角度来看, 继承是一种定义集合成员关系的方式, 类定义了一组内容属性, 可由更具体的集合(子类)继承和订制. class Employee: def __init__(self, name, salary=0): self.name = name self.salary = salary def give_raise(self, percent): self.salary = self.salary + (self.salary * percent) def work(self): print(self.name, &quot;dose stuff&quot;) def __repr__(self): return &quot;&lt;Emplpyee: name=%s, salary=%s&gt;&quot; % (self.name, self.salary) class Chef(Employee): def __init__(self, name): Employee.__init__(self, name, 50000) def work(self): print(self.name, &quot;makes food&quot;) class Server(Employee): def __init__(self, name): Employee.__init__(self, name, 40000) def work(self): print(self.name, &quot;interfaces with customer&quot;) class PizzaRobot(Chef): def __init__(self, name): Chef.__init__(self, name) def work(self): print(self.name, &quot;make pizza&quot;) if __name__ == &quot;__main__&quot;: bob = PizzaRobot(&quot;bob&quot;) print(bob) bob.work() bob.give_raise(0.20) print(bob) print(&apos;-&apos; * 12) for klass in Employee, Chef, Server, PizzaRobot: print(klass.__name__) obj = klass(klass.__name__) obj.work() 组合: 有一个关系从程序员的角度看, 组合设计吧其他对象嵌入容器对象内, 并使其实现容器方法.对设计师来说, 组合是另一种表示问题领域中关系的方式. 组合是组件, 就是整体中的组成部分. 组合反应了各组成部分之间的关系, 通常称为有一个关系. 有些 OOP 设计书籍中把它称为聚合. 组合就是指内嵌对象几何体, 组合类一般提供自己的接口, 并通过内嵌的对象来实现接口. 如下面示例中的 PizzaShop 类, 是容器和控制器, 其构造函数会创建员工实例, 并将其嵌入. from employees import PizzaRobot, Server class Customer: def __init__(self, name): self.name = name def order(self, server): print(self.name, &quot;order from&quot;, server) def pay(self, server): print(self.name, &quot;pays for item to&quot;, server) class Oven: def bake(self): print(&quot;oven back&quot;) class PizzaShop: def __init__(self): self.server = Server(&quot;Pzt&quot;) self.chef = PizzaRobot(&quot;bob&quot;) self.oven = Oven() def order(self, name): customer = Customer(name) customer.order(self.server) self.chef.work() self.oven.bake() customer.pay(self.server) if __name__ == &quot;__main__&quot;: scene = PizzaShop() scene.order(&quot;Homer&quot;) print(&quot;-&quot; * 20) scene.order(&quot;Shaggy&quot;) # 数据流处理器示例: 包含组合和继承 class Processor: def __init__(self, reader, writer): self.reader = reader self.writer = writer def process(self): while 1: data = self.reader.readline() if not data: break data = self.converter(data) self.writer.write(data) def converter(self): assert False, &quot;Convert must be defined&quot; class Uppercase(Processor): def converter(self, data): return data.upper() if __name__ == &quot;__main__&quot;: import sys obj = Uppercase(open(&quot;test.txt&quot;), sys.stdout) obj.process() 委托: delegation委托: 值控制器对象内嵌其他对象, 而把运算请求传给这些对象. 控制器负责管理工作, 如记录存取等. 在 Python 中委托以 getattr 钩子方法实现, 该方法会拦截对不存在属性的读取, 包装类(有时称为代理类) 可以使用 getattr 把任意读取转发给被包装的对象. 包装类包有被包装对象的接口, 而且自己也可以增加其他运算. class Wrapper: def __init__(self, obj): self.wrapped = obj def __getattr__(self, attr_name): print(&quot;Trace&quot;, attr_name) return getattr(self.wrapped, attr_name) x = Wrapper([1, 2, 3]) x.append(4) print(x.wrapped) y = Wrapper({&quot;a&quot;: 1, &quot;b&quot;: 2}) print(y.keys()) 实际效果就是以包装类内额外的代码来增强被包装的对象的整个接口. 可以利用这种方式记录方法调用, 把方法调用转给其他或订制的逻辑等的. 包装对象和委托操作是扩展内置类型的一种方式. 与函数装饰器是关联性很强的概念, 只在用来增加特定函数或方法调用, 而不是对对象的整个接口. 还有类装饰器, 他充当向一个类的所有实例自动添加诸如基于委托的包装器的一种方式. 类的伪私有属性: 让类内的某些变量局部化. 也称为变量名压缩, 压缩后的变量名有时会被称为私有属性, 但这其实只是一种把类所创建的变量名局部化的一种方式而已: 名称压缩无法阻止类外代码对他的读取. 这种功能主要是为了避免实例内的命名空间的冲突, 而不是限制变量名的读取. 因此, 压缩的变量名最好称为伪私有, 而不是私有. 使用一个单个的下划线来编写内部名称(如 _x), 这只是一个非正式的惯例, 即这是一个不应该修改的名字, 这对 Python 自身来说没有什么意义. 变量名压缩: class 语句内开头有两个下划线, 但结尾没有两个下划线的变量, 会自动扩张, 从而包含所在类的名称, 如 位于 spam 类中的 x 变量会变为 _spamx : 原始的变量名会在头部加入一个下划线, 然后是所在类名称. 因为修改后的变量名包含了所在类的名称, 相当于变得独特, 不会和同一层次中其他类所创建的类似变量名相冲突. 变量名压缩只发生在 class 语句内, 而且只针对开头有两个下划线的变量名, 包含实例方法和实例属性 class C1: def meth1(self): self.__x = 88 def meth2(self): print(self.__x) class C2: def metha(self): self.__x = 99 def methb(self): print(self.__x) class C3(C1, C2): pass I = C3() I.meth1() I.metha() print(I.__dict__) # {&apos;_C1__x&apos;: 88, &apos;_C2__x&apos;: 99} I.meth2() # 88 I.methb() # 99 多重继承多重继承: 类和其实例继承了列出的所有超类的变量名. 搜索属性时, Python 会由左到右搜索类首行中的超类, 知道找到相符者. 属性搜索方式: 传统类: 深度优先, Python 3.0 之前 属性搜索对所有路径优先, 知道继承树的最顶端, 然后从左到右进行. 可以自继承 object 类, 转变为新式类. 新式类: 广度优先, Python 3.0 属性搜索处理, 沿着树层级, 以更加广度优先的方式进行. 所有类都继承自 object. 新式类变化: 类和类型合并 类现在就是类型, 并且类型现在就是类. type(I) 内置函数返回一个实例所创建自的类, 而不是一个通用的实例类型, 并且通常和 I.class 相同. 类是 type类 的实例, type可能子类化为定制类创建, 并且所有的类继承自 object . 继承搜索顺序 多继承的钻石模式有一种略微不同的搜索顺序. 总体而言, 他可能先横向搜索再纵向搜索, 并且先宽度优先, 就深度优先搜索. 针对内置函数的属性获取 新的高级工具 slot 特性 描述符 getattribute 方法. 类是对象 : 通用对象的工厂.工厂可以将代码和动态配置对象的构造细节隔离开. def factory(aClass, *args): return aClass(*args) class Spam: def doit(self, message): print(message) class Person: def __init__(self, name, job): self.name = name self.job = job obj1 = factory(Spam) obj1.doit(&quot;hello world&quot;) obj2 = factory(Person, &quot;Guido&quot;, &quot;guru&quot;) print(obj2.__dict__) 31 类的高级主题###扩展内置类型: 通过嵌入扩展类型class Set: def __init__(self, value=[]): self.data = [] self.concat(value) def intersect(self, other): res = [] for x in self.data: if x in other: res.append(x) return Set(res) def union(self, other): res = self.data[:] for x in other: if not x in res: res.append(x) return Set(res) def concat(self, value): for x in value: if not x in self.data: self.data.append(x) def __len__(self): return len(self.data) def __getitem__(self, item): return self.data[item] def __and__(self, other): return self.intersect(other) def __or__(self, other): return self.union(other) def __repr__(self): return &quot;Set: &quot; + repr(self.data) x = Set([1, 3, 5, 7]) print(x.union(Set([1, 4, 7]))) print(x | Set([1, 4, 6])) 通过子类扩展类型class MyList(list): def __getitem__(self, offset): print(&quot;(indexing %s at %s)&quot; % (self, offset)) return list.__getitem__(self, offset-1) if __name__ == &quot;__main__&quot;: print(list(&quot;abc&quot;)) x = MyList(&quot;abc&quot;) print(x) print(x[1]) print(x[3]) x.append(&quot;spam&quot;) print(x) x.reverse() print(x) 新式类 变化: 类型模型变化 钻石继承变动 扩展 slots 实例 类特性 getattribute 和 描述符 元类 静态方法和类方法 装饰器和元类: 函数装饰器 类装饰器 元类 类陷阱: 修改类属性的副作用 修改可变的类属性也可能产生副作用 多重继承: 顺序很重要 类,方法及嵌套作用域 Python 中基于委托的类: getattr 和 内置函数 过度包装 36 Unicode 和 字符串37 管理属性38 装饰器39 元类 与设计相关的其他话题 抽象超类 装饰器 类型子类 静态方法和类方法 管理属性 元类 混合类 委托 组合 继承, 多重继承 工厂 私有属性, 绑定方法 数据结构和算法 序列解包 Python2,3 解包可以作用在任何可迭代对象上, 而不仅仅是列表或元组. 包含字符串,文件对象, 迭代器和生成器. data = [“ACME”,21,21.1,(2012,12,21)]name,shares,price,(year,mon,day) = dataname &quot;ACME&quot; year 2012 # 解压部分 &gt;&gt; data = [&quot;ACME&quot;,21,21.1,(2012,12,21)] &gt;&gt; _, _, price,date = data &gt;&gt; price 21.1 &gt;&gt; date (2012,12,21) 星号表达式 : 解压可迭代对象赋值给多个变量 : Python3 record = (‘Dave’, &#39;dave@example.com‘, ‘773-555-1212’, ‘847-555-1212’)name, email, *phone_numbers = recordname &apos;Dave&apos; email &apos;dave@example.com&apos; phone_numbers # 此处 , phone_numbers 永远是列表类型, 不管解压的电话号码数量是多少. [&apos;773-555-1212&apos;, &apos;847-555-1212&apos;] 位于前半段 : &gt;&gt;&gt; *night,ten = range(11) &gt;&gt;&gt; night [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] &gt;&gt;&gt; ten 10 字符串操作 &gt;&gt;&gt; line = &apos;nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false&apos; &gt;&gt;&gt; uname,*fields,homedir,sh = line.split(&quot;:&quot;) &gt;&gt;&gt; uname &apos;nobody&apos; &gt;&gt;&gt; fields [&apos;*&apos;, &apos;-2&apos;, &apos;-2&apos;, &apos;Unprivileged User&apos;] &gt;&gt;&gt; homedir &apos;/var/empty&apos; &gt;&gt;&gt; sh &apos;/usr/bin/false&apos; 丢弃元素 : 可以使用普通的废弃名字, 如 _ 或者 ign 等 &gt;&gt;&gt; record = (&quot;ACME&quot;,50,123.45,(12,15,2012)) &gt;&gt;&gt; name,*_,(*_,year) = record &gt;&gt;&gt; name &apos;ACME&apos; 双端队列, deque : 保留最后 N 个元素 from collections import dequeq = deque(maxlen=3)q.append(1)q.append(2)q.append(3)q deque([1, 2, 3], maxlen=3) q.append(4)q deque([2, 3, 4], maxlen=3) 可用方法 : q.append() Add an element to the right side of the deque . q.appendleft() Add an element to the left side of the deque q.clear() Remove all element from the deque copy() Return a shallow copy of a deque count() D.count(value) --&gt; integer -- return number of occurrences of value . extend() Extend the right side of the deque with elements from the iterable. extendleft() Extend the left side of the deque with elements from the iterable . index() Return the first index of value . Raise ValueError if the value is not present. insert() insert object before index . pop() Remove and return the rightmost element. popleft() Remove and return the leftmost element. remove() remove the first occurrence of value. reverse() reverse *IN PLACE* ** 在双端队列两端插入或删除元素时间复杂度都是 O(1) 的, 而在 列表的开头插入或删除元素的时间复杂度是 O(n) . 堆数据结构 : 查找最大或最小的 N 个元素. heapq.nlargest() &amp; heapq.nsmallest() import heapq nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2] print(heapq.nlargest(3, nums)) print(heapq.nsmallest(3, nums)) [42, 37, 23] [-4, 1, 2] 复杂数据结构 : portfolio = [ {&apos;name&apos;: &apos;IBM&apos;, &apos;shares&apos;: 100, &apos;price&apos;: 91.1}, {&apos;name&apos;: &apos;AAPL&apos;, &apos;shares&apos;: 50, &apos;price&apos;: 543.22}, {&apos;name&apos;: &apos;FB&apos;, &apos;shares&apos;: 200, &apos;price&apos;: 21.09}, {&apos;name&apos;: &apos;HPQ&apos;, &apos;shares&apos;: 35, &apos;price&apos;: 31.75}, {&apos;name&apos;: &apos;YHOO&apos;, &apos;shares&apos;: 45, &apos;price&apos;: 16.35}, {&apos;name&apos;: &apos;ACME&apos;, &apos;shares&apos;: 75, &apos;price&apos;: 115.65} ] cheap = heapq.nsmallest(3, portfolio, key=lambda s: s[&apos;price&apos;]) expensive = heapq.nlargest(3, portfolio, key=lambda s: s[&apos;price&apos;]) # 上面的代码在对每个元素进行对比的时候, 会以 price 的值进行比较. 堆数据结构 如果希望在一个集合中查找最小或最大的 N 个元素, 并且 N 小于集合元素数量, &gt;&gt;&gt; nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2] &gt;&gt;&gt; import heapq &gt;&gt;&gt; heapq.heapify(nums) &gt;&gt;&gt; nums [-4, 2, 1, 23, 7, 2, 18, 23, 42, 37, 8] 堆数据结构最重要的特征是 heap[0] 永远是最小的元素. 并且剩余的元素可以很容易的通过调用 heapq.heappop() 方法得到, 该方法会先将第一个元素弹出来, 然后用下一个最小的元素来取代被弹出元素(时间复杂度 O(log N), N为堆大小). &gt;&gt; heapq.heappop(nums) -4 &gt;&gt; heapq.heappop(nums) 1 &gt;&gt; heapq.heappop(nums) 2 ** 仅仅查找唯一最大或最小的元素, 那么 min() 和 max() 函数更快. ** 如果 N 的大小和集合大小接近的时候, 通常先排序该集合, 然后使用切片操作会更快. heapq.heappush() &amp; heapq.heappop() : heapq.heappop() 删除并返回优先级最高的元素, 并一次类推. 如果优先级相同, 则比较 index(如果有的话). import heapq class PriorityQueue: def __init__(self): self._queue = [] self._index = 0 def push(self, item, priority): heapq.heappush(self._queue, (-priority, self._index, item)) self._index += 1 def pop(self): return heapq.heappop(self._queue)[-1] &gt;&gt;&gt; class Item: ... def __init__(self, name): ... self.name = name ... def __repr__(self): ... return &apos;Item({!r})&apos;.format(self.name) ... &gt;&gt;&gt; q = PriorityQueue() &gt;&gt;&gt; q.push(Item(&apos;foo&apos;), 1) &gt;&gt;&gt; q.push(Item(&apos;bar&apos;), 5) &gt;&gt;&gt; q.push(Item(&apos;spam&apos;), 4) &gt;&gt;&gt; q.push(Item(&apos;grok&apos;), 1) &gt;&gt;&gt; q.pop() Item(&apos;bar&apos;) &gt;&gt;&gt; q.pop() Item(&apos;spam&apos;) &gt;&gt;&gt; q.pop() Item(&apos;foo&apos;) &gt;&gt;&gt; q.pop() Item(&apos;grok&apos;) 字典 字典中键映射多个值 from collections import defaultdict d = defaultdict(list) d[&apos;a&apos;].append(1) d[&apos;a&apos;].append(2) d[&apos;b&apos;].append(4) d = defaultdict(set) d[&apos;a&apos;].add(1) d[&apos;a&apos;].add(2) d[&apos;b&apos;].add(4) 字典排序: 在迭代时时, 保持元素被插入式的顺序. dic = {&apos;a&apos;:31, &apos;bc&apos;:5, &apos;c&apos;:3, &apos;asd&apos;:4, &apos;aa&apos;:74, &apos;d&apos;:0} dict= sorted(dic.iteritems(), key=lambda d: d[1], reverse = True) print dict # 输出 [(&apos;aa&apos;, 74), (&apos;a&apos;, 31), (&apos;bc&apos;, 5), (&apos;asd&apos;, 4), (&apos;c&apos;, 3), (&apos;d&apos;, 0)] OrderedDict内部维护着一个根据键插入顺序排序的双向链表。每次当一个新的元素插入进来的时候，它会被放到链表的尾部。对于一个已经存在的键的重复赋值不会改变键的顺序。 需要注意的是，一个OrderedDict的大小是一个普通字典的两倍，因为它内部维护着另外一个链表。 from collections import OrderedDict def ordered_dict(): d = OrderedDict() d[&apos;foo&apos;] = 1 d[&apos;bar&apos;] = 2 d[&apos;spam&apos;] = 3 d[&apos;grok&apos;] = 4 # Outputs &quot;foo 1&quot;, &quot;bar 2&quot;, &quot;spam 3&quot;, &quot;grok 4&quot; for key in d: print(key, d[key]) 查找字典相同点 : 为了寻找两个字典的相同点，可以简单的在两字典的 keys() 或者 items() 方法返回结果上执行集合操作。 python 3 # Find keys in common a.keys() &amp; b.keys() # { &apos;x&apos;, &apos;y&apos; } # Find keys in a that are not in b a.keys() - b.keys() # { &apos;z&apos; } # Find (key,value) pairs in common a.items() &amp; b.items() # { (&apos;y&apos;, 2) } 字典列表, 根据某个或某几个字典字段来排序 `operator.itemgetter()` . operator.itemgetter() 函数有一个被rows中的记录用来查找值的索引参数。可以是一个字典键名称，一个整形值或者任何能够传入一个对象的 __getitem__() 方法的值。如果你传入多个索引参数给 itemgetter() ，它生成的 callable 对象会返回一个包含所有元素值的元组，并且sorted()函数会根据这个元组中元素顺序去排序。但你想要同时在几个字段上面进行排序(比如通过姓和名来排序，也就是例子中的那样)的时候这种方法是很有用的。 &gt;&gt;&gt; rows = [ {&apos;fname&apos;: &apos;Brian&apos;, &apos;lname&apos;: &apos;Jones&apos;, &apos;uid&apos;: 1003}, {&apos;fname&apos;: &apos;David&apos;, &apos;lname&apos;: &apos;Beazley&apos;, &apos;uid&apos;: 1002}, {&apos;fname&apos;: &apos;John&apos;, &apos;lname&apos;: &apos;Cleese&apos;, &apos;uid&apos;: 1001}, {&apos;fname&apos;: &apos;Big&apos;, &apos;lname&apos;: &apos;Jones&apos;, &apos;uid&apos;: 1004} ] &gt;&gt;&gt; from operator import itemgetter &gt;&gt;&gt; rows_by_fname = sorted(rows, key=itemgetter(&apos;fname&apos;)) &gt;&gt;&gt; rows_by_uid = sorted(rows, key=itemgetter(&apos;uid&apos;)) # itemgetter()函数也支持多个keys &gt;&gt;&gt; rows_by_lfname = sorted(rows, key=itemgetter(&apos;lname&apos;,&apos;fname&apos;)) # 适用于min()和max()等函数 &gt;&gt;&gt; min(rows, key=itemgetter(&apos;uid&apos;)) {&apos;fname&apos;: &apos;John&apos;, &apos;lname&apos;: &apos;Cleese&apos;, &apos;uid&apos;: 1001} &gt;&gt;&gt; max(rows, key=itemgetter(&apos;uid&apos;)) {&apos;fname&apos;: &apos;Big&apos;, &apos;lname&apos;: &apos;Jones&apos;, &apos;uid&apos;: 1004} 用一个字典的子集构建另一个字典: 字典推到 prices = { &apos;ACME&apos;: 45.23, &apos;AAPL&apos;: 612.78, &apos;IBM&apos;: 205.55, &apos;HPQ&apos;: 37.20, &apos;FB&apos;: 10.75 } # Make a dictionary of all prices over 200 p1 = {key: value for key, value in prices.items() if value &gt; 200} # Make a dictionary of tech stocks tech_names = {&apos;AAPL&apos;, &apos;IBM&apos;, &apos;HPQ&apos;, &apos;MSFT&apos;} p2 = {key: value for key, value in prices.items() if key in tech_names} 命名切片 &gt;&gt;&gt; items = [0, 1, 2, 3, 4, 5, 6] &gt;&gt;&gt; a = slice(2, 4) &gt;&gt;&gt; items[2:4] [2, 3] &gt;&gt;&gt; items[a] [2, 3] &gt;&gt;&gt; items[a] = [10,11] &gt;&gt;&gt; items [0, 1, 10, 11, 4, 5, 6] &gt;&gt;&gt; del items[a] &gt;&gt;&gt; items [0, 1, 4, 5, 6] # 对切片对象, 分别调用它的s.start, s.stop, s.step属性来获取更多的信息 &gt;&gt;&gt; a = slice(5, 50, 2) &gt;&gt;&gt; a.start 5 &gt;&gt;&gt; a.stop 50 &gt;&gt;&gt; a.step 2 # 通过调用切片的indices(size)方法将它映射到一个确定大小的序列上，这个方法返回一个三元组(start,stop,step)，所有值都会被合适的缩小以满足边界限制，从而使用的时候避免出现IndexError异常。 &gt;&gt;&gt; s = &apos;HelloWorld&apos; &gt;&gt;&gt; a.indices(len(s)) (5, 10, 2) &gt;&gt;&gt; for i in range(*a.indices(len(s))): print(s[i]) W r d 命名元组: collections.namedtuple() 支持所有的元组操作. collections.namedtuple() 函数通过使用一个普通的元组对象来帮你解决这个问题。这个函数实际上是一个返回Python中标准元组类型子类的一个工厂方法。你需要传递一个类型名和你需要的字段给它，然后它就会返回一个类，你可以初始化这个类，为你定义的字段传递值等。 &gt;&gt;&gt; from collections import namedtuple &gt;&gt;&gt; Subscriber = namedtuple(&apos;Subscriber&apos;, [&apos;addr&apos;, &apos;joined&apos;]) &gt;&gt;&gt; sub = Subscriber(&apos;jonesy@example.com&apos;, &apos;2012-10-19&apos;) &gt;&gt;&gt; sub Subscriber(addr=&apos;jonesy@example.com&apos;, joined=&apos;2012-10-19&apos;) &gt;&gt;&gt; sub.addr &apos;jonesy@example.com&apos; &gt;&gt;&gt; sub.joined &apos;2012-10-19&apos; &gt;&gt;&gt; 命名元组另一个用途就是作为字典的替代，因为字典存储需要更多的内存空间。如果你需要构建一个非常大的包含字典的数据结构，那么使用命名元组会更加高效。但是需要注意的是，不像字典那样，一个命名元组是不可更改的。如果你真的需要改变然后的属性，那么可以使用命名元组实例的 _replace() 方法， 它会创建一个全新的命名元组并将对应的字段用新的值取代。_replace() 方法还有一个很有用的特性就是当你的命名元组拥有可选或者缺失字段时候，它是一个非常方便的填充数据的方法。你可以先创建一个包含缺省值的原型元组，然后使用 _replace() 方法创建新的值被更新过的实例。 from collections import namedtuple Stock = namedtuple(&apos;Stock&apos;, [&apos;name&apos;, &apos;shares&apos;, &apos;price&apos;, &apos;date&apos;, &apos;time&apos;]) # Create a prototype instance stock_prototype = Stock(&apos;&apos;, 0, 0.0, None, None) # Function to convert a dictionary to a Stock def dict_to_stock(s): return stock_prototype._replace(**s) &gt;&gt;&gt; a = {&apos;name&apos;: &apos;ACME&apos;, &apos;shares&apos;: 100, &apos;price&apos;: 123.45} &gt;&gt;&gt; dict_to_stock(a) Stock(name=&apos;ACME&apos;, shares=100, price=123.45, date=None, time=None) &gt;&gt;&gt; b = {&apos;name&apos;: &apos;ACME&apos;, &apos;shares&apos;: 100, &apos;price&apos;: 123.45, &apos;date&apos;: &apos;12/17/2012&apos;} &gt;&gt;&gt; dict_to_stock(b) Stock(name=&apos;ACME&apos;, shares=100, price=123.45, date=&apos;12/17/2012&apos;, time=None) 如果你的目标是定义一个需要更新很多实例属性的高效数据结构，那么命名元组并不是你的最佳选择。这时候你应该考虑定义一个包含 __slots__ 方法的类. 找出序列中出现次数最多的元素 collections.Counter() from collections import Counter words = [ &apos;look&apos;, &apos;into&apos;, &apos;my&apos;, &apos;eyes&apos;, &apos;look&apos;, &apos;into&apos;, &apos;my&apos;, &apos;eyes&apos;, &apos;the&apos;, &apos;eyes&apos;, &apos;the&apos;, &apos;eyes&apos;, &apos;the&apos;, &apos;eyes&apos;, &apos;not&apos;, &apos;around&apos;, &apos;the&apos;, &apos;eyes&apos;, &quot;don&apos;t&quot;, &apos;look&apos;, &apos;around&apos;, &apos;the&apos;, &apos;eyes&apos;, &apos;look&apos;, &apos;into&apos;, &apos;my&apos;, &apos;eyes&apos;, &quot;you&apos;re&quot;, &apos;under&apos; ] word_counts = Counter(words) # 出现频率最高的3个单词 top_three = word_counts.most_common(3) print(top_three) # Outputs [(&apos;eyes&apos;, 8), (&apos;the&apos;, 5), (&apos;look&apos;, 4)] &gt;&gt;&gt; word_counts[&apos;not&apos;] 1 &gt;&gt;&gt; word_counts[&apos;eyes&apos;] 8 # 更新, 增加更多方法. &gt;&gt;&gt; morewords = [&apos;why&apos;,&apos;are&apos;,&apos;you&apos;,&apos;not&apos;,&apos;looking&apos;,&apos;in&apos;,&apos;my&apos;,&apos;eyes&apos;] &gt;&gt;&gt; word_counts.update(morewords) # 数学运算 &gt;&gt;&gt; a = Counter(words) &gt;&gt;&gt; b = Counter(morewords) &gt;&gt;&gt; a Counter({&apos;eyes&apos;: 8, &apos;the&apos;: 5, &apos;look&apos;: 4, &apos;into&apos;: 3, &apos;my&apos;: 3, &apos;around&apos;: 2, &quot;you&apos;re&quot;: 1, &quot;don&apos;t&quot;: 1, &apos;under&apos;: 1, &apos;not&apos;: 1}) &gt;&gt;&gt; b Counter({&apos;eyes&apos;: 1, &apos;looking&apos;: 1, &apos;are&apos;: 1, &apos;in&apos;: 1, &apos;not&apos;: 1, &apos;you&apos;: 1, &apos;my&apos;: 1, &apos;why&apos;: 1}) # Combine counts &gt;&gt;&gt; c = a + b &gt;&gt;&gt; c Counter({&apos;eyes&apos;: 9, &apos;the&apos;: 5, &apos;look&apos;: 4, &apos;my&apos;: 4, &apos;into&apos;: 3, &apos;not&apos;: 2, &apos;around&apos;: 2, &quot;you&apos;re&quot;: 1, &quot;don&apos;t&quot;: 1, &apos;in&apos;: 1, &apos;why&apos;: 1, &apos;looking&apos;: 1, &apos;are&apos;: 1, &apos;under&apos;: 1, &apos;you&apos;: 1}) # Subtract counts &gt;&gt;&gt; d = a - b &gt;&gt;&gt; d Counter({&apos;eyes&apos;: 7, &apos;the&apos;: 5, &apos;look&apos;: 4, &apos;into&apos;: 3, &apos;my&apos;: 2, &apos;around&apos;: 2, &quot;you&apos;re&quot;: 1, &quot;don&apos;t&quot;: 1, &apos;under&apos;: 1}) 从一个数据序列中取出需要的值或缩短序列 列表推导式 &gt;&gt;&gt; mylist = [1, 4, -5, 10, -7, 2, 3, -1] &gt;&gt;&gt; [n for n in mylist if n &gt; 0] [1, 4, 10, 2, 3] &gt;&gt;&gt; [n for n in mylist if n &lt; 0] [-5, -7, -1] &gt;&gt;&gt; [n if n&gt;0 else 0 for n in mylist] [1, 4, 0, 10, 0, 2, 3, 0] 生成器 &gt;&gt;&gt; pos = (n for n in mylist if n &gt; 0) &gt;&gt;&gt; pos &lt;generator object &lt;genexpr&gt; at 0x1006a0eb0&gt; &gt;&gt;&gt; for x in pos: print(x) filter() values = [&apos;1&apos;, &apos;2&apos;, &apos;-3&apos;, &apos;-&apos;, &apos;4&apos;, &apos;N/A&apos;, &apos;5&apos;] def is_int(val): try: x = int(val) return True except ValueError: return False ivals = list(filter(is_int, values)) print(ivals) itertools.compress() ，它以一个 iterable 对象和一个相对应的Boolean选择器序列作为输入参数。然后输出 iterable 对象中对应选择器为True的元素。当你需要用另外一个相关联的序列来过滤某个序列的时候，这个函数是非常有用的。 addresses = [ &apos;5412 N CLARK&apos;, &apos;5148 N CLARK&apos;, &apos;5800 E 58TH&apos;, &apos;2122 N CLARK&apos; &apos;5645 N RAVENSWOOD&apos;, &apos;1060 W ADDISON&apos;, &apos;4801 N BROADWAY&apos;, &apos;1039 W GRANVILLE&apos;, ] counts = [ 0, 3, 10, 4, 1, 7, 6, 1] &gt;&gt;&gt; from itertools import compress &gt;&gt;&gt; more5 = [n &gt; 5 for n in counts] &gt;&gt;&gt; more5 [False, False, True, False, False, True, True, False] &gt;&gt;&gt; list(compress(addresses, more5)) [&apos;5800 E 58TH&apos;, &apos;4801 N BROADWAY&apos;, &apos;1039 W GRANVILLE&apos;] sorted()/min()/max() 内置的 sorted() 函数有一个关键字参数 key ，可以传入一个 callable 对象给它，这个 callable 对象对每个传入的对象返回一个值，这个值会被 sorted 用来排序这些对象。比如，如果你在应用程序里面有一个User实例序列，并且你希望通过他们的user_id属性进行排序，你可以提供一个以User实例作为输入并输出对应user_id值的 callable 对象。 # 使用 lambda class User: def __init__(self, user_id): self.user_id = user_id def __repr__(self): return &apos;User({})&apos;.format(self.user_id) def sort_notcompare(): users = [User(23), User(3), User(99)] print(users) print(sorted(users, key=lambda u: u.user_id)) # 使用 operator.attrgetter() &gt;&gt;&gt; from operator import attrgetter &gt;&gt;&gt; sorted(users, key=attrgetter(&apos;user_id&apos;)) [User(3), User(23), User(99)] itertools.groupby() : 有一个字典或实例的序列, 然后根据某个特定的字段来分组迭代访问. groupby() 函数扫描整个序列并且查找连续相同值(或者根据指定key函数返回值相同)的元素序列。在每次迭代的时候，它会返回一个值和一个迭代器对象，这个迭代器对象可以生成元素值全部等于上面那个值的组中所有对象。 一个非常重要的准备步骤是要根据指定的字段将数据排序。因为 groupby() 仅仅检查连续的元素，如果事先并没有排序完成的话，分组函数将得不到想要的结果。 rows = [ {&apos;address&apos;: &apos;5412 N CLARK&apos;, &apos;date&apos;: &apos;07/01/2012&apos;}, {&apos;address&apos;: &apos;5148 N CLARK&apos;, &apos;date&apos;: &apos;07/04/2012&apos;}, {&apos;address&apos;: &apos;5800 E 58TH&apos;, &apos;date&apos;: &apos;07/02/2012&apos;}, {&apos;address&apos;: &apos;2122 N CLARK&apos;, &apos;date&apos;: &apos;07/03/2012&apos;}, {&apos;address&apos;: &apos;5645 N RAVENSWOOD&apos;, &apos;date&apos;: &apos;07/02/2012&apos;}, {&apos;address&apos;: &apos;1060 W ADDISON&apos;, &apos;date&apos;: &apos;07/02/2012&apos;}, {&apos;address&apos;: &apos;4801 N BROADWAY&apos;, &apos;date&apos;: &apos;07/01/2012&apos;}, {&apos;address&apos;: &apos;1039 W GRANVILLE&apos;, &apos;date&apos;: &apos;07/04/2012&apos;}, ] from operator import itemgetter from itertools import groupby # Sort by the desired field first rows.sort(key=itemgetter(&apos;date&apos;)) # Iterate in groups for date, items in groupby(rows, key=itemgetter(&apos;date&apos;)): print(date) for i in items: print(&apos; &apos;, i) 07/01/2012 {&apos;date&apos;: &apos;07/01/2012&apos;, &apos;address&apos;: &apos;5412 N CLARK&apos;} {&apos;date&apos;: &apos;07/01/2012&apos;, &apos;address&apos;: &apos;4801 N BROADWAY&apos;} 07/02/2012 {&apos;date&apos;: &apos;07/02/2012&apos;, &apos;address&apos;: &apos;5800 E 58TH&apos;} {&apos;date&apos;: &apos;07/02/2012&apos;, &apos;address&apos;: &apos;5645 N RAVENSWOOD&apos;} {&apos;date&apos;: &apos;07/02/2012&apos;, &apos;address&apos;: &apos;1060 W ADDISON&apos;} 07/03/2012 {&apos;date&apos;: &apos;07/03/2012&apos;, &apos;address&apos;: &apos;2122 N CLARK&apos;} 07/04/2012 {&apos;date&apos;: &apos;07/04/2012&apos;, &apos;address&apos;: &apos;5148 N CLARK&apos;} {&apos;date&apos;: &apos;07/04/2012&apos;, &apos;address&apos;: &apos;1039 W GRANVILLE&apos;} 多个字典或映射, 从逻辑上合并为一个单一的映射后执行某些操作. ChainMap对于编程语言中的作用范围变量(比如globals, locals等)是非常有用的。 a = {&apos;x&apos;: 1, &apos;z&apos;: 3 } b = {&apos;y&apos;: 2, &apos;z&apos;: 4 } from collections import ChainMap c = ChainMap(a,b) print(c[&apos;x&apos;]) # Outputs 1 (from a) print(c[&apos;y&apos;]) # Outputs 2 (from b) print(c[&apos;z&apos;]) # Outputs 3 (from a) # 如果出现重复键，那么第一次出现的映射值会被返回。因此，例子程序中的c[‘z&apos;]总是会返回字典a中对应的值，而不是b中对应的值。 &gt;&gt;&gt; len(c) 3 &gt;&gt;&gt; list(c.keys()) [&apos;x&apos;, &apos;y&apos;, &apos;z&apos;] &gt;&gt;&gt; list(c.values()) [1, 2, 3] # 对于字典的更新或删除操作总是影响的是列表中第一个字典 &gt;&gt;&gt; c[&apos;z&apos;] = 10 &gt;&gt;&gt; c[&apos;w&apos;] = 40 &gt;&gt;&gt; del c[&apos;x&apos;] &gt;&gt;&gt; a {&apos;w&apos;: 40, &apos;z&apos;: 10} &gt;&gt;&gt; del c[&apos;y&apos;] Traceback (most recent call last): ... KeyError: &quot;Key not found in the first mapping: &apos;y&apos;&quot; &gt;&gt;&gt; values = ChainMap() &gt;&gt;&gt; values[&apos;x&apos;] = 1 # Add a new mapping &gt;&gt;&gt; values = values.new_child() &gt;&gt;&gt; values[&apos;x&apos;] = 2 # Add a new mapping &gt;&gt;&gt; values = values.new_child() &gt;&gt;&gt; values[&apos;x&apos;] = 3 &gt;&gt;&gt; values ChainMap({&apos;x&apos;: 3}, {&apos;x&apos;: 2}, {&apos;x&apos;: 1}) &gt;&gt;&gt; values[&apos;x&apos;] 3 # Discard last mapping &gt;&gt;&gt; values = values.parents &gt;&gt;&gt; values[&apos;x&apos;] 2 # Discard last mapping &gt;&gt;&gt; values = values.parents &gt;&gt;&gt; values[&apos;x&apos;] 1 &gt;&gt;&gt; values ChainMap({&apos;x&apos;: 1}) 字符串与文本字符串分割 简单分割 string.split() 指定多个分割符或分隔符周围不确定 &gt;&gt;&gt; line = &apos;asdf fjdk; afed, fjek,asdf, foo&apos; &gt;&gt;&gt; import re # 匹配 , ; 空格, 并且后面紧跟任意个的空格. &gt;&gt;&gt; re.split(r&apos;[;,\s]\s*&apos;, line) [&apos;asdf&apos;, &apos;fjdk&apos;, &apos;afed&apos;, &apos;fjek&apos;, &apos;asdf&apos;, &apos;foo&apos;] 如果正则表达式中有括号分组, 那么被匹配的文本也将出现在结果列表中. &gt;&gt;&gt; fields = re.split(r&apos;(;|,|\s)\s*&apos;, line) &gt;&gt;&gt; fields [&apos;asdf&apos;, &apos; &apos;, &apos;fjdk&apos;, &apos;;&apos;, &apos;afed&apos;, &apos;,&apos;, &apos;fjek&apos;, &apos;,&apos;, &apos;asdf&apos;, &apos;,&apos;, &apos;foo&apos;] &gt;&gt;&gt; re.split(r&apos;(?:,|;|\s)\s*&apos;, line) [&apos;asdf&apos;, &apos;fjdk&apos;, &apos;afed&apos;, &apos;fjek&apos;, &apos;asdf&apos;, &apos;foo&apos;] 有时候, 获取分割字符也是有用的. &gt;&gt;&gt; values = fields[::2] &gt;&gt;&gt; delimiters = fields[1::2] + [&apos;&apos;] &gt;&gt;&gt; values [&apos;asdf&apos;, &apos;fjdk&apos;, &apos;afed&apos;, &apos;fjek&apos;, &apos;asdf&apos;, &apos;foo&apos;] &gt;&gt;&gt; delimiters [&apos; &apos;, &apos;;&apos;, &apos;,&apos;, &apos;,&apos;, &apos;,&apos;, &apos;&apos;] # Reform the line using the same delimiters &gt;&gt;&gt; &apos;&apos;.join(v+d for v,d in zip(values, delimiters)) &apos;asdf fjdk;afed,fjek,asdf,foo&apos; 字符串匹配 检查字符串开头或结尾匹配: str.startswith(), str.endswith() &gt;&gt;&gt; filename = &apos;spam.txt&apos; &gt;&gt;&gt; filename.endswith(&apos;.txt&apos;) True 如果检查多种匹配可能, 只要将所有的匹配放入到一个元组中即可 &gt;&gt;&gt; import os &gt;&gt;&gt; filenames = os.listdir(&apos;.&apos;) &gt;&gt;&gt; filenames [ &apos;Makefile&apos;, &apos;foo.c&apos;, &apos;bar.py&apos;, &apos;spam.c&apos;, &apos;spam.h&apos; ] &gt;&gt;&gt; [name for name in filenames if name.endswith((&apos;.c&apos;, &apos;.h&apos;)) ] [&apos;foo.c&apos;, &apos;spam.c&apos;, &apos;spam.h&apos; &gt;&gt;&gt; any(name.endswith(&apos;.py&apos;) for name in filenames) True glob 通配符匹配字符串: fnmatch.fnmatch(), fnmatch.fnmatchcase() fnmatch() 函数匹配能力介于简单的字符串方法和强大的正则表法式之间. 但是如果你的代码需要做文件名的匹配, 最好使用 glob 模块 &gt;&gt;&gt; from fnmatch import fnmatch, fnmatchcase &gt;&gt;&gt; fnmatch(&apos;foo.txt&apos;, &apos;*.txt&apos;) True &gt;&gt;&gt; fnmatch(&apos;foo.txt&apos;, &apos;?oo.txt&apos;) True &gt;&gt;&gt; fnmatch(&apos;Dat45.csv&apos;, &apos;Dat[0-9]*&apos;) True &gt;&gt;&gt; names = [&apos;Dat1.csv&apos;, &apos;Dat2.csv&apos;, &apos;config.ini&apos;, &apos;foo.py&apos;] &gt;&gt;&gt; [name for name in names if fnmatch(name, &apos;Dat*.csv&apos;)] [&apos;Dat1.csv&apos;, &apos;Dat2.csv&apos;] fnmatch.fnmatch() 使用底层的操作系统的大小写敏感规则来匹配. fnmatch.fnmatchcase() 则完全使用自定义的模式做大小写匹配. # On OS X (Mac) &gt;&gt;&gt; fnmatch(&apos;foo.txt&apos;, &apos;*.TXT&apos;) False # On Windows &gt;&gt;&gt; fnmatch(&apos;foo.txt&apos;, &apos;*.TXT&apos;) True # fnmatchcase() &gt;&gt;&gt; fnmatchcase(&apos;foo.txt&apos;, &apos;*.TXT&apos;) False str.find() 如果匹配到, 则返回匹配第一个字符的索引; 如果没有匹配到, 则返回负数(-1) re 与正则表达式, re.compile(),re.mathc(),re.findall(),re.finditer() &gt;&gt;&gt; text1 = &apos;11/27/2012&apos; &gt;&gt;&gt; text2 = &apos;Nov 27, 2012&apos; &gt;&gt;&gt; import re # Simple matching: \d+ means match one or more digits &gt;&gt;&gt; if re.match(r&apos;\d+/\d+/\d+&apos;, text1): print(&apos;yes&apos;) yes &gt;&gt;&gt; if re.match(r&apos;\d+/\d+/\d+&apos;, text2): print(&apos;yes&apos;) 使用同一个模式做多次匹配, 可以先将模式字符串预编译为模式对象. &gt;&gt;&gt; datepat = re.compile(r&apos;\d+/\d+/\d+&apos;) &gt;&gt;&gt; if datepat.match(text1): print &quot;yes&quot; yes &gt;&gt;&gt; if datepat.match(text2): print &quot;yes&quot; re.match() 总是从字符串开始去匹配, re.findall() 查找字符串任意部分的模式出现位置, 并以列表形式返回所有的匹配. re.finditer() 同 re.findall() 以迭代方式返回匹配. &gt;&gt;&gt; text = &apos;Today is 11/27/2012. PyCon starts 3/13/2013.&apos; &gt;&gt;&gt; datepat.findall(text) [&apos;11/27/2012&apos;, &apos;3/13/2013&apos;] 定义正则时, 通常利用括号来捕获分组. 捕获分组可以使得后面的处理更加简单, 因为可以分别为每个组的内容提取出来. &gt;&gt;&gt; datepat = re.compile(r&apos;(\d+)/(\d+)/(\d+)&apos;) &gt;&gt;&gt; m = datepat.match(&apos;11/27/2012&apos;) &gt;&gt;&gt; m &lt;_sre.SRE_Match object at 0x1005d2750&gt; # Extract the contents of each group &gt;&gt;&gt; m.group(0) &apos;11/27/2012&apos; &gt;&gt;&gt; m.group(1) &apos;11&apos; &gt;&gt;&gt; m.group(2) &apos;27&apos; &gt;&gt;&gt; m.group(3) &apos;2012&apos; &gt;&gt;&gt; m.groups() (&apos;11&apos;, &apos;27&apos;, &apos;2012&apos;) &gt;&gt;&gt; month, day, year = m.groups() # Find all matches (notice splitting into tuples) &gt;&gt;&gt; text &apos;Today is 11/27/2012. PyCon starts 3/13/2013.&apos; &gt;&gt;&gt; datepat.findall(text) [(&apos;11&apos;, &apos;27&apos;, &apos;2012&apos;), (&apos;3&apos;, &apos;13&apos;, &apos;2013&apos;)] &gt;&gt;&gt; for month, day, year in datepat.findall(text): print(&apos;{}-{}-{}&apos;.format(year, month, day)) 2012-11-27 2013-3-13 # re 模块级别的函数 &gt;&gt;&gt; re.findall(r&apos;(\d+)/(\d+)/(\d+)&apos;, text) [(&apos;11&apos;, &apos;27&apos;, &apos;2012&apos;), (&apos;3&apos;, &apos;13&apos;, &apos;2013&apos;)] 字符串替换 str.replace() &gt;&gt;&gt; text = &apos;yeah, but no, but yeah, but no, but yeah&apos; &gt;&gt;&gt; text.replace(&apos;yeah&apos;, &apos;yep&apos;) &apos;yep, but no, but yep, but no, but yep&apos; re.sub(), re.subn() &gt;&gt;&gt; text = &apos;Today is 11/27/2012. PyCon starts 3/13/2013.&apos; &gt;&gt;&gt; import re &gt;&gt;&gt; re.sub(r&apos;(\d+)/(\d+)/(\d+)&apos;, r&apos;\3-\1-\2&apos;, text) &apos;Today is 2012-11-27. PyCon starts 2013-3-13.&apos; # 预编译处理 &gt;&gt;&gt; import re &gt;&gt;&gt; datepat = re.compile(r&apos;(\d+)/(\d+)/(\d+)&apos;) &gt;&gt;&gt; datepat.sub(r&apos;\3-\1-\2&apos;, text) &apos;Today is 2012-11-27. PyCon starts 2013-3-13.&apos; 除了替换后的结果, 还需要知道共替换了几次 `re.subn()`. &gt;&gt;&gt; newtext, n = datepat.subn(r&apos;\3-\1-\2&apos;, text) &gt;&gt;&gt; newtext &apos;Today is 2012-11-27. PyCon starts 2013-3-13.&apos; &gt;&gt;&gt; n 2 传递一个替换回调函数: 一个替换回调函数的参数是一个 `match` 对象, 也就是 `match()` 或者 `find()` 返回的对象. 使用 `group()` 方法来提取特定的匹配部分. 回调函数最后返回替换字符串. &gt;&gt;&gt; from calendar import month_abbr &gt;&gt;&gt; def change_date(m): mon_name = month_abbr[int(m.group(1))] return &apos;{} {} {}&apos;.format(m.group(2), mon_name, m.group(3)) &gt;&gt;&gt; datepat.sub(change_date, text) &apos;Today is 27 Nov 2012. PyCon starts 13 Mar 2013.&apos; 文本操作时, 忽略大小写. re.IGNORECASE &gt;&gt;&gt; text = &apos;UPPER PYTHON, lower python, Mixed Python&apos; &gt;&gt;&gt; re.findall(&apos;python&apos;, text, flags=re.IGNORECASE) [&apos;PYTHON&apos;, &apos;python&apos;, &apos;Python&apos;] &gt;&gt;&gt; re.sub(&apos;python&apos;, &apos;snake&apos;, text, flags=re.IGNORECASE) &apos;UPPER snake, lower snake, Mixed snake&apos; re.DOTALL re.DOTALL 让正则表达式中的 . 匹配包括换行符在内的任意字符. 处理 Unicode 字符串2.9 将 Unicode 文本标准化. 数字,日期和时间数字的四舍五入 round(value, ndigits) : 四舍五入 &gt;&gt;&gt; round(1.23, 1) 1.2 &gt;&gt;&gt; round(1.27, 1) 1.3 &gt;&gt;&gt; round(-1.27, 1) -1.3 &gt;&gt;&gt; round(1.25361,3) 1.254 当一个值刚好在两个边界的中间的时候, round() 返回离他最近的偶数. 即 1.5 和 2.5 四舍五入后都得到 2. &gt;&gt;&gt; round(1.5) 2.0 &gt;&gt;&gt; round(2.5) 3.0 给 round() 函数的 ndigits 参数也可以是负数, 此时, 舍入运算会作用在十位, 百位, 千位等上面. &gt;&gt;&gt; a = 1627731 &gt;&gt;&gt; round(a, -1) 1627730 &gt;&gt;&gt; round(a, -2) 1627700 &gt;&gt;&gt; round(a, -3) 1628000 不要把四舍五入运算与格式化输出混淆. &gt;&gt;&gt; x = 1.23456 &gt;&gt;&gt; format(x, &apos;0.2f&apos;) &apos;1.23&apos; &gt;&gt;&gt; format(x, &apos;0.3f&apos;) &apos;1.235&apos; &gt;&gt;&gt; &apos;value is {:0.3f}&apos;.format(x) &apos;value is 1.235&apos; decimal : 精确的数学运算 decimal 模块实现了 IBM 的 通用小数运算规范, 但会有一定的性能损耗. &gt;&gt;&gt; from decimal import Decimal &gt;&gt;&gt; a = Decimal(&apos;4.2&apos;) // 参数为字符串 &gt;&gt;&gt; b = Decimal(&apos;2.1&apos;) // 参数为字符串 &gt;&gt;&gt; a + b Decimal(&apos;6.3&apos;) &gt;&gt;&gt; print(a + b) 6.3 &gt;&gt;&gt; (a + b) == Decimal(&apos;6.3&apos;) True Decimal 对象支持所有的常用数学计算. decimal 模块的一个主要特征是允许你控制计算的每一方面, 包括数字位数和四舍五入计算. &gt;&gt;&gt; from decimal import localcontext &gt;&gt;&gt; a = Decimal(&apos;1.3&apos;) &gt;&gt;&gt; b = Decimal(&apos;1.7&apos;) &gt;&gt;&gt; print(a / b) 0.7647058823529411764705882353 &gt;&gt;&gt; with localcontext() as ctx: ctx.prec = 3 print(a / b) 0.765 &gt;&gt;&gt; with localcontext() as ctx: ctx.prec = 50 print(a / b) 0.76470588235294117647058823529411764705882352941176 format() : 数字的格式化输出 format() 格式化输出数字, 支持 浮点数 和 decimal 模块中的 Decimal 对象. 格式化输出单个数字的时候, 可以使用内置的 format() 函数. 指出数字的位数后, 结果值或根据 round() 函数同样的规则进行四舍五入. &gt;&gt;&gt; x = 1234.56789 # Two decimal places of accuracy &gt;&gt;&gt; format(x, &apos;0.2f&apos;) &apos;1234.57&apos; # Right justified in 10 chars, one-digit accuracy &gt;&gt;&gt; format(x, &apos;&gt;10.1f&apos;) &apos; 1234.6&apos; # Left justified &gt;&gt;&gt; format(x, &apos;&lt;10.1f&apos;) &apos;1234.6 &apos; # Centered &gt;&gt;&gt; format(x, &apos;^10.1f&apos;) &apos; 1234.6 &apos; # Inclusion of thousands separator &gt;&gt;&gt; format(x, &apos;,&apos;) &apos;1,234.56789&apos; &gt;&gt;&gt; format(x, &apos;0,.1f&apos;) &apos;1,234.6&apos; 使用指数法输出, 将 f 改成 e/E 即可. &gt;&gt;&gt; format(x, &apos;e&apos;) &apos;1.234568e+03&apos; &gt;&gt;&gt; format(x, &apos;0.2E&apos;) &apos;1.23E+03&apos; 指定宽度和精度: 同时指定宽度和精度的一般形式是 [&lt;&gt;^]?width[,]?(.digits)? ，其中 width 和 digits 为整数，? 代表可选部分. 同样的格式也被用在字符串的 format() 方法中 &gt;&gt;&gt; &apos;The value is {:0,.2f}&apos;.format(x) &apos;The value is 1,234.57&apos; 二进制 bin(), 八进制 oct(), 十六进制 hex() 整数 大多数情况下处理二进制, 八进制, 十六进制整数是简单的. 只需记住那些转换属于整数和其对应的文本表示之间的转换即可. 永远只有一种整数类型. &gt;&gt;&gt; x = 1234 &gt;&gt;&gt; bin(x) &apos;0b10011010010&apos; &gt;&gt;&gt; oct(x) &apos;0o2322&apos; &gt;&gt;&gt; hex(x) &apos;0x4d2&apos; 不输出 0b, 0o, 0x 前缀. &gt;&gt;&gt; format(x, &apos;b&apos;) &apos;10011010010&apos; &gt;&gt;&gt; format(x, &apos;o&apos;) &apos;2322&apos; &gt;&gt;&gt; format(x, &apos;x&apos;) &apos;4d2&apos; 为了以不同的进制转换数字字符串, 使用带有进制的 int() 函数即可. &gt;&gt;&gt; int(&apos;4d2&apos;, 16) 1234 &gt;&gt;&gt; int(&apos;10011010010&apos;, 2) 1234 Python 的八进制语法: &gt;&gt;&gt; import os &gt;&gt;&gt; os.chmod(&quot;script.py&quot;, 0o755) // 注意 0o755 整数与字节字符串: int.from_bytes(), int.to_bytes(), int.bit_length(). Python3 字节顺序规则 (little或big) 仅仅指定了构建整数时的字节的低位高位排列方式。 int.from_bytes() 将 bytes 解析为整数. data = b&apos;\x00\x124V\x00x\x90\xab\x00\xcd\xef\x01\x00#\x004&apos; &gt;&gt;&gt; len(data) 16 &gt;&gt;&gt; int.from_bytes(data, &apos;little&apos;) 69120565665751139577663547927094891008 &gt;&gt;&gt; int.from_bytes(data, &apos;big&apos;) 94522842520747284487117727783387188 int.to_bytes() 将一个大整数转换为一个字节字符串. &gt;&gt;&gt; x = 94522842520747284487117727783387188 &gt;&gt;&gt; x.to_bytes(16, &apos;big&apos;) b&apos;\x00\x124V\x00x\x90\xab\x00\xcd\xef\x01\x00#\x004&apos; &gt;&gt;&gt; x.to_bytes(16, &apos;little&apos;) b&apos;4\x00#\x00\x01\xef\xcd\x00\xab\x90x\x00V4\x12\x00&apos; int.bit_length() 确定字节大小 &gt;&gt;&gt; x = 523 ** 23 &gt;&gt;&gt; x 335381300113661875107536852714019056160355655333978849017944067 &gt;&gt;&gt; x.to_bytes(16, &apos;little&apos;) Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; OverflowError: int too big to convert &gt;&gt;&gt; x.bit_length() 208 &gt;&gt;&gt; nbytes, rem = divmod(x.bit_length(), 8) &gt;&gt;&gt; if rem: nbytes += 1 &gt;&gt;&gt; x.to_bytes(nbytes, &apos;little&apos;) b&apos;\x03X\xf1\x82iT\x96\xac\xc7c\x16\xf3\xb9\xcf...\xd0&apos; 正无穷, 负无穷或 Nan 的浮点数 : float() &gt;&gt;&gt; a = float(&apos;inf&apos;) &gt;&gt;&gt; b = float(&apos;-inf&apos;) &gt;&gt;&gt; c = float(&apos;nan&apos;) &gt;&gt;&gt; a inf &gt;&gt;&gt; b -inf &gt;&gt;&gt; c nan 测试 正无穷, 负无穷和 Nan 的存在，使用 math.isinf() 和 math.isnan() 函数 &gt;&gt;&gt; math.isinf(a) True &gt;&gt;&gt; math.isnan(c) True 无穷大数在执行数学计算的时候会传播: &gt;&gt;&gt; a = float(&apos;inf&apos;) &gt;&gt;&gt; a + 45 inf &gt;&gt;&gt; a * 10 inf &gt;&gt;&gt; 10 / a 0.0 # 有些操作时未定义的额会返回一个 NaN 结果 &gt;&gt;&gt; a = float(&apos;inf&apos;) &gt;&gt;&gt; a/a nan &gt;&gt;&gt; b = float(&apos;-inf&apos;) &gt;&gt;&gt; a + b nan NaN 值会在所有操作中传播, 而不会产生异常. &gt;&gt;&gt; c = float(&apos;nan&apos;) &gt;&gt;&gt; c + 23 nan &gt;&gt;&gt; c / 2 nan &gt;&gt;&gt; c * 2 nan &gt;&gt;&gt; math.sqrt(c) nan # NaN 值的一个特别的地方是, 他们之间的比较操作总是返回 False. # 也因此, 测试 NaN 值唯一安全的方法就是使用 math.isnan() &gt;&gt;&gt; c = float(&apos;nan&apos;) &gt;&gt;&gt; d = float(&apos;nan&apos;) &gt;&gt;&gt; c == d False &gt;&gt;&gt; c is d False fractions() 分数计算 fractions 模块可以被用来执行包含分数的数学运算. &gt;&gt;&gt; from fractions import Fraction &gt;&gt;&gt; a = Fraction(5, 4) &gt;&gt;&gt; b = Fraction(7, 16) &gt;&gt;&gt; print(a + b) 27/16 &gt;&gt;&gt; print(a * b) 35/64 # Getting numerator/denominator &gt;&gt;&gt; c = a * b &gt;&gt;&gt; c.numerator 35 &gt;&gt;&gt; c.denominator 64 # Converting to a float &gt;&gt;&gt; float(c) 0.546875 # Limiting the denominator of a value &gt;&gt;&gt; print(c.limit_denominator(8)) 4/7 # Converting a float to a fraction &gt;&gt;&gt; x = 3.75 &gt;&gt;&gt; y = Fraction(*x.as_integer_ratio()) &gt;&gt;&gt; y Fraction(15, 4) numpy 大数据集运算(数组/网格)/矩阵/线性代数运算 底层实现中, NumPy 数组使用了 C 或者 Fortran 语言的机制分配内存, 即他们是一个非常大的连续的并由同类型数据组成的内存区域. 所以, 可以构造一个比普通 Python 列表大的多的数组. &gt;&gt;&gt; grid += 10 &gt;&gt;&gt; grid array([[ 10., 10., 10., ..., 10., 10., 10.], [ 10., 10., 10., ..., 10., 10., 10.], [ 10., 10., 10., ..., 10., 10., 10.], ..., [ 10., 10., 10., ..., 10., 10., 10.], [ 10., 10., 10., ..., 10., 10., 10.], [ 10., 10., 10., ..., 10., 10., 10.]]) &gt;&gt;&gt; np.sin(grid) array([[-0.54402111, -0.54402111, -0.54402111, ..., -0.54402111, -0.54402111, -0.54402111], [-0.54402111, -0.54402111, -0.54402111, ..., -0.54402111, -0.54402111, -0.54402111], [-0.54402111, -0.54402111, -0.54402111, ..., -0.54402111, -0.54402111, -0.54402111], ..., [-0.54402111, -0.54402111, -0.54402111, ..., -0.54402111, -0.54402111, -0.54402111], [-0.54402111, -0.54402111, -0.54402111, ..., -0.54402111, -0.54402111, -0.54402111], [-0.54402111, -0.54402111, -0.54402111, ..., -0.54402111, -0.54402111, -0.54402111]]) NumPy 的一个主要特征是他会给 Python 提供一个数组对象, 相比标准的 Python 列表更适合做数学运算. &gt;&gt;&gt; import numpy as np &gt;&gt;&gt; ax = np.array([1, 2, 3, 4]) &gt;&gt;&gt; ay = np.array([5, 6, 7, 8]) &gt;&gt;&gt; ax * 2 // 标量运算 array([2, 4, 6, 8]) &gt;&gt;&gt; ax + 10 // 标量运算 array([11, 12, 13, 14]) &gt;&gt;&gt; ax + ay array([ 6, 8, 10, 12]) &gt;&gt;&gt; ax * ay array([ 5, 12, 21, 32]) 对整个数组中的所有元素同时执行数学运算可以使得作用在整个数组上的函数 运算简单而快速. &gt;&gt;&gt; def f(x): return 3*x**2 - 2*x + 7 &gt;&gt;&gt; f(ax) array([ 8, 15, 28, 47]) 其他通用数学函数: 使用这些通用函数比循环数组并使用 math 模块中的函数要快得多. &gt;&gt;&gt; np.sqrt(ax) array([ 1. , 1.41421356, 1.73205081, 2. ]) &gt;&gt;&gt; np.cos(ax) array([ 0.54030231, -0.41614684, -0.9899925 , -0.65364362]) NumPy 中的索引功能: 它扩展了 Python 列表的索引功能, 特别是对于多维数组. &gt;&gt;&gt; a = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) &gt;&gt;&gt; a array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12]]) # Select row 1 &gt;&gt;&gt; a[1] array([5, 6, 7, 8]) # Select column 1 &gt;&gt;&gt; a[:,1] array([ 2, 6, 10]) # Select a subregion and change it &gt;&gt;&gt; a[1:3, 1:3] array([[ 6, 7], [10, 11]]) &gt;&gt;&gt; a[1:3, 1:3] += 10 &gt;&gt;&gt; a array([[ 1, 2, 3, 4], [ 5, 16, 17, 8], [ 9, 20, 21, 12]]) # Broadcast a row vector across an operation on all rows &gt;&gt;&gt; a + [100, 101, 102, 103] array([[101, 103, 105, 107], [105, 117, 119, 111], [109, 121, 123, 115]]) &gt;&gt;&gt; a array([[ 1, 2, 3, 4], [ 5, 16, 17, 8], [ 9, 20, 21, 12]]) # Conditional assignment on an array &gt;&gt;&gt; np.where(a &lt; 10, a, 10) array([[ 1, 2, 3, 4], [ 5, 10, 10, 8], [ 9, 10, 10, 10]]) 矩阵 : 类似数组对象, 但遵循线性代数的计算规则. &gt;&gt;&gt; import numpy as np &gt;&gt;&gt; m = np.matrix([[1,-2,3],[0,4,5],[7,8,-9]]) &gt;&gt;&gt; m matrix([[ 1, -2, 3], [ 0, 4, 5], [ 7, 8, -9]]) # Return transpose &gt;&gt;&gt; m.T matrix([[ 1, 0, 7], [-2, 4, 8], [ 3, 5, -9]]) # Return inverse &gt;&gt;&gt; m.I matrix([[ 0.33043478, -0.02608696, 0.09565217], [-0.15217391, 0.13043478, 0.02173913], [ 0.12173913, 0.09565217, -0.0173913 ]]) # Create a vector and multiply &gt;&gt;&gt; v = np.matrix([[2],[3],[4]]) &gt;&gt;&gt; v matrix([[2], [3], [4]]) &gt;&gt;&gt; m * v matrix([[ 8], [32], [ 2]]) numpy.linalg 子包中包含更多的操作函数. &gt;&gt;&gt; import numpy.linalg # Determinant &gt;&gt;&gt; numpy.linalg.det(m) -229.99999999999983 # Eigenvalues &gt;&gt;&gt; numpy.linalg.eigvals(m) array([-13.11474312, 2.75956154, 6.35518158]) # Solve for x in mx = v &gt;&gt;&gt; x = numpy.linalg.solve(m, v) &gt;&gt;&gt; x matrix([[ 0.96521739], [ 0.17391304], [ 0.46086957]]) &gt;&gt;&gt; m * x matrix([[ 2.], [ 3.], [ 4.]]) &gt;&gt;&gt; v matrix([[2], [3], [4]]) random() 随机数 random() 有大量的函数用来产生随机数和随机选择元素. `random.choice(list)` 从一个序列中随机的抽取一个元素 &gt;&gt;&gt; import random &gt;&gt;&gt; values = [1, 2, 3, 4, 5, 6] &gt;&gt;&gt; random.choice(values) 2 &gt;&gt;&gt; random.choice(values) 3 &gt;&gt;&gt; random.choice(values) 1 `random.sample(list, N)` 提取 N 个不同的元素样本 &gt;&gt;&gt; random.sample(values, 2) [6, 2] &gt;&gt;&gt; random.sample(values, 2) [4, 3] &gt;&gt;&gt; random.sample(values, 3) [4, 3, 1] &gt;&gt;&gt; random.sample(values, 3) [5, 4, 1] `random.shuffle(list)` 打乱序列中元素的顺序. &gt;&gt;&gt; random.shuffle(values) &gt;&gt;&gt; values [2, 4, 6, 5, 3, 1] &gt;&gt;&gt; random.shuffle(values) &gt;&gt;&gt; values [3, 5, 2, 1, 6, 4] `random.randint(start_num, end_num)` 生成随机整数 &gt;&gt;&gt; random.randint(0,10) 0 &gt;&gt;&gt; random.randint(0,10) 7 &gt;&gt;&gt; random.randint(0,10) 10 &gt;&gt;&gt; random.randint(0,10) 3 `random.random()` 生成 0 ~ 1 之间均匀分布的浮点数. &gt;&gt;&gt; random.random() 0.9406677561675867 &gt;&gt;&gt; random.random() 0.133129581343897 &gt;&gt;&gt; random.random() 0.4144991136919316 `random.getrandbits(N)` 获取 N 位随机位(二进制)的整数 &gt;&gt;&gt; random.getrandbits(200) 335837000776573622800628485064121869519521710558559406913275 random模块使用 `Mersenne Twister` 算法来计算生成随机数。这是一个确定性算法，但是你可以通过 `random.seed()` 函数修改初始化种子。比如： random.seed() # Seed based on system time or os.urandom() random.seed(12345) # Seed based on integer given random.seed(b&apos;bytedata&apos;) # Seed based on byte data 除了上述介绍的功能，random模块还包含基于**均匀分布**、**高斯分布**和其他分布的随机数生成函数。比如 - `random.uniform()` 计算均匀分布随机数， - `random.gauss()` 计算正态分布随机数 - 其他随机数算法. 在random模块中的函数**不应该**用在和密码学相关的程序中。如果你确实需要类似的功能，可以使用`ssl模块`中相应的函数。比如，`ssl.RAND_bytes()` 可以用来生成一个安全的随机字节序列。 日期和时间 时间间隔 dateutil.relativadelta() datetime.timedelta datetime.timedelta &gt;&gt;&gt; from datetime import timedelta &gt;&gt;&gt; a = timedelta(days=2, hours=6) &gt;&gt;&gt; b = timedelta(hours=4.5) &gt;&gt;&gt; c = a + b &gt;&gt;&gt; c.days 2 &gt;&gt;&gt; c.seconds 37800 &gt;&gt;&gt; c.seconds / 3600 10.5 &gt;&gt;&gt; c.total_seconds() / 3600 58.5 dateutil.relativadelta() &gt;&gt;&gt; a = datetime(2012, 9, 23) &gt;&gt;&gt; a + timedelta(months=1) Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; TypeError: &apos;months&apos; is an invalid keyword argument for this function &gt;&gt;&gt; &gt;&gt;&gt; from dateutil.relativedelta import relativedelta &gt;&gt;&gt; a + relativedelta(months=+1) datetime.datetime(2012, 10, 23, 0, 0) &gt;&gt;&gt; a + relativedelta(months=+4) datetime.datetime(2013, 1, 23, 0, 0) &gt;&gt;&gt; # Time between two dates &gt;&gt;&gt; b = datetime(2012, 12, 21) &gt;&gt;&gt; d = b - a &gt;&gt;&gt; d datetime.timedelta(89) &gt;&gt;&gt; d = relativedelta(b, a) &gt;&gt;&gt; d relativedelta(months=+2, days=+28) &gt;&gt;&gt; d.months 2 &gt;&gt;&gt; d.days 28 # 下一个周五 &gt;&gt;&gt; from datetime import datetime &gt;&gt;&gt; from dateutil.relativedelta import relativedelta &gt;&gt;&gt; from dateutil.rrule import * &gt;&gt;&gt; d = datetime.now() &gt;&gt;&gt; print(d) 2012-12-23 16:31:52.718111 # 下一个周五 &gt;&gt;&gt; print(d + relativedelta(weekday=FR)) 2012-12-28 16:31:52.718111 &gt;&gt;&gt; # 上一个周五 &gt;&gt;&gt; print(d + relativedelta(weekday=FR(-1))) 2012-12-21 16:31:52.718111 # 日期修改 from datetime import date d = date.today() # datetime.date(2017, 12, 11) d.replace(day=1) # datetime.date(2017, 12, 1) d.replace(month=1) # datetime.date(2017, 1, 11) 字符串转换为日期 datetime.strptime &gt;&gt;&gt; from datetime import datetime &gt;&gt;&gt; text = &apos;2012-09-20&apos; &gt;&gt;&gt; y = datetime.strptime(text, &apos;%Y-%m-%d&apos;) &gt;&gt;&gt; z = datetime.now() &gt;&gt;&gt; diff = z - y &gt;&gt;&gt; diff datetime.timedelta(3, 77824, 177393) dateutil.parser.parse 结合时区的日期操作 &gt;&gt;&gt; from datetime import datetime &gt;&gt;&gt; from pytz import timezone &gt;&gt;&gt; d = datetime(2012, 12, 21, 9, 30, 0) &gt;&gt;&gt; print(d) 2012-12-21 09:30:00 # Localize the date for Chicago : 本地化时间 &gt;&gt;&gt; central = timezone(&apos;US/Central&apos;) &gt;&gt;&gt; loc_d = central.localize(d) &gt;&gt;&gt; print(loc_d) 2012-12-21 09:30:00-06:00 # Convert to Bangalore time : 转换为 班加罗尔 时间 &gt;&gt;&gt; bang_d = loc_d.astimezone(timezone(&apos;Asia/Kolkata&apos;)) &gt;&gt;&gt; print(bang_d) 2012-12-21 21:00:00+05:30 # 时间转换为 UTC 时间 &gt;&gt;&gt; print(loc_d) 2013-03-10 01:45:00-06:00 &gt;&gt;&gt; utc_d = loc_d.astimezone(pytz.utc) &gt;&gt;&gt; print(utc_d) 2013-03-10 07:45:00+00:00 # 使用ISO 3166国家代码作为关键字去查阅字典 pytz.country_timezones 获取时区 &gt;&gt;&gt; pytz.country_timezones[&apos;IN&apos;] [&apos;Asia/Kolkata&apos;] &gt;&gt;&gt; pytz.country_names # 所有国家全名与 ISO 3166 对应字典. 迭代器与生成器 迭代协议机制 __iter__() __next__() StopIteration Python 的迭代协议要求一个 __iter__() 方法, 返回一个特殊的迭代器对象, 这个迭代器对象实现了 __next__() 方法并通过 StopIteration 异常标识迭代完成. 手动遍历迭代器 def manual_iter(): with open(&quot;/etc/passwd&quot;) as f: try: while True: line = next(f) print line except StopIteration: pass __iter__ Python 的迭代协议需要 __iter__() 方法返回一个实现了 __next__() 方法的迭代器对象. 如果只是遍历其他容器的内容, 无需关系底层是怎样实现的, 所做的只是传递迭代请求即可. iter() 函数只是简单的调用 obj.__iter__() 方法返回对应的迭代器对象. class Node: def __init__(self, value): self._value = value self._children = [] def __repr__(self): return &apos;Node({!r})&apos;.format(self._value) def add_child(self, node): self._children.append(node) def __iter__(self): return iter(self._children) # Example if __name__ == &apos;__main__&apos;: root = Node(0) child1 = Node(1) child2 = Node(2) root.add_child(child1) root.add_child(child2) # Outputs Node(1), Node(2) for ch in root: print(ch) 使用生成器创建迭代器. 一个函数中需要有一个 yield 语句即可将其转换为一个生成器, 生成器只能用于迭代操作. 一个生成器函数主要特征是它只会回应在迭代中使用到的 next 操作. 一旦生成器函数返回退出, 迭代终止. def frange(start, stop, incre=1): x = start while x &lt; stop: yield x x += incre &gt;&gt;&gt; def countdown(n): ... print(&apos;Starting to count from&apos;, n) ... while n &gt; 0: ... yield n ... n -= 1 ... print(&apos;Done!&apos;) # Create the generator, notice no output appears &gt;&gt;&gt; c = countdown(3) &gt;&gt;&gt; c &lt;generator object countdown at 0x1006a0af0&gt; # Run to first yield and emit a value &gt;&gt;&gt; next(c) Starting to count from 3 3 # Run to the next yield &gt;&gt;&gt; next(c) 2 # Run to next yield &gt;&gt;&gt; next(c) 1 # Run to next yield (iteration stops) &gt;&gt;&gt; next(c) Done! Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; StopIteration 实现迭代器协议 depth_first() 方法 首先返回自己本身并迭代每一个子节点, 并通过调用子节点的 depth_first() 方法(使用 yield from 语句) 返回对应元素. class Node(object): &quot;&quot;&quot;docstring for Node&quot;&quot;&quot; def __init__(self, value): self._value = value self._children = [] def __repr__(self): return &quot;Node({!r})&quot;.format(self._value) def add_child(self, node): self._children.append(node) def __iter__(self): return iter(self._children) def depth_first(self): yield self for c in self: yield from c.depth_first() if __name__ == &quot;__main__&quot;: root = Node(0) child1 = Node(1) child2 = Node(2) root.add_child(child1) root.add_child(child2) child1.add_child(Node(3)) child1.add_child(Node(4)) child2.add_child(Node(5)) for ch in root.depth_first(): print(ch) # Outputs Node(0), Node(1), Node(3), Node(4), Node(2), Node(5) 手动实现迭代器协议: class Node2(object): def __init(self, value): self._value = value self._children = [] def __repr__(self): return &quot;Node2({!r})&quot;.format(self._value) def add_child(self, node): self._children.append(node) def __iter__(self): return iter(self._children) def depth_first(self): return DepthFirstIterator(self) class DepthFirstIterator(object): &quot;&quot;&quot; Depth-first traversal &quot;&quot;&quot; def __init__(self, start_node): self._node = start_node self._children_iter = None self._child_iter = None def __iter__(self): return self def __next__(self): &quot;&quot;&quot; return myself if just started create an iterator for children &quot;&quot;&quot; if self._children_iter is None: self._children_iter = iter(self) return self._node # if processing a child, return its next item elif self._child_iter: try: nextchild = next(self._child_iter) return nextchild except StopIteration: self._child_iter = None return next(self) else: self._child_iter = next(self._children_iter).depth_first() return next(self) 实现一个反方向的迭代 使用内置的 reversed() 函数: 反向迭代仅仅当对象的大小可预先确定或者对象实现了 __reversed__() 的特殊方法时才能生效. 如果两者都不符合, 则必须手动转换为一个列表才可以. &gt;&gt;&gt; a = range(1,5) &gt;&gt; for i in reversed(a): print i 实现 __reversed__() 方法来实现反向迭代 class Countdown(object): def __init__(self, start): self.start = start def __iter__(self): n = self.start while n&gt;0: yield n n -= 1 def __reversed__(self): n = 1 while n &lt;= self.start: yield n n += 1 for rr in reversed(Countdown(10)): print rr for rr in Countdown(10): print rr 带有外部状态的生成器 from collections import deque class LineHistory: def __init__(self, lines, histlen=3): self.lines = lines self.history = deque(maxlen=3) def __iter__(self): for lineno, line in enumerate(self.lines, 1): self.history.append((lineno, line)) yield line def clear(self): self.history.clear() with open(&quot;/path/to/somefile.txt&quot;) as f: lines = LineHistory(f) for line in lines: if &quot;python&quot; in line: for lineno, hline in lines.history: print(&quot;{}:{}&quot;.format(linene, hline), end=&quot;&quot;) 迭代器/生成器切片itertools.islice() 迭代器和生成器不能使用标准的切片操作, 因为他们的长度事先我们并不知道, 并且也没有实现索引. itertools.islice() 函数返回一个可以生成指定元素的迭代器, 他通过遍历并丢弃知道切片开始索引位置的所有元素. 然后, 开始一个一个的返回元素, 知道切片结束索引位置. islice() 会消耗传入的迭代器中的数据. 因此,必须考虑迭代器时不可逆的事实. &gt;&gt;&gt; def count(n): ... while True: ... yield n ... n += 1 ... &gt;&gt;&gt; c = count(0) &gt;&gt;&gt; c[10:20] Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; TypeError: &apos;generator&apos; object is not subscriptable # Now using islice() &gt;&gt;&gt; import itertools &gt;&gt;&gt; for x in itertools.islice(c, 10, 20): print(x) 10 11 12 13 14 15 16 17 18 19 跳过可迭代对象的开始部分itertools.dropwhile() 和 itertools.islice() itertools.dropwhile() 接受一个函数对象和一个可迭代对象作为参数, 它返回一个迭代器对象, 丢弃原有序列知道函数返回 True 之前的所有元素, 然后返回后面所有的元素. # 跳过文件 开头的, 以 `#` 开始的行. from itertools import dropwhile with open(&quot;/etc/fstab&quot;) as f: for line in dropwhile(lambda line: line.startswith(&quot;#&quot;), f): print(line, end=&quot;&quot;) # 跳过文件中, 所有以 `#` 开头的行. with open(&apos;/etc/passwd&apos;) as f: lines = (line for line in f if not line.startswith(&apos;#&apos;)) for line in lines: print(line, end=&apos;&apos;) `itertools.islice()` 如果知道要跳过的元素的个数时. from itertools import islice items = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, 1, 4, 10, 15] for x in islice(iterms, 3, None): print x 迭代遍历一个集合中元素的所有可能的排列或组合 itertools.permutations() 它接受一个集合并产生一个元素序列, 每个元组由集合中的所有元素的一个可能排列组成, 即通过打乱集合中元素排列顺序生成一个元组. 另, 可以传递一个可选的长度参数, 得到指定长度的所有排列. items = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;] from itertools import permutations for p in permutations(items): print p # output (&apos;a&apos;, &apos;b&apos;, &apos;c&apos;) (&apos;a&apos;, &apos;c&apos;, &apos;b&apos;) (&apos;b&apos;, &apos;a&apos;, &apos;c&apos;) (&apos;b&apos;, &apos;c&apos;, &apos;a&apos;) (&apos;c&apos;, &apos;a&apos;, &apos;b&apos;) (&apos;c&apos;, &apos;b&apos;, &apos;a&apos;) `itertools.combinations()` 可以得到输入集合中元素的所有组合. 对于 combinations() 来说, 元素的顺序已经不重要了, 即 (&quot;a&quot;, &quot;b&quot;) 跟 (&quot;b&quot;, &quot;a&quot;) 其实是一样的(最终只会输出一个). &gt;&gt;&gt; from itertools import combinations &gt;&gt;&gt; for c in combinations(items, 3): ... print(c) ... (&apos;a&apos;, &apos;b&apos;, &apos;c&apos;) &gt;&gt;&gt; for c in combinations(items, 2): ... print(c) ... (&apos;a&apos;, &apos;b&apos;) (&apos;a&apos;, &apos;c&apos;) (&apos;b&apos;, &apos;c&apos;) &gt;&gt;&gt; for c in combinations(items, 1): ... print(c) ... (&apos;a&apos;,) (&apos;b&apos;,) (&apos;c&apos;,) `itertools.combinations_with_replacement()` 计算组合的时候, 一旦元素被选取就会从候选中剔除掉, 那么接下来就不会考虑他了. 而 `itertools.combinations_with_replacement()` 允许一个元素被选择多次. for c in combinations_with_replacement(items, 3): print c # output (&apos;a&apos;, &apos;a&apos;, &apos;a&apos;) (&apos;a&apos;, &apos;a&apos;, &apos;b&apos;) (&apos;a&apos;, &apos;a&apos;, &apos;c&apos;) (&apos;a&apos;, &apos;b&apos;, &apos;b&apos;) (&apos;a&apos;, &apos;b&apos;, &apos;c&apos;) (&apos;a&apos;, &apos;c&apos;, &apos;c&apos;) (&apos;b&apos;, &apos;b&apos;, &apos;b&apos;) (&apos;b&apos;, &apos;b&apos;, &apos;c&apos;) (&apos;b&apos;, &apos;c&apos;, &apos;c&apos;) (&apos;c&apos;, &apos;c&apos;, &apos;c&apos;) 在迭代一个序列的同时, 跟踪正在被处理的元素索引 enumerate() 可以实现在迭代一个序列的同时, 跟踪正在被处理的元素索引. items = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;] for idx, val in enumerate(items, 1): print idx, val 1 a 2 b 3 c 在遍历文件时, 想在错误消息中使用行号定位时, 非常有用. def parse_date(filename): with open(filename, &apos;rt&apos;) as f: for lineno, line in enumerate(f, 1): fields = line.split() try: count = int(filelds[1]) # ... except ValueError as e: print(&quot;Line {} : Parse error: {}&quot;.format(lineno, e)) 一个简单的单词统计程序: 统计单词都出现在那些行 from collections import defaultdict word_summary = defaultdict(list) with open(&quot;/path/to/file.txt&quot;, &apos;r&apos;) as f: lines = f.readlines() for idx, line in enumerate(lines): words = [w.strip().lower() for w in line.split()] for word in words: word_summary[word].append(idx) 迭代多个序列, 每次分别从一个序列中取一个元素. zip(list_a, list_b) 会生成一个可返回元组 (x,y)的迭代器, 其中 x 来自 list_a, y 来自 list_b. 一旦其中某个序列结束, 则整个迭代宣告结束, 因此, 迭代长度跟参数中最短序列长度一致. &gt;&gt;&gt; a = [1, 2, 3] &gt;&gt;&gt; b = [&apos;w&apos;, &apos;x&apos;, &apos;y&apos;, &apos;z&apos;] &gt;&gt;&gt; for i in zip(a,b): print(i) (1, &apos;w&apos;) (2, &apos;x&apos;) (3, &apos;y&apos;) itertools.zip_longest() 则一最长的序列为准, 返回元组. &gt;&gt;&gt; from itertools import zip_longest &gt;&gt;&gt; for i in zip_longest(a,b): print(i) (1, &apos;w&apos;) (2, &apos;x&apos;) (3, &apos;y&apos;) (None, &apos;z&apos;) &gt;&gt;&gt; for i in zip_longest(a, b, fillvalue=0): print(i) (1, &apos;w&apos;) (2, &apos;x&apos;) (3, &apos;y&apos;) (0, &apos;z&apos;) 不同集合上元素的迭代. itertools.chain() 接受一个或多个可迭代对象作为输入参数, 然后创建一个迭代器, 依次连续的返回每个可迭代对象中的元素. 对不同集合中所有元素执行某些操作, 即把不同集合当做一个集合来处理, 更加优雅, 而不是用 for 循环. &gt;&gt;&gt; a = [1, 2, 3, 4] &gt;&gt;&gt; b = [&apos;x&apos;, &apos;y&apos;, &apos;z&apos;] &gt;&gt;&gt; from itertools import chain &gt;&gt;&gt; for x in chain(a,b): print x 1 2 3 4 x y z 创建数据处理管道: 生成器. 一个遍历目录寻找文件, 并搜索文件内容的程序. 在如下代码中, yield 作为数据的生产者, 而 for 循环语句作为数据的消费者. 当这些生成器被连在一起后, 每个 yield 会将一个单独的数据元素传递给迭代处理管道的下一阶段. 在例子的最后部分, sum() 函数是最终的程序驱动者, 每次从生成器管道中提取出一个元素. import os import fnmatch import gzip import bz2 import re def gen_find(filepat, top): &quot;&quot;&quot; Find all filenames in a dir tree that match a shell wildcard pattern &quot;&quot;&quot; for path, dirlist, filelist in os.walk(top): for name in fnmatch.filter(filelist, filepat): yield os.path.join(path, name) def gen_opeber(filenames): &quot;&quot;&quot; Open a sequence of filenames once at a time producing a file object. The file is closed immediately when proceeding to the next iteration. &quot;&quot;&quot; for filename in filenames: if filenam.endswith(&quot;.gz&quot;): f = gzip.open(filename, &apos;rt&apos;) elif filename.endswith(&quot;.bz2&quot;): f = bz2.open(filename, &quot;rt&quot;) else: f = open(filename, &apos;rt&apos;) yield f f.close() def gen_concatenate(iterators): &quot;&quot;&quot; Chain a sequence of iterators together into a single sequence. 将输入序列拼接成一个很长的序列. yield from it : 将 yield 操作代理到父生成器上, 简单的返回生成器 it 所产生的所有值. &quot;&quot;&quot; for it in iterators: yield from it def gen_grep(pattern, lines): &quot;&quot;&quot; Look for a regex pattern in a sequence of lines. &quot;&quot;&quot; pat = re.compile(pattern) for line in lines: if pat.search(line): yield line lognames = gen_find(&quot;access-log*&quot;, &apos;www&apos;) files = gen_opener(lognames) lines = gen_concatenate(files) pylines = gen_grep(&apos;(?i)python&apos;, lines) bytecolumn = (line.rsplit(None, 1)[1] for line in pylines) all_bytes = (int(x) for x in bytecolumn if x != &apos;-&apos;) print(&quot;Total&quot;, sum(all_bytes)) 将一个多层嵌套的序列展开成一个单层列表 yield from. yield from 在希望在生成器中调用其他生成器作为子例程时非常有用. yield from 在涉及到基于协程和生成器的并发编程中扮演着更加重要的角色. from collection import Iterable def flatten(items, ignore_types=(str, bytes)): for x in items: if isinstance(x, Iterable) and not isinstance(x, ignore_types): yield from flatten(x) eles: yield x items = [1, 2, [3, 4, [5, 6], 7], 8] for x in flatten(items): print(x) 将多个序列, 合并到一个序列然后迭代遍历 heapq.merge(). heapq.merge() 需要所有输入序列必须是拍过序的.他仅仅是检查所有序列的开始部分, 并返回最小的值, 这个过程会一直持续直到所有输入序列中的元素都被遍历完. heapq.merge() 可迭代特性意味着他不会立马读取所有序列, 可以再非常长的序列中使用它, 而不会有太大的开销. &gt;&gt;&gt; import heapq &gt;&gt;&gt; b = [2, 5, 6, 11] &gt;&gt;&gt; a = [1, 4, 7, 10] &gt;&gt;&gt; for i in heapq.merge(a,b): print(i) 1 2 4 5 6 7 10 11 &gt;&gt;&gt; a &gt;&gt;&gt; [1, 4, 7, 10] &gt;&gt;&gt; b &gt;&gt;&gt; [2, 5, 6, 11] 迭代器代替 while 无线循环 iter() 函数可以接受一个可选的 callable 对象和一个标记(结尾)值作为输入参数. 当以这种方式使用时, 他会创建一个迭代器, 这个迭代器会不断调用callable 对象直到返回值和标记值相等位置. 该方法对于一些特定的会被重复调用的函数很有效果, 如涉及到 IO 调用的函数(从套接字或文件中以数据块的方式读取数据). CHUNKSIZE=8192 def reader(s): for chunk in iter(lamdba: s.recv(CHUNKSIZE), b&quot;&quot;): process_data(data) 文件与IO 读写文本/二进制数据 # 指定文件换行符 open(&apos;somefile.txt&apos;, &apos;rt&apos;, newline=&apos;&apos;) # 指定编码 open(&apos;sample.txt&apos;, &apos;rt&apos;, encoding=&apos;ascii&apos;) # 编码出现问题时, 使用 `errors` 参数来处理错误. open(&apos;sample.txt&apos;, &apos;rt&apos;, encoding=&apos;ascii&apos;, errors=&apos;replace&apos;) open(&apos;sample.txt&apos;, &apos;rt&apos;, encoding=&apos;ascii&apos;, errors=&apos;ignore&apos;) # 读写模式 rt: 文本模式, 读 wt: 文本模式, 写, 之前的内容会被覆盖重写. at: 文本模式, 写, 追加 xt: 文件在文件系统上不存在, 才会写入.即不允许覆盖已存在的文件内容. ## 在读取和写入二进制数据时, 需要指明所有返回的数据都是字节字符串格式的, 而不是文本字符串. rb: 二进制模式, 读, wb: 二进制模式, 写, xb: 文件在文件系统上不存在, 才会写入.即不允许覆盖已存在的文件内容. # Read the entire file as a single byte string with open(&apos;somefile.bin&apos;, &apos;rb&apos;) as f: data = f.read() # Write binary data to a file with open(&apos;somefile.bin&apos;, &apos;wb&apos;) as f: f.write(b&apos;Hello World&apos;) # 从二进制模式的文件中读取或写入文本数据，必须确保要进行解码和编码操作. with open(&apos;somefile.bin&apos;, &apos;rb&apos;) as f: data = f.read(16) text = data.decode(&apos;utf-8&apos;) with open(&apos;somefile.bin&apos;, &apos;wb&apos;) as f: text = &apos;Hello World&apos; f.write(text.encode(&apos;utf-8&apos;)) # 二进制 IO 的一个鲜为人知的特性就是: 数组和C结构体能直接写入, 而不需要中间转换为对象. import array nums = array.array(&apos;i&apos;, [1, 2, 3, 4]) with open(&apos;data.bin&apos;,&apos;wb&apos;) as f: f.write(nums) 将 print() 函数的输出重定向到一个文件中取, 分割符, 换行符 # 文件必须是以文本模式打开的. with open(&quot;somefile.txt&quot;, &apos;rt&apos;) as f: print(&quot;Hello World!&quot;, file=f) # 以非空格分隔符来输出数据, 设置换行符. &gt;&gt;&gt; print(&apos;ACME&apos;, 50, 91.5, sep=&apos;,&apos;, end=&apos;!!\n&apos;) ACME,50,91.5!! &gt;&gt;&gt; row = (&apos;ACME&apos;, 50, 91.5) &gt;&gt;&gt; print(*row, sep=&apos;,&apos;) ACME,50,91.5 字符串的 IO 操作. io.StringIO() 和 io.BytesIO() 使用操作类文件对象的程序来操作文本或二进制字符串. io.StringIO io.BytesIO 在模拟普通的文件时, 很有用. 但是, 他们的实例没有正确的整数类型文件描述符, 因此, 他们不能再那些需要使用真实的系统级文件如文件, 管道或者套接字的程序中使用. io.StringIO() 只能用于文本 &gt;&gt;&gt; s = io.StringIO() &gt;&gt;&gt; s.write(&apos;Hello World\n&apos;) 12 &gt;&gt;&gt; print(&apos;This is a test&apos;, file=s) 15 # Get all of the data written so far &gt;&gt;&gt; s.getvalue() &apos;Hello World\nThis is a test\n&apos; &gt;&gt;&gt; # Wrap a file interface around an existing string &gt;&gt;&gt; s = io.StringIO(&apos;Hello\nWorld\n&apos;) &gt;&gt;&gt; s.read(4) &apos;Hell&apos; &gt;&gt;&gt; s.read() &apos;o\nWorld\n&apos; io.BytesIO() 二进制数据. &gt;&gt;&gt; s = io.BytesIO() &gt;&gt;&gt; s.write(b&apos;binary data&apos;) &gt;&gt;&gt; s.getvalue() b&apos;binary data&apos; 读写压缩文件gzip`bz2` 以文本(rt,wt)/二进制(rb, wb)形式读写数据 # 读取 import gzip with gzip.open(&quot;somefile.zip&quot;, &apos;rt&apos;) as f: text = f.read() import bz2 with bz2.open(&quot;somefile.bz2&quot;, &apos;rt&apos;) as f: text = f.read() # 写入 import gzip with gzip.open(&apos;somefile.gz&apos;, &apos;wt&apos;) as f: f.write(text) import bz2 with bz2.open(&apos;somefile.bz2&apos;, &apos;wt&apos;) as f: f.write(text) # 指定压缩级别, 默认为 9, 即最高压缩级别. with gzip.open(&apos;somefile.gz&apos;, &apos;wt&apos;, compresslevel=5) as f: f.write(text) `gzip.open()` 和 `bz2.open()` 可以作用在一个已存在并以二进制模式打开的文件上.这样就允许, `gzip` 和 `bz2` 模块工作在很多类文件对象上, 如套接字, 管道和内存中的文件等. import gzip f = open(&apos;somefile.gz&apos;, &apos;rb&apos;) with gzip.open(f, &apos;rt&apos;) as g: text = g.read() 内存映射的二进制文件mmp 内存映射一个二进制文件到一个可变字节数组中, 目的可能是为了随机访问他的内容或是原地做些修改. import os import mmap def memory_map(filename, access=mmap.ACCESS_WRITE): size = os.path.getsize(filename) fd = os.open(filename, os.O_RDWR) return mmap.mmap(fd, szie, access=access) size = 1000000 with open(&apos;data&apos;, &apos;wb&apos;) as f: f.seek(size - 1) f.write(b&apos;\x00&apos;) with memory_map(&apos;data&apos;) as m: print(len(m)) print(m[0:10]) mmap.ACCESS_WRITE : 同时支持读和写操作. mmap.ACCESS_READ : 只读 mmap.ACCESS_COPY : 只在本地修改数据, 不写回原始文件. 内存映射文件并不会导致整个文件被读取到内存中, 即文件并没有被复制到内存缓存或数组中, 相反, 操作系统仅仅为文件内容保留了一段虚拟内存.当访问文件的不同区域时, 这些区域的内容才根据需要被读取并映射到内存区域中. os.path 目录文件操作 path = ‘/path/to/test.txt’ os.path.basename(path) os.path.dirname(path) os.path.join(“tmp”, “data”) os.path.expanduser(path) &gt;&gt;&gt; path = &apos;~/Data/data.csv&apos; &gt;&gt;&gt; os.path.expanduser(path) &apos;/root/Data/data.csv&apos; &gt;&gt;&gt; os.path.splitext(path) (&apos;~/Data/data&apos;, &apos;.csv&apos;) 文件或目录是否存在 os.path.exists(‘/etc/passwd’) os.path.isfile(“/etc/passwd”) os.path.islink(“/usr/local/bin/python3”) os.path.realpath(“/usr/local/bin/python3”) # 根据链接寻找源文件. 获取文件元数据 –&gt; 需要考虑文件的权限问题. os.path.getsize(“/etc/passwd”) os.path.getmtime(“/etc/passwd”) os.path.getctime(“/etc/passwd”) os.path.getatime(“/etc/passwd”) os.stat(“/etc/passwd”) 获取某个目录下的文件列表 os.listdir(“somedir”) # 获取所有文件 names = [name for name in os.listdir(&apos;somedir&apos;) if os.path.isfile(os.path.join(&apos;somedir&apos;, name))] # 获取所有目录 dirnames = [name for name in os.listdir(&apos;somedir&apos;) if os.path.isdir(os.path.join(&apos;somedir&apos;, name))] # 根据文件扩展名匹配 pyfiles = [name for name in os.listdir(&apos;somedir&apos;) if name.endswith(&apos;.py&apos;)] # 使用 glob 和 fnmatch 匹配 import glob pyfiles = glob.glob(&apos;somedir/*.py&apos;) from fnmatch import fnmatch pyfiles = [name for name in os.listdir(&apos;somedir&apos;) if fnmatch(name, &apos;*.py&apos;)] os.walk(“/path/to/dir”) 将文件描述符包装成文件对象. 一个操作系统上已经打开的 IO 通道(如文件, 管道, 套接字等)的整型文件描述符, 可以被包装成为一个更高层的 Python 文件对象. 文件描述符仅仅是一个有操作系统指定的整数, 用来指代某个系统的 IO 通道. # 打开一个低级文件描述符 import os fd = os.open(&quot;somefile.txt&quot;, os.O_WRONLY | os.O_CREAT) # turn into a proper file f = open(fd, &apos;wt&apos;) f.write(&quot;Hello world\n&quot;) f.close() 操作管道的例子 from socket import socket, AF_INET, SOCK_STREAM def echo_client(client_sock, addr): print(&quot;Got connection from&quot;, addr) # make text-mode file wrappers for socket reading/writing client_in = open(client_sock.fileno(), &apos;rt&apos;, encoding=&apos;latin-1&apos;, closed=False) client_out = open(client_sock.fileno(), &apos;wt&apos;, encoding=&apos;latin-1&apos;, closed=False) # echo lines back to the client using file IO for line in client_in: client_out.write(line) client_out.flush() client_out.close() def echo_server(address): sock = socket(AF_INET, SOCK_STREAM) sock.bind(address) sock.listen(1) while True: client, addr = sock.accept() echo_client(client, addr) 创建临时文件和文件夹: 使用完成之后, 自动销毁掉. tempfile 模块 tempfile.TemporaryFile(mode) 创建临时匿名文件 from tempfile import TemporaryFile with TemporaryFile(&apos;w+t&apos;) as f: # Read/write to the file f.write(&apos;Hello World\n&apos;) f.write(&apos;Testing\n&apos;) # Seek back to beginning and read the data f.seek(0) data = f.read() # Temporary file is destroyed 或 f = TemporaryFile(&apos;w+t&apos;) # Use the temporary file ... f.close() # File is destroyed tempfile.NamedTemporaryFile() 创建临时命名文件 with NamedTemporaryFile(&apos;w+t&apos;, delete=False) as f: print(&apos;filename is:&apos;, f.name) f.name : 获取文件名 delete=False : 文件关闭时, 不自动删除文件. # 指定文件的前缀, 后缀, 及存放目录 f = NamedTemporaryFile(prefix=&apos;mytemp&apos;, suffix=&apos;.txt&apos;, dir=&apos;/tmp&apos;) f.name # &apos;/tmp/mytemp8ee899.txt&apos; `tempfile.TemporaryDirectory()` 创建临时目录 from tempfile import TemporaryDirectory with TemporaryDirectory() as dirname: print(&apos;dirname is:&apos;, dirname) # Use the directory ... # Directory and all contents destroyed 获取临时文件的存放目录 &gt;&gt;&gt; tempfile.gettempdir() &apos;/var/folders/7W/7WZl5sfZEF0pljrEB1UMWE+++TI/-Tmp-&apos; 更加底层的创建临时文件/目录方法: `tempfile.mkstemp()`, `tempfile.mkdtemp()` , 这些方法只负责创建, 而不再做进一步的管理工作. 如 `mkstemp()` 仅仅返回一个原始的 OS 文件描述符, 需要自己实现将其转换为一个真正的文件对象, 同时还需要自己清理这些文件. # 创建临时文件 &gt;&gt;&gt; tempfile.mkstemp() (3, &apos;/var/folders/7W/7WZl5sfZEF0pljrEB1UMWE+++TI/-Tmp-/tmp7fefhv&apos;) # 创建临时目录 &gt;&gt;&gt; tempfile.mkdtemp() &apos;/var/folders/7W/7WZl5sfZEF0pljrEB1UMWE+++TI/-Tmp-/tmp5wvcv6&apos; 函数 强制关键字参数 def recv(maxsize, *, block): &apos;Receives a message&apos; pass recv(1024, True) # TypeError recv(1024, block=True) # Ok # 在接受任意多个位置参数的函数中指定关键字参数. def mininum(*values, clip=None): m = min(values) if clip is not None: m = clip if clip &gt; m else m return m minimum(1, 5, 2, -5, 10) # Returns -5 minimum(1, 5, 2, -5, 10, clip=0) # Returns 0 给函数增加元信息 : 函数参数注解. 函数参数注解能提示程序员应该怎样正确使用这个函数. Python 解释器不会对这些注解添加任何语义, 也不会被类型检查, 运行时与没有添加注解之前的效果没有任何差别, 然而, 对那些阅读源码的人非常有帮助, 第三方工具和框架核能对这些注解添加语义. def fadd(x:int, y:int) -&gt; int: return x + y &gt;&gt;&gt; help(fadd) Help on function fadd in module __main__: fadd(x:int, y:int) -&gt; int 函数的注解信息, 存储在函数的 __annotations__ 属性中. &gt;&gt;&gt; fadd.__annotations__ {&apos;return&apos;: int, &apos;x&apos;: int, &apos;y&apos;: int} 用注解实现多分派(重载函数) lambda 函数 lambda 允许定义简单的函数, 但他的使用时由限制的, 只能指定单个表达式, 其结果就是表达式的返回值. lamdba 的典型使用场景就时排序或数据 reduce 等. In [60]: names = [&apos;David Beazley&apos;, &apos;Brian Jones&apos;, &apos;Raymond Hettinger&apos;, &apos;Ned Batchelde ...: r&apos;] In [61]: sorted(names, key=lambda name: name.split()[-1].lower()) Out[61]: [&apos;Ned Batchelder&apos;, &apos;David Beazley&apos;, &apos;Raymond Hettinger&apos;, &apos;Brian Jones&apos;] lambda 表达式的参数, 是一个自由变量, 在运行时绑定, 如果想让 lambda 函数在定义时就捕获到值, 可以将那个参数值定义成默认参数即可. # 自由变量, 在运行时绑定. In [64]: x = 10 In [65]: a = lambda y: x+y In [66]: x = 20 In [67]: b = lambda y: x+y In [68]: a(10) Out[68]: 30 In [69]: b(10) Out[69]: 30 # 使用默认值: 定义时绑定. In [70]: x = 10 In [71]: a = lambda y, x=x: x+y In [72]: x = 20 In [73]: b = lambda y, x=x: x+y In [74]: a(10) Out[74]: 20 In [75]: b(10) Out[75]: 30 闭包 — 使用闭包将单个方法的类转换为函数. # 类 from urllib.request import urlopen class UrlTemplate: def __init__(self, template): self.template = template def open(self, **kwagrs): return urlopen(self.template.format_map(kwagrs)) yahoo = UrlTemplate(&quot;http://finance.yahoo.com/d/quotes.csv?s={names}&amp;f={fields}&quot;) for line in yahoo.open(names=&quot;IBM,APPLE,FB&quot;, field=&quot;sl1c1v&quot;): print(line.decode(&quot;utf-8&quot;)) # 闭包 def urltemplate(template): def opener(**kwargs): return urlopen(template.format_map(kwargs)) return opener yahoo = UrlTemplate(&quot;http://finance.yahoo.com/d/quotes.csv?s={names}&amp;f={fields}&quot;) for line in yahoo.open(names=&quot;IBM,APPLE,FB&quot;, field=&quot;sl1c1v&quot;): print(line.decode(&quot;utf-8&quot;)) 带额外状态信息的回调函数: 比如是事件处理器, 等待后台任务完成后的回调, 并且还需要让回调函数拥有额外的状态值. &gt;&gt;&gt; def apply_async(func, args, *, callback): result = func(*args) callback(result) &gt;&gt;&gt; def print_result(result): print(&quot;Got: &quot;, result) &gt;&gt;&gt; def add(x,y): return x+y &gt;&gt;&gt; apply_async(add, (2,3), callback=print_result) Got: 5 &gt;&gt;&gt; apply_async(add, (&apos;hello&apos;, &apos;world&apos;), callback=print_result) Got: helloworld 让回调函数访问外部信息. # 方式一 : 使用一个绑定方法来替代一个简单函数 &gt;&gt;&gt; class ResultHandler: def __init__(self): self.sequence = 0 def handler(self, result): self.sequence += 1 print(&apos;[{}] Got: {}&apos;.format(self.sequence, result)) &gt;&gt;&gt; r = ResultHandler() &gt;&gt;&gt; apply_async(add, (2,3), callback=r.handler) [1] Got: 5 &gt;&gt;&gt; apply_async(add, (2,3), callback=r.handler) [2] Got: 5 # 方式二 : 使用一个闭包来捕获状态值 &gt;&gt;&gt; def make_handler(): sequence = 0 def handler(result): nonlocal sequence sequence += 1 print(&apos;[{}] Got: {}&apos;.format(sequence, result)) return handler &gt;&gt;&gt; handler = make_handler() &gt;&gt;&gt; apply_async(add, (2,3), callback=handler) [1] Got: 5 &gt;&gt;&gt; apply_async(add, (2,3), callback=handler) [2] Got: 5 &gt;&gt;&gt; apply_async(add, (2,3), callback=handler) [3] Got: 5 # 方式三 : 使用协程来完成 &gt;&gt;&gt; def make_handler(): sequence = 0 while True: result = yield sequence += 1 print(&apos;[{}] Got: {}&apos;.format(sequence, result)) &gt;&gt;&gt; handler = make_handler() &gt;&gt;&gt; next(handler) &gt;&gt;&gt; apply_async(add, (2,3),callback=handler.send) [1] Got: 5 &gt;&gt;&gt; apply_async(add, (2,3),callback=handler.send) [2] Got: 5 基于回调函数的软件通常都有可能变得非常复杂. 一部分原因是回调函数通常会跟请求执行代码断开. 因此, 请求执行和处理结果之间的执行环境实际上已经丢失. 如果希望回调函数连续执行多步操作, 那就必须解决如何保存和恢复相关的状态信息了. 至少有两种主要方式来捕获和保存状态信息, 1. 在一个对象实例(通过一个绑定方法)捕获保存状态信息 2. 在一个闭包中保存, 捕获保存状态信息 使用闭包或许更加轻量级和自然一点, 因为闭包可以很自然的通过函数来构造, 还能自动捕获所有被使用到的变量.因此, 无需去担心如何取存储额外的状态信息(代码中自动判定). 3. 使用协程作为回调函数. 协程与闭包密切相关. 某种意义上, 协程更加简洁, 因为他只有一个函数. 并且, 可以很自由的修改变量而无需去使用 `nonlocal` 声明. 唯一的缺点就是比较难以理解: 比如使用之前需要调用 `next()`. 另, 协程还可以作为一个内联回调函数的定义. 通过使用生成器和协程可以使得回调函数内联在某个函数中. &gt;&gt;&gt; from queue import Queue &gt;&gt;&gt; from functools import wraps &gt;&gt;&gt; class Async: def __init__(self, func, args): self.func = func self.args = args &gt;&gt;&gt; def inlined_async(func): @wraps(func) def wrapper(*args): f = func(*args) result_queue = Queue() result_queue.put(None) while True: result = result_queue.get() try: a = f.send(result) apply_async(a.func, a.args, callback=result_queue.put) except StopIteration: break return wrapper &gt;&gt;&gt; @inlined_async def test(): r = yield Async(add,(2,3)) print(r) r = yield Async(add,(&apos;hello&apos;, &apos;world&apos;)) print(r) for n in range(10): r = yield Async(add,(n,n)) print(r) print(&quot;Bye&quot;) &gt;&gt;&gt; test() 5 helloworld 0 2 4 6 8 10 12 14 16 18 Bye 首先, 在需要使用到回调的代码中, 关键点在于当前计算工作会挂起并在将来的某个时候重启(如异步执行). 当计算重启时, 回调函数被调用来持续处理结果. `apply_async()` 函数演示了执行回调的实际逻辑, 尽管实际情况中它可能会更加复杂(包括线程, 进程, 事件处理器等). 计算的暂停与重启思路与生成器函数的执行模型不谋而合. 具体来讲, `yield` 操作会使一个生成器函数产生一个值并暂停. 接下来调用生成器的 `__next__()` 或 `send()` 方法又会让他从暂停处继续处理. 上例中, `inline_async()` 装饰器会逐步遍历生成器函数的所有 `yield` 语句, 每次一个. 为了这样做, 刚开始的时候, 创建了一个 `result` 队列并向里面放入一个 `None` 值. 然后开始一个循环操作, 从队列中取出结果值, 并发送给生成器. 他会持续到下一个 `yield` 语句, 在这里一个 `Async` 的实例被接收到. 然后, 循环开始检查函数和参数, 并开始进行异步计算 `apply_async()` , 然后, 这个计算有一个诡异部分是它没有使用一个普通的回调函数, 而是用队列的 `put()` 方法来回调. 主循环立即返回顶部并在队列上执行 `get()` 操作, 如果数据存在, 他一定是 `put()` 回调存放的结果. 如果没有数据, 那么先暂停操作并等待结果的到来, 其具体实现由 `apply_async()` 函数来决定. 扩展函数中的某个闭包, 允许他能访问和修改函数的内部变量. 通常, 闭包的内部变量对于外界来讲是完全隐藏的. 但是, 可以通过编写访问函数并将其作为函数属性绑定到闭包上来实现这个目的. &gt;&gt;&gt; def sample(): n = 0 def func(): print(&apos;n=&apos;, n) def get_n(): return n def set_n(value): nonlocal n # nonlocal 可以让我们编写函数来修改内部变量的值. n = value func.get_n = get_n # 函数属性允许用一种很简单的方式将访问方法绑定到闭包函数上 func.set_n = set_n return func &gt;&gt;&gt; f = sample() &gt;&gt;&gt; f() n= 0 &gt;&gt;&gt; f.set_n(10) &gt;&gt;&gt; f() n= 10 &gt;&gt;&gt; f.get_n() 10 类与对象 通过 format() 函数和字符串方法使得一个对象能支持自定义的格式化. __format__() 方法给 Pyuthon 的字符串格式化功能提供一个钩子, 但是格式化代码的解析工作完全由类自己决定, 因此, 格式化代码可以是任何值. _formats = { &apos;ymd&apos; : &apos;{d.year}-{d.month}-{d.day}&apos;, &apos;mdy&apos; : &apos;{d.month}/{d.day}/{d.year}&apos;, &apos;dmy&apos; : &apos;{d.day}/{d.month}/{d.year}&apos; } class Date: def __init__(self, year, month, day): self.year = year self.month = month self.day = day def __format__(self, code): if code == &apos;&apos;: code = &apos;ymd&apos; fmt = _formats[code] return fmt.format(d=self) &gt;&gt;&gt; d = Date(2012, 12, 21) &gt;&gt;&gt; format(d) &apos;2012-12-21&apos; &gt;&gt;&gt; format(d, &apos;mdy&apos;) &apos;12/21/2012&apos; &gt;&gt;&gt; &apos;The date is {:ymd}&apos;.format(d) &apos;The date is 2012-12-21&apos; &gt;&gt;&gt; &apos;The date is {:mdy}&apos;.format(d) &apos;The date is 12/21/2012&apos; 让对象支持上下文管理(with 语句) 让对象兼容 with 语句, 需要实现 __enter__() 和 __exit__() 方法. 当出现 with 语句的时候, 对象的 __enter__() 方法会被触发, 它返回的值(如果有的话) 会被赋值给 as 声明的变量. 然后, with 语句块里面的代码开始执行. 最后, __exit__() 方法被触发进行清理工作. __exit__() 方法的三个参数包含了异常类型、异常值和追溯信息(如果有的话). __exit__() 方法能自己决定怎样利用这个异常信息，或者忽略它并返回一个None值。如果 __exit__() 返回 True ，那么异常会被清空，就好像什么都没发生一样，with 语句后面的程序继续在正常执行。 from socket import socket, AF_INET, SOCK_STREAM class LazyConnection: &quot;&quot;&quot; 该类的关键特点是它表示一个网络连接, 但是初始化的时候, 不做任何事(如没有建立一个链接). 连接的建立和关闭是使用 with 语句自动完成的. &quot;&quot;&quot; def __init__(self, address, family=AF_INET, type=SOCK_STREAM): self.address = address self.family = family self.type = type self.sock = None def __enter__(self): if self.sock is not None: raise RuntimeError(&quot;Already connected) self.sock = socket(self.family, self.type) self.sock.connect(self.address) return self.sock def __exit__(self, exc_ty, exc_val, tb): self.sock.close() self.sock = None from functools import partial conn = LazyConnection((&quot;www.python.com&quot;, 80)) with conn as s: # conn.__enter__() executes: connection open s.send(b&apos;GET /index.html HTTP/1.0\r\n&apos;) s.send(b&apos;Host: www.python.com\r\n&apos;) s.send(b&apos;\r\n&apos;) resp = b&apos;&apos;.join(iter(partial(s.recv, 8192), b&apos;&apos;)) # conn.__exit__() executes: connection closed __slots__ 属性来减少实例所占的内存 __slots__ 更多的使用来做为一个内存优化工具. 当定义 __slots__ 后, Python 会为实例使用一种更加紧凑的内部表示. 实例通过一个很小的固定大小的数组来构建, 而不是为每个实例定义一个字典. 在 __slots__ 中列出的属性名在内部被映射到这个数组的指定小标上. 使用 __slots__ 后,不能再给实例添加新的属性了, 只能使用在 __slots__ 中定义的属性. 定义了 __slots__ 后, 类不再支持一些普通的类特性了, 如继承. class Date: __slots__ = [&quot;year&quot;, &quot;month&quot;, &quot;day&quot;] def __init__(self, year, month, day): self.year = year self.month = month self.day = day 私有数据与属性 _ 开头 : 内部实现, 适用于属性, 方法, 模块名和模块级别的函数. __ 开头 : 在类定义中, 这种定义形式的方法的访问形式变为 _CLASSNAME__METHODNAME. 这种重命名的目的是为了继承, 即这种属性通过继承时无法覆盖的. 大多数情况下, 应该使用非公共名称以单下划线开头, 但是如果涉及到子类, 并且有些内部属性应该在子类中隐藏起来, 才考虑使用双下划线方案. property: 给实例增加除了访问与修改之外的其他处理逻辑. property 的一个关键特征是他看上与普通的 attribute 没什么两样, 但是访问他的时候会自动触发 getter, setter 和 deleter 方法. class Person: def __init__(self, first_name): self.first_name = first_name # Getter function @property def first_name(self): return self._first_name # Setter function @first_name.setter def first_name(self, value): if not isinstance(value, str): raise TypeError(&quot;Expected a string&quot;) self._first_name = value # deleter function(optional) @first_name.deleter def first_name(self): raise AttributeError(&quot;Can&apos;t delete attribute&quot;) tom = Person(&quot;tom&quot;) print(tom.first_name) tom.first_name = &quot;NotJerry&quot; print(tom.first_name) 在已存在的 get 和 set 方法的基础上定义 property. class Person: def __init__(self, first_name): self.set_first_name(first_name) def get_first_name(self): return self._first_name def set_first_name(self, value): if not isinstance(value, str): raise TypeError(&quot;Expected a string&quot;) self._first_name = value def del_first_name(self): raise AttributeError(&quot;Cann&apos;t delete attribute&quot;) name = property(get_first_name, set_first_name, del_first_name) 一个 property 属性其实就是一系列相关绑定方法的集合.如果查看拥有 property 的类, 就会发现 property 本身的 fget, fset, fdel 属性就是类里面的普通方法. In [2]: Person.first_name.fget Out[2]: &lt;function __main__.Person.first_name&gt; In [3]: Person.first_name.fdel Out[3]: &lt;function __main__.Person.first_name&gt; In [4]: Person.first_name.fset Out[4]: &lt;function __main__.Person.first_name&gt; Property 还是一种定义动态计算 attribute 的方法. 这种类型的 attribute 并不会被实际存储, 而是在需要的时候, 计算出来. import math class Circle: &quot;&quot;&quot;关于圆的半径, 直径, 周长和面积. 统一了所有的访问接口. &quot;&quot;&quot; def __init__(self, radius): self.radius = radius @property def area(self): return math.pi * self.radius ** 2 @property def diameter(self): return self.radius * 2 @property def perimeter(self): return 2 * math.pi * self.radius super() : 在子类中调用父类的方法 主要有一些用途: 调用父类中的一个方法 class A: def spam(self): print(&quot;A.spam&quot;) class B: def spam(self): print(&quot;B.spam&quot;) super().spam() # call parent spam() 在 __init__() 方法中确保父类被正确的初始化了 class A: def __init__(self): self.x = 0 class B(A): def __init__(self): super().__init__() self.y = 1 覆盖 Python 特殊方法 class Proxy: def __init__(self, obj): self._obj = obj # Delegate attribute lookup to internal obj def __getattr__(self, name): return getattr(self._obj, name) # Delegate attribute assignment def __setattr__(self, name, value): if name.startswith(&quot;_&quot;): super().__setattr__(name, value) # Call original __setattr__ else: setattr(self._obj, name, value) Python 是如何实现继承的: 对于定义的每一个类, Python 会计算出一个所谓的 方法解析顺序(MRO) 列表, 这个 MRO 列表就是一个简单的所有基类的线性顺序表. 使用 Base.init() 示例 : 有些 __init__() 方法被调用多次. class Base: def __init__(self): print(&quot;Base.__init__&quot;) class A(Base): def __init__(self): Base.__init__(self) print(&quot;A.__init__&quot;) class B(Base): def __init__(self): Base.__init__(self) print(&quot;B.__init__&quot;) class C(A, B): def __init__(self): A.__init__(self) B.__init__(self) print(&quot;C.__init__&quot;) c = C() Base.__init__ A.__init__ Base.__init__ B.__init__ C.__init__ 使用 super().init() 示例 : 每个 __init__() 只会被调用一次 class Base: def __init__(self): print(&quot;Base.__init__&quot;) class A(Base): def __init__(self): super().__init__() print(&quot;A.__init__&quot;) print(self.__mro__) class B(Base): def __init__(self): super().__init__() print(&quot;B.__init__&quot;) print(self.__mro__) class C(A, B): def __init__(self): super().__init__() # only one call to super() here print(&quot;C.__init__&quot;) print(self.__mro__) c = C() Base.__init__ B.__init__ A.__init__ C.__init__ Python 在 MRO(Class.__mro__) 列表上, 从左到右开始查找基类, 直到找到第一个匹配这个属性的类为止. 而 MRO 列表的构造是通过一个 C3 线性化算法 来实现的. 它实际上就是合并所有父类的 MRO 列表并遵循如下三条准则: ① 子类会先于父类被检查 ② 多个父类会根据他们在列表中的顺序被检查 ③ 如果对下一个类存在两个合法的选择, 选择第一个父类. MRO 列表中的类顺序会让你定义的任意类层级关系变得有意义. 当使用 `super()` 函数时, Python 会在 MRO 列表上继续搜索下一个类. 只要每一个重定义的方法统一使用 `super()` 并只调用它一次, 那么控制流会遍历整个 MRO 列表, 每个方法也只会被调用一次. 这也是为什么在第二个例子中不会出现调用两次 `Base.__init__()` 的原因. `super()` 不一定去查找某个类在 MRO 中下一个直接父类, 因此, 甚至可以在一个没有直接父类的类中使用它. 在子类中扩展定义在父类中的 property 功能 class Person: def __init__(self, name): self.name = name @property def name(self): return self._name @name.setter def name(self, value): if not isinstance(value, str): raise TypeError(&quot;Expected a string&quot;) self._name = value @name.deleter def name(self): raise AttributeError(&quot;Can&apos;t delete attribute&quot;) class SubPerson(Person): &quot;&quot;&quot;继承并扩展了 name 属性 &quot;&quot;&quot; @property def name(self): print(&quot;Getting name&quot;) return super().name @name.setter def name(self, value): print(&quot;setting name to&quot;, value) # 为了委托给之前定义的 seter 方法, # 需要将控制权传递给之前定义的 name 属性的 __set__() 方法. # 但是, 获取这个方法的唯一途径就是使用 类变量 而不是 实例变量 来访问它. super(SubPerson, SubPerson).name.__set__(self, value) @name.deleter def name(self): print(&quot;Deleting name&quot;) super(SubPerson, SubPerson).name.__delete__(self) class SubPerson2(Person): # 只扩展 property 的 getter 方法 @Person.name.getter def name(self): print(&quot;Getting name in SubPerson2&quot;) return super().name # 只扩展 property 的 setter 方法 @Person.name.setter def name(self, value): print(&quot;Setting name to %s in SubPerson2&quot; % value) super(SubPerson2, SubPerson2).name.__set__(self, value) 在子类中扩展一个 property 可能会引出许多不易察觉的问题, 因为一个 property 其实是 getter, setter, deleter 方法的集合, 而不是单个方法. 因此, 在扩展一个 property 的时候, 需要先确定你是否要重新定义所有的方法, 还是说只修其中的一个. 用于扩展一个描述器 # A descriptoy class String: def __init__(self, name): self.name = name def __get__(self, instance, cls): if instance is None: return self return instance.__dict__[self.name] def __set__(self, instance, value): if not isinstance(value, str): raise TypeError(&quot;Expected a string&quot;) instance.__dict__[self.name] = value # A class with a descriptor class Person: name = String(&quot;name&quot;) def __init__(self, name): self.name = name # Extending a descriptor with a property class SUbPerson(Person): @property def name(self): print(&quot;Getting name&quot;) return super().name @name.setter def name(self, value): print(&quot;Setting name to&quot;, value) super(SUbPerson, SubPerson).name.__set__(self, value) @name.deleter def name(self): print(&quot;Deleting name&quot;) super(SubPerson, SubPerson).name.__delete__(self) 创建新的类或实例属性: 描述器 一个描述器就是一个实现了三个核心的属性访问操作(get, set, delete)的类, 分别为 __get__(), __set__(), __delete__() 这三个特殊的方法. 这些方法接受一个实例作为输入, 之后相应的操作实例底层的字典. 为了使用一个描述器, 需将这个描述器的实例作为类属性放到一个类的定义中. 当使用一个描述器之后, 所有对描述器属性的访问都会被 __get__(), __set__(), __delete__() 方法捕获到. 作为输入, 描述器的每一个方法会接受一个操作实例. 为了实现请求操作, 会相应的操作实例底层的字典(dict 属性). class Integer: def __init__(self, name): self.name = name def __get__(self, instance, cls): &quot;&quot;&quot; __get__ 方法比较复杂的原因归结于 实例变量和类变量的不同, 如果一个描述器被当做一个类变量来访问, 那么 instance 参数被设置成 None. 这种情况下, 标准做法就是简单返回这个描述器本身即可. &quot;&quot;&quot; print(&quot;__get__&quot;) if instance is None: return self else: return instance.__dict__[self.name] def __set__(self, instance, value): print(&quot;__set__&quot;) if not isinstance(value, int): raise TypeError(&quot;Expected an int&quot;) instance.__dict__[self.name] = value def __delete__(self, instance): print(&quot;__delete__&quot;) del instance.__dict__[self.name] class Point: x = Integer(&apos;x&apos;) y = Integer(&apos;y&apos;) def __init__(self, x, y): self.x = x self.y = y p = Point(2, 3) print(p.x) # Calls Point.x.__get__(p, Point) print(p.y) # Calls Point.y.__get__(p, Point) p.x = 123 # Calls Point.x.__set__(p, 123) p.y = 456 # Calls Point.x.__set__(p, 456) print(p.x) print(p.y) 描述器可实现大部分 Python 类特性中的底层魔法, 包括 `@classmethod`, `@staticmethod`, `@property`, 甚至是 `__slots__` 特性, 他也是很多高级库和框架中的重要工具之一. 描述器只能在类级别被定义, 而不能为每个实例单独定义. 如果只是想简单的自定义某个类的单个属性访问的话, 无需使用描述器, 使用 property 技术更加容易和简单. 描述器通常是那些使用到 装饰器或者元类的大型框架中的一个组件. 同时他们的使用也被隐藏在后面. # Descriptor for a type-checked attribute class Typed: def __init__(self, name, expected_type): self.name = name self.expected_type = expected_type def __get__(self, instance, cls): if instance is None: return self else: return instance.__dict__[self.name] def __set__(self, instance, value): if not isinstance(value, self.expected_type): raise TypeError(&quot;Expected &quot; + self.expected_type) instance.__dict__[self.name] = value def __delete__(self, instance): del instance.__dict__[self.name] # Class decorator that applies it to selected attributes def typeassert(**kwargs): def decorate(cls): for name, expected_type in kwargs.items(): # Attach a Typed descriptor to the class setattr(cls, name, Typed(name, expected_type)) return cls return decorate # Example use @typeassert(name=str, shares=int, price=float) class Stock: def __init__(self, name, shares, price): self.name = name self.shares = shares self.price = price 使用延迟计算属性: 使用一个描述器类. 构建延迟计算属性的主要目的是为了提升性能.他通过以非常高效的方式使用描述器的一个精妙特性来达到这种效果. 当一个描述器被放入一个类的定义时, 每次访问属性时他的 __get__(), __set__(), __delete__() 方法就会被触发. 不过, 如果一个描述器只定义了一个 __get__() 方法的话, 他比通常的具有更弱的绑定. 特别的, 只有在当被访问属性不在实例底层的字典中时 __get__() 方法才会被触发. lazyproperty 类利用了这一点, 使用 __get__() 方法在实例中存储计算出来的值, 这个实例使用相同的名字作为他的 property. 这样一来, 结果值被存储在实力字典中, 并且以后就不需要再去计算这个 property 了. class lazyproperty: def __init__(self, func): self.func = func def __get__(self, instance, cls): if instance is None: return self else: value = self.func(instance) setattr(instance, self.func.__name__, value) return value # def __set__(self, instance, value): # pass import math class Circle: def __init__(self, radius): self.radius = radius @lazyproperty def area(self): print(&quot;Computing area&quot;) return math.pi * self.radius**2 @lazyproperty def perimeter(self): print(&quot;Computing perimeter&quot;) return 2 * math.pi * self.radius c = Circle(4.0) print(vars(c)) print(c.radius) print(vars(c)) print(c.area) print(vars(c)) print(c.perimeter) print(c.perimeter) print(c.perimeter) print(c.perimeter) print(c.perimeter) print(vars(c)) # 输出 {&apos;radius&apos;: 4.0} 4.0 {&apos;radius&apos;: 4.0} Computing area 50.26548245743669 {&apos;radius&apos;: 4.0, &apos;area&apos;: 50.26548245743669} Computing perimeter 25.132741228718345 25.132741228718345 25.132741228718345 25.132741228718345 25.132741228718345 {&apos;radius&apos;: 4.0, &apos;area&apos;: 50.26548245743669, &apos;perimeter&apos;: 25.132741228718345} 但是, 这种方案有种小缺陷就是: 值被创建出来后时可以被修改的. 如下是一个不是非常高效的修改方案: def lazyproperty(func): name = &quot;__lazy__&quot; + func.__name__ @property def lazy(self): if hasattr(self, name): return getattr(self, name) else: value = func(self) setattr(self, name, value) return value return lazy 简化数据结构的初始化: 很多仅仅作为数据结构的类, 不想写太多 __init__() 函数. 可以在一个基类中写一个公用的 __init__() 函数. # 支持位置参数 class Structure1: # class variable that specifies expected fields _fields = [] def __init__(self, *args): if len(args) != len(self._fields): raise TypeError(&quot;Expected {} arguments&quot;.format(len(self._fields))) # set the arguments for name, value in zip(self._fields, args): setattr(self, name, value) class Stock(Structure1): _fields = [&quot;name&quot;, &quot;shares&quot;, &quot;price&quot;] # 支持位置参数和关键字参数, 可以将关键字参数设置为实例属性. class Structure2: _fields = [] def __init__(self, *args, **kwargs): if len(args) &gt; len(self._fields): raise TypeError(&quot;Expected {} arguments&quot;.format(len(self._fields))) # Set all of the positional arguments for name, value in zip(self._fields, args): setattr(self, name, value) # Set the remaining keyword arguments for name in self._fields[len(args):]: setattr(self, name, kwargs.pop(name)) # check for any remaining unknown arguments if kwargs: raise TypeError(&quot;Invalid arguments(s): {}&quot;.format(&apos;,&apos;.join(kwargs))) class Stock(Structure2): _fields = [&quot;name&quot;, &quot;shares&quot;, &quot;price&quot;] s1 = Stock(&quot;ACME&quot;, 50, 91.1) s2 = Stock(&quot;ACME&quot;, 50, price=91.1) s3 = Stock(&quot;ACME&quot;, shares=50, price=91.1) s4 = Stock(&quot;ACME&quot;, shares=50, price=91.1, aa=1) # Error # 将不在 _fields 中的名称加入到属性中. class Structure3: # Class variable that specifies expected fields _fields = [] def __init__(self, *args, **kwargs): if len(args) != len(self._fields): raise TypeError(&quot;Expected {} arguments&quot;.format(len(self._fields))) # Set the arguments for name, value in zip(self._fields, args): setattr(self, name, value) # Set the additional arguments (if any) extra_args = kwargs.keys() - self._fields for name in extra_args: setattr(self, name, kwargs.pop[name]) if kwargs: raise TypeError(&quot;Duplicate values for {}&quot;.format(&quot;,&quot;.join(kwargs))) class Stock(Structure3): _fields = [&quot;name&quot;, &quot;shares&quot;, &quot;price&quot;] s1 = Stock(&quot;ACME&quot;, 50, 91.1) s2 = Stock(&quot;ACME&quot;, 50, 91.1, date=&quot;8/2/2012&quot;) 定义接口或抽象基类, 并通过执行类型检查来确保子类实现了某些特定的方法: abc 模块 抽象类的一个特点是他不能直接被实例化. 使用 abc 模块可以轻松定义抽象基类. 抽象类的目的就是让别的类继承并实现特定的抽象方法. class Stock(IStream): def read(self, maxbytes=-1): pass def write(self, data): pass 抽象基类的一个主要用途是在代码中检查某些类是否为特定类型, 实现了特定的接口. def serialize(obj, stream): if not isinstance(stream, IStream): raise TypeError(&quot;Ex[ected an IStream&quot;) pass 通过注册的方式实现的抽象基类: import io # Register the built-in I/O classes as supporting our interface IStream.register(io.IOBase) # Open a normal ifle and type check f= open(&quot;foo.txt&quot;) print(isinstance(f, IStream)) # True @abstractmethod 还能注解静态方法, 类方法 和 property, 只需保证这个注解紧靠在函数定义前即可. class A(metaclass=ABCMeta): @property @abstractmethod def name(self): pass @name.setter @abstractmethod def name(self, value): pass @classmethod @abstractmethod def method1(cls): pass @staticmethod @abstractmethod def method2(): pass 标准库中有很多用到抽象基类的地方. - `collections` 模块定义了很多跟容器和迭代器(序列, 映射, 集合等)有关的抽象基类. - `numbers` 库定义了跟数字对象(整数, 浮点数, 有理数等)有关的基类. - `io` 库定义了很多跟 I/O 操作相关的基类. 可以使用预定义的抽象类来执行更通用的类型检查. import collections # Check if x is a Sequence if isinstance(x, collections.Sequence): pass # Check if x is a iterable if isinstance(x, collections.Iterable): pass # Check if x has a size if isinstance(x, collections.Sized): pass # Check if x is a mapping if isinstance(x, collections.Mapping): pass 尽管 ABCs 可以很方便的进行类型检查, 但是在代码中不要过多的使用它. 因为 Python 本质是一门动态编程语言, 其目的是提供更多的灵活性, 强制类型检查会使代码变得更加复杂. 实现数据模型的类型约束 希望定义某些在属性赋值上面有限制的数据结构.所以, 要自定义属性赋值函数, 这种情况下最好使用描述器. # Base class. Usea a descriptor to set a value. class Descriptor: def __init__(self, name=None, **opts): self.name = name for name, value in opts.items(): setattr(self, name, value) def __set__(self, instance, value): instance.__dict__[self.name] = value # Descriptor for enforcing types: class Typed(Descriptor): expected_type = type(None) def __set__(self, instance, value): if not isinstance(value, self.expected_type): raise TypeError(&quot;Expected &quot; + str(self.expected_type)) super().__set__(instance, value) # Descriptor for enforcing types class Unsigned(Descriptor): def __set__(self, instance, value): if value &lt; 0: raise ValueError(&quot;Expected &gt;= 0&quot;) super().__set__(instance, value) class MaxSized(Descriptor): def __init__(self, name=None, **opts): if &quot;size&quot; not in opts: raise TypeError(&quot;Missing size option&quot;) super().__init__(name, **opts) def __set__(self, instance, value): if len(value) &gt;= self.size: raise ValueError(&quot;Size must be &lt;&quot; + str(self.size)) super().__set__(instance, value) # 实际定义的各种不同数据类型. class Integer(Typed): expected_type = int class UnsignedInteger(Integer, Unsigned): pass class Float(Typed): expected_type = float class UnsignedFloat(Float, Unsigned): pass class String(Typed): expected_type = str class SizedString(String, MaxSized): pass # 使用以上类型约束, 定义类 class Stock: # Specify constraints name = SizedString(&quot;name&quot;, size=8) shares = UnsignedInteger(&quot;shares&quot;) price = UnsignedFloat(&quot;price&quot;) def __init__(self, name, shares, price): self.name = name self.shares = shares self.price = price 使用**类装饰器**实现的类型约束检查 # Class decorator to apply constraints def check_attribute(**kwargs): def decorate(cls): for key, value in kwargs.items(): if isinstance(value, Descriptor): value.name = key setattr(cls, key, value) else: setattr(cls, key, value(key)) return cls return decorate # Example @check_attributes(name=SizedString, shares=UnsignedInteger, price=UnsignedFloat) class Stock: def __init__(self, name, shares, price): self.name = name self.shares = shares self.price = price 使用**元类**实现的类型约束检查 # A Metaclass that applies checking class CheckedMeta(type): def __new__(cls, clsname, bases, methods): # Attach attribute names to the descriptors for key, value in methods.items(): if isinstance(value, Descriptor): value.name = key return type.__new__(cls, clsname, bases, methods) # Example class Stock(metaclass=CheckedMeta): name = SizedString(size=8) shares = UnsignedInteger() price = UnsignedFloat() def __init__(self, name, shares, price): self.name = name self.shares = shares self.price = price 使用**装饰器**实现的类型约束: 效果与上面的一样, 但执行速度更快. # Base class. Uses a descriptor to set a value class Descriptor: def __init__(self, name=None, **opts): self.name = name for key, value in opts.items(): setattr(self, key, value) def __set__(self, instance, value): instance.__dict__[self.name] = value # Decorator for applying type checking def Typed(expected_type, cls=None): if cls is None: return lambda cls: Typed(expected_type, cls) super_set = cls.__set__ def __set__(self, instance, value): if not isinstance(value, expected_type): raise TypeError(&quot;Expected &quot; + str(expected_type)) super_set(self, instance, value) cls.__set__ = __set__ return cls # Decorator for unsigned values def Unsigned(cls): super_set = cls.__set__ def __set__(self, instance, value): if value &lt; 0: raise ValueError(&quot;Expected &gt;= 0&quot;) super_set(self, instance, value) cls.__set__ = __set__ return cls # Decorator for allowing sized values def MaxSized(cls): super_init = cls.__init__ def __init__(self, name=None, **opts): if &quot;size&quot; not in opts: raise TypeError(&quot;Missing size option&quot;) super_init(self, name, **opts) cls.__init__ = __init__ super_set = cls.__set__ def __set__(self, instance, value): if len(value) &gt;= self.size: raise ValueError(&quot;Size must be &lt;&quot; + str(self.size)) super_set(self, instance, value) cls.__set__ = __set__ return cls # Specialized decriptors @Typed(int) class Integer(Descriptor): pass @Unsigned class UnsignedInteger(Integer): pass @Typed(float) class Float(Descriptor): pass @Unsigned class UnsignedFloat(Float): pass @Typed(str) class String(Descriptor): pass @MaxSized class SizedString(String): pass class Stock: # Specify constraints name = SizedString(&apos;name&apos;, size=8) shares = UnsignedInteger(&apos;shares&apos;) price = UnsignedFloat(&apos;price&apos;) def __init__(self, name, shares, price): self.name = name self.shares = shares self.price = price 实现自定义容器 collections 定义了很多抽象基类, 当需要自定义容器类的时候, 他们会非常有用. 但是, 有时候需要实现 collections 抽象基类中的所有抽象方法. # 继承自 Sequence 抽象类, 并且实现元素按照顺序存储. import collections import bisect class SortedItems(collections.Sequence): def __init__(self, initial=None): self._items = sorted(initial) if initial is not None else [] # Required sequence methods def __getitem__(self, index): return self._items[index] # Required sequence methods def __len__(self): return len(self._items) # method for adding an item in the right location # bisect 是在一个排序列表中插入元素的高效方法, 可以保证元素插入后还保持顺序. def add(self, item): bisect.insort(self._items, item) items = SortedItems([5, 3, 1]) print(list(items)) # [1, 3, 5] print(items[0], items[-1]) # 1 5 items.add(2) print(list(items)) # [1, 2, 3, 5] # 自定义容器会满足大部分类型检查需要 print(isinstance(items, collections.Iterable)) # True print(isinstance(items, collections.Sequence)) # True print(isinstance(items, collections.Container)) # True print(isinstance(items, collections.Sized)) # True print(isinstance(items, collections.Mapping)) # False 使用 collections 中的抽象基类可以确保自定义的容器实现了所有必要的方法. 并且还能简化类型检查. collections 中的很多抽象类会为一些常见容器操作提供默认实现, 这样一来, 只需实现最感兴趣的方法即可. class Items(collections.MutableSequence): def __init__(self, initial=None): self._items = list(initial) if initial is not None else [] def __getitem__(self, index): print(&quot;Getting: &quot;, index) return self._items[index] def __setitem__(self, index, value): print(&quot;Setting: &quot;, index, value) self._items[index] = value def __delitem__(self, index): print(&quot;Deleting: &quot;, index) del self._items[index] def insert(self, index, value): print(&quot;Inserting: &quot;, index, vlaue) self._items.insert(index, object) def __len__(self): print(&quot;Len&quot;) return len(self._items) numbers 提供了一个类似的跟整数类型相关的抽象类型集合. 属性的代理访问: 将某个实例的属性访问代理到内部另一个实例方法中去, 目的可能是作为继承的一个替代方法或者实现代理模式. 通过自定义属性访问方法, 可以用不同方式自定义代理类行为(如插入日志, 只读访问等) 代理 是一种编程模式, 他将某个操作转移到另外一个对象来实现. __getatt__ 实际是一个后备方法, 只有在属性不存在的时候才会调用. 因此, 如果代理类实例本身有这个属性的话, 那么, 不会触发这个方法. 另外, __getattr__ 对于大部分以双下划线 __ 开始和结尾的属性并不适用. 另外, __setattr__ __delattr__ 需要额外的魔法来区分代理实例和被代理实例 _obj 属性. 一个通常的约定是只代理那些不以下划线_ 开头的属性(代理类只暴露被代理类的公共属性). class A: def spam(self, x): print(&quot;spam&quot;) def foo(self): print(&quot;foo&quot;) class B2: def __init__(self): self._a = A() def bar(self): print(&quot;bar&quot;) # Expost all of the methods defined on class A # __getattr__ 方法是在访问 attribute 不存在的时候被调用. def __getattr__(self, name): return getattr(self._a, name) b = B2() b.spam(123) # Call B.__getattr__(&quot;spam&quot;) b.bar() # Call B.bar() 一个通用代理模式的示例: # A proxy class that wraps around another object, but exposts its public attributes class Proxy: def __init__(self, obj): self._obj = obj # Delegate attribute lookup to internal obj def __getattr__(self, name): print(&quot;Getattr: &quot;, name) return getattr(self._obj, name) # Delegate attribute assignment def __setattr__(self, name, value): if name.startswith(&quot;_&quot;): super().__setattr__(name, value) else: print(&quot;Setattr: &quot;, name, value) setattr(self._obj, name, value) # Delegate attributes deletion def __delattr__(self, name): if name.startswith(&quot;_&quot;): super().__delattr__(name) else: delattr(self._obj, name) class Spam: def __init__(self, x): self.x = x def bar(self, y): print(&quot;Spam.bar: &quot;, self.x, y) s = Spam(2) p = Proxy(s) print(p.x) p.bar(3) p.x = 36 在类中定义多个构造器: 类方法. 为了实现多个构造器, 需要使用到 类方法. 类方法的一个主要用途就是定义多个构造器, 他接受一个 class 作为第一个参数(cls). import time class Date: def __init__(self, year, month, day): self.year = year self.month = month self.day = day @classmethod def today(cls): t = time.localtime() return cls(t.tm_year, t.tm_mon, t.tm_mday) a = Date(2012, 12, 21) b = Date.today() 绕过 __init__, 使用 __new__ 来创建新的类实例. 使用 __new__ 创建新的类实例 : 在反序列对象或实现某个类方法构造函数时需要绕过 __init__() 方法来创建对象. from time import localtime class Date: def __init__(self, year, month, day): self.year = year self.month = month self.day = day @classmethod def today(cls): d = cls.__new__(cls) t = localtime() d.year = t.tm_year d.month = t.tm_mon d.day = t.tm_mday return d 使用 Mixins 扩展类功能 你有很多有用的方法, 向使用它们类扩展其他类的功能. 但是这些类并没有任何继承的关系. 此时, 应当使用混入类. 如下的混入类使用起来没有任何意义, 事实上, 如果去实例化任何一个类, 除了产生异常外没有任何作用. 他们是用来通过多重继承和其他映射对象混入使用的. class LoggedMappingMixin: &quot;&quot;&quot;Add logging to get/set/delete operations for debugging. &quot;&quot;&quot; __slots__ = () # 混入类都没有实例变量, 因为直接实例化混入类没有任何意义. def __getitem__(self, key): print(&quot;Getting &quot; + str(key)) return super().__getitem__(key) def __setitem__(self, key, value): print(&quot;Setting {} = {!r}&quot;.format(key, value)) return super().__setitem__(key, value) def __delitem__(self, key): print(&quot;Deleting &quot; + str(key)) return super().__delitem__(key) class SetOnceMappingMixin: &quot;&quot;&quot;Only allow a key to be set once. &quot;&quot;&quot; __slots__ = () def __setitem__(self, key, value): if key in self: raise KeyError(str(key) + &quot; already set&quot;) return super().__setitem__(key, value) class StringKeysMappingMixin: &quot;&quot;&quot;Restrict keys to strings only &quot;&quot;&quot; __slots__ = () def __setitem__(self, key, value): if not isinstance(key, str): raise TypeError(&quot;Key must be a string&quot;) return super().__setitem__(key, value) class LoggedDict(LoggedMappingMixin, dict): pass d = LoggedDict() d[&quot;x&quot;] = 23 print(d[&quot;x&quot;]) del d[&quot;x&quot;] from collections import defaultdict class SetOnceDefaultDict(SetOnceMappingMixin, defaultdict): pass sd = SetOnceDefaultDict(list) sd[&quot;x&quot;].append(2) sd[&quot;x&quot;].append(3) sd[&quot;x&quot;] = 23 # KeyError: x already set. 混入类在标准库中很多地方都出现过, 通常都是用来扩展某些类的功能. 他们也是多继承的一个主要用途. 例如, 编写网络代码时, 通常会使用 `socketserver` 模块中的 `ThreadingMixIn` 来给其他网络相关类增加多线程支持. from xmlrpc.server import SimpleXMLRPCServer from socketserver import ThreadingMixIn class ThreadedXMLRPCServer(ThreadingMixIn, SimpleXMLRPCServer): pass 混入类注意事项: 1. 混入类不能直接被实例化使用 2. 混入类没有自己的状态信息, 即 没有定义 `__init__()` 方法, 并且没有实例属性. **类装饰器实现的混入类**: def LoggedMapping(cls): cls_getitem = cls.__getitem__ cls_setitem = cls.__setitem__ cls_delitem = cls.__delitem__ def __getitem__(self, key): print(&quot;Getting &quot; + str(key)) return cls_getitem(self, key) def __setitem__(self, key, value): print(&quot;Setting {} = {!r}&quot;.format(key, value)) return cls_setitem(self, key, value) def __delitem__(self, key): print(&quot;Deleteing &quot; + str(key)) return cls_delitem(self, key) cls.__getitem__ = __getitem__ cls.__setitem__ = __setitem__ cls.__delitem__ = __delitem__ return cls @LoggedMapping class LoggedDict(dict): pass 实现状态对象或状态机: 状态模式 有很多程序中, 有些对象会根据状态的不同来执行不同的操作. 使用状态模式, 为每个状态定义一个对象(类), 代码如下: class Connection1: def __init__(self): self.new_state(ClosedConnectionState) def new_state(self, newstate): self._state = newstate # Delegate to the state class def read(self): return self._state.read(self) def write(self, data): return self._state.write(self, data) def open(self): return self._state.open(self) def close(self): return self._state.close(self) # Connection state base class class ConnectionState: @staticmethod def read(conn): raise NotImplementedError() @staticmethod def write(conn, data): raise NotImplementedError() @staticmethod def open(conn): raise NotImplementedError() @staticmethod def close(conn): raise NotImplementedError() # Implementation of different states class ClosedConnectionState(ConnectionState): @staticmethod def read(conn): raise RuntimeError(&quot;Not Open&quot;) @staticmethod def write(conn, data): raise RuntimeError(&quot;Not Open&quot;) @staticmethod def open(conn): conn.new_state(OpenConnectionState) @staticmethod def close(conn): raise RuntimeError(&quot;Already closed&quot;) class OpenConnectionState(ConnectionState): @staticmethod def read(conn): print(&quot;reading&quot;) @staticmethod def write(conn, data): print(&quot;Writing&quot;) @staticmethod def open(conn): raise RuntimeError(&quot;Already Open&quot;) @staticmethod def close(conn): conn.new_state(ClosedConnectionState) # Example to use c = Connection1() print(c._state) # &lt;class &apos;__main__.ClosedConnectionState&apos;&gt; c.read() # Error: Not Open c.open() print(c._state) # &lt;class &apos;__main__.OpenConnectionState&apos;&gt; c.read() # reading c.close() print(c._state) # &lt;class &apos;__main__.ClosedConnectionState&apos;&gt; 这里看上去有点奇怪, 每个状态对象都只有静态方法, 并没有存储任何的实例属性数据. 实际上, 所有状态信息都只存在 Connection1 实例中. 在基类中定义的 NotImplementedError 只是确保子类实现了相应的方法, 这离也可以使用抽象基类的方式实现. 通过字符串调用对象方法 调用一个方法实际上是两部独立操作, 第一步是查找属性, 第二步是函数调用. 因为, 为了调用某个方法, 可以先通过 getattr() 来查找这个属性, 然后再去以函数方式调用它即可. operator.methodcaller() 创建一个可调用对象, 并同时提供所有必要参数, 然后调用的时候只需要将实例对象传递给他即可. 使用 getattr() import math class Point: def __init__(self, x, y): self.x = x self.y = y def __repr__(self): return &quot;Point({!r},{!r})&quot;.format(self.x, self.y) def distance(self, x, y): return math.hypot(self.x - x, self.y - y) p = Point(2, 3) d = getattr(p, &quot;distance&quot;)(0, 0) # Calls p.distance(0, 0) 使用 operator.methodcaller() import operator operator.methodcaller(&quot;distance&quot;, 0, 0)(p) 当需要通过相同的参数多次调用某个方法时, 使用 operator.methodcaller 就很方便. points = [ Point(1, 2), Point(3, 0), Point(10, -3), Point(-5, -7), Point(-1, 8), Point(3, 2) ] # Sort by distance from origin (0, 0) points.sort(key=operator.methodcaller(&quot;distance&quot;, 0, 0)) 实现访问者模式 当需要处理由大量不同类型的对象组成的复杂数据结构, 每一个对象都需要进行不同的处理. 此时, 可以使用访问者模式来编码. 使用递归 这种方式实现的访问者模式的一个缺点就是他严重依赖递归, 如果数据结构嵌套层次太深, 可能会有问题, 有时会超过 Python 的递归深度限制(sys.getrecursionlimit()) class Node: pass class UnaryOperator(Node): def __init__(self, operand): self.operand = operand class BinaryOperator(Node): def __init__(self, left, right): self.left = left self.right = right class Add(BinaryOperator): pass class Sub(BinaryOperator): pass class Mul(BinaryOperator): pass class Div(BinaryOperator): pass class Negate(UnaryOperator): pass class Number(Node): def __init__(self, value): self.value = value # 1 + 2 * (3 - 4) / 5 t1 = Sub(Number(3), Number(4)) t2 = Mul(Number(2), t1) t3 = Div(t2, Number(5)) t4 = Add(Number(1), t3) # print(t1, t2, t3, t4) print(&quot;-&quot; * 30) class NodeVisitor: def visit(self, node): methname = &quot;visit_&quot; + type(node).__name__ meth = getattr(self, methname, None) if meth is None: meth = self.generic_visit return meth(node) def generic_visit(self, node): raise RuntimeError(&quot;No {} method&quot;.format(&quot;visit_&quot; + type(node).__name__)) class Evaluator(NodeVisitor): def visit_Number(self, node): return node.value def visit_Add(self, node): return self.visit(node.left) + self.visit(node.right) def visit_Sub(self, node): return self.visit(node.left) - self.visit(node.right) def visit_Mul(self, node): return self.visit(node.left) * self.visit(node.right) def visit_Div(self, node): return self.visit(node.left) / self.visit(node.right) def visit_Negate(self, node): return -node.operand e = Evaluator() print(e.visit(t4)) # 0.6 print(&quot;-&quot; * 20) class StackCode(NodeVisitor): def generate_code(self, node): self.instructions = [] self.visit(node) return self.instructions def visit_Number(self, node): self.instructions.append((&quot;PUSH&quot;, node.value)) def binop(self, node, instruction): self.visit(node.left) self.visit(node.right) self.instructions.append((instruction)) def visit_Add(self, node): self.binop(node, &quot;ADD&quot;) def visit_Sub(self, node): self.binop(node, &quot;SUB&quot;) def visit_Mul(self, node): self.binop(node, &quot;MUL&quot;) def visit_Div(self, node): self.binop(node, &quot;DIV&quot;) def unaryop(self, node, instruction): self.visit(node.operand) self.instructions.append((instruction, )) def visit_Negate(self, node): self.unaryop(node, &quot;NEG&quot;) s = StackCode() print(s.generate_code(t4)) # [(&apos;PUSH&apos;, 1), (&apos;PUSH&apos;, 2), (&apos;PUSH&apos;, 3), (&apos;PUSH&apos;, 4), (&apos;SUB&apos;,), (&apos;MUL&apos;,), (&apos;PUSH&apos;, 5), (&apos;DIV&apos;,), (&apos;ADD&apos;,)] HTTP 的请求分发控制器 class HTTPHandler: def handle(self, request): methname = &quot;do_&quot; + request.request_method getattr(self, methname)(request) def do_GET(self, request): pass def do_POST(self, request): pass def do_HEAD(slef, request): pass 在跟解析和编译相关的编程中, 使用后访问者模式是非常常见的额. Python 本身的 `ast` 模块值得关注一下. - 使用**生成器或迭代器** 避免递归的一个通常方法是使用一个栈或对垒的数据结构. 例如, 深度优先的遍历算法, 第一次碰到一个节点时, 将其压如栈中, 处理完后弹出栈. `visit()` 方法的核心思路就是这样. 如下展示了生成器和迭代器在程序控制流方面的强大功能. 当程序执行碰到 `yield` 语句时, 生成器会返回一个数据并暂时挂起.即, yield 暂时将程序控制器让出给调用者. import types class Node: pass class UnaryOperator(Node): def __init__(self, operand): self.operand = operand class BinaryOperator(Node): def __init__(self, left, right): self.left = left self.right = right class Add(BinaryOperator): pass class Sub(BinaryOperator): pass class Mul(BinaryOperator): pass class Div(BinaryOperator): pass class Negate(UnaryOperator): pass class Number(Node): def __init__(self, value): self.value = value class NodeVisitor: def visit(self, node): stack = [node] last_result = None while stack: try: last = stack[-1] if isinstance(last, types.GeneratorType): stack.append(last.send(last_result)) last_result = None elif isinstance(last, Node): stack.append(self._visit(stack.pop())) else: last_result = stack.pop() except StopIteration: stack.pop() return last_result def _visit(self, node): methname = &quot;visit_&quot; + type(node).__name__ meth = getattr(self, methname, None) if meth is None: meth = self.generic_visit return meth(node) def generic_visit(self, node): raise RuntimeError(&quot;No {} method&quot;.format(&quot;visit_&quot; + type(node).__name__)) class Evaluator(NodeVisitor): def visit_Number(self, node): return node.value def visit_Add(self, node): yield (yield node.left) + (yield node.right) def visit_Sub(self, node): yield (yield node.left) - (yield node.right) def visit_Mul(self, node): yield (yield node.left) * (yield node.right) def visit_Div(self, node): yield (yield node.left) / (yield node.right) def visit_Negate(self, node): yield - (yield node.operand) if __name__ == &apos;__main__&apos;: t1 = Sub(Number(3), Number(4)) t2 = Mul(Number(2), t1) t3 = Div(t2, Number(5)) t4 = Add(Number(1), t3) e = Evaluator() print(e.visit(t4)) # 0.6 a = Number(0) for n in range(1, 100000): a = Add(a, Number(n)) e = Evaluator() print(e.visit(a)) # 4999950000 循环引用数据结构的内存管理. 当程序创建了很多循环引用数据结构(如树, 图, 观察者模式等), 此时, 即处理内存管理. import weakref class Node: def __init__(self, value): self.value = value self._parent = None self.children = [] def __repr__(self): return &quot;Node({!r:})&quot;.format(self.value) @property def parent(self): return None if self._parent is None else self._parent() @parent.setter def parent(self, node): self._parent = weakref.ref(node) def add_child(self, child): self.children.append(child) child.parent = self # 允许 parent 静默终止. root = Node(&quot;parent&quot;) c1 = Node(&quot;child&quot;) root.add_child(c1) print(c1.parent) # Node(&apos;parent&apos;) del root print(c1.parent) # None 循环引用的数据结构在 Python 中是一个很棘手的问题, 因为正常的垃圾回收机制不能适用于这种情形. 弱引用消除了引用循环的问题, 本质来讲, 弱引用就是一个对象指针, 他不会增加他的引用计数. 可以通过 weakref 来创建弱引用. 为了访问弱引用所引用的对象, 可以像函数一样调用即可. 如果那个对象还存在就返回它, 否则返回 None. 由于原始对象的引用计数没有增加, 那么就可以删除它了. &gt;&gt;&gt; import weakref &gt;&gt;&gt; a = Node() &gt;&gt;&gt; a_ref = weakref.ref(a) &gt;&gt;&gt; a_ref &lt;weakref at 0x100581f70; to &apos;Node&apos; at 0x1005c5410&gt; &gt;&gt;&gt; print(a_ref()) &lt;__main__.Node object at 0x1005c5410&gt; &gt;&gt;&gt; del a Data.__del__ &gt;&gt;&gt; print(a_ref()) None 让类支持比较操作 可以实现一个特殊方法来支持, 如 __ge__() 实现 &gt;= 操作. 但是, 当要实现所有的操作符方法, 就比较麻烦. 装饰器 functools.total_ordering 可用来简化这个处理. 使用它来装饰一个类, 只需定义一个 __eq__() 方法, 外加其他方法(lt, le, gt, ge) 中的一个即可. 然后装饰器会自动填充其他比较方法. from functools import total_ordering class Room: def __init__(self, name, length, width): self.name = name self.length = length self.width = width self.square_feet = self.length * self.width @total_ordering class House: def __init__(self, name, style): self.name = name self.style = style self.rooms = list() @property def living_space_footage(self): return sum(r.square_feet for r in self.rooms) def add_room(self, room): self.rooms.append(room) def __str__(self): return &quot;{}: {} square foot {}&quot;.format(self.name, self.living_space_footage, self.style) def __eq__(self, other): return self.living_space_footage == other.living_space_footage def __lt__(self, other): return self.living_space_footage &lt; other.living_space_footage h1 = House(&quot;h1&quot;, &quot;Cape&quot;) h1.add_room(Room(&apos;Master Bedroom&apos;, 14, 21)) h1.add_room(Room(&apos;Living Room&apos;, 18, 20)) h1.add_room(Room(&apos;Kitchen&apos;, 12, 16)) h1.add_room(Room(&apos;Office&apos;, 12, 12)) h2 = House(&apos;h2&apos;, &apos;Ranch&apos;) h2.add_room(Room(&apos;Master Bedroom&apos;, 14, 21)) h2.add_room(Room(&apos;Living Room&apos;, 18, 20)) h2.add_room(Room(&apos;Kitchen&apos;, 12, 16)) h3 = House(&apos;h3&apos;, &apos;Split&apos;) h3.add_room(Room(&apos;Master Bedroom&apos;, 14, 21)) h3.add_room(Room(&apos;Living Room&apos;, 18, 20)) h3.add_room(Room(&apos;Office&apos;, 12, 16)) h3.add_room(Room(&apos;Kitchen&apos;, 15, 17)) houses = [h1, h2, h3] print(&apos;Is h1 bigger than h2?&apos;, h1 &gt; h2) # prints True print(&apos;Is h2 smaller than h3?&apos;, h2 &lt; h3) # prints True print(&apos;Is h2 greater than or equal to h1?&apos;, h2 &gt;= h1) # Prints False print(&apos;Which one is biggest?&apos;, max(houses)) # Prints &apos;h3: 1101-square-foot Split&apos; print(&apos;Which is smallest?&apos;, min(houses)) # Prints &apos;h2: 846-square-foot Ranch&apos; 实际上, `total_ordering` 就是定义了一个从每个比较支持方法到所有需要定义的其他方法的一个映射而已. 如果定义了 `__le__()` 方法, 那么, 他就被用来构建所有其他的需要定义的那些特殊方法. class House: def __eq__(self, other): pass def __lt__(self, other): pass # methods create by @total_ordering __le__ = lambda self, other: self &lt; other or self == other __gt__ = lambda self, other: not (self &lt; other or self == other) __ge__ = lambda self, other: not (self &lt; other) __ne__ = lambda self, other: not self == other 创建缓存实例 在创建一个类对象时, 如果之前使用同样参数创建过这个对象, 希望返回它的缓存引用. 使用一个和类本身分开的工厂函数 class Spam: def __init__(self, name): self.name = name import weakref _spam_cache = weakref.WeakValueDictionary() # 使用一个和类本身分开的工厂函数 def get_spam(name): if name not in _spam_cache: s = Spam(name) _spam_cache[name] = s else: s = _spam_cache[name] return s a = get_spam(&quot;foo&quot;) b = get_spam(&quot;bar&quot;) print(a is b) # False c = get_spam(&quot;foo&quot;) print(a is c) # True 将缓存代码放到一个单独的管理类中. 然后将这些组件粘合起来. 这种写法为潜在的灵活性提供了更多的支持. import weakref class CacheSpamManager: def __init__(self): self._cache = weakref.WeakValueDictionary() def get_spam(self, name): if name not in self._cache: s = Spam(name) self._cache[name] = s else: s = self._cache[name] return s def clear(self): self._cache.clear() class Spam: manager = CacheSpamManager() def __init__(self, name): self.name = name # Python 3 中的静态方法 def get_spam(name): return Spam.manager.get_spam(name) a = Spam.get_spam(&quot;name&quot;) b = Spam.get_spam(&quot;name&quot;) print(a is b) # True c = Spam(&quot;foo&quot;) d = Spam(&quot;foo&quot;) print(c is d) # False 另一种更加强化的暗示: 不应该直接实例化 Spam 对象, 可以让 `__init__()` 方法抛出一个异常. class CacheSpamManager: def __init__(self): self._cache = weakref.WeakValueDictionary() def get_spam(self, name): if name not in self._cache: s = Spam._new(name) self._cache[name] = s else: s = self._cache[name] return s class Spam: def __init__(self, *args, **kwagrs): raise RuntimeError(&quot;Can&apos;t instantiate directly!&quot;) # Alternate constructor @classmethod def _new(cls, name): self = cls.__new__(cls) self.name = name return self a = CacheSpamManager() m = a.get_spam(&quot;name&quot;) n = a.get_spam(&quot;name&quot;) print(m is n) # True 元编程元编程的主要目的是创建函数和类, 并用他们来操作代码(比如修改, 生成或者包装已有的代码). Python 中基于这个目的的主要特性包括 装饰器, 类装饰器, 以及元类. 还有其他主题, 包括对象签名, 用 exec() 来执行代码 以及 检查函数和类的内部结构. 装饰器 及保存函数元数据 一个简单的装饰器. import time from functools import wraps def timethis(func): &quot;&quot;&quot; Decorator that reports the execution time.&quot;&quot;&quot; @wraps(func) # 用来保存函数的元数据 def wrapper(*args, **kwargs): start = time.time() result = func(*args, **kwargs) end = time.time() print(func.__name__, end - start) return result return wrapper @timethis def countdown(n): while n&gt;0: n -= 1 countdown(10123901) # countdown 1.0877728462219238 countdown(101111) # countdown 0.01100778579711914 保存函数的元数据@wraps(func): @wraps 装饰器的一个重要特性就是他可以通过__wrapped__ 属性来访问被包装的那个函数(原函数). 但是, 并不是所有的装饰器都使用了 @wraps, 如 @staticmethod, @classmethod 创建的描述符对象吧原数函数保存在 __func__ 属性中. 底层的函数签名可以使用 __wrapped__ 属性来传递. import time from functools import wraps def timethis(func): &quot;&quot;&quot; Decorator that reports the execution time.&quot;&quot;&quot; @wraps(func) # 用来保存函数的元数据 def wrapper(*args, **kwargs): start = time.time() result = func(*args, **kwargs) end = time.time() print(func.__name__, end - start) return result return wrapper @timethis def countdown(n:int): &quot;&quot;&quot;DocString for countdown&quot;&quot;&quot; while n&gt;0: n -= 1 countdown(101111) # countdown 0.01100778579711914 print(countdown.__doc__) # DocString for countdown print(countdown.__name__) # countdown print(countdown.__annotations__) # {&apos;n&apos;: &lt;class &apos;int&apos;&gt;} 可接受参数的装饰器 其中的思想很简单: 最外层的 logged() 函数接受所需的参数, 并让他们对装饰器的内层函数可见. 内层的 decorate() 函数接受一个函数并给他加上一个包装层. 关键部分在于: 这个包装层可以使用传递给 logged() 的参数. from functools import wraps import logging def logged(level, name=None, message=None): &quot;&quot;&quot;Add logging to a function. Level is the logging level, name is the logger name, add message is the log message. If name and message aren&apos;t specified, they default to the function&apos;s module and name. &quot;&quot;&quot; def decorate(func): logname = name if name else func.__module__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) return wrapper return decorate # Example use @logged(logging.DEBUG) def add(x, y): return x + y @logged(logging.CRITICAL, message=&quot;Example&quot;) def spam(): print(&quot;Spam!&quot;) 编写一个可接受参数的装饰器是需要技巧的, 因为涉及底层的调用顺序. @decorator(x, y, z) def func(a, b): pass # 可以映射为如下调用 def func(a, b): pass func = decorator(x, y, z)(a, b) # decorator(x, y, z) 必须返回一个可调用对象. 该对象接受一个函数作为参数, 并对其进行包装. 定义一个属性可由用户修改的装饰器 编写一个装饰器来包装函数, 但是可以让用户调整装饰器的属性, 这样在运行时能够控制装饰器的行为. P342 – from functools import wraps, partial import logging # Utility decorator to attach a function as an attribute of obj def attach_wrapper(obj, func=None): if func is None: return partial(attach_wrapper, obj) setattr(obj, func.__name__, func) return func def logged(level, name=None, message=None): &quot;&quot;&quot;Add logging to a function. Level is the logging level, name is the logger name, add message is the log message. If name and message aren&apos;t specified, they default to the function&apos;s module and name. &quot;&quot;&quot; def decorate(func): logname = name if name else func.__module__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) # Attach setter functions @attach_wrapper(wrapper) def set_level(newlevel): nonlocal level level = newlevel @attach_wrapper(wrapper) def set_message(newmsg): nonlocal logmsg logmsg = newmsg return wrapper return decorate # Example use @logged(logging.DEBUG) def add(x, y): return x + y @logged(logging.CRITICAL, message=&quot;Example&quot;) def spam(): print(&quot;Spam!&quot;) logging.basicConfig(level=logging.DEBUG) add(2, 4) # DEBUG:__main__:add add.set_message(&quot;Add called!&quot;) add(2, 4) # DEBUG:__main__:Add called! add.set_level(logging.WARNING) add(2, 4) # WARNING:__main__:Add called! 模块与包__init__.py 文件优先 py 文件被导入.__all__ = [“a”, “b”] : 用来显式列出可导出的符号名. 如果列表为空, 则任何符号都不会导出; 如果 __all__ 中包含有未定义的名称, 那么在执行 import 语句是会产生一个 AttributeError 异常. 重新加载模块: import imp imp.reload(MOD_NAME) # 是适用于 from module import name 这样的语句导入定义. 让目录或 zip 文件称为可运行的脚本 __main__.py : 这与标准库中的包有所不同, 这里只是把代码打包起来方便给其他人执行. # 目录 : $ tree new new/ ├── a.py └── __main__.py $ python new # zip 文件 $ cd new &amp;&amp; zip new.zip * $ python new.zip 获取包中的数据文件 mypkg/ __init__.py somedata.dat spam.py # spam.py import pkgutil data = pkgutil.get_data(__package__, &quot;somedata.dat&quot;) pkgutil.get_data() 函数是一个高级工具, 可以把文件内容以**字节串**形式返回文件原始内容. 其第一个参数为 包名的字符串表示, 也可以使用 __package__ 变量; 第二个参数为 数据文件 相对于包的名称(数据文件必须位于包内). 网络与 web 编程并发编程脚本编程与系统管理测试调试与异常 管理属性 getattr 和 setattr 方法: 把未定义的属性获取和所有的属性赋值, 指定通用的处理器方法 getattribute 方法: 把所有属性获取都执行 Python2.6 的新式类和 Python3.0 的所有类中的一个泛型处理器方法. property 内置函数: 把特性属性访问定位到 get 和 set 处理器函数, 也叫作特性(Property). 特性和描述符有很大关系, 基本上是描述符的一种受限制的形式. 描述符协议, 把特定属性访问定位到具有任意 get 和 set 处理器方法的类的实例. 特性class Person: def __init__(self, name): self._name = name def getName(self): print(&quot;Fetch ...&quot;) return self._name def setName(self, value): print(&quot;Setting ...&quot;) self._name = value def delName(self): print(&quot;remove ing&quot;) del self._name name = property(getName, setName, delName, &quot;Name Property Docs&quot;) 描述符描述符协议允许吧一个特性属性的 get 和 set 操作执行一个单独类对象的方法. 提供了一种方式来插入在访问属性的时候自动运行的代码, 并且允许拦截属性删除并且为属性提供文档. 描述符作为单独的类创建, 并且他们就像方法函数一样分配给类属性. 和任何其他的类属性一样, 他们可以通过子类和实例继承. 通过为描述符自身提供一个 self, 以及提供客户类的实例, 都可以提供访问拦截方法. class Descriptor: &quot;&quot;&quot;Docstring goes here self: 描述符实例 instance: 描述符实例所附加的客户类的实例. 可以是访问的属性所属的实例(用于 instance.attr), 也可以是所访问的属性直接属于类的时候是 None(用于 class.attr ) owner: 指定描述符实例要附加到的类. value: &quot;&quot;&quot; def __get__(self, instance, owner): &quot;&quot;&quot;return attr value &quot;&quot;&quot; pass def __set__(self, instance, value): &quot;&quot;&quot;Return None&quot;&quot;&quot; pass def __delete__(self, instance): &quot;&quot;&quot;Return None&quot;&quot;&quot; pass 如果描述符的任意一个方法空缺, 通常意味着不支持相应类型的访问. 例如, 要设置一个属性是只读的, 必须定义 set 来捕获赋值并引发一个异常. class Descriptor: def __get__(self, instance, owner): print(self, instance, owner, sep=&quot;\n&quot;) return &quot;Bob&quot; class Sub: attr = Descriptor() x = Sub() x.attr &lt;__main__.Descriptor object at 0x03AD4410&gt; &lt;__main__.Sub object at 0x03AD4470&gt; &lt;class &apos;__main__.Sub&apos;&gt; Sub.attr &lt;__main__.Descriptor object at 0x03874410&gt; None &lt;class &apos;__main__.Sub&apos;&gt; 计算属性 class DescSquare: def __init__(self, start): self.value = start def __get__(self, instance, owner): return self.value ** 2 def __set__(self, instance, value): self.value = value class Client: x = DescSquare(3) c = Client() print(c.x) # 9 c.x = 4 print(c.x) # 16 在描述符中使用状态信息: 实例状态 或 描述符状态. 描述符状态用来管理内部用于描述符工作的数据 实例状态记录了和客户类相关的信息, 以及可能由客户类创建的信息. 使用实例状态示例: class InstState: def __get__(self, instance, owner): print(&quot;InstState get&quot;) return instance._Y * 100 def __set__(self, instance, value): print(&quot;InstState Set&quot;) instance._Y = value class CalcAttrs: Y = InstState() def __init__(self): self._Y = 3 self.Z = 4 obj = CalcAttrs() print(obj.Y, obj.Z) # 300 4 obj.Y = 6 obj.Z = 7 print(obj.Y, obj.Z) # 600 4 特性与描述符相关 class Property: def __init__(self, fget=None, fset=None, fdel=None, doc=None): self.fget = fget self.fset= fset self.fdel = fdel self.__doc__ = doc def __get__(self, instance, instancetype=None): if instance is None: return self if self.fget is None: raise AttributeError(&quot;Cann&apos;t get attribute&quot;) return self.fget(instance) def __set__(self, instance, value): if self.fget is None: raise AttributeError(&quot;Can&apos;t set attribute&quot;) self.fset(instance, value) def __delete__(self, isinstance): if self.fdel is None: raise AttributeError(&quot;Can&apos;t delete attribute&quot;) self.fdel(instance) getattr 和 getattributegetattr 和 getattribute 操作符重载方法, 提供了拦截类实例的属性获取的另一种方法. 允许插入当访问属性的时候, 自动运行的代码. __getattr__ : 针对未定义的属性运行.即, 属性没有存储在实例上, 或者没有从其父类继承. __getattribute__ : 针对每个属性. 在使用时, 应当避免通过把属性访问传递给超类而导致递归循环. 如果一个类定义或继承了如下方法, 那么当一个实例用于后面的注释所提到的情况时, 他们将自动运行: def __getattr__(self, name) # On undefined attribude fetch [obj.name] def __getattribute__(self, name) # On all attribude fetch [obj.name] def __setattr__(self, name) # On all attribude assignment [obj.name = value] def __delattr__(self, name) # On all attribude deletion [del obj.name] 实例: class Catcher: def __getattr__(self, name): print(&quot;Get:&quot;, name) def __setattr__(self, name, value): print(&quot;Set: &quot;, name, value) x = Catcher() x.job # Get: job x.pay # Get: pay x.pay = 100 # Set: pay 100 x.pay # Get: pay 避免循环: 由于 getattr 仅针对未定义的属性调用, 所以他可以在自己的代码中自由的获取其他属性. 然而, 由于 getattribute 和 setattr 针对所有属性, 因此, 他们的代码中要注意在访问其他属性的时候, 避免再次调用自己并触发一次递归循环. getattribute : 把获取指向更高的超类 # WRONG: 死循环 def __getattribute__(self, name): x = self.other # 把获取指向更高的超类 def __getattribute__(self, name): x = object.__getattribute__(self, &quot;other&quot;) setattr : 把属性作为实例 dict 命名空间字典中一个键赋值 # 死循环 def __setattr__(self, name, value): self.name = value # 把属性作为实例的 __dict__ 命名空间字典的一个键赋值 def __setattr__(self, name, value): self.__dict__[name] = value 示例: 在 __init__ 构造函数中的属性赋值也会触发 __setattr__ class Person: def __init__(self, name): self._name = name def __getattr__(self, attr): if attr == &quot;name&quot;: print(&quot;Fetch ...&quot;) return self._name else: raise AttributeError(attr) # __getattr__ 替换为 __getattribute__ 实现 # def __getattribute__(self, attr): # if attr == &quot;name&quot;: # print(&quot;Fetch ...&quot;) # attr = &quot;_name&quot; # return object.__getattribute__(self, attr) def __setattr__(self, attr, value): if attr == &quot;name&quot;: print(&quot;Set ...&quot;) attr = &quot;_name&quot; self.__dict__[attr] = value def __delattr__(self, attr): if attr == &quot;name&quot;: print(&quot;Remove ...&quot;) attr = &quot;_name&quot; del self.__dict__[attr] bob = Person(&quot;Bob Smith&quot;) print(bob.name) bob.name = &quot;Robert Smith&quot; print(bob.name) del bob.name getattr 和 getattribute 区别: getattr 仅拦截未定义属性; getattribute 拦截所有属性. # __getattr__ class GetAttr: attr1 = 1 def __init__(self): self.attr2 =2 def __getattr__(self, attr): print(&quot;Get:&quot; + attr) return 3 obj = GetAttr() print(obj.attr1) # 1 print(obj.attr2) # 2 print(obj.attr3) # Get: attr3\n3 # __getattribute__ class GetAttribute: attr1 = 1 def __init__(self): self.attr2 =2 def __getattribute__(self, attr): print(&quot;Get:&quot; + attr) if attr == &quot;attr3&quot;: return 3 else: return object.__getattribute__(self, attr) obj = GetAttribute() print(obj.attr1) # Get:attr1\n1 print(obj.attr2) # Get:attr2\n1 print(obj.attr3) # Get:attr3\n1 拦截内置操作 针对 str, add, getitem 方法的属性获取分别通过打印, +表达式, 索引 隐式调用运行. 在 Python3.0 中, getattr 和 getattribute 都不会针对这样的属性运行. 在 Python2.6 中, 如果属性在类中未定义的话, getattr 会针对这样的属性运行. 在 Python2.6 中, getattribute 只针对新式类可用, 并且在 Python3.0 中可用. 装饰器装饰器本身的形式是处理其他的可调用对象的可调用对象. 装饰器提供一种方法, 在函数和类定义语句的末尾插入自动运行代码. 对于函数装饰器, 在 def 末尾; 对于类装饰器, 在 class 末尾. Python 装饰器以两种相关的形式呈现: 函数装饰器 在函数定义的时候进行名称重绑定, 提供一个逻辑层来管理函数和方法, 或随后对他们的调用. 类装饰器 在类定义的时候, 进程名称重绑定, 提供一个逻辑层来管理类, 或管理随后调用他们所创建的实例. 装饰器用法: 用包装器来拦截对函数和类的调用. 通过返回装饰的对象自身, 而不是包装器, 装饰器编程针对函数和类的一种简单的后创建步骤. 函数装饰器可以用来管理函数对象, 即可以用来管理函数调用和函数对象. 类装饰器可以用来直接管理类对象, 即可以用来管理类实例和类自身. 这种用法与元类有重合, 实际上, 都是在类创建过程的最后运行. 示例代码: def decorator(O): # Save of augment funciton or class O return O @decorator def F(): ... @decorator class C: ... 装饰器基础函数装饰器函数装饰器是一种关于函数的运行时声明, 函数的定义需要遵守此声明. @decorator # 装饰器返回与 F 具有相同数目的参数的一个可调用对象. def F(arg): ... F(99) # 等同于 def F(arg): ... F = decorator(F) F(99) 编写函数装饰器示例 跟踪调用 统计对装饰的函数的调用次数 class tracer: def __init__(self, func): self.calls = 0 self.func = func def __call__(self, *args): self.calls += 1 print(&quot;Call %s to %s&quot; % (self.calls, self.func.__name__)) self.func(*args) @tracer def spam(a, b, c): print(a + b + c) for i in range(10): spam(i , i+1, i+2) print(spam.calls) # 10 print(spam) # &lt;__main__.tracer object at 0x035C4470&gt; 状态信息保持选项 函数装饰器有各种选项来保持装饰的时候所提供的状态信息, 一遍在实际函数调用过程中使用. 他们通常需要支持多个装饰的对象以及多个调用, 但是, 有多重方法来实现这些目标: 实例属性, 全局变量, 非局部变量, 函数属性, 等都可用于保持状态. - 类实例属性 class tracer: def __init__(self, func): self.calls = 0 self.func = func def __call__(self, *args, **kwargs): self.calls += 1 print(&quot;Call %s to %s&quot; % (self.calls, self.func.__name__)) self.func(*args, **kwargs) @tracer def spam(a, b, c): print(a + b + c) @tracer def eggs(x, y): print(x * y) spam(1, 2, 3) # Call 1 to spam \n 6 spam(a=4, b=5, c=6) # Call 2 to spam \n 15 eggs(2, 16) # Call 1 to eggs \n 32 eggs(4, y=16) # Call 2 to eggs \n 64 - 封闭作用域和全局作用域 将计数器溢出到共同的全局作用域意味着计数器将为每个包装的函数所共享. 和类实例属性不同, 全局计数器是跨程序的, 而不是针对每个函数的, 对于任何跟踪的函数的调用, 计数器都会递增. calls = 0 def tracer(func): def wrapper(*args, **kwagrs): global calls calls += 1 print(&quot;Call %s to %s&quot; % (calls, func.__name__)) return func(*args, **kwagrs) return wrapper @tracer def spam(a, b, c): print(a + b + c) @tracer def eggs(x, y): print(x * y) spam(1, 2, 3) # Call 1 to spam \n 6 spam(a=4, b=5, c=6) # Call 2 to spam \n 15 eggs(2, 16) # Call 3 to eggs \n 32 eggs(4, y=16) # Call 4 to eggs \n 64 - 封闭作用域和 nonlocal nonlocal 语序修改封闭的函数作用于变量, 所以他可以充当针对每次装饰的, 可修改的数据. def tracer(func): calls = 0 def wrapper(*args, **kwagrs): nonlocal calls calls += 1 print(&quot;Call %s to %s&quot; % (calls, func.__name__)) return func(*args, **kwagrs) return wrapper @tracer def spam(a, b, c): print(a + b + c) @tracer def eggs(x, y): print(x * y) spam(1, 2, 3) # Call 1 to spam \n 6 spam(a=4, b=5, c=6) # Call 2 to spam \n 15 eggs(2, 16) # Call 1 to eggs \n 32 eggs(4, y=16) # Call 2 to eggs \n 64 由于封装的作用域变量不能跨程序而成为全局的, 所以每个包装的函数再次有了自己的计数器. - 函数属性. 函数属性可以实现与 nonlocal 一样的功能: 每个被装饰的函数有自己的计数器. 这种方法有效是因为名称 wrapper 保持在封闭的 tracer 函数的作用域中. 当我们随后增加 wrapper.calls 时, 并不是在修改 wrapper 本身, 因此不需要 nonlocal 声明. 同时, 函数属性允许我们从装饰器代码的外部访问保存的状态, 因此, 它具有更广泛的可见性. def tracer(func): def wrapper(*args, **kwargs): wrapper.calls += 1 print(&quot;Call %s to %s&quot; % (wrapper.calls, func.__name__)) return func(*args, **kwargs) wrapper.calls = 0 return wrapper 装饰类方法 使用基于类的装饰器装饰类的时候失败了(如下), 其根本原因在于 tracer 类的 call 方法的 self , 它必须是 tracer 对象, 以提供对 tracer 的状态信息的访问. 但是, 当我们用 call 把装饰方法名重绑定到一个类实例对象的时候, Python 指向 self 传递了 tracer 实例, 根本没有在参数列表中传递 Person 主体. 此外, 由于 tracer 不知道我们要用方法调用处理的 Person 实例的任何信息, 没有办法创建一个带有一个实例的绑定的方法, 因此, 没有办法正确的分配调用. class tracer: def __init__(self, func): self.calls = 0 self.func = func def __call__(self, *args, **kwargs): self.calls += 1 print(&quot;Call %s to %s&quot; % (self.calls, self.func.__name__)) return self.func(*args, **kwargs) @tracer def spam(a, b, c): print(a+b+c) spam(1, 2, 3) spam(a=1, b=2, c=4) class Person: def __init__(self, name, pay): self.name = name self.pay = pay @tracer def giveRaise(self, percent): self.pay *= (1.0 + percent) @tracer def lastName(self): return self.name.split()[-1] bob = Person(&quot;Bob Smith&quot;, 500) bob.giveRaise(0.25) # 失败, TypeError: giveRaise() missing 1 required positional argument: &apos;percent&apos; 使用嵌套函数来装饰方法 def tracer(func): calls = 0 def onCall(*args, **kwargs): nonlocal calls calls += 1 print(&quot;Call %s to %s&quot; % (calls, func.__name__)) return func(*args, **kwargs) return onCall @tracer def spam(a, b, c): print(a+b+c) spam(1, 2, 3) spam(a=1, b=2, c=4) class Person: def __init__(self, name, pay): self.name = name self.pay = pay @tracer def giveRaise(self, percent): self.pay *= (1.0 + percent) @tracer def lastName(self): return self.name.split()[-1] bob = Person(&quot;Bob Smith&quot;, 500) bob.giveRaise(0.25) print(bob.pay) print(bob.lastName()) - 使用描述符装饰方法 class tracer: def __init__(self, func): self.calls = 0 self.func = func def __call__(self, *args, **kwargs): self.calls += 1 print(&quot;Call %s to %s&quot; % (self.calls, self.func.__name__)) return self.func(*args, **kwargs) def __get__(self, instance, owner): return wrapper(self, instance) class wrapper: def __init__(self, desc, subj): self.desc = desc self.subj = subj def __call__(self, *args, **kwargs): return self.desc(self.subj, *args, **kwargs) @tracer def spam(a, b, c): print(a+b+c) spam(1, 2, 3) spam(a=1, b=2, c=4) class Person: def __init__(self, name, pay): self.name = name self.pay = pay @tracer def giveRaise(self, percent): self.pay *= (1.0 + percent) @tracer def lastName(self): return self.name.split()[-1] bob = Person(&quot;Bob Smith&quot;, 500) bob.giveRaise(0.25) print(bob.pay) print(bob.lastName()) # 也可以使用如下实现嵌套函数和封闭作用域: class tracer: def __init__(self, func): self.calls = 0 self.func = func def __call__(self, *args, **kwargs): self.calls += 1 print(&quot;Call %s to %s&quot; % (self.calls, self.func.__name__)) return self.func(*args, **kwargs) def __get__(self, instance, owner): def wrapper(*args, **kwargs): return self(instance, *args, **kwargs) return wrapper 计时调用 对一个装饰的函数的调用进行及时. import time class timer: def __init__(self, func): self.func = func self.alltime = 0 def __call__(self, *args, **kwargs): start = time.clock() result = self.func(*args, **kwargs) elapsed = time.clock() - start self.alltime += elapsed print(&quot;%s: %.5f, %.5f&quot; % (self.func.__name__, elapsed, self.alltime)) return result @timer def listcomp(N): return [x*2 for x in range(N)] @timer def mapcall(N): # map 在 python3 中是一个迭代器, 所以, 用 list 解包 return list(map((lambda x: x*2), range(N))) for i in [5, 50000, 500000, 1000000]: listcomp(i) mapcall(i) print(&quot;-&quot; * 20) 添加装饰器参数 : 让装饰器可配置. 以下代码把最初的 Timer类 嵌入了一个封闭的函数中, 以便创建一个作用域以保持装饰器参数. 外围的 timer 函数在装饰发生前调用, 并且它只是返回 Timer类 作为实际的装饰器. 在装饰时, 创建了一个 Timer类的实例来记录装饰函数自身, 而且访问了位于封闭函数作用于中的装饰器参数. import time def timer(label=&quot;&quot;, trace=True): class Timer: def __init__(self, func): self.func = func self.alltime = 0 def __call__(self, *args, **kwargs): start = time.clock() result = self.func(*args, **kwargs) elapsed = time.clock() - start self.alltime += elapsed if trace: format = &quot;%s %s: %.5f, %.5f&quot; values = (label, self.func.__name__, elapsed, self.alltime) print(format % values) return result return Timer @timer(label=&quot;[CCC]==&gt;&quot;) def listcomp(N): return [x*2 for x in range(N)] @timer(label=&quot;[MMM]==&gt;&quot;, trace=False) def mapcall(N): return list(map((lambda x: x*2), range(N))) for i in [5, 50000, 500000, 1000000]: listcomp(i) mapcall(i) print(&quot;-&quot; * 20) 类装饰器Python 2.6 和 Python 3 扩展了装饰器, 使其也能在类上有效.类装饰器是管理类的一种方式, 或者用管理或扩展类所创建的实例的额外逻辑来包装实例构建调用. 类装饰器的结果是当随后创建一个实例的时候才运行. @decorator class C: ... x = C(99) # 等同于 class C: ... C = decorator(C) x = C(99) 示例: 插入一个对象来拦截一个类实例的未定义的属性. 装饰器把类的名称调用重新绑定到另一个类, 这个类在一个封闭的作用域中保持了最初的类, 并且当调用它的时候, 创建并嵌入了最初的类的一个实例. 当随后从该实例获取一个属性的时候, 包装器的 __getattr__ 拦截了他, 并且将其委托给最初的类的嵌入的实例. 此外, 每个被装饰的类都创建一个新的作用域, 他记住了最初的类. def decorator(cls): class Wrapper: def __init__(self, *args): self.wrapped = cls(*args) def __getattr__(self, name): return getattr(self.wrapped, name) return Wrapper @decorator class C: def __init__(self, x, y): self.attr = &quot;spam&quot; x = C(6, 7) print(x.attr) # spam 单体类: 管理类的所有实例由于类装饰器可以拦截实例创建调用, 所以他们可以用来管理一个类的所有实例, 或者扩展这些实例的接口. 管理一个类的所有实例: 使用全局属性 instances = {} def getInstance(aClass, *args): if aClass not in instances: instances[aClass] = aClass(*args) return instances[aClass] def singleton(aClass): &quot;&quot;&quot; 使用全局表&quot;&quot;&quot; def onCall(*args): return getInstance(aClass, *args) return onCall 使用封闭作用域 def singleton(aClass): &quot;&quot;&quot;不依赖于装饰器之外的全局作用域中的名称. 只用于 python3 .&quot;&quot;&quot; instance = None def onCall(*args): nonlocal instance if instance == None: instance = aClass(*args) return instance return onCall 使用类 class singleton: &quot;&quot;&quot; 对每个类使用一个实例. &quot;&quot;&quot; def __init__(self, aClass): self.aClass = aClass self.instance = None def __call__(self, *args): if self.instance == None: self.instance = self.aClass(*args) return self.instance 调用装饰器结果 @singleton class Person: def __init__(self, name, hours, rate): self.name = name self.hours = hours self.rate = rate def pay(self): return self.hours * self.rate @singleton class Spam: def __init__(self, val): self.attr = val bob = Person(&quot;bob&quot;, 40, 10) print(bob.name, bob.pay()) # bob 400 sue = Person(&quot;Sue&quot;, 50, 20) print(sue.name, sue.pay()) # bob 400 x = Spam(42) y = Spam(99) print(x.attr, y.attr) # 42 42 跟踪对象接口:类装饰器的另一个场景是每个产生实例的接口. 类装饰器基本上可以在实例上安装一个包装器逻辑层, 来以某种方式管理对其接口的访问. __getattr__ 运算符重载方法作为包装嵌入的实例的整个对象接口的一种方法, 以便实现委托编码模式. class Wrapper: &quot;&quot;&quot; __getattr__ 拦截一个控制器类中的方法调用 &quot;&quot;&quot; def __init__(self, obj): self.wrapped = obj def __getattr__(self, attrname): print(&quot;Trace:&quot;, attrname) return getattr(self.wrapped, attrname) x = Wrapper([1,2,3]) x.append(4) # Trace: append print(x.wrapped) # [1, 2, 3, 4] 拦截实例创建调用, 下面的类装饰器可以实现跟踪整个对象接口. def Tracer(aClass): class Wrapper: def __init__(self, *args, **kwargs): self.fetches = 0 self.wrapped = aClass(*args, **kwargs) def __getattr__(self, attrname): print(&quot;Trace: &quot; + attrname) self.fetches += 1 return getattr(self.wrapped, attrname) return Wrapper @Tracer class Spam: def display(self): print(&quot;Spam!&quot; * 8) @Tracer class Person: def __init__(self, name, hours, rate): self.name = name self.hours = hours self.rate = rate def pay(self): return self.hours * self.rate food = Spam() food.display() print([food.fetches]) bob = Person(&quot;bob&quot;, 40, 50) print(bob.name) print(bob.pay()) sue = Person(&quot;Sue&quot;, rate=100, hours=60) print(sue.name) print(sue.pay()) print(bob.name) print(bob.pay()) print([bob.fetches, sue.fetches]) 手动示例, 这中装饰器方法允许我们把实例创建移动到装饰器自身之中, 而不是要求传入一个预先生成的对象, 即他允许我们保留常规的实例创建语法并且通常实现装饰器的所有有限. 我们只需要用装饰器语法来扩展类, 而不是要求所有的实例创建调用都通过一个包装器来手动的指向对象. def Tracer(aClass): class Wrapper: def __init__(self, *args, **kwargs): self.fetches = 0 self.wrapped = aClass(*args, **kwargs) def __getattr__(self, attrname): print(&quot;Trace: &quot; + attrname) self.fetches += 1 return getattr(self.wrapped, attrname) return Wrapper @Tracer class MyList(list): pass l = MyList([1,2,3]) l.append(4) # Trace: append print(l.wrapped) # [1, 2, 3, 4] WrapList = Tracer(list) x = WrapList([4,5,6]) x.append(7) # Trace: append print(x.wrapped) # [4, 5, 6, 7] 类错误之二: 保护多个实例如下示例, 可能看上去类似上面的实例, 但他对于一个给定多个实例并不是很有效: 每个实例创建都会触发 __call__, 这会覆盖前面的实例. 直接效果是 Tracer 只保留了一个实例, 即最后创建的一个实例. 我们为每个类装饰器创建了一个装饰器实例, 但是不是针对每个类实例 –&gt; 解决方法: 放弃基于类的装饰器. class Tracer: def __init__(self, aClass): self.aClass = aClass def __call__(self, *args): self.wrapped = self.aClass(*args) return self def __getattr__(self, attrname): print(&quot;Trace: &quot;, attrname) return getattr(self.wrapped, attrname) @Tracer class Person: def __init__(self, name): self.name = name bob = Person(&quot;bob&quot;) print(bob.name) # Trace: name\bbob sue = Person(&quot;sue&quot;) print(sue.name) # Trace: name\bsue print(bob.name) # Trace: name\bsue, 只保留最后一个实例. 装饰器嵌套@spam @eggs class C: pass X = C() # 等同于 class C: pass C = spam(eggs(C)) X = C() 示例: def d1(F): print(&quot;d1&quot;) return lambda: &quot;X&quot; + F() def d2(F): print(&quot;d2&quot;) return lambda: &quot;Y&quot; + F() def d3(F): print(&quot;d3&quot;) return lambda: &quot;Z&quot; + F() @d1 @d2 @d3 def func(): return &quot;Spam&quot; print(func()) # XYZSpam 装饰器参数装饰器参数在装饰发生之前就解析了, 并且他们通常用来保持状态信息供随后的调用使用. 装饰器参数往往意味着可调用对象的 3 个层级: 接受装饰器参数的一个可调用对象, 他返回一个可调用对象以作为装饰器, 该装饰器返回一个可调用对象来处理对最初的函数或类调用. 这三个层级的每一个都可能是一个函数或类, 并且可能一作用域或类属性的形式保存了状态. @decorator(A, B) def F(arg): ... F(99) # 等同于 def F(arg): ... F = decorator(A, B)(F) F(99) # 装饰器函数 def decorator(A, B): # Save or use A, B def actualDecorator(F: # Save or use function F # return a callable : nested def, class with __call__ , etc. return callable return actualDecorator 装饰器直接管理函数和类装饰器通过装饰器代码来运行新的函数和类, 从而有效的工作, 他们也可以用来管理函数和类对象自身. registry = {} def register(obj): registry[obj.__name__] = obj return obj @register def spam(x): return(x**2) @register def ham(x): return(x**3) @register class Eggs: def __init__(self, x): self.data = x**4 def __str__(self): return str(self.data) print(&quot;-&quot; * 30) for name in registry: print(name, &quot;=&gt;&quot;, registry[name], type(registry[name])) print(spam(2)) print(ham(2)) x = Eggs(2) print(x) for name in registry: print(name, &quot;=&gt;&quot;, registry[name](2)) 例如, 一个用户界面可能使用这样的技术, 为用户动作注册回调处理程序, 处理程序可能通过函数或类名来注册. 或者使用装饰器参数来指定主体事件; 包含装饰器的一条额外的 def 语句可能会用来保持这样的参数以便在装饰时使用. 如下装饰器把函数属性分配给记录信息, 以便随后供一个 API 使用, 但他没有插入一个包含器层来拦截随后的调用. def decorate(func): func.marked = True return func @decorate def spam(a, b): return a + b print(spam.marked) # True def annotate(text): def decorate(func): func.label = text return func return decorate @annotate(&quot;spam data&quot;) def spam(a, b): return a+b print(spam.label, &quot; | &quot; , spam(1,2), &quot; | &quot; , spam.label) # spam data | 3 | spam data 装饰器利弊:潜在缺陷: 类型修改: 当插入包装器的时候, 一个装饰器函数或类不会保持其最初的类型, 其名称重新绑定到一个包装器对象, 在使用对象名称或测试对象类型的程序中, 这可能很重要. 在单体的例子中, 装饰器和管理函数的方法都为实例保持了最初的类类型; 在跟踪器的代码中, 没有一种方法这么做, 因为需要有包装器. 额外调用: 通过装饰添加一个包装层, 在每次调用装饰对象的时候, 会引发一次额外调用所需的额外性能成本(调用相对消耗时间的操作), 因此装饰包装器可能会使程序变慢. 在跟踪器代码中, 两种方法都需要每个属性通过一个包装器层来指向; 单体的示例通过保持最初的类类型而避免了额外调用. 类似的问题也适用于函数装饰器: 装饰和管理器函数都会导致额外调用, 并且当装饰的时候通常会发生类型变化(不装饰的时候就没有). 优点: 明确的语法 装饰器使得扩展明确而显然, 即容易识别. 此外, 装饰器允许函数和示例创建调用使用所有 Python 程序员所熟悉的常规语法. 代码可维护性 装饰器避免了在每个函数或类调用中重复扩展代码. 一致性 装饰器案例装饰器实现的私有属性, 使用委托, 即在一个对象中嵌入一个对象, 这种模式使得区分主题对象的内部访问和外部访问容易多了, 对主体对象的来自外部的属性访问, 由包装器层的重载方法拦截, 如果合法则委托给类; 类自身内部的访问则没有拦截且允许不经检查而运行. 如下的类装饰器接受任意多个参数, 以命名私有属性. &quot;&quot;&quot; Privacy for attributest fetched from class instances. See self-test code at end of file for a usage example. Decorator same as : Doubles = Private(&quot;date&quot;, &quot;size&quot;)(Doubler). Private returns onDecorator , onDecorator returns on Instance, and each onInstance instance embeds a Doubler instance. &quot;&quot;&quot; traceMe = False def trace(*args): if traceMe: print(&quot;[&quot; + &quot;&quot;.join(map(str, args)) + &quot;]&quot;) def private(*privates): def onDecorator(aClass): class onInstance: def __init__(self, *args, **kwargs): self.wrapped = aClass(*args, **kwargs) def __getattr__(self, attr): trace(&quot;get: &quot;, attr) if attr in privates: raise TypeError(&quot;private attribute fetch: &quot; + attr) else: return getattr(self.wrapped, attr) def __setattr__(self, attr, value): trace(&quot;set: &quot;, attr, &apos; | &apos;, value) if attr == &quot;wrapped&quot;: self.__dict__[attr] = value elif attr in privates: raise TypeError(&quot;private attribute change: &quot; + attr) else: setattr(self.wrapped, attr, value) return onInstance return onDecorator if __name__ == &quot;__main__&quot;: traceMe = True @private(&quot;data&quot;, &quot;size&quot;) class Doubler: def __init__(self, label, start): self.label = label self.data = start def size(self): return len(self.data) def double(self): for i in range(self.size()): self.data[i] = self.data[i] * 2 def display(self): print(&quot;%s =&gt; %s&quot; % (self.label, self.data)) x = Doubler(&quot;X is&quot;, [1, 2, 3]) y = Doubler(&quot;y is&quot;, [-10, -20, -30]) print(&quot;-&quot; * 40) print(x.label) x.display() x.double() x.display() print(&quot;-&quot; * 40) print(y.label) y.display() y.double() y.display() y.label = &quot;Spam&quot; y.display() 泛化的私有属性及公开属性控制 &quot;&quot;&quot; Class decorator with Private and Public attribute declarations. Controls accesss to attributes stored on an instance, or inherited by it from its classes. Private declares all the names that can. Caveat: this works in 3.0 for normally named attributes only: __X__ operator overloading methods implicitly run for built-in operations do not trigger either __getattr__ or __getattribute__ in new-style classes. And __X__ methods here to intercept and delegate built-ins. &quot;&quot;&quot; traceME = False def trace(*args): if traceME: print(&quot;[&quot; + &quot; &quot;.join(map(str, args)) + &quot;]&quot;) def accessControl(failIf): def onDecorator(aClass): class onInstance: def __init__(self, *args, **kwargs): self.__wrapped = aClass(*args, **kwargs) def __getattr__(self, attr): trace(&quot;Get: &quot;, attr) if failIf(attr): raise TypeError(&quot;private attribute fetch: &quot; + attr) else: return getattr(self.__wrapped, attr) def __setattr__(self, attr, value): trace(&quot;Set: &quot;, attr) if attr == &quot;_onInstance__wrapped&quot;: self.__dict__[attr] = value elif failIf(attr): raise TypeError(&quot;private attribute change: &quot; + attr) else: setattr(self.__wrapped, attr, value) return onInstance return onDecorator def private(*attribute): return accessControl(failIf=(lambda attr: attr in attribute)) def public(*attribute): return accessControl(failIf=(lambda attr: attr not in attribute)) @private(&apos;age&apos;) class Person: &quot;&quot;&quot; private(&quot;age&quot;)(Person) accesssControl(failIf(lambda attr: attr in attribute))(Person) &quot;&quot;&quot; def __init__(self, name, age): self.name = name self.age = age x = Person(&quot;bob&quot;, 12) print(x.name) x.name = &quot;sue&quot; print(x.name) # print(x.age) # 出错 @public(&quot;name&quot;) class PersonB: def __init__(self, name, age): self.name = name self.age = age y = PersonB(&quot;bob&quot;, 23) print(y.name) y.name = &quot;Sue&quot; print(y.name) # print(y.age) # 出错 # y.age = 34 # 出错 验证函数参数: 该函数装饰器自动测试传递给一个函数或方法的参数是否在有效的数值范围内. def rangetest(*argchecks): def onDecorator(func): if not __debug__: &quot;&quot;&quot; __debug__ 是内置变量, Python 将其设置为 True, 除非他将以 -0 优化命令行标识运行. 如 python -0 main.py . &quot;&quot;&quot; return func else: def onCall(*args): for (ix, low, high) in argchecks: if args[ix] &lt; low or args[ix] &gt; high: errmsg = &quot;Argument %s not in %s..%s&quot; % (args[ix], low, high) raise TypeError(errmsg) return func(*args) return onCall return onDecorator @rangetest((1, 0 , 120)) def persinfo(name, age): print(&quot;%s is %s years old&quot; % (name, age)) @rangetest([0, 1, 12], [1, 1, 31], [2, 0, 2009]) def birthday(M, D, Y): print(&quot;birthday = {0}/{1}/{2}&quot;.format(M, D, Y)) class Person: def __init__(self, name, job, pay): self.job = job self.pay = pay @rangetest([1, 0.0, 1.0]) def giveRaise(self, percent): self.pay = int(self.pay * (1+percent)) persinfo(&quot;Bob Smith&quot;, 45) birthday(5, 31, 1963) sue = Person(&quot;Sue Jones&quot;, &quot;dev&quot;, 100) sue.giveRaise(0.1) print(sue.pay) 针对关键字和默认泛化 &quot;&quot;&quot; function decorator that performs range-test validation for passed arguments. Arguments are specified by keyword to the decorator. In the actual call, arguments may be passed by position or keyword, and defaults may be omitted. &quot;&quot;&quot; trace = True def rangetest(**argchecks): def onDecorator(func): if not __debug__: return func else: import sys code = func.__code__ allargs = code.co_varnames[:code.co_argcount] funcname = func.__name__ def onCall(*pargs, **kwargs): # All pargs match first N expected args by position # The rest must be in kargs or be omitted defaults positionals = list(allargs) positionals = positionals[:len(pargs)] for (argname, (low, high)) in argchecks.items(): # For all args to be checked if argname in kwargs: # Was passed by name if kwargs[argname] &lt; low or kwargs[argname] &gt; high: errmsg = &quot;{0} argument &apos;{1}&apos; not in {2} .. {3}&quot;.format( funcname, argname, low, high ) elif argname in positionals: # Was passed by position position = positionals.index(argname) if pargs[position] &lt; low or pargs[position] &gt; high: errmsg = &quot;{0} argument &apos;{1}&apos; not in {2} .. {3}&quot;.format( funcname, argname, low, high ) raise TypeError(errmsg) else: # Assume not passed: default if trace: print(&quot;Argument &apos;{0}&apos; defaulted&quot;.format(argname)) return func(*pargs, **kwargs) # OK: run original call return onCall return onDecorator 装饰器的代码依赖于内省 API 和 对参数传递的细微限制 def func(a, b, c, d): x = 1 y =2 code = func.__code__ print(code, type(code)) # &lt;code object func at 0x03237700, file &quot;D:\VBoxShare\Work\Documents\PyProject\PyCookbook\test2.py&quot;, line 3&gt; &lt;class &apos;code&apos;&gt; print(code.co_nlocals) # 6 print(code.co_argcount) # 4 print(code.co_varnames) # (&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;x&apos;, &apos;y&apos;) print(code.co_varnames[:code.co_argcount]) # (&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;) import sys print(sys.version_info) # sys.version_info(major=3, minor=6, micro=2, releaselevel=&apos;final&apos;, serial=0) code = func.__code__ if sys.version_info[0] == 3 else func.func_code 元类 :元类只是扩展了装饰器的代码插入模式. 元类允许我们拦截并扩展类创建, 他提供了一个 API 以插入在一条 class 语句结束时运行的额外逻辑, 尽管是以与装饰器不同的方式. 同样, 他提供了一种通用的协议来管理程序中的类对象. 元类允许我们获得更高层级的控制, 来控制一组类如何工作. 通过声明一个元类, 告诉解释器, 把类对象的创建路由到指定的类. 另一方面, 元类为各种没有它而难以实现或不可能实现的编码模式打开了大门. 允许我们以广泛的方式控制 Python 的行为, 并与 Python 的内部与工具构建有更多关系的编程方法/工具, 这些工具为我们提供了在各种环境中插入逻辑的方法–在运算符计算时, 属性访问时, 函数调用时, 类实例创建时, 类对象创建时: 内省属性 像 __class__ 和 __dict__ 这样的特殊属性允许我们查看 Python 对象的内部实现方式, 以便更广泛的处理他们. 运算符重载 像 __str__ 和 __add__ 这样的特殊命名方法, 在类中编写来拦截并提供应用于类实例的内置操作行为. 他们自动运行作为内置操作的响应, 并且允许类符合期望的接口. 属性拦截方法 一类特殊的运算符重载方法提供了一种方法在实例上广泛的拦截属性访问: getattr, setattr, getattribute 允许包装的类插入自动运行的代码, 这些代码可以验证属性请求并且将他们委托给嵌入的对象. 他们允许一个对象的任意数目的属性–要么是选取的属性, 要么是所有的属性–在访问的时候计算. 类特性 内置函数 property 允许吧代码和特殊的类属性关联起来, 当获取/赋值/删除该属性的时候自动运行代码. 特性考虑到了访问特定属性时候的自动代码调用. 类属性描述符 特性只是定义根据访问自动运行函数的属性描述的一种简介的方式. 描述符允许我们在单独的类中编写 get, set, delete 处理程序的方法, 当分配给该类的一个实例的属性被访问的时候自动运行他们. 他们提供了一种通用的方式, 来插入当访问一个特定的属性时自动运行的代码, 并且在一个属性的常规查找之后触发他们. 函数和类装饰器 装饰器允许我们添加当调用一个函数或创建一个类实例的时候自动运行的逻辑. 装饰器语法插入名称重新绑定逻辑, 在函数或类定义语句的末尾自动运行该逻辑–装饰的函数和类名重新绑定到拦截了随后调用的可调用对象. 元类 元类允许在一条 class 语句的末尾, 插入当创建一个类对象的时候自动运行的逻辑. 这个逻辑不会吧类名重新绑定到一个装饰器可调用对象, 而是把类自身的创建指向特定的逻辑. 元类模型 类是类型的实例 python 3 : 用户定义的类对象是名为 type 的对象的实例, type 本身是一个类. 在 Python 3 中, 类型的概念与类的概念合并了, 实际上, 这两者基本上时同义词: 类是类型, 类型也是类: 类型有派生自 type 的类定义 用户定义的类是类型类的实例 用户定义的类是产生他们自己的实例的类型. python 2.6 : 新式类继承自 object, 他是 type 的一个子集; 传统类是 type 的一个实例, 并且并不创建自一个类. 元类是 type 的子类 在 Python3 及 Python2.6 的新式类中: type 是产生用户定义的类的一个类 元类是 type 类的一个子类 类对象是 type 类的一个实例, 或一个子类 实例对象产生自一个类. 为了控制创建类以及扩展其行为的方式, 所需要做的只是指定一个用户定义和的类川谷关键字一个用户定义的元类, 而不是常规的 type 类. Class 语句协议 class 语句的工作原理: 当 Python 遇到一条 class 语句, 他会运行其嵌套的代码块以创建其属性, 所有在嵌套的代码块的顶层分配的名称都产生结果的类对象中的属性. 这些名称通常是嵌套的 def 所创建的方法函数. 但是, 他们也可以是分配来创建有所有实例共享的类数据的任意属性. 从技术上讲, Python 遵从一个标准的协议来使这发生: 在一条 class 语句的末尾, 并且在运行了一个命名空间词典中的所有嵌套代码之后, 他调用 type 对象发来创建 class 对象. class = type(class_name, super_classes, attribute_dict) type 对象反过来定义了一个 call 运算符重载方法, 当调用 type 对象的时候, 该方法运行两个其他的方法: type.__new__(type_class, class_name, super_classes, attribute_dict) type.__init__(class, class_name, super_classes, attribute_dict) new 方法创建并返回了新的 class 对象, 并且随后 init 方法初始化了新创建的对象. 这是 type 元类子类通常用来定制类的钩子. 示例: 如下所示类定义: class Spam(eggs): data = 1 def meth(self, arg): pass python 将从内部运行嵌套的代码块来创建该类的两个属性(data 和 meth) 在 class 语句的末尾调用 type 对象, 产生 class 对象: Spam=type(&quot;Spam&quot;, (Eggs,), {&quot;data&quot;: 1, &quot;meth&quot;: meth, &apos;__module__&apos;: &quot;__main__&quot;}) 由于这个类在 class 语句的末尾运行, 他是用来扩展和处理的一个类的理想的钩子. 技巧在于, 用将要拦截这个调用的一个订制子类来替代类型. 声明与编写元类1. 声明元类 Python 3.0 中: 在类标题中吧想要的元类作为一个关键字参数列出来. class Spam(Eggs, metaclass=Meta): # 3.0 and later pass 继承的超类要在元类之前. Python 2.6 中: 使用一个类属性而不是一个关键字参数. – 需要继承自 object. class Spam(object): __metaclass__ = Meta 当以这些方式声明的时候, 创建类对象的调用在 class 语句的底部运行, 修改为调用元类而不是默认的 type. class = Meta(class_name, super_classes, attribute_dict) 由于元类是 type 的一个子类, 所有 type 类的 call 把创建和初始化新的类对象的调用委托给元类, 如果他定义了这些方法的订制版本: Meta.__new__(Meta, class_name, super_classes, attribute_dict) Meta.__init__(class, class_name, super_classes, attribute_dict) 示例: class Spam(Eggs, metaclass=Meta): data = 1 def meth(self, arg): pass # 在这条语句的末尾, Python 内部运行如下的代码来创建 class 对象. Spam = Meta(&quot;Spam&quot;, (Eggs,), {&quot;data&quot;: 1, &quot;meth&quot;: meth, &quot;__module&quot;: &quot;__main__&quot;}) # 如果元类定义了 __new__ 或 __init__ 的自己版本, 在此处的调用期间, 他们将依次由继承的 type 类的 __call__ 方法调用, 以创建并初始化新类. 2. 编写元类. 基本元类 如下的实例中, 是一个最简单的元类, 他是只带有一个 new 方法的 type 的子类, 该方法通过运行 type 的默认版本创建类对象. 他通常执行所需的任何订制并且调用 type 的 超类的 new 方法来创建并运行新的类对象: class MetaOne(type): def __new__(meta, classname, supers, classdict): print(&quot;In MetaOne.new&quot;, classname, supers, classdict, sep=&quot;\n...&quot;) return type.__new__(meta, classname, supers, classdict) class Eggs: pass print(&quot;making class&quot;) class Spam(Eggs, metaclass=MetaOne): data = 1 def meth(self, arg): pass print(&quot;Making instance&quot;) X = Spam() print(&quot;data&quot;, X.data) # 输出 # making class # In MetaOne.new # ...Spam # ...(&lt;class &apos;__main__.Eggs&apos;&gt;,) # ...{&apos;__module__&apos;: &apos;__main__&apos;, &apos;__qualname__&apos;: &apos;Spam&apos;, &apos;data&apos;: 1, &apos;meth&apos;: &lt;function Spam.meth at 0x03B18738&gt;} # Making instance # data 1 订制构建和初始化 元类也可以介入 init 协议, 有 type 对象的 call 调用: 通常, new 创建并返回了类对象, init 初始化了以及创建的类. 类初始化方法在类构建方法之后运行, 但是, 两者都在 class 语句最后运行, 并且在创建任何实例之前运行. 元类也可以用作在创建时管理类的钩子: class MetaOne(type): def __new__(meta, classname, supers, classdict): print(&quot;In MetaOne.new&quot;, classname, supers, classdict, sep=&quot;\n...&quot;) return type.__new__(meta, classname, supers, classdict) def __init__(Class, classname, supers, classdict): print(&quot;In MetaOne init:&quot;, classname, supers, classdict, sep=&quot;\n...&quot;) print(&quot;... init class object:&quot;, list(Class.__dict__.keys())) class Eggs: pass print(&quot;making class&quot;) class Spam(Eggs, metaclass=MetaOne): data = 1 def meth(self, arg): pass print(&quot;Making instance&quot;) X = Spam() print(&quot;data&quot;, X.data) # 输出 # making class # In MetaOne.new # ...Spam # ...(&lt;class &apos;__main__.Eggs&apos;&gt;,) # ...{&apos;__module__&apos;: &apos;__main__&apos;, &apos;__qualname__&apos;: &apos;Spam&apos;, &apos;data&apos;: 1, &apos;meth&apos;: &lt;function Spam.meth at 0x02C58738&gt;} # In MetaOne init: # ...Spam # ...(&lt;class &apos;__main__.Eggs&apos;&gt;,) # ...{&apos;__module__&apos;: &apos;__main__&apos;, &apos;__qualname__&apos;: &apos;Spam&apos;, &apos;data&apos;: 1, &apos;meth&apos;: &lt;function Spam.meth at 0x02C58738&gt;} # ... init class object: [&apos;__module__&apos;, &apos;data&apos;, &apos;meth&apos;, &apos;__doc__&apos;] # Making instance # data 1 其他元类编写技巧 使用简单的工厂函数 例如, 元类根本不是真的需要类. 正如我们所学的, class 语句发布了一条简单的调用, 在其处理的最后创建了一个类. 因此, 实际上任何可调用对象都可以用作一个元类, 只要他接受传递的参数并且返回与目标类兼容的一个对象. 实际上, 一个简单的对象工厂函数, 就像一个类一样工作: def MetaFunc(classname, supers, classdict): print(&quot;In MetaFunc&quot;, classname, supers, classdict, sep=&quot;\n...&quot;) return type(classname, supers, classdict) class Eggs: pass print(&quot;making class&quot;) class Spam(Eggs, metaclass=MetaFunc): data = 1 def meth(self, arg): pass print(&quot;Making instance&quot;) X = Spam() print(&quot;data&quot;, X.data) # 输出 # making class # In MetaFunc # ...Spam # ...(&lt;class &apos;__main__.Eggs&apos;&gt;,) # ...{&apos;__module__&apos;: &apos;__main__&apos;, &apos;__qualname__&apos;: &apos;Spam&apos;, &apos;data&apos;: 1, &apos;meth&apos;: &lt;function Spam.meth at 0x038486F0&gt;} # Making instance # data 1 运行时, 在 class 语句的末尾调用 MetaFunc 函数, 并且他返回期待的新的类对象. 函数直接捕获 type 对象的 __call__ 通常会默认拦截的调用. - 用元类重载类创建调用 由于他设计常规的 OOP 机制, 所以, 对于元类来说, 也可能直接在一条 class 语句的末尾捕获创建调用, 通过订制的 __call__ , 如下也创建了一个元类的实例 : class SuperMeta(type): def __call__(meta, classname, supers, classdict): print(&quot;In SuperMeta.call&quot;, classname, supers, classdict, sep=&quot;\n...&quot;) return type.__call__(meta, classname, supers, classdict) class SubMeta(type, metaclass=SuperMeta): def __new__(meta, classname, supers, classdict): print(&quot;In SubMeta.new: &quot;, classname, supers, classdict, sep=&quot;\n...&quot;) return type.__new__(meta, classname, supers, classdict) def __init__(Class, classname, supers, classdict): print(&quot;In SubMeta init:&quot;, classname, supers, classdict, sep=&quot;\n...&quot;) print(&quot;... init class object:&quot;, list(Class.__dict__.keys())) class Eggs: pass print(&quot;making class&quot;) class Spam(Eggs, metaclass=SubMeta): data = 1 def meth(self, arg): pass print(&quot;Making instance&quot;) X = Spam() print(&quot;data&quot;, X.data) # 输出 # making class # In SuperMeta.call # ...Spam # ...(&lt;class &apos;__main__.Eggs&apos;&gt;,) # ...{&apos;__module__&apos;: &apos;__main__&apos;, &apos;__qualname__&apos;: &apos;Spam&apos;, &apos;data&apos;: 1, &apos;meth&apos;: &lt;function Spam.meth at 0x02F18780&gt;} # In SubMeta.new: # ...Spam # ...(&lt;class &apos;__main__.Eggs&apos;&gt;,) # ...{&apos;__module__&apos;: &apos;__main__&apos;, &apos;__qualname__&apos;: &apos;Spam&apos;, &apos;data&apos;: 1, &apos;meth&apos;: &lt;function Spam.meth at 0x02F18780&gt;} # In SubMeta init: # ...Spam # ...(&lt;class &apos;__main__.Eggs&apos;&gt;,) # ...{&apos;__module__&apos;: &apos;__main__&apos;, &apos;__qualname__&apos;: &apos;Spam&apos;, &apos;data&apos;: 1, &apos;meth&apos;: &lt;function Spam.meth at 0x02F18780&gt;} # ... init class object: [&apos;__module__&apos;, &apos;data&apos;, &apos;meth&apos;, &apos;__doc__&apos;] # Making instance # data 1 元类名查找规则与我们所习惯的方式有所不同, 如, __call__ 方法在一个对象的类中查找; 对于元类, 这意味着一个元类的元素. - 用常规类重载类创建调用 要使用常规的基于继承的名称查找, 可以用常规类和实例实现相同的效果. 注意下面的示例中, __new__ 和 __init__ 必须有不同的名称, 否则, 当创建 SubMeta 实例的时候, 他们会自动运行, 而不是随后作为一个元类调用: class SuperMeta: def __call__(self, classname, supers, classdict): print(&quot;In SuperMeta.call&quot;, classname, supers, classdict, sep=&quot;\n...&quot;) Class = self.__New__(classname, supers, classdict) self.__Init__(Class, classname, supers, classdict) return Class class SubMeta(SuperMeta): def __New__(self, classname, supers, classdict): print(&quot;In SubMeta.new: &quot;, classname, supers, classdict, sep=&quot;\n...&quot;) return type(classname, supers, classdict) def __Init__(self, Class, classname, supers, classdict): print(&quot;In SubMeta init:&quot;, classname, supers, classdict, sep=&quot;\n...&quot;) print(&quot;... init class object:&quot;, list(Class.__dict__.keys())) class Eggs: pass print(&quot;making class&quot;) class Spam(Eggs, metaclass=SubMeta()): data = 1 def meth(self, arg): pass def __init__(self): self.page = 12 print(&quot;Making instance&quot;) X = Spam() print(&quot;data&quot;, X.data) print(&quot;page&quot;, X.page) # 输出 # making class # In SuperMeta.call # ...Spam # ...(&lt;class &apos;__main__.Eggs&apos;&gt;,) # ...{&apos;__module__&apos;: &apos;__main__&apos;, &apos;__qualname__&apos;: &apos;Spam&apos;, &apos;data&apos;: 1, &apos;meth&apos;: &lt;function Spam.meth at 0x035987C8&gt;, &apos;__init__&apos;: &lt;function Spam.__init__ at 0x03598780&gt;} # In SubMeta.new: # ...Spam # ...(&lt;class &apos;__main__.Eggs&apos;&gt;,) # ...{&apos;__module__&apos;: &apos;__main__&apos;, &apos;__qualname__&apos;: &apos;Spam&apos;, &apos;data&apos;: 1, &apos;meth&apos;: &lt;function Spam.meth at 0x035987C8&gt;, &apos;__init__&apos;: &lt;function Spam.__init__ at 0x03598780&gt;} # In SubMeta init: # ...Spam # ...(&lt;class &apos;__main__.Eggs&apos;&gt;,) # ...{&apos;__module__&apos;: &apos;__main__&apos;, &apos;__qualname__&apos;: &apos;Spam&apos;, &apos;data&apos;: 1, &apos;meth&apos;: &lt;function Spam.meth at 0x035987C8&gt;, &apos;__init__&apos;: &lt;function Spam.__init__ at 0x03598780&gt;} # ... init class object: [&apos;__module__&apos;, &apos;data&apos;, &apos;meth&apos;, &apos;__init__&apos;, &apos;__doc__&apos;] # Making instance # data 1 # page 12 实例与继承的关系. 由于元类以类似于继承超类的方式来定会, 因此, 他们看上去有点容易令人混淆, 一些关键点有助于概括和澄清这一模型: 元类继承自 type 类. 尽管他们有一种特殊的角色元类, 但元类是用 class 语句编写的, 并且遵从 Python 中有用的 OOP 模型. 例如, 就像 type 的子类一样, 他们可以重新定义 type 对象的方法, 需要的时候重载或定制他们. 元类通常重新定义 type 类的 new 和 init , 以定制类常见和初始化, 但是, 如果他们希望直接捕获类末尾的创建调用的话, 他们也可以重新定义 call. 尽管元类不常见, 他们甚至是返回任意对象而不是 type 子类的简单函数. 元类声明由 子类 继承. 在用户定义的类中, metaclass=M 声明由该类的子类继承, 因此, 对于在超类链中继承了这一声明的每个类的构建, 该元类都将运行. 元类属性没有由类实例继承. 元类声明指定了一个实例关系, 他和继承不同. 由于类是元类的实例, 所以, 元类中定义的行为应用于类, 而不是类随后的实例. 实例从他们的类和超类中获取行为, 但是, 不是从任何元类获取行为. 从技术上讲, 实例属性查找通常只是搜索实例及其所有类的 dict 字典; 元类不包含在实例查找中. 为声明最后两点, 示例如下: class MetaOne(type): def __new__(meta, classname, supers, classdict): print(&quot;In MetaOne.new : &quot;, classname) return type.__new__(meta, classname, supers, classdict) def toast(self): print(&quot;toast&quot;) class Super(metaclass=MetaOne): def spam(self): print(&quot;Spam&quot;) class C(Super): def eggs(self): print(&quot;eggs&quot;) X = C() X.eggs() X.spam() X.toast() # 输出 # In MetaOne.new : Super # In MetaOne.new : C # eggs # Spam 3. 元类示例 向一个类添加方法 比较了类扩展和实例包装的基于元类和基于装饰器的实现. 手动扩展类方法: class Client1: def __init__(self, value): self.value = value def spam(self): return self.value * 2 class Client2: value = &quot;ni?&quot; def eggsfunc(obj): return obj.value * 4 def hamfunc(obj, value): return value + &quot;ham&quot; Client1.eggs = eggsfunc Client1.ham = hamfunc Client2.eggs = eggsfunc Client2.ham = hamfunc X = Client1(&quot;Ni&quot;) print(X.spam()) print(X.eggs()) print(X.ham(&quot;bacon&quot;)) Y = Client2() print(Y.eggs()) print(Y.ham(&quot;bacon&quot;)) 通过元类添加类方法 def eggsfunc(obj): return obj.value * 4 def hamfunc(obj, value): return value + &quot;ham&quot; class Extender(type): def __new__(meta, classname, supers, classdict): classdict[&quot;eggs&quot;] = eggsfunc classdict[&quot;ham&quot;] = hamfunc return type.__new__(meta, classname, supers, classdict) class Client1(metaclass=Extender): def __init__(self, value): self.value = value def spam(self): return self.value * 2 class Client2(metaclass=Extender): value = &quot;ni?&quot; X = Client1(&quot;Ni&quot;) print(X.spam()) print(X.eggs()) print(X.ham(&quot;bacon&quot;)) Y = Client2() print(Y.eggs()) print(Y.ham(&quot;bacon&quot;)) 实际上, 元类结构支持更多的动态行为.例如, 主体类可以基于运行时的任意逻辑配置. class Extender(type): def __new__(meta, classname, supers, classdict): if sometest(): classdict[&quot;eggs&quot;] = eggsfunc else: classdict[&quot;eggs&quot;] = eggsfunc2 if someothertest(): classdict[&quot;ham&quot;] = hamfunc else: classdict[&quot;ham&quot;] = lambda *args: &quot;Not supported&quot; return type.__new__(meta, classname, supers, classdict) 基于装饰器的扩展 def eggsfunc(obj): return obj.value * 4 def hamfunc(obj, value): return value + &quot;ham&quot; def Extender(aClass): aClass.eggs = eggsfunc aClass.ham = hamfunc return aClass @Extender class Client1: def __init__(self, value): self.value = value def spam(self): return self.value * 2 @Extender class Client2: value = &quot;ni?&quot; 使用元类来管理实例: 如下示例依赖于两个技巧, 首先, 他必须使用一个简单的函数而不是类, 因为 type 子类必须附加给对象创建协议; 其次, 必须通过手动调用 type 来手动创建主题类, 他需要返回一个实例包装器, 但是元类也负责创建和返回主体类. def Tracer(classname, supers, classdict): aClass = type(classname, supers, classdict) class Wrapper: def __init__(self, *args, **kwargs): self.wrapped = aClass(*args, **kwargs) def __getattr__(self, attrname): print(&quot;Tracer&quot;, attrname) return getattr(self.wrapped, attrname) return Wrapper class Person(metaclass=Tracer): def __init__(self, name, hours, rate): self.name = name self.hours = hours self.rate = rate def pay(self): return self.hours * self.rate bob = Person(&quot;bob&quot;, 40, 50) print(bob.name) print(bob.pay()) 自动装饰所有方法 使用元类追踪: def tracer(func): calls = 0 def onCall(*args, **kwargs): nonlocal calls calls += 1 print(&quot;Call %s to %s&quot; % (calls, func.__name__)) return func(*args, *kwargs) return onCall from types import FunctionType class MetaTrace(type): def __new__(meta, classname, supers, classdict): for attr, attrval in classdict.items(): if type(attrval) is FunctionType: # 在类创建的时候, 元类自动把函数装饰器应用于每个方法. # 并且, 函数装饰器自动拦截方法调用. classdict[attr] = tracer(attrval) return type.__new__(meta, classname, supers, classdict) class Person(metaclass=MetaTrace): def __init__(self, name, pay): self.name = name self.pay = pay def giveRaise(self, percent): self.pay *= (1.0 + percent) def lastName(self): return self.name.split()[-1] bob = Person(&quot;Bob Smith&quot;, 500) sue = Person(&quot;Sue Jones&quot;, 100) print(bob.name, sue.name) sue.giveRaise(0.2) print(sue.pay) print(bob.lastName(), sue.lastName()) # 输出 # Call 1 to __init__ # Call 2 to __init__ # Bob Smith Sue Jones # Call 1 to giveRaise # 120.0 # Call 1 to lastName # Call 2 to lastName # Smith Jones 把任何装饰器应用于方法: 上一个示例的泛化. def tracer(func): calls = 0 def onCall(*args, **kwargs): nonlocal calls calls += 1 print(&quot;Call %s to %s&quot; % (calls, func.__name__)) return func(*args, *kwargs) return onCall from types import FunctionType def decorateAll(decorator): class MetaDecorate(type): def __new__(meta, classname, supers, classdict): for attr, attrval in classdict.items(): if type(attrval) is FunctionType: classdict[attr] = tracer(attrval) return type.__new__(meta, classname, supers, classdict) return MetaDecorate class Person(metaclass=decorateAll(tracer)): def __init__(self, name, pay): self.name = name self.pay = pay def giveRaise(self, percent): self.pay *= (1.0 + percent) def lastName(self): return self.name.split()[-1] bob = Person(&quot;Bob Smith&quot;, 500) sue = Person(&quot;Sue Jones&quot;, 100) print(bob.name, sue.name) sue.giveRaise(0.2) print(sue.pay) print(bob.lastName(), sue.lastName()) # 输出 # Call 1 to __init__ # Call 2 to __init__ # Bob Smith Sue Jones # Call 1 to giveRaise # 120.0 # Call 1 to lastName # Call 2 to lastName # Smith Jones 把任何装饰器应用于方法: 使用类装饰器实现. def tracer(func): calls = 0 def onCall(*args, **kwargs): nonlocal calls calls += 1 print(&quot;Call %s to %s&quot; % (calls, func.__name__)) return func(*args, *kwargs) return onCall from types import FunctionType def decorateAll(decorator): def DecoDecorate(aClass): for attr, attrval in aClass.__dict__.items(): if type(attrval) is FunctionType: setattr(aClass, attr, decorator(attrval)) return aClass return DecoDecorate @decorateAll(tracer) class Person: def __init__(self, name, pay): self.name = name self.pay = pay def giveRaise(self, percent): self.pay *= (1.0 + percent) def lastName(self): return self.name.split()[-1] bob = Person(&quot;Bob Smith&quot;, 500) sue = Person(&quot;Sue Jones&quot;, 100) print(bob.name, sue.name) sue.giveRaise(0.2) print(sue.pay) print(bob.lastName(), sue.lastName()) 装饰器分类 函数装饰器 类装饰器 函数实现的装饰器 类实现的装饰器 call 返回 包装器的装饰器 返回 函数/类 本身的装饰器 contextlibcontextlib 提供了一个装饰器和一些实用工具函数, 用于创建与 with 语句结合使用的上下文管理器. contextmanager(func): 一个装饰器, 根据生成器函数func 创建一个上下文管理器. @contextmanager def foo(args): statements try: yield value except Exception as e: error handling (if any) statements 当语句 with foo(args) as value 出现时, 使用所提供的参数执行生成器函数, 知道到达第一条 yield 语句. yield 的返回值放在变量 value 中. 此时执行 with 语句体. 完成之后, 生成器函数将继续执行. 如果 with 语句体内, 出现任何异常, 生成器函数内会抛出该异常并可以被适当处理. nested(mrg1, mrg2m, ..., mrgN) : 此函数在一个操作中调用多个上下文管理器(mrg1, mrg2 …) 返回一个数组, 其中包含 with 语句的不同返回值. 语句 with nested(m1, m2) as (x, y): statements 与语句 with m1 as x: with m2 as y: statements 含义相同. 注意: 如果内部上下文管理器捕获并禁止了异常, 将不会被外部管理器传送任何异常信息. closing(object) : 创建上下文管理器, 在执行过程中离开 with 语句体时, 自动执行 object.close(). with语句体返回的值与 object 相同. 几个重要的库collection, operator, contextlib, functools, 数据类型, 数据结构list, tuple, dict, setcollection.namedtuple, collection.deque, collection.OrderedDict, collection.Defaultdict Queue.Queue 123456789101112131415161718192021222324252627282930比较 : persons = &#123;&#125;class Person(object): def __init__(self, name): self.name = name def __hash__(self): return hash(self.name)persons[Person(&quot;kehan&quot;)] = 1print(Person(&quot;kehan&quot;) in persons) #False----------------------------------------persons = &#123;&#125;class Person(object): def __init__(self, name): self.name = name def __hash__(self): return hash(self.name) def __eq__(self, r): return True if r.name == self.name else Falsepersons[Person(&quot;kehan&quot;)] = 1print(Person(&quot;kehan&quot;) in persons) #True 推导式 与 函数式1234567891011121314t_columns = filter(lambda x: x.endswith(&quot;_time&quot;), model.FIELDS)t_columns = [f for f in model.FIELDS if f.endswith(&quot;_time&quot;)]# 小于0置为0ages = [-1, 10, 20]sum([age if age &gt;=0 else 0 for age in ages ])sum(age if age &gt;=0 else 0 for age in ages) # 生成器sum(map(lambda age: age if age &gt;=0 else 0, ages)) 算法, 算法复杂度, 基本算法实现(排序)排序123456789101112131415161718192021222324252627peoples = [ &#123;"age": 1, "name": "kehan"&#125;, &#123;"age": 24, "name": "lwy"&#125;, &#123;"age": 25, "name": "skycrab"&#125;,]# age从小到大,sorted(peoples, key=lambda p:p["age"])# 从大到小sorted(peoples, key=operator.itemgetter("age"), reverse=True)operator.attrgetter # 属性operator.itemgetter #元素operator.methodcaller #方法#最大agemax(peoples, key=operator.itemgetter("age"))&#123;'age': 25, 'name': 'skycrab'&#125;min(peoples, key=operator.itemgetter("age"))&#123;'age': 25, 'name': 'skycrab'&#125;# operator模块是一个宝藏a = [1, 2, 3]reduce(operator.imul, a) # 6reduce(lambda x, y: x+y, a) # 6 二分查找前提: 已排序数列12345678910a=[1, 5, 10, 15,20]# bisect.bisect_right(a, x) 返回a中插入x的序号bisect.bisect_right(a, 11)Out[11]: 3bisect.insort_right(a,11)In [13]: aOut[13]: [1, 5, 10, 11, 15, 20] 堆排序 : 解决 TOP N 问题1234567# heapq是最小堆a=[1]heapq.heappush(a, 10) # a=[1, 10]heapq.heappop(a) #弹出1heapq.nlargest(2, peoples, key=operator.itemgetter(&quot;age&quot;))[&#123;&apos;age&apos;: 25, &apos;name&apos;: &apos;skycrab&apos;&#125;, &#123;&apos;age&apos;: 24, &apos;name&apos;: &apos;lwy&apos;&#125;] 反射(自省) getattr, setattr, hasattr, dir __dict__, __slots__ : 有 __slots__, 无 __dict__ callable, isinstance : class FunCall(object): def __call__(self, *args, **kwargs): print(*args, **kwargs) traceback : try: 1/0 except Exception: print(&apos;-&apos; * 30) print(traceback.format_exc()) ------------------------------ Traceback (most recent call last): File &quot;&lt;ipython-input-40-507b353d716b&gt;&quot;, line 2, in &lt;module&gt; 1/0 ZeroDivisionError: integer division or modulo by zero inspect : 好处是什么: orm 属性拦截123456789101112131415161718192021222324252627282930313233class Merge(object): &quot;&quot;获取django多个结果&quot;&quot; def __init__(self, query_set): self.query_set = query_set def __getattr__(self, name): return sum(getattr(q, name) for q in self.query_set)class ObjectDict(dict): &quot;&quot;&quot;字典当做对象使用&quot;&quot;&quot; def __getattr__(self, name): try: return self[name] except KeyError: raise AttributeError(name) def __setattr__(self, name, value): self[name] = valueclass PermWrapper(object): def __init__(self, user): self.user = user self.superuser = user.is_superuser self.perms = set([&quot;101&quot;, &quot;102&quot;]) def __getitem__(self, module_name): if hasattr(self, module_name): return getattr(self, module_name) return module_name in self.permsperm = PermWrapper()perm[&quot;superuser&quot;]perm[&quot;101&quot;] 装饰器 闭包 好处: 解耦 面向切面编程(aop) 用处 : 日志记录, 权限控制, 事务处理等 分类: 不带参数, 带参数, 类装饰器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546def decor(func): @wraps(func) def wrapper(*args, **kwargs): # before hook return func(*args, **kwargs) # after hookdef super_required(view_func): &quot;&quot;&quot;超级用户控制&quot;&quot;&quot; @wraps(view_func) def decorator(request, *args, **kwargs): if request.user.is_authenticated() and request.user.is_superuser: return view_func(request, *args, **kwargs) else: return HttpReesponseRedirect(&quot;/login/?next=&#123;0&#125;&quot;.format(request.path)) return decorator## 使用 torndb 记录执行 SQL 语句和执行时间 : 属性拦截和装饰器结合def log(level): &quot;&quot;&quot;记录日志&quot;&quot;&quot; assert level in (&quot;debug&quot;, &quot;info&quot;, &quot;warn&quot;, &quot;error&quot;) def decorator(func): @wraps(func) def wrapper(*args, **kwargs): start = time.time() result = func(*args, **kwargs) write = getattr(logger, level) write(&quot;sql: %s\nrun time: %s seconds&quot;, args, time.time() - start) return result return wrapper return decoratorclass Connection(object): def __init__(self): self.conn = torndb.Connection(HOST, DB, USER, PASSWORED) def __getattr__(self, name): func = getattr(self.conn, name) return log(&quot;info&quot;)(func)conn = Connection()conn.get(&quot;select * from users whrer id=3&quot;)conn.execute(&quot;delete *from users&quot;)&gt; sql: select * from users whrer id=3&gt; run time: 0.5111111 seconds 描述符和属性作用: 覆盖默认属性查找方式a.x –&gt; a.dict[‘x’] –&gt; type(a).dict[“x”] –&gt; baseclass(type(a)).dict[“x”] get, set, delete数据描述符: get, set (描述符优先) class descriptor(object): def __init__(self, value): self.value = value def __get__(self, obj, type=None): return self.value def __set__(self, obj, value): pass class Test(object): def __init__(self): self.age = 100 age = descriptor(200) t = Test() print t.age # 200 非数据描述符: get(dict 优先) class descriptor(object): def __init__(self, value): self.value = value def __get__(self, obj, type=None): print obj, type return self.value class Test(object): def __init__(self): self.age = 100 age = descriptor(200) t = Test() print(t.age) # 100 只支持 new style objects描述符有 __getattribute__ 调用, 只有在新式类中才有. properties, methods, statis methods, class methods, super classmethod 实现原理class ClassMethod(object): &quot;&quot;&quot; Emulate PyClassMethod_Type() in Objects/funcobject.c &quot;&quot;&quot; def __init__(self, f): self.f = f def __get__(self, obj, klass=None): if klass is NOne: klass = type(obj) def newfunc(*args): return self.f(klass, *args) return newfunc class class_property(object): &quot;&quot;&quot; Aproperty can decorator class or instance class. class Foo(object): @class_property def foo(cls): return 2 print Foo.foo # 42 print Foo().foo # 42 &quot;&quot;&quot; def __init__(self, func, name=Noen, doc=None): self.__name__ = name or func.__name__ self.__module__ = func.__module__ self.__doc__ = doc or func.__doc__ self.func = func def __get__(self, obj, type=None): value = self.func(type) return value class cached_property(object): &quot;&quot;&quot; A property that is only computed once per instance and then replaces itself with an ordinary attribute. Deleting the attribute resets the property. class Foo(object): @cached_property def foo(self): return 42*10 print(Foo().foo) # 420 &quot;&quot;&quot; def __init__(self, func): self.__doc__ = getattr(func, &apos;__doc__&apos;) self.func = func def __get__(self, obj, cls): if obj is None: return slef value = obj.__dict__[self.func.__name__] = self.func(obj) return value class class_cached_property(object): def __init__(self, func): self.__doc__ = getattr(func, &quot;__doc__&quot;) self.func = func def __get__(self, obj, cls): if cls is None: return self value = self.func(cls) setattr(cls, slef.func.__name__, vlaue) return value 生成器1234567891011def task(): begin = yield print(&quot;begin&quot;, begin) yield for x in range(begin): yield xt = task()t.send(None)t.send(2) # (&quot;begin&quot;, 2)print([x for x in t]) # [1, 2] 模拟线程并发1234567891011121314151617181920212223242526272829303132def thread1(): for x in range(4): yield xdef thread2(): for x in range(4,8): yield xthreads=[]threads.append(thread1())threads.append(thread2())def run(threads): #写这个函数，模拟线程并发 for t in threads: try: print t.next() except StopIteration: pass else: threads.append(t)run(threads)结果：04152637 123456789101112131415161718192021class Task(object): def __init__(self): self._queue = collections.deque() self.work = 0 def add(self, gen): self._queue.append(gen) self.work += 1 def finish(self): return self.work &lt;= 0 def run(self): while not self.finish(): try: gen = self._queue.popleft() gen.send(None) except StopIteration: self.work -= 1 else: self._queue.append(gen)t=Task()t.add(thread1()) t.add(thread2())t.run() 上下文管理器123456789101112131415161718192021222324import osclass cd(object): def __init__(self, path): self.src = os.getcwd() self.dest = path def __enter__(self): os.chdir(self.dest) def __exit__(self, exc_type, exc_val, exc_tb): os.chdir(self.src)from contextlib import contextmanager@contextmanagerdef cd(path): cwd = os.getcwd() try: os.chdir(path) yield finally: os.chdir(cwd) 元类type1234567891011121314151617181920In [98]: class A(object): ...: pass ...: In [99]: type(A)Out[99]: typeIn [100]: B = type(&quot;B&quot;, (object, ), &#123;&quot;name&quot;: &quot;BNBB&quot;&#125;)In [101]: BOut[101]: __main__.BIn [102]: AOut[102]: __main__.AIn [103]: type(B)Out[103]: typeIn [104]: B.nameOut[104]: &apos;BNBB&apos; new &amp;&amp; init__new__(cls, classname, bases, dict_attr) : new 的 cls 参数是元类自己__init__(cls, classname, bases, dict_attr) : init 的 cls 参数是元类创建的那个类. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# coding: utf-8import re_extract = &#123;&#125;_site = re.compile(r&quot;.*\.(?P&lt;site&gt;.+?)\.com&quot;)def parse(url): &quot;&quot;&quot; 解析视频真实地址 &quot;&quot;&quot; site = _site.search(url).group(&quot;site&quot;) parser = _extract[site] return = parser.parse(url)parse(&quot;http://www.letv.com/ptv/vplay/1111.html&quot;)class VideoMeta(type): def __init__(cls, classname, base, dict_attr): assert hasattr(cls, &quot;parse&quot;) assert hasattr(cls, &quot;NAME&quot;) _extract[dict_attr[&quot;NAME&quot;]] = cls() return type.__init__(cls, classname, bases, dict_attr)class Video(object): __metaclass__ = VideoMeta NAME = &quot;BASE&quot; def parse(self, url): raise NotImplementedErrorclass LeTV(Video): NAME = &quot;letv&quot; def parse(self, url): passclass UpperMeta(type): def __new__(cls, classname, bases, dict_attr): attr = &#123;k.upper() if not k.startswith(&quot;__&quot;) else k:v for k,v in dict_attr.items()&#125; return type.__new__(cls, classname, bases, attr)class Person(object): __metaclass__ = Uppercase name = &quot;lwy&quot; age = 24print(&quot;name&quot; in Person.__dict__)print(&quot;NAME&quot; in Person.__dict__) 垃圾回收 引用计数为主 优点: 简单, 实用 缺点: 吞吐量不高, 循环引用. 标记-清除 和 分代收集为辅. 1234567891011121314gc.set_debug(gc.DEBUG_STATS)a = []b = []a.append(b)b.append(a)del adel bprint(&quot;unreachable:&quot;, gc.collect())gc: collecting generation 2...gc: objects in each generation: 504 3398 0gc: done, 2 unreachable, 0 uncollectable, 0.0010s elapsed.(&apos;unreachable:&apos;, 2) 没有不可达对象, 靠引用计数就可以. 12345678910111213gc.set_debug(gc.DEBUG_STATS)a = []b = []a.append(b)b.append(a)del aprint(&quot;unreachable:&quot;, gc.collect())gc: collecting generation 2...gc: objects in each generation: 504 3398 0gc: done, 0.0010s elapsed.(&apos;unreachable:&apos;, 0) gc.enabld() gc.disable() gc.get_threshold() # (700, 10, 10) gc.collect([generation]) # 返回不可达对象数量. gc.is_tracked() 多线程, 多进程其他]]></content>
  </entry>
</search>
